<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>pedestrian on Jian&#39;s Blog</title>
    <link>https://jianye0428.github.io/tags/pedestrian/</link>
    <description>Recent content in pedestrian on Jian&#39;s Blog</description>
    <image>
      <url>https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png</url>
      <link>https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sun, 12 Jun 2022 09:44:14 +0800</lastBuildDate><atom:link href="https://jianye0428.github.io/tags/pedestrian/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Social_NCE: Contrastive Learning of Socially-aware Motion Representation</title>
      <link>https://jianye0428.github.io/posts/tech/2022-06-12_social_nce/</link>
      <pubDate>Sun, 12 Jun 2022 09:44:14 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/tech/2022-06-12_social_nce/</guid>
      <description>paper link: https://arxiv.org/abs/2012.11717
论文解读参考:
[1] https://zhuanlan.zhihu.com/p/434650863
[2] https://www.gushiciku.cn/pl/amod
Issue to solve and its Solution Due to the ill-distributed training Data, it&amp;rsquo;s difficult to capture the notion of the &amp;ldquo;negative&amp;rdquo; examples like collision.
Solution:
Modeling the negative samples through self-supervision:
 a social contrastive loss: regularizes the extracted motion representation by discerning the ground-truth positive events from synthetic negative ones; Construct negative samples based on prior knowledge of rare but dangerous circumstances.</description>
    </item>
    
    <item>
      <title>Social_STGCNN: A Social Spatio-Temporal Graph Convolutional Neural Network for Human Trajectory Prediction</title>
      <link>https://jianye0428.github.io/posts/tech/2022-06-08_social_stgcnn/</link>
      <pubDate>Wed, 08 Jun 2022 16:36:37 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/tech/2022-06-08_social_stgcnn/</guid>
      <description>paper link: https://arxiv.org/abs/2002.11927?from=leiphonecolumn_paperreview0323
网络结构 特点: Social STGCNN不同于其他方法只是聚合各种学习的行人状态，而是对行人交互做图建模。其中提出一种kernel function把行人社交交互嵌入一个adjacency matrix。
 代码显示，图建模一般在数据前处理完成。
 Model Description 两部分：时空图卷积神经网络ST-GCNN、时间外推器TXP-CNN。
ST-GCNN对行人轨迹的图表示进行时空卷积操作以提取特征。这些特征是观察到的行人轨迹历史的紧凑表示。 TXP-CNN将这些特征作为输入，并预测所有行人作为一个整体的未来轨迹。我们使用时间外推器的名字是因为TXP-CNN期望通过卷积运算外推未来的轨迹。
给定T帧，构造表示 $G=(V,A)$ 的时空图. 然后，$G$ 通过时空图卷积神经网络(ST-GCNNs)转发，创建一个时空嵌入。 之后，TXP-CNNs 预测了未来的轨迹。 $P$ 是行人位置的维数，$N$ 是行人的数目，$T$ 是时间步长, $\hat{P}$是来自ST-GCNN的嵌入的维数.
(1) Graph Representation of Pedestrian Trajectories
我们首先构造一组空间图 $G_t$，表示每个时间步长 $t$ 在场景中行人的相对位置，$G_t = (V_t, E_t)$ 。 $V_t$是图 $G_t$ 的顶点集，观察到的位置 $(x^i_t，y^i_t)$ 是顶点 $v^i_t$ 的属性; $E_t$ 是边集，如果顶点 $v^i_t$ 和顶点 $v^j_t$ 相连 $e^{ij}_t = 1$ ，否则 $=0$。
为了建模两个节点之间相互影响的强度，我们附加了一个值$a^{ij}_t$, 它是由每个$ e^{ij}_t$ 的某种核函数计算得到。$a^{ij}_t$ 被组织为带权邻接矩阵$A_t$。
$a^{ij}_{sim,t}$是要在邻接矩阵$A_t$中使用的内核函数。 定义为:
$$\begin{equation} a^{ij}_{sim,t}= \left { \begin{aligned} 1/||v^i_t - v^j_t||_2 , ||v^i_t - v^j_t||_1\neq0 \ 0, Otherwise \end{aligned} \right.</description>
    </item>
    
  </channel>
</rss>
