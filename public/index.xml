<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Jian&#39;s Blog</title>
    <link>https://jianye0428.github.io/</link>
    <description>Recent content on Jian&#39;s Blog</description>
    <image>
      <url>https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png</url>
      <link>https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sun, 12 Jun 2022 09:44:14 +0800</lastBuildDate><atom:link href="https://jianye0428.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Social_NCE: Contrastive Learning of Socially-aware Motion Representation</title>
      <link>https://jianye0428.github.io/posts/tech/2022-06-12_social_nce/</link>
      <pubDate>Sun, 12 Jun 2022 09:44:14 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/tech/2022-06-12_social_nce/</guid>
      <description>paper link: https://arxiv.org/abs/2012.11717
论文解读参考:
[1] https://zhuanlan.zhihu.com/p/434650863
[2] https://www.gushiciku.cn/pl/amod
Issue to solve and its Solution Due to the ill-distributed training Data, it&amp;rsquo;s difficult to capture the notion of the &amp;ldquo;negative&amp;rdquo; examples like collision.
Solution:
Modeling the negative samples through self-supervision:
 a social contrastive loss: regularizes the extracted motion representation by discerning the ground-truth positive events from synthetic negative ones; Construct negative samples based on prior knowledge of rare but dangerous circumstances.</description>
    </item>
    
    <item>
      <title>Pytorch Notes</title>
      <link>https://jianye0428.github.io/posts/notes/2022-06-09_pytorch/</link>
      <pubDate>Thu, 09 Jun 2022 19:14:27 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/notes/2022-06-09_pytorch/</guid>
      <description>1. torch.einsum() torch.einsum(equation, *operands)-&amp;gt;Tensor:爱因斯坦求和 ref1: 算子部署: https://blog.csdn.net/HW140701/article/details/120654252 ref2: 例子: https://zhuanlan.zhihu.com/p/361209187
三条基本规则:
 规则一: equation 箭头左边，在不同输入之间重复出现的索引表示，把输入张量沿着该维度做乘法操作，比如还是以上面矩阵乘法为例， &amp;ldquo;ik,kj-&amp;gt;ij&amp;rdquo;，k 在输入中重复出现，所以就是把 a 和 b 沿着 k 这个维度作相乘操作； 规则二: 只出现在 equation 箭头左边的索引，表示中间计算结果需要在这个维度上求和，也就是上面提到的求和索引； 规则三: equation 箭头右边的索引顺序可以是任意的，比如上面的 &amp;ldquo;ik,kj-&amp;gt;ij&amp;rdquo; 如果写成 &amp;ldquo;ik,kj-&amp;gt;ji&amp;rdquo;，那么就是返回输出结果的转置，用户只需要定义好索引的顺序，转置操作会在 einsum 内部完成  特殊规则:
 equation 可以不写包括箭头在内的右边部分，那么在这种情况下，输出张量的维度会根据默认规则推导。就是把输入中只出现一次的索引取出来，然后按字母表顺序排列，比如上面的矩阵乘法 &amp;ldquo;ik,kj-&amp;gt;ij&amp;rdquo; 也可以简化为 &amp;ldquo;ik,kj&amp;rdquo;，根据默认规则，输出就是 &amp;ldquo;ij&amp;rdquo; 与原来一样； equation 中支持 &amp;ldquo;&amp;hellip;&amp;rdquo; 省略号，用于表示用户并不关心的索引。比如只对一个高维张量的最后两维做转置可以这么写： 1 2 3  a = torch.randn(2,3,5,7,9) # i = 7, j = 9 b = torch.einsum(&amp;#39;...ij-&amp;gt;...ji&amp;#39;, [a])     2.</description>
    </item>
    
    <item>
      <title>Social_STGCNN: A Social Spatio-Temporal Graph Convolutional Neural Network for Human Trajectory Prediction</title>
      <link>https://jianye0428.github.io/posts/tech/2022-06-08_social_stgcnn/</link>
      <pubDate>Wed, 08 Jun 2022 16:36:37 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/tech/2022-06-08_social_stgcnn/</guid>
      <description>paper link: https://arxiv.org/abs/2002.11927?from=leiphonecolumn_paperreview0323
网络结构 特点: Social STGCNN不同于其他方法只是聚合各种学习的行人状态，而是对行人交互做图建模。其中提出一种kernel function把行人社交交互嵌入一个adjacency matrix。
 代码显示，图建模一般在数据前处理完成。
 Model Description 两部分：时空图卷积神经网络ST-GCNN、时间外推器TXP-CNN。
ST-GCNN对行人轨迹的图表示进行时空卷积操作以提取特征。这些特征是观察到的行人轨迹历史的紧凑表示。 TXP-CNN将这些特征作为输入，并预测所有行人作为一个整体的未来轨迹。我们使用时间外推器的名字是因为TXP-CNN期望通过卷积运算外推未来的轨迹。
给定T帧，构造表示 $G=(V,A)$ 的时空图. 然后，$G$ 通过时空图卷积神经网络(ST-GCNNs)转发，创建一个时空嵌入。 之后，TXP-CNNs 预测了未来的轨迹。 $P$ 是行人位置的维数，$N$ 是行人的数目，$T$ 是时间步长, $\hat{P}$是来自ST-GCNN的嵌入的维数.
(1) Graph Representation of Pedestrian Trajectories
我们首先构造一组空间图 $G_t$，表示每个时间步长 $t$ 在场景中行人的相对位置，$G_t = (V_t, E_t)$ 。 $V_t$是图 $G_t$ 的顶点集，观察到的位置 $(x^i_t，y^i_t)$ 是顶点 $v^i_t$ 的属性; $E_t$ 是边集，如果顶点 $v^i_t$ 和顶点 $v^j_t$ 相连 $e^{ij}_t = 1$ ，否则 $=0$。
为了建模两个节点之间相互影响的强度，我们附加了一个值$a^{ij}_t$, 它是由每个$ e^{ij}_t$ 的某种核函数计算得到。$a^{ij}_t$ 被组织为带权邻接矩阵$A_t$。
$a^{ij}_{sim,t}$是要在邻接矩阵$A_t$中使用的内核函数。 定义为:
$$\begin{equation} a^{ij}_{sim,t}= \left { \begin{aligned} 1/||v^i_t - v^j_t||_2 , ||v^i_t - v^j_t||_1\neq0 \ 0, Otherwise \end{aligned} \right.</description>
    </item>
    
    <item>
      <title>详解最大似然估计(MLE)、最大后验概率估计(MAP)，以及贝叶斯公式的理解</title>
      <link>https://jianye0428.github.io/posts/tech/2022-05-30_mle/</link>
      <pubDate>Mon, 30 May 2022 16:38:56 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/tech/2022-05-30_mle/</guid>
      <description>最大似然估计（Maximum likelihood estimation, 简称MLE）和最大后验概率估计（Maximum a posteriori estimation, 简称MAP）是很常用的两种参数估计方法，如果不理解这两种方法的思路，很容易弄混它们。下文将详细说明MLE和MAP的思路与区别。
但别急，我们先从概率和统计的区别讲起。
概率和统计是一个东西吗？ 概率(probabilty)和统计(statistics)看似两个相近的概念，其实研究的问题刚好相反。
概率研究的问题是，已知一个模型和参数，怎么去预测这个模型产生的结果的特性(例如均值，方差，协方差等等)。 举个例子，我想研究怎么养猪(模型是猪)，我选好了想养的品种、喂养方式、猪棚的设计等等(选择参数)，我想知道我养出来的猪大概能有多肥，肉质怎么样(预测结果)。
统计研究的问题则相反。统计是，有一堆数据，要利用这堆数据去预测模型和参数。仍以猪为例。现在我买到了一堆肉，通过观察和判断，我确定这是猪肉(这就确定了模型。在实际研究中，也是通过观察数据推测模型是／像高斯分布的、指数分布的、拉普拉斯分布的等等)，然后，可以进一步研究，判定这猪的品种、这是圈养猪还是跑山猪还是网易猪，等等(推测模型参数)。
一句话总结：概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。
显然，本文解释的MLE和MAP都是统计领域的问题。它们都是用来推测参数的方法。为什么会存在着两种不同方法呢？ 这需要理解贝叶斯思想。我们来看看贝叶斯公式。
贝叶斯公式到底在说什么？ 学习机器学习和模式识别的人一定都听过贝叶斯公式(Bayes’ Theorem)： 式[1] $P(A|B)=\frac{P(B|A)P(A)}{P(B)}$
贝叶斯公式看起来很简单，无非是倒了倒条件概率和联合概率的公式。
把B展开，可以写成: 式[2] $P(A|B)=\frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|\sim A)P(\sim A)}$
这个式子就很有意思了。
想想这个情况。一辆汽车(或者电瓶车)的警报响了，你通常是什么反应？有小偷？撞车了？ 不。。 你通常什么反应都没有。因为汽车警报响一响实在是太正常了！每天都要发生好多次。本来，汽车警报设置的功能是，出现了异常情况，需要人关注。然而，由于虚警实在是太多，人们渐渐不相信警报的功能了。
贝叶斯公式就是在描述，你有多大把握能相信一件证据？（how much you can trust the evidence）
我们假设响警报的目的就是想说汽车被砸了。把$A$计作“汽车被砸了”，$B$计作“警报响了”，带进贝叶斯公式里看。我们想求等式左边发生$A∣B$的概率，这是在说警报响了，汽车也确实被砸了。汽车被砸**引起(trigger)**警报响，即B∣A。但是，也有可能是汽车被小孩子皮球踢了一下、被行人碰了一下等其他原因(统统计作$\sim A$)，其他原因引起汽车警报响了，即 $B|\sim A$。那么，现在突然听见警报响了，这时汽车已经被砸了的概率是多少呢(这即是说，警报响这个证据有了，多大把握能相信它确实是在报警说汽车被砸了)想一想，应当这样来计算。用警报响起、汽车也被砸了这事件的数量，除以响警报事件的数量(这即[式1])。进一步展开，即警报响起、汽车也被砸了的事件的数量，除以警报响起、汽车被砸了的事件数量加上警报响起、汽车没被砸的事件数量(这即[式2])。
再思考[式2]。想让$P(A∣B)=1$，即警报响了，汽车一定被砸了，该怎么做呢？让$P(B|\sim A)P(\sim A) = 0$即 可 。很容易想清楚，假若让$P(\sim A)=0$,即杜绝了汽车被球踢、被行人碰到等等其他所有情况，那自然，警报响了，只剩下一种可能——汽车被砸了。这即是提高了响警报这个证据的说服力。
**从这个角度总结贝叶斯公式：做判断的时候，要考虑所有的因素。**老板骂你，不一定是你把什么工作搞砸了，可能只是他今天出门前和太太吵了一架。
再思考[式2]。观察【式2】右边的分子，$P(B∣A)$为汽车被砸后响警报的概率。姑且认为这是1吧。但是，若$P(A)$很小，即汽车被砸的概率本身就很小，则$P(B∣A)P(A)$仍然很小，即【式2】右边分子仍然很小，$P(A|B)$还是大不起来。 这里，$​P(A)$ 即是常说的先验概率，如果A的先验概率很小，就算$P(B∣A)$较大，可能A的后验概率$P(A∣B)$还是不会大(假设$P(B∣\sim A)P(\sim A)$不变的情况下)。
从这个角度思考贝叶斯公式：一个本来就难以发生的事情，就算出现某个证据和他强烈相关，也要谨慎。证据很可能来自别的虽然不是很相关，但发生概率较高的事情。
似然函数 似然(likelihood)这个词其实和概率(probability)是差不多的意思，Colins字典这么解释:The likelihood of something happening is how likely it is to happen.</description>
    </item>
    
    <item>
      <title>Machine Learning Algo</title>
      <link>https://jianye0428.github.io/posts/notes/2022-05-28_ml/</link>
      <pubDate>Sat, 28 May 2022 09:11:55 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/notes/2022-05-28_ml/</guid>
      <description>用pickle保存和加载模型  保存模型 1 2 3 4 5 6 7  import pickle from sklearn.svm import SVC model_dir = &amp;#39;./model.pkl&amp;#39; model = SVC() with open(model_dir, &amp;#39;wb&amp;#39;) as f: pickle.dump(model, f) f.close() # 注意:保存完模型之后要关闭文件    加载模型 1 2 3 4 5  import pickle model_dir = &amp;#39;./model.pkl&amp;#39; with open(model_dir, &amp;#39;rb&amp;#39;) as f: model = pickel.load(f) print(mode.predict(x))     逻辑回归 Logistic Regression  LR Implementation code snippets 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72  from sklearn.</description>
    </item>
    
    <item>
      <title>Numpy Notes</title>
      <link>https://jianye0428.github.io/posts/notes/2022-05-24_numpy/</link>
      <pubDate>Tue, 24 May 2022 20:52:49 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/notes/2022-05-24_numpy/</guid>
      <description>numpy function   np.stack();np.vstack();np.hstack();np.concatenate() 区别
  np.concatenate()函数根据指定的维度，对一个元组、列表中的list或者ndarray进行连接
1 2 3  # np.concatenate() numpy.concatenate((a1, a2, ...), axis=0)#在0维进行拼接 numpy.concatenate((a1, a2, ...), axis=1)#在1维进行拼接     np.stack()函数的原型是numpy.stack(arrays, axis=0)，即将一堆数组的数据按照指定的维度进行堆叠。
1 2 3  # np.stack() numpy.stack([a1, a2], axis=0)#在0维进行拼接 numpy.stack([a1, a2], axis=1)#在1维进行拼接    注意:进行stack的两个数组必须有相同的形状，同时，输出的结果的维度是比输入的数组都要多一维。
   np.vstack()的函数原型：vstack(tup) ，参数tup可以是元组，列表，或者numpy数组，返回结果为numpy的数组。它是垂直（按照行顺序）的把数组给堆叠起来。
  np.hstack()的函数原型：hstack(tup) ，参数tup可以是元组，列表，或者numpy数组，返回结果为numpy的数组。它其实就是水平(按列顺序)把数组给堆叠起来，与vstack()函数正好相反。
   ref: https://cloud.tencent.com/developer/article/1378491
    </description>
    </item>
    
    <item>
      <title>Python Notes</title>
      <link>https://jianye0428.github.io/posts/notes/2022-05-23_python/</link>
      <pubDate>Mon, 23 May 2022 08:51:45 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/notes/2022-05-23_python/</guid>
      <description>python文件相关 os.path模块   os.path.exists(): 判断当前目录以及文件是否存在 os.path.mkdir(): 若目录或文件不存在，则创建
1 2 3 4 5 6 7 8 9  import os # 目录 dirs = &amp;#39;/Users/joseph/work/python/&amp;#39; if not os.path.exists(dirs): os.makedirs(dirs) # 文件 filename = &amp;#39;/Users/joseph/work/python/poem.txt&amp;#39; if not os.path.exists(filename): os.system(r&amp;#34;touch {}&amp;#34;.format(path))#调用系统命令行来创建文件     os.listdir()： 用于返回指定的文件夹包含的文件或文件夹的名字的列表
1 2 3 4 5 6 7 8  # 打开文件 path = &amp;#34;/var/www/html/&amp;#34; # 如果目录名字为中文 需要转码处理 path = unicode(path,&amp;#39;utf-8&amp;#39;) dirs = os.listdir(path) # 输出所有文件和文件夹 for file in dirs: print(file)     os.</description>
    </item>
    
    <item>
      <title>Pandas Notes</title>
      <link>https://jianye0428.github.io/posts/notes/2022-05-23_pandas/</link>
      <pubDate>Mon, 23 May 2022 08:51:34 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/notes/2022-05-23_pandas/</guid>
      <description>pandas notes Input/Output   pd.read_csv(filepath): 读取csv文件 ref: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html?highlight=read_csv
  pd.read_pickle():读取pickle数据
1 2  import pandas pandas.read_pickle(filepath_or_buffer, compression=&amp;#39;infer&amp;#39;, storage_options=None)   ref: https://pandas.pydata.org/docs/reference/api/pandas.read_pickle.html Parameters:
 filepath_or_buffer: 文件名或者文件路径 字符串、路径对象(实现 os.PathLike[str] )或 file-like 对象实现二进制 readlines() 函数。 compression: str or dict, default ‘infer’ 用于on-disk 数据的即时解压缩。如果 ‘infer’ 和 ‘filepath_or_buffer’ 是 path-like，则从以下扩展名检测压缩：“.gz”、“.bz2”、“.zip”、“.xz”或“.zst”(否则不压缩)。如果使用‘zip’，ZIP 文件必须只包含一个要读入的数据文件。设置为None 不解压缩。也可以是键 &amp;lsquo;method&amp;rsquo; 设置为 {&#39;zip&#39; , &#39;gzip&#39; , &#39;bz2&#39; , &#39;zstd&#39; } 之一的字典，其他键值对分别转发到 zipfile.ZipFile , gzip.GzipFile , bz2.BZ2File 或 zstandard.ZstdDecompressor 。例如，可以使用自定义压缩字典为 Zstandard 解压缩传递以下内容：compression={&amp;lsquo;method&amp;rsquo;: &amp;lsquo;zstd&amp;rsquo;, &amp;lsquo;dict_data&amp;rsquo;: my_compression_dict}。 storage_options: dict, optional 对特定存储连接有意义的额外选项，例如主机、端口、用户名、密码等。对于 HTTP(S) URL，键值对作为标头选项转发到 urllib。对于其他 URL(例如以 “s3://” 和 “gcs://” 开头)，键值对被转发到fsspec 。有关详细信息，请参阅fsspec和urllib。    General functions 通用函数 Series DataFrame DataFrame是一个【表格型】的数据结构，可以看做是【由Series组成的字典】（共用同一个索引）。DataFrame由按一定顺序排列的多列数据组成。设计初衷是将Series的使用场景从一维拓展到多维。</description>
    </item>
    
    <item>
      <title>Linux filesystem</title>
      <link>https://jianye0428.github.io/posts/tech/2022-05-13_linux_filesystem/</link>
      <pubDate>Fri, 13 May 2022 10:53:31 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/tech/2022-05-13_linux_filesystem/</guid>
      <description>Linux系统各系统文件夹下的区别 首先，usr 指 Unix System Resource，而不是User。
通常，
  /usr/bin下面的都是系统预装的可执行程序，会随着系统升级而改变。
  /usr/local/bin目录是给用户放置自己的可执行程序的地方，推荐放在这里，不会被系统升级而覆盖同名文件。
  如果两个目录下有相同的可执行程序，谁优先执行受到PATH环境变量的影响，比如我的一台服务器的PATH变量为。
1  echo $PATH   这里/usr/local/bin优先于/usr/bin, 一般都是如此。
/lib是内核级的, /usr/lib是系统级的, /usr/local/lib是用户级的.
  / - 对你的电脑来说, 有且只有一个根目录。所有的东西都是从这里开始。举个例子: 当你在终端里输入&amp;quot;/home&amp;quot;，你其实是在告诉电脑，先从/(根目录)开始，再进入到home目录。
  /lib/ — 包含许多被/bin/和/sbin/中的程序使用的库文件。目录/usr/lib/中含有更多用于用户程序的库文件。/lib目录下放置的是/bin和/sbin目录下程序所需的库文件。/lib目录下的文件的名称遵循下面的格式：
  libc.so.* ld* 仅仅被/usr目录下的程序所使用的共享库不必放到/lib目录下。只有/bin和/sbin下的程序所需要的库有必要放到/lib目录下。实际上，libm.so.*类型的库文件如果被是/bin和/sbin所需要的，也可以放到/usr/lib下。     /bin/ — 用来贮存用户命令。目录 /usr/bin 也被用来贮存用户命令。
  /sbin/ — 许多系统命令(例如 shutdown)的贮存位置。目录/usr/sbin中也包括了许多系统命令。
  /root/ — 根用户(超级用户)的主目录。
  /mnt/ — 该目录中通常包括系统引导后被挂载的文件系统的挂载点。譬如，默认的光盘挂载点是/mnt/cdrom/.
  /boot/ — 包括内核和其它系统启动期间使用的文件。</description>
    </item>
    
    <item>
      <title>Build VIM 8.2 from source</title>
      <link>https://jianye0428.github.io/posts/tech/2022-05-11_vim_installation/</link>
      <pubDate>Wed, 11 May 2022 10:00:13 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/tech/2022-05-11_vim_installation/</guid>
      <description>VIM 8.2 安装 1. Install Python3.9 from source   Update the packages list and install the packages necessary to build Python
1  sudo apt update &amp;amp;&amp;amp; sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev libsqlite3-dev wget libbz2-dev     Download the latest release’s source code from the Python download page using wget
1  wegt https://www.python.org/ftp/python/3.9.0/Python-3.9.1.tgz     Switch to the Python source directory and execute the configure script which performs a number of checks to make sure all of the dependencies on your system are present</description>
    </item>
    
    <item>
      <title>Git Command Notes</title>
      <link>https://jianye0428.github.io/posts/tech/2022-05-11_git_command/</link>
      <pubDate>Wed, 11 May 2022 09:59:56 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/tech/2022-05-11_git_command/</guid>
      <description>git command record as my cheatsheet 1. git rebase ref: https://git-scm.com/docs/git-rebase
  用法一:git rebase &amp;lt;branch-name&amp;gt; 将topic分支的base由E改为master
1 2 3  A---B---C topic / D---E---F---G master   运行:
1 2  git rebase master git rebase master topic   结果:
1 2 3  A&amp;#39;--B&amp;#39;--C&amp;#39; topic / D---E---F---G master    if upstream branch already has a change like below:
 1 2 3  A---B---C topic / D---E---A&amp;#39;---F master   then run the command git rebase master, you will get following result:</description>
    </item>
    
    <item>
      <title>Ubuntu 22.04 | zsh 以及 oh-my-zsh的安装和配置</title>
      <link>https://jianye0428.github.io/posts/tech/2022-05-09_zsh_installation/</link>
      <pubDate>Mon, 09 May 2022 11:54:06 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/tech/2022-05-09_zsh_installation/</guid>
      <description>zsh说明   zsh是一个Linux下强大的shell, 由于大多数Linux产品安装以及默认使用bash shell, 但是丝毫不影响极客们对zsh的热衷, 几乎每一款Linux产品都包含有zsh，通常可以用apt-get、urpmi或yum等包管理器进行安装.
  zsh是bash的增强版，其实zsh和bash是两个不同的概念，zsh更加强大。
  通常zsh配置起来非常麻烦，且相当的复杂，所以oh-my-zsh是为了简化zsh的配置而开发的，因此oh-my-zsh算是zsh的配置.
  准备   查看当前系统用shell版本
1  echo $SHELL     查看系统自带哪些shell
1  cat /etc/shells     安装zsh  通过命令行安装zsh 1  sudo apt install zsh     zsh配置   将zsh设置为默认的shell
1  chsh -s /bin/zsh     然后重启电脑
1  reboot     安装oh-my-zsh及其个性化配置 安装oh-my-zsh  执行以下命令安装oh-my-zsh 1  sh -c &amp;#34;$(wget https://raw.</description>
    </item>
    
    <item>
      <title>PPO -- Proximal Policy Optimization</title>
      <link>https://jianye0428.github.io/posts/tech/2022-05-06_ppo/</link>
      <pubDate>Fri, 06 May 2022 13:16:25 +0200</pubDate>
      
      <guid>https://jianye0428.github.io/posts/tech/2022-05-06_ppo/</guid>
      <description>PPO Architechture </description>
    </item>
    
    <item>
      <title>DQN -- Deep Q Network</title>
      <link>https://jianye0428.github.io/posts/tech/2022-05-05_dqn/</link>
      <pubDate>Thu, 05 May 2022 21:52:44 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/tech/2022-05-05_dqn/</guid>
      <description>[DQN]paper link: https://arxiv.org/pdf/1312.5602v1.pdf
DQN: Playing Atari with Deep Reinforcement Learning General Architecture Here is Network listed:
 play Atari games using RL and perform better than human CNN + Q Learning: CNN for frame-skiped images features extraction; and Q Learning for policy generation     Network Channel Kernel Size Stride Activation Output Size     Input NA NA NA NA 84x84x4   First Conv 16 8x8 4 Relu 20x20x6   Second Conv 32 4x4 2 Relu 9x9x32   Hidden NA NA NA Relu 256   Output NA NA NA None 4 to 18     在当时，普遍的做法是为每一个action学习一个函数，而不是一个网络结构直接输出所有q的value.</description>
    </item>
    
    
    
    <item>
      <title>TensorRT custom operator development -- ScatterElements</title>
      <link>https://jianye0428.github.io/posts/tech/2022-04-24_tensorrt_custom_operator/</link>
      <pubDate>Sun, 24 Apr 2022 19:34:50 +0800</pubDate>
      
      <guid>https://jianye0428.github.io/posts/tech/2022-04-24_tensorrt_custom_operator/</guid>
      <description>TensorRT Installation Custom Operator ScatterElements </description>
    </item>
    
  </channel>
</rss>
