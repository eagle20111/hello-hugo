[{"content":"https://blog.csdn.net/qq_41667348/category_11789612.html\nhttps://zhuanlan.zhihu.com/p/492988036 https://www.zhihu.com/column/c_1020971709242818560\nhttps://blog.csdn.net/qq_35503971/article/details/106337900\n简介 EM Planner是Apollo面向L4的实时运动规划算法，该算法首先通过顶层多车道策略，选择出一条参考路径，再根据这条参考线，在Frenet坐标系下，进行车道级的路径和速度规划，规划主要通过Dynamic Programming和基于样条的Quadratic Programming实现。EM Planner充分考虑了无人车安全性、舒适性、可扩展性的需求，通过考虑交通规则、障碍物决策、轨迹光滑性等要求，可适应高速公路、低速城区场景的规划需求。通过Apollo仿真和在环测试，EM Planner算法体现了高度的可靠性，和低耗时性。\n多车道EM Planner框架 整体框架 所有规划需要的信息在EM Planner的顶层汇集，然后参考线生成器会生成一些基于障碍物和交通规则的候选车道级参考线，这个过程主要是依赖于高精度地图和Routing模块给出的全局规划结果。以下是车道级的规划过程：\n首先会基于给定参考线生成Frenet坐标系，通过给定参考线将所有的自车信息和环境信息转换到参考线下的Frenet坐标系。 接下来所有的车道级信息将会传递给车道级最优求解器，该求解器会求解最优路径和最优速度。在求解最优路径时，周围环境信息将会被投影到Frenet坐标系（E-step），然后基于投影的信息生成一条光滑路径（M-step）。 同样的，在求解最优速度时，一旦生成了一条最优路径，障碍物就会被投影到ST图中（E-step），然后最优速度求解器会生成一条光滑的速度规划（M-step）。结合路径和速度规划结果，就生成了一条给定车道的光滑轨迹。 最后一步会将所有的车道级轨迹传递给参考线轨迹决策器，基于当前车辆状态、相关约束和每条轨迹的代价，轨迹决策器会决定一条最优的轨迹。 多车道策略 利用搜索算法【2】【3】结合代价估算形成变道策略是一种比较常见的处理变道问题的方法，但是这种方法存在计算量大、难以适用交规以及前后决策可能缺少连贯性等特点。Apollo的解决办法是将多车道策略划分为两种类型：无法通行的被动变道，和能够通行的主动变道。\n被动变道一般由道路阻挡造成的，通过全局规划模块重新生成全局路径解决； 主动变道是考虑动态障碍物而做出的决策。Apollo通过同步生成多条候选车道的方法解决主动变道问题，在Frenet坐标系下，投影障碍物、考虑交规后生成多条车道级的候选路径，最后传递到变道决策器中选择出一条最优的车道决策。 路径-速度迭代算法 在Frenet坐标下的轨迹规划实际上是带约束的3D最优求解问题。该问题一般有两种求解方法：直接3D最优化求解和路径-速度解耦求解。\n直接方法【4】【5】试图在SLT坐标系下使用轨迹采样或Lattice搜索,这些方法都受到搜索复杂度的限制，因此搜索结果是次优的。 而路径-速度解耦规划会分别求解路径和速度的最优解。速度的生成将会在生产的路径上进行【6】。虽然结果可能也不是最优的，但会在速度和路径分别求解时更加灵活。 EM Planner迭代地进行路径和速度最优求解，通过估计和来向、低速障碍物的交互，上一帧的速度规划将有助于下一帧的路径规划。然后将路径规划结果再交给速度最优求解器来推算出一个最优的速度结果。\n决策和交通规则约束 交通规则是硬约束，而与障碍物的交互是软约束。一些决策方法直接考虑的是数值上的最优解【7】，也有像【5】一样同时进行规划和决策。而Apollo EM Planner的决策是优先于规划的，决策模块将会为规划带来更明确的意图，减少最优求解的搜索空间。决策部分的第一步是将车辆的运动意图用一根粗略、灵活的轨迹来描述。这条轨迹也可以用来估计与障碍物之间的交互，并且当情景更加复杂时，这种基于轨迹的决策方法也是灵活的。第二步是基于决策生成的轨迹来构造一个凸空间，用来做基于样条光滑的轨迹生成，主要是通过二次规划来达到迭代生产路径、速度解的目的。\n车道级EM PLanner框架 整体框架 框架包括了一帧规划中的两个E-step和两个M-step，轨迹信息将会在前后两帧中传递，以下是整个车道级规划的流程：\n在第一个E-step中，障碍物会被投影到车道Frenet坐标系，障碍物包括了静态障碍物和动态障碍物。静态障碍物会直接从笛卡尔坐标系转换到Frenet坐标系，而动态的信息则以其运动轨迹来描述。通过上一帧的预测信息，和自车的运动信息，可以估算自车和动态障碍物在每个时间点的交互情况，轨迹重叠的部分会被映射到Frenet坐标系中。初次之外，在最优路径求解过程中，动态障碍物的出现会最终导致自车做出避让的决策。因此，出于安全的考虑，SL投影只考虑低速和来向障碍物，而对于高速的动态障碍物，EM Planner的平行变道策略会考虑这种情景。 在第二个E-step，所有的障碍物都会在ST中与生成的速度信息进行估计，如果对应的ST中重叠部分，那么对应区域将会在ST中进行重新生成。 在两次M-step过程中，通过Dynamic Programming和Quadratic Programming生成路径和速度规划。然而在进行投影的SL和ST坐标内求解时非凸的，因此，为了解决这个问题，首先使用Dynamic Programming获得一个粗略的解，同时这个解也能够提供诸如避让、减速、超车的决策。通过这个粗略的解，可以构建一个凸的通道，然后使用基于Quadratic Programming的样条最优求解。 接下来的部分将会详细介绍框架中的步骤。\nSL和ST投影（E-step） SL投影 SL投影是基于类似于【3】中的G2光滑参考线（曲率导数连续）。给定一个时刻，如果自车与预测的障碍物轨迹有重叠区域，那么这个重叠区域将会在SL坐标系被标注为与动态障碍物的估计交互区域。这个区域可以理解为自车和动态障碍物的包围盒的重叠区域。图4展示了这一种案例，红色代表动态障碍物的预测轨迹，用离散点来表示；蓝色表示自车的状态。\nST投影 ST投影用于帮助我们估计自车的速度规划。当生成了一条光滑的路径以后，与自车有交互的动态障碍物和静态障碍物都会被投影到路径上，同理，这种交互也定义为包围盒的重叠。如图5，这是一个ST图投影案例。\n红色区域表示在2s处距离自车40m远切入规划路径的动态障碍物ST信息，绿色表示在自车后的动态障碍物ST信息，M-step将会在剩下的区域找到可行光滑最优解。\nDP路径（M-step） M-step求解Frenet坐标系下的最优路径规划，实际上在一个非凸的区间（从左和从右避让是两个局部最优情景）就是找到一个最优的 $l=f(s)$ 方程。主要包括两步：基于Dynamic Programming的路径决策和基于样条的路径规划。\n基于Dynamic Programming的路径步骤提供一条粗略的路径信息，其可以带来可行通道和绕障决策，如图6所示，这一步包括Lattice采样、代价函数、Dynamic Programming搜索。\nLattice采样基于Frenet坐标系，多行的点在撒在自车前。如图7所示，行与行之间的点使用五次方多项式连接，而行与行之间的间隔取决于自车速度、道路结构、是否换道等等。出于安全考虑，路径总长可以达到200m或者覆盖8s的行驶长度。\n每段Lattice路径的代价通过光滑程度、障碍物避让、车道代价来评价：\n而光滑程度又通过以下方程来衡量，一阶导表示朝向偏差，二阶导表示曲率，三阶导表示曲率导数：\n障碍物的代价由以下方程给出，方程中的d由自车bounding box到障碍物bounding box的距离表示。\n车道代价由以下方程给出，主要是考虑在道路上与否以及与参考线之间的差异，一般是与车道中心线的差异：\n样条QP路径（M-step） 基于样条的路径可以理解为是Dynamic Programming更精细的版本。通过DP采样出的路径生成一条可通行通道，然后在通道中利用基于Quadratic Programming的样条曲线生产光滑路径。具体实例如图8所示，步骤流程可由图9所示：\nQP的目标函数为：\n其中 $ g(s) $ 为DP规划的路径，$ f(s) $ 的一阶导表示朝向、二阶导表示曲率、三阶导表示曲率的导数。该函数描述了避让障碍物和曲线光滑性之间的权衡。\nQP的约束包括边界约束和动力学可行性。这些约束都会施加在每个s处，通过限制l来将车辆限制在车道内。由于EM Planner使用的是自行车模型，因此这样对l的限制也是不够的。如图10所示，为了使得边界约束变凸并且线性，在自车的前后两端各增加了一个半圆。前轮到后轮中心的距离用 l f l_f lf​表示，车宽用w表示，因此车的左前角的横向位置可以用以下方程给出：\n通过线性化可以变为：\n同理，其余三个角的位置都可以被线性化，显然因为 $ \\theta $ 足够小，小于 $ pi/12 $，因此可以这样线性化。\n$ f(s) $ 的二阶导和三阶导与动力学可行性相关，除了边界条件以外，生成的路径还应该和自车的初始条件相匹配。因为所有的约束都是线性的，所以使用Quadratic Programming求解非常迅速。\n具体的光滑样条曲线和QP问题可以在附录中查阅。\nDP速度求解（M-step） M-step的速度规划是在ST图中求解最优速度规划，即求解出最优函数 S ( t ) S(t) S(t)。与求解最优路径相似，在ST图中求解最优速度规划也是非凸的最优化问题。同样也采用Dynamic Programming配合样条曲线Quadratic Programming来找到光滑速度规划。图12是速度求解的pipeline：\nDP速度求解包括代价函数、ST栅格图以及Dynamic Programming搜索。生成的结果包括分段线性的速度规划、可通行通道以及障碍物速度决策。如图11所示，该结果在QP中用来作为参考速度规划，通过该参考速度生成凸的区域。\n在栅格图中，使用有限差分法来估计速度、加速度和jerk：\n从DP生成的速度中选择出最优的一条的方法是最小化以下的代价函数：\n第一项是速度误差，g用来惩罚与 $ V_ref $ 的不同的误差。第二项、第三项用来描述曲线的光滑程度。最后一项用来描述障碍物代价，以到障碍物的距离来衡量。\nDP搜索空间也收到车辆动力学约束，并且也有单调性约束，因为不希望车辆倒退。一些对于动力学约束的必要简化也用来加速算法。\nQP速度求解（M-step） 因为分段线性的速度规划不能满足动力学的要求，所以需要使用Quadratic Programming来填补动力学空缺。图13是样条曲线QP速度求解的pipeline：\nQP速度求解包括三部分：代价函数、线性约束以及样条曲线QP求解器。 除了初始条件约束以外，主要有以下的边界约束：\n第一个约束是单调性约束；第二、第三、第四约束主要是交通规则和车辆动力学约束。通过约束、cost函数计算以后，spline QP speed会生成一条如图14中的光滑可行的速度规划。\n结合路径规划，EM Planner最终会生成一条光滑轨迹。\n解QP问题的说明 为了安全考虑，路径和速度大概在100个不同的位置或时间点，那么约束就有超过600个。对于速度、路径求解，分段五次多项式已经足够，因此样条曲线大概有3-5个多项式，大概就有30个参数。因此Quadratic Programming就变成了相对小的目标函数，和相对大的约束。QP能比较好的解决这个问题，并且使用了上一帧的解作为热启动，加速求解过程。实践中，QP问题解的平均时间3ms。\nDP和QP非凸问题的说明 在非凸问题上，DP和QP都有他们单独的限制。DP和QP的组合，能够很好吸收两者优点，并求得一个理性解。\nDP:DP的优劣受到撒点分辨率和时间分辨率的影响，通常在运行时间限制的情况下，一般只会得出一个粗糙解而非最优解，比如会从障碍物左侧绕开，但并不是按照最完美的路径绕开。 QP:QP需要在凸空间求解，因此必须借助DP的解来形成凸空间。随机的或者基于规则的决策，通常会给QP带来非凸的空间，因此解QP问题会失败或者陷入局部最优。 DP+QP:（1）通过DP寻求粗糙解；（2）DP解能够生成凸空间；（3）QP在DP解形成的凸空间内，很大可能能够获得全局最优解。 案例分析 图15展示了EM Planner在规划周期内，帧与帧之间完成最优轨迹规划的过程。\n假设自车以10m/s的速度行进，一动态障碍物沿着相反方向朝着我们以同样10m/s的速度驶来，EM Planner按以下步骤迭代生成速度和路径规划：\n历史规划（图15-a）：在动态障碍物出现之前，自车以恒定速度10m/s向前行驶。 路径规划迭代1（图15-b）：基于当前车速和动态障碍物的车速，两者将会在S=40m处相遇，因此，最好的方法是在S=40m处绕开障碍物。 速度规划迭代1（图15-c）：基于路径规划结果，即从右侧避开障碍物，自车将调整其速度规划，在避开障碍物之前减速到5m/s。 路径规划迭代2（图15-d）：由于产生了新的速度规划，自车将不再会与动态障碍物在S=40m处避开，而会在一个新的位置S=30m处避开障碍物。因此，路径规划结果也将会随速度规划改变而重新更新。 速度规划迭代2（图15-e）：由于路径规划已经更新，新的绕障位置在S=30m处，因此在S=40处减速也就没有必要了，新的速度规划使得自车可以在S=40m处加速而在S=30m处形成一个光滑的绕障。 经过迭代之后，最终车辆将在S=30m处减速绕障，并且绕障结束之后会加速，这样一个过程和人类驾驶员的表现很相似。 但值得注意的是，并不是每次规划都必须采取如上四步骤，根据场景不同可能会产生更多或更少的步骤。一般而言，场景越复杂，所需要的步骤就越多。\n总结 EM Planner是一种基于弱决策的算法，相比于强决策算法，EM Planner在复杂场景、多障碍物情况下表现更好。强决策依赖于提前制定出的决策行为，并且有难以理解和预测与障碍物交互的缺陷、难以满足大量障碍物阻挡生成基于规则的最佳轨迹的缺陷。 EM Planner通过将三维规划问题转化为两个二维规划问题，显著地降低了运算复杂度，因此会带来运行时间的压缩和整个系统的可交互性。\n","permalink":"https://jianye0428.github.io/en/posts/notes/planning/emplanner/","summary":"https://blog.csdn.net/qq_41667348/category_11789612.html https://zhuanlan.zhihu.com/p/492988036 https://www.zhihu.com/column/c_1020971709242818560 https://blog.csdn.net/qq_35503971/article/details/106337900 简介 EM Planner是Apollo面向L4的实时运动规划算法，该算法首先通过顶层多车道策略，选择出一条参考路径，再根据这条参考线，在","title":"EMPlanner"},{"content":"一、Lattice Planner简介 LatticePlanner算法属于一种局部轨迹规划器，输出轨迹将直接输入到控制器，由控制器完成对局部轨迹的跟踪控制。因此，Lattice Planner输出的轨迹是一条光滑无碰撞满足车辆运动学约束和速度约束的平稳安全的局部轨迹。Lattice Planner的输入端主要由三部分组成，感知及障碍物信息、参考线信息及定位信息。\n[pic]\n局部规划模块的输出是带有速度信息的一系列轨迹点组成的轨迹，其保证了车辆控制器在车辆跟踪控制过程中的平稳性和安全性。\n二、Lattice规划算法实现过程 Lattice规划算法是一种基于采样的运动规划算法，通过将车辆坐标系转换到参考线坐标系，也就是frenet坐标系下，然后在frenet坐标系下分别对frenet的d轴和s轴进行规划，形成frenet坐标系下的规划轨迹，然后将frenet坐标系下的轨迹合成到世界坐标系下还原为世界坐标系下的轨迹。算法实现过程大概可以分为以下几步：\n将车辆当前位姿信息转换到frenet坐标系下，获得车辆在frenet坐标系的初始状态；根据当前速度计算前瞻距离，获得前瞻点，获得车辆在前瞻点位置frenet坐标系下的目标状态。 对轨迹状态进行采样，分别是轨迹运行时间t，目标速度v，及到参考线的横向位移d，通过这三个规划参数可以获得采样状态。 构建横向位移和纵向位移的多项式规划函数s(t)，d(s)，获得横向位移和纵向位移的规划函数后，进行时间插值就可以获得参考线frenet坐标系下的轨迹点，最后将轨迹点从frenet坐标系转换到cartesian坐标系，就可以获得物理世界采样轨迹，由于横向和纵向都是通过高次多项式插值获得，以此cartesian坐标系下的轨迹也是光滑的。 采样轨迹的碰撞检测、曲率约束及最优轨迹打分。采样轨迹是一系列满足速度约束的光滑轨迹，但其还需要满足无碰撞和车辆运动学曲率约束的强制约束，及远离障碍物和靠近参考线等组成的代价约束。采样轨迹的打分就是为了获得一条最优的满足约束条件的无碰撞光滑轨迹。该轨迹也是lattice输出到controller用于车辆跟随的轨迹。 Frenet坐标系和Cartesian坐标系的相互转换\nFrenet坐标系是参考线上的坐标系，是一个动坐标系。Frenet坐标系的建立，以车辆位置到参考线的最近点R作为frenet坐标系的原点，以参考线切线方向作为T轴，垂直于T轴向外为N轴。如下图所示，是frenet坐标系和cartesian坐标系的相互转换关系，黑色虚线是车辆当前运行的轨迹方向，黑色实线是车辆运行的参考线。\n[pic]\n如上图所示，参考线（Reference line）是一条光滑的车道线，按上图所示将汽车的坐标点P（图中红色点）投影到参考线上，得到一个参考线上的投影点R（图中绿色点）。从参考线起点到投影点的路径长度就是汽车在Frenet坐标系下的纵向偏移量，用s表示。而投影点到汽车位置的距离 $l(s)$ 则是汽车在Frenet坐标系下的横向偏移量。因为参考线是足够光滑的，我们也可通过汽车的朝向、速度、加速度来计算出Frenet坐标系下，横向和纵向偏移量的一阶导和二阶导。这里将横向偏移量 $l(s)$ 设计成纵向偏移量s的函数。这是因为对于carlike模型的汽车而言，横向运动是由纵向运动诱发的。而\u0026lt;/font color=red\u0026gt;将坐标点转换到frenet坐标系的目的则是为了方便规划曲线的生成和车道线横向和纵向方向上的轨迹采样，从而获得覆盖整个车道的光滑采样轨迹。\nfrenet坐标系和cartesian坐标系的转换关系可以可以参考如下论文[https://link.zhihu.com/?target=https%3A//www.researchgate.net/profile/Moritz-Werling/publication/224156269_Optimal_Trajectory_Generation_for_Dynamic_Street_Scenarios_in_a_Frenet_Frame/links/54f749df0cf210398e9277af/Optimal-Trajectory-Generation-for-Dynamic-Street-Scenarios-in-a-Frenet-Frame.pdf]\n如下所示是两个坐标系之间的变换公式。 ref:https://blog.csdn.net/u013468614/article/details/108748016 cartesian坐标系到frenet坐标系的变换公式：\nfrenet坐标系到cartesian坐标系的变换公式：\n上式中，各变量的含义如下：\n如下图所示绿色线代表了参考线reference_line，红色和蓝色线代表经过横向偏移位移均匀变化之后形成的路线。\n三、Lattice Planner轨迹采样 Lattice规划器的轨迹采样，主要分为横向采样、纵向采样以及轨迹时间周期采样。\n横向轨迹的采样需要涵盖多种横向运动状态，需要根据车道宽度设置横向采样的采样区间，通过横向采样间隔，形成不同的横向采样偏移量。 纵向采样的采样区间可以通过前瞻点的位移长度s，作为基准采样长度，然后通过对轨迹速度ds进行采样。 时间周期采样，就是对轨迹的运行周期时间进行采样。而百度Apollo的轨迹采样，只对横向位移和纵向位移进行了采样，并设计了采样状态横向偏移量，-0.5，0.0和0.5，以及四个到达这些横向偏移量的纵向位移，分别为10，20，40，80来得到采样状态。所以Lattice规划器的轨迹采样主要是对轨迹横纵向状态进行采样，但采样方式可以根据环境情况进行调整。 四、Lattice Planner速度规划 有了前面的采样状态，现在需要做的是根据采样状态生成横向 $l(s)$ 和纵向 $s(t)$ 和规划函数，两种规划函数都是通过多项式进行拟合求解生成。主要使用了4次和5次多項式拟合，从而满足了车辆运行过程中的一阶导，二阶导连续，也就是速度和加速度连续，保证了轨迹的平滑性要求。\n对于纵向轨迹 $s(t)$ ，在停车和跟车状态，都是五次多项式，但对于巡航状态，由于我们不需要确定状态的S值，所以只有五个变量，因此用四次多项式就可以了。对于横向轨迹$l(s)$也使用了五次多项式拟合。\n这里规划器的采样方式没有使用Apollo中Lattice的横纵向采样方式，而是采用了上文中提到的采样方式，因此约束变量有：\n巡航模式下的纵向拟合函数的求解\n五、轨迹生成及轨迹评价函数 轨迹的生成成就是将frenet坐标系下的轨迹转换到cartesian坐标系中，前面我们知道了位姿点在frenet坐标系和cartesian坐标系的相互转换关系，因此现在我们需要做的就是对横纵向轨迹函数 $s(t)$ 和 $l(s(t))$ 进行轨迹的时间细分形成规划函数的横纵向轨迹规划点 $s(t_i)$ 和 $l(s(t_i))$，该规划点是在frenet坐标系中，因此需要进行frenet坐标系到cartesian坐标系的坐标转换，从而形成控制器可用的采样轨迹。\n获得采用轨迹之后，接着需要进行目标轨迹的曲率检查和碰撞检测，目的是为了使目标采样轨迹满足车辆的运动学控制要求和无碰撞要求，这样就形成了安全可靠的轨迹簇。这些轨迹簇都可以满足车辆的控制要求，但并不是最优的，因此需要从轨迹簇中选出一组最优的运行轨迹。这时就需要引入轨迹评价函数，用来对候选轨迹进行打分。\n轨迹评价函数主要为了使得目标轨迹尽量靠近静态参考线轨迹运行，同时，速度尽量不发生大突变，满足舒适性要求，且尽量远离障碍物。因此最后轨迹评价函数可以通过如下伪代码描述：\n$$traj_cost = k_lat * cost_lat + k_lon * cost_lon + k_obs * obs_cost;$$\n上式中， - k_lat : 表示纵向误差代价权重 - cost_lat： 表示纵向误差，综合考虑纵向速度误差，时间误差及加加速度的影响。 - k_lon : 表示横向误差代价权重 - cost_lon： 表示横向向误差，综合考虑了横向加速度误差及横向偏移误差的影响。 - k_obs : 表示障碍物代价权重 - obs_cost： 表示障碍物距离损失。 最后选择出代价值最好的一条轨迹输入到控制器，用于控制器的跟踪控制。\n","permalink":"https://jianye0428.github.io/en/posts/notes/planning/latticeplanner/","summary":"一、Lattice Planner简介 LatticePlanner算法属于一种局部轨迹规划器，输出轨迹将直接输入到控制器，由控制器完成对局部轨","title":"LatticePlanner"},{"content":"ref: [1]. https://blog.csdn.net/qq_41854911/article/details/119657617\nC++ 11 新特性总结 C++ 11是什么，C++ 11标准的由来 C++ 这门编程语言的历史可以追溯至 1979 年，当时的 Bjarne Stroustrup（C++ 之父，后续简称 Stroustrup）还在使用 Simula 语言进行开发工作。\nSimula 语言被认为是第一个面向对象的编程语言。Stroustrup 也非常赞赏 Simula 语言的这种特性，但由于实例开发中 Simula 语言的执行效率太低，所以此后不久，Stroustrup 开始从事“带类的C”编程语言的开发工作。\n注意在开发初期，并没有 C++ 这个称谓。所谓“带类的C”，顾名思义就是在 C 语言的基础上，为其加入面向对象的思想（扩增一些写好的类和对象）。初期的 C++ 除了具备 C 语言的所有功能外，还具有类、基本继承、内联函数、默认函数参数以及强类型检查等简单功能。\n不仅如此，Stroustrup 还在 CPre（C语言编译器）的基础上，专门为“带类的C”开发了一个编译器，称为 Cfront，它可以将带有类的 C 代码自动转换为普通 C 语言程序。值得一提的是在 1993 年，Cfront 因难以支持 C++ 异常机制被弃用。\n1983 年，“带类的C”正式被称为“C++”，其中“++”就取自 C 语言中的“++”运算符，这也从侧面表明了 Stroustrup 对于 C++ 这门编程语言的定位。 与此同时，C++还增添了很多功能，比如虚函数、函数重载、引用、const 关键字以及 // 注释符号等。\n在随后的几年时间里，C++ 得到了快速地发展。比如说， C++ 不断地被更新，类中增加了受保护成员（protected）和私有成员（private），并允许使用多继承等；Stroustrup 出版了 《带注释的C++参考手册》一书，其一度被当做 C++ 开发的重要参考；Borland 发布了 Turbo C ++编译器，该编译器包含有大量的第三方 C++ 库，极大便利了 C ++ 的开发，等等。\n直到 1998 年，C++ 标准委员会发布了第一版 C++ 标准，并将其命名为 C++98 标准。据不知名人士透露，《带注释的C++参考手册》这本书对 C++98 标准的制定产生了很大的影响。\n经过作者的不断迭代，一本书往往会先后发布很多个版本，其中每个新版本都是对前一个版本的修正和更新。C++ 编程语言的发展也是如此。截止到目前（2020年），C++的发展历经了以下 3 个个标准：\n2011 年，新的 C++ 11 标准诞生，用于取代 C++ 98 标准。此标准还有一个别名，为“C++ 0x”； 2014 年，C++ 14 标准发布，该标准库对 C++ 11 标准库做了更优的修改和更新； 2017 年底，C++ 17 标准正式颁布。 所谓标准，即明确 C++ 代码的编写规范，所有的 C++ 程序员都应遵守此标准。\n值得一提的是在 C++ 11 标准之前，C++ 标准委员会还在 2003 年对 C++ 98 标准做了一次修改（称为 C++ 03 标准），但由于其仅仅修复了一些 C++ 98 标准中存在的漏洞，并未修改核心语法，因此人们习惯将这次修订和 C++ 98 合称为 C++98/03 标准。\n以上 3 个标准中，相比对前一个版本的修改和更新程度，C++ 11 标准无疑是颠覆性的，该标准在 C++ 98 的基础上修正了约 600 个 C++ 语言中存在的缺陷，同时添加了约 140 个新特性，这些更新使得 C++ 语言焕然一新。读者可以这样理解 C++ 11 标准，它在 C++ 98/03 标准的基础上孕育出了全新的 C++ 编程语言，造就了 C++ 新的开始。\n那么，C++ 11 标准到底包含哪些新特性呢？别急，接下来会分篇给大家做详细地讲解。\nC++ auto类型推导完全攻略 在 C++11 之前的版本（C++98 和 C++ 03）中，定义变量或者声明变量之前都必须指明它的类型，比如 int、char 等；但是在一些比较灵活的语言中，比如 C#、JavaScript、PHP、Python 等，程序员在定义变量时可以不指明具体的类型，而是让编译器（或者解释器）自己去推导，这就让代码的编写更加方便。\nC++11 为了顺应这种趋势也开始支持自动类型推导了！C++11 使用 auto 关键字来支持自动类型推导。\nauto 类型推导的语法和规则\n在之前的 C++ 版本中，auto 关键字用来指明变量的存储类型，它和 static 关键字是相对的。auto 表示变量是自动存储的，这也是编译器的默认规则，所以写不写都一样，一般我们也不写，这使得 auto 关键字的存在变得非常鸡肋。\nC++11 赋予 auto 关键字新的含义，使用它来做自动类型推导。也就是说，使用了 auto 关键字以后，编译器会在编译期间自动推导出变量的类型，这样我们就不用手动指明变量的数据类型了。\nauto 关键字基本的使用语法如下：\n1 auto name = value; name 是变量的名字，value 是变量的初始值。\n注意：auto 仅仅是一个占位符，在编译器期间它会被真正的类型所替代。或者说，C++ 中的变量必须是有明确类型的，只是这个类型是由编译器自己推导出来的\nauto 类型推导的简单例子：\n1 2 3 4 auto n = 10; auto f = 12.8; auto p = \u0026amp;n; auto url = “http://c.biancheng.net/cplus/”; 下面我们来解释一下：\n第 1 行中，10 是一个整数，默认是 int 类型，所以推导出变量 n 的类型是 int。 第 2 行中，12.8 是一个小数，默认是 double 类型，所以推导出变量 f 的类型是 double。 第 3 行中，\u0026amp;n 的结果是一个 int* 类型的指针，所以推导出变量 p 的类型是 int*。 第 4 行中，由双引号\u0026quot;\u0026ldquo;包围起来的字符串是 const char* 类型，所以推导出变量 url 的类型是 const char*，也即一个常量指针。 我们也可以连续定义多个变量：\n1 2 int n = 20; auto *p = \u0026amp;n, m = 99; 先看前面的第一个子表达式，\u0026amp;n 的类型是 int*，编译器会根据 auto *p 推导出 auto 为 int。后面的 m 变量自然也为 int 类型，所以把 99 赋值给它也是正确的。\n这里我们要注意，推导的时候不能有二义性。在本例中，编译器根据第一个子表达式已经推导出 auto 为 int 类型，那么后面的 m 也只能是 int 类型，如果写作m=12.5就是错误的，因为 12.5 是double 类型，这和 int 是冲突的。\n还有一个值得注意的地方是：使用 auto 类型推导的变量必须马上初始化，这个很容易理解，因为 auto 在 C++11 中只是“占位符”，并非如 int 一样的真正的类型声明。\nauto 的高级用法\nauto 除了可以独立使用，还可以和某些具体类型混合使用，这样 auto 表示的就是“半个”类型，而不是完整的类型。请看下面的代码：\n1 2 3 4 5 int x = 0; auto *p1 = \u0026amp;x; //p1 为 int *，auto 推导为 int auto p2 = \u0026amp;x; //p2 为 int*，auto 推导为 int* auto \u0026amp;r1 = x; //r1 为 int\u0026amp;，auto 推导为 int auto r2 = r1; //r2 为 int，auto 推导为 int 下面我们来解释一下：\n第 2 行代码中，p1 为 int* 类型，也即 auto * 为 int *，所以 auto 被推导成了 int 类型。 第 3 行代码中，auto 被推导为 int* 类型，前边的例子也已经演示过了。 第 4 行代码中，r1 为 int \u0026amp; 类型，auto 被推导为 int 类型。 第 5 行代码是需要重点说明的，r1 本来是 int\u0026amp; 类型，但是 auto 却被推导为 int 类型，这表明当=右边的表达式是一个引用类型时，auto 会把引用抛弃，直接推导出它的原始类型。 接下来，我们再来看一下 auto 和 const 的结合：\n1 2 3 4 5 int x = 0; const auto n = x; //n 为 const int ，auto 被推导为 int auto f = n; //f 为 const int，auto 被推导为 int（const 属性被抛弃） const auto \u0026amp;r1 = x; //r1 为 const int\u0026amp; 类型，auto 被推导为 int auto \u0026amp;r2 = r1; //r1 为 const int\u0026amp; 类型，auto 被推导为 const int 类型`在这里插入代码片` 下面我们来解释一下：\n第 2 行代码中，n 为 const int，auto 被推导为 int。 第 3 行代码中，n 为 const int 类型，但是 auto 却被推导为 int 类型，这说明当=右边的表达式带有 const 属性时， auto 不会使用 const 属性，而是直接推导出 non-const 类型。 第 4 行代码中，auto 被推导为 int 类型，这个很容易理解，不再赘述。 第 5 行代码中，r1 是 const int \u0026amp; 类型，auto 也被推导为 const int 类型，这说明当 const 和引用结合时，auto 的推导将保留表达式的 const 类型。 最后我们来简单总结一下 auto 与 const 结合的用法：\n当类型不为引用时，auto 的推导结果将不保留表达式的 const 属性； 当类型为引用时，auto 的推导结果将保留表达式的 const 属性。 auto 的限制\n前面介绍推导规则的时候我们说过，使用 auto 的时候必须对变量进行初始化，这是 auto 的限制之一。那么，除此以外，auto 还有哪些其它的限制呢？\nauto 不能在函数的参数中使用。 这个应该很容易理解，我们在定义函数的时候只是对参数进行了声明，指明了参数的类型，但并没有给它赋值，只有在实际调用函数的时候才会给参数赋值；而 auto 要求必须对变量进行初始化，所以这是矛盾的。\nauto 不能作用于类的非静态成员变量（也就是没有 static 关键字修饰的成员变量）中。\nauto 关键字不能定义数组，比如下面的例子就是错误的：\n1 2 char url[] = “http://c.biancheng.net/”; auto str[] = url; //arr 为数组，所以不能使用 auto auto 不能作用于模板参数，请看下面的例子： 1 2 3 4 5 6 7 8 9 template \u0026lt;typename T\u0026gt; class A{ //TODO: }; int main(){ A\u0026lt;int\u0026gt; C1; A\u0026lt;auto\u0026gt; C2 = C1; //错误 return 0; } auto 的应用\n使用 auto 定义迭代器\nauto 的一个典型应用场景是用来定义 stl 的迭代器。\n我们在使用 stl 容器的时候，需要使用迭代器来遍历容器里面的元素；不同容器的迭代器有不同的类型，在定义迭代器时必须指明。而迭代器的类型有时候比较复杂，书写起来很麻烦，请看下面的例子：\n1 2 3 4 5 6 7 #include \u0026lt;vector\u0026gt; using namespace std; int main(){ vector\u0026lt; vector\u0026lt;int\u0026gt; \u0026gt; v; vector\u0026lt; vector\u0026lt;int\u0026gt; \u0026gt;::iterator i = v.begin(); return 0; } 可以看出来，定义迭代器 i 的时候，类型书写比较冗长，容易出错。然而有了 auto 类型推导，我们大可不必这样，只写一个 auto 即可。\n修改上面的代码，使之变得更加简洁：\n1 2 3 4 5 6 7 #include \u0026lt;vector\u0026gt; using namespace std; int main(){ vector\u0026lt; vector\u0026lt;int\u0026gt; \u0026gt; v; auto i = v.begin(); //使用 auto 代替具体的类型 return 0; } auto 可以根据表达式 v.begin() 的类型（begin() 函数的返回值类型）来推导出变量 i 的类型。\nauto 用于泛型编程\nauto 的另一个应用就是当我们不知道变量是什么类型，或者不希望指明具体类型的时候，比如泛型编程中。我们接着看例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include \u0026lt;iostream\u0026gt; using namespace std; class A{ public: static int get(void){ return 100; } }; class B{ public: static const char* get(void){ return \u0026#34;http://c.biancheng.net/cplus/\u0026#34;; } }; template \u0026lt;typename T\u0026gt; void func(void){ auto val = T::get(); cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; endl; } int main(void){ func\u0026lt;A\u0026gt;(); func\u0026lt;B\u0026gt;(); return 0; } 运行结果：\n1 100 本例中的模板函数 func() 会调用所有类的静态函数 get()，并对它的返回值做统一处理，但是 get() 的返回值类型并不一样，而且不能自动转换。这种要求在以前的 C++ 版本中实现起来非常的麻烦，需要额外增加一个模板参数，并在调用时手动给该模板参数赋值，用以指明变量 val 的类型。\n但是有了 auto 类型自动推导，编译器就根据 get() 的返回值自己推导出 val 变量的类型，就不用再增加一个模板参数了。\n下面的代码演示了不使用 auto 的解决办法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #include \u0026lt;iostream\u0026gt; using namespace std; class A{ public: static int get(void){ return 100; } }; class B{ public: static const char* get(void){ return \u0026#34;http://c.biancheng.net/cplus/\u0026#34;; } }; template \u0026lt;typename T1, typename T2\u0026gt; //额外增加一个模板参数 T2 void func(void){ T2 val = T1::get(); cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; endl; } int main(void){ //调用时也要手动给模板参数赋值 func\u0026lt;A, int\u0026gt;(); func\u0026lt;B, const char*\u0026gt;(); return 0; } C++ decltype类型推导完全攻略 decltype 是 C++11 新增的一个关键字，它和 auto 的功能一样，都用来在编译时期进行自动类型推导。不了解 auto 用法的读者请转到(《C++ auto》)[http://c.biancheng.net/view/6984.html]。\ndecltype 是“declare type”的缩写，译为“声明类型”。\n既然已经有了 auto 关键字，为什么还需要 decltype 关键字呢？因为 auto 并不适用于所有的自动类型推导场景，在某些特殊情况下 auto 用起来非常不方便，甚至压根无法使用，所以 decltype 关键字也被引入到 C++11 中。\nauto 和 decltype 关键字都可以自动推导出变量的类型，但它们的用法是有区别的：\n1 2 auto varname = value; decltype(exp) varname = value; 其中，varname 表示变量名，value 表示赋给变量的值，exp 表示一个表达式。\nauto 根据=右边的初始值 value 推导出变量的类型，而 decltype 根据 exp 表达式推导出变量的类型，跟=右边的 value 没有关系。\n另外，auto 要求变量必须初始化，而 decltype 不要求。这很容易理解，auto 是根据变量的初始值来推导出变量类型的，如果不初始化，变量的类型也就无法推导了。decltype 可以写成下面的形式：\n1 decltype(exp) varname; exp 注意事项\n原则上讲，exp 就是一个普通的表达式，它可以是任意复杂的形式，但是我们必须要保证 exp 的结果是有类型的，不能是 void；例如，当 exp 调用一个返回值类型为 void 的函数时，exp 的结果也是 void 类型，此时就会导致编译错误。\nC++ decltype 用法举例：\n1 2 3 4 int a = 0; decltype(a) b = 1; //b 被推导成了 int decltype(10.8) x = 5.5; //x 被推导成了 double decltype(x + 100) y; //y 被推导成了 double 可以看到，decltype 能够根据变量、字面量、带有运算符的表达式推导出变量的类型。读者请留意第 4 行，y 没有被初始化。\ndecltype 推导规则\n上面的例子让我们初步感受了一下 decltype 的用法，但你不要认为 decltype 就这么简单，它的玩法实际上可以非常复杂。当程序员使用 decltype(exp) 获取类型时，编译器将根据以下三条规则得出结果：\n如果 exp 是一个不被括号( )包围的表达式，或者是一个类成员访问表达式，或者是一个单独的变量，那么 decltype(exp) 的类型就和 exp 一致，这是最普遍最常见的情况。 如果 exp 是函数调用，那么 decltype(exp) 的类型就和函数返回值的类型一致。 如果 exp 是一个左值，或者被括号( )包围，那么 decltype(exp) 的类型就是 exp 的引用；假设 exp 的类型为 T，那么 decltype(exp) 的类型就是 T\u0026amp;。 为了更好地理解 decltype 的推导规则，下面来看几个实际的例子。\n【实例1】exp 是一个普通表达式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #include \u0026lt;string\u0026gt; using namespace std; class Student{ public: static int total; string name; int age; float scores; }; int Student::total = 0; int main(){ int n = 0; const int \u0026amp;r = n; Student stu; decltype(n) a = n; //n 为 int 类型，a 被推导为 int 类型 decltype(r) b = n; //r 为 const int\u0026amp; 类型, b 被推导为 const int\u0026amp; 类型 decltype(Student::total) c = 0; //total 为类 Student 的一个 int 类型的成员变量，c 被推导为 int 类型 decltype(stu.name) url = \u0026#34;http://c.biancheng.net/cplus/\u0026#34;; //total 为类 Student 的一个 string 类型的成员变量， url 被推导为 string 类型 return 0; } 这段代码很简单，按照推导规则 1，对于一般的表达式，decltype 的推导结果就和这个表达式的类型一致。\n【实例2】exp 为函数调用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 /函数声明 int\u0026amp; func_int_r(int, char); //返回值为 int\u0026amp; int\u0026amp;\u0026amp; func_int_rr(void); //返回值为 int\u0026amp;\u0026amp; int func_int(double); //返回值为 int const int\u0026amp; fun_cint_r(int, int, int); //返回值为 const int\u0026amp; const int\u0026amp;\u0026amp; func_cint_rr(void); //返回值为 const int\u0026amp;\u0026amp; //decltype类型推导 int n = 100; decltype(func_int_r(100, \u0026#39;A\u0026#39;)) a = n; //a 的类型为 int\u0026amp; decltype(func_int_rr()) b = 0; //b 的类型为 int\u0026amp;\u0026amp; decltype(func_int(10.5)) c = 0; //c 的类型为 int decltype(fun_cint_r(1,2,3)) x = n; //x 的类型为 const int \u0026amp; decltype(func_cint_rr()) y = 0; // y 的类型为 const int\u0026amp;\u0026amp; 需要注意的是，exp 中调用函数时需要带上括号和参数，但这仅仅是形式，并不会真的去执行函数代码。\n【实例3】exp 是左值，或者被( )包围：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 using namespace std; class Base{ public: int x; }; int main(){ const Base obj; //带有括号的表达式 decltype(obj.x) a = 0; //obj.x 为类的成员访问表达式，符合推导规则一，a 的类型为 int decltype((obj.x)) b = a; //obj.x 带有括号，符合推导规则三，b 的类型为 int\u0026amp;。 //加法表达式 int n = 0, m = 0; decltype(n + m) c = 0; //n+m 得到一个右值，符合推导规则一，所以推导结果为 int decltype(n = n + m) d = c; //n=n+m 得到一个左值，符号推导规则三，所以推导结果为 int\u0026amp; return 0; } 这里我们需要重点说一下左值和右值：左值是指那些在表达式执行结束后依然存在的数据，也就是持久性的数据；右值是指那些在表达式执行结束后不再存在的数据，也就是临时性的数据。有一种很简单的方法来区分左值和右值，对表达式取地址，如果编译器不报错就为左值，否则为右值。\ndecltype 的实际应用\nauto 的语法格式比 decltype 简单，所以在一般的类型推导中，使用 auto 比使用 decltype 更加方便，你可以转到《C++ auto》查看很多类似的例子，本节仅演示只能使用 decltype 的情形。\n我们知道，auto 只能用于类的静态成员，不能用于类的非静态成员（普通成员），如果我们想推导非静态成员的类型，这个时候就必须使用 decltype 了。下面是一个模板的定义：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #include \u0026lt;vector\u0026gt; using namespace std; template \u0026lt;typename T\u0026gt; class Base { public: void func(T\u0026amp; container) { m_it = container.begin(); } private: typename T::iterator m_it; //注意这里 }; int main() { const vector\u0026lt;int\u0026gt; v; Base\u0026lt;const vector\u0026lt;int\u0026gt;\u0026gt; obj; obj.func(v); return 0; } 单独看 Base 类中 m_it 成员的定义，很难看出会有什么错误，但在使用 Base 类的时候，如果传入一个 const 类型的容器，编译器马上就会弹出一大堆错误信息。原因就在于，T::iterator并不能包括所有的迭代器类型，当 T 是一个 const 容器时，应当使用 const_iterator。\n要想解决这个问题，在之前的 C++98/03 版本下只能想办法把 const 类型的容器用模板特化单独处理，增加了不少工作量，看起来也非常晦涩。但是有了 C++11 的 decltype 关键字，就可以直接这样写：\n1 2 3 4 5 6 7 8 9 template \u0026lt;typename T\u0026gt; class Base { public: void func(T\u0026amp; container) { m_it = container.begin(); } private: decltype(T().begin()) m_it; //注意这里 }; 看起来是不是很清爽？\n注意，有些低版本的编译器不支持T().begin()这种写法，以上代码我在 VS2019 下测试通过，在 VS2015 下测试失败。\n汇总auto和decltype的区别 通过(《C++ auto》)[http://c.biancheng.net/view/6984.html]和(《C++ decltype》)[http://c.biancheng.net/view/7151.html]两节的学习，相信大家已经掌握了 auto 和 decltype 的语法规则以及使用场景，这节我们将 auto 和 decltype 放在一起，综合对比一下它们的区别，并告诉大家该如何选择。\n语法格式的区别\nauto 和 decltype 都是 C++11 新增的关键字，都用于自动类型推导，但是它们的语法格式是有区别的，如下所示：\nauto varname = value; //auto的语法格式 decltype(exp) varname [= value]; //decltype的语法格式\n其中，varname 表示变量名，value 表示赋给变量的值，exp 表示一个表达式，方括号[ ]表示可有可无。\nauto 和 decltype 都会自动推导出变量 varname 的类型：\nauto 根据=右边的初始值 value 推导出变量的类型； decltype 根据 exp 表达式推导出变量的类型，跟=右边的 value 没有关系。 另外，auto 要求变量必须初始化，也就是在定义变量的同时必须给它赋值；而 decltype 不要求，初始化与否都不影响变量的类型。这很容易理解，因为 auto 是根据变量的初始值来推导出变量类型的，如果不初始化，变量的类型也就无法推导了。\nauto 将变量的类型和初始值绑定在一起，而 decltype 将变量的类型和初始值分开；虽然 auto 的书写更加简洁，但 decltype 的使用更加灵活。\n请看下面的例子：\n1 2 3 4 5 6 auto n1 = 10; decltype(10) n2 = 99; auto url1 = \u0026#34;http://c.biancheng.net/cplus/\u0026#34;; decltype(url1) url2 = \u0026#34;http://c.biancheng.net/java/\u0026#34;; auto f1 = 2.5; decltype(n1*6.7) f2; 这些用法在前面的两节中已经进行了分析，此处就不再赘述了。\n对 cv 限定符的处理\n「cv 限定符」是 const 和 volatile 关键字的统称：\nconst 关键字用来表示数据是只读的，也就是不能被修改； volatile 和 const 是相反的，它用来表示数据是可变的、易变的，目的是不让 CPU 将数据缓存到寄存器，而是从原始的内存中读取。 在推导变量类型时，auto 和 decltype 对 cv 限制符的处理是不一样的。decltype 会保留 cv 限定符，而 auto 有可能会去掉 cv 限定符。\n以下是 auto 关键字对 cv 限定符的推导规则：\n如果表达式的类型不是指针或者引用，auto 会把 cv 限定符直接抛弃，推导成 non-const 或者 non-volatile 类型。 如果表达式的类型是指针或者引用，auto 将保留 cv 限定符。 下面的例子演示了对 const 限定符的推导：\n1 2 3 4 5 6 7 8 9 10 11 12 //非指针非引用类型 const int n1 = 0; auto n2 = 10; n2 = 99; //赋值不报错 decltype(n1) n3 = 20; n3 = 5; //赋值报错 //指针类型 const int *p1 = \u0026amp;n1; auto p2 = p1; *p2 = 66; //赋值报错 decltype(p1) p3 = p1; *p3 = 19; //赋值报错 在 C++ 中无法将一个变量的完整类型输出，我们通过对变量赋值来判断它是否被 const 修饰；如果被 const 修饰那么赋值失败，如果不被 const 修饰那么赋值成功。虽然这种方案不太直观，但也是能达到目的的。\nn2 赋值成功，说明不带 const，也就是 const 被 auto 抛弃了，这验证了 auto 的第一条推导规则。p2 赋值失败，说明是带 const 的，也就是 const 没有被 auto 抛弃，这验证了 auto 的第二条推导规则。\nn3 和 p3 都赋值失败，说明 decltype 不会去掉表达式的 const 属性。\n对引用的处理\n当表达式的类型为引用时，auto 和 decltype 的推导规则也不一样；decltype 会保留引用类型，而 auto 会抛弃引用类型，直接推导出它的原始类型。请看下面的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #include \u0026lt;iostream\u0026gt; using namespace std; int main() { int n = 10; int \u0026amp;r1 = n; //auto推导 auto r2 = r1; r2 = 20; cout \u0026lt;\u0026lt; n \u0026lt;\u0026lt; \u0026#34;, \u0026#34; \u0026lt;\u0026lt; r1 \u0026lt;\u0026lt; \u0026#34;, \u0026#34; \u0026lt;\u0026lt; r2 \u0026lt;\u0026lt; endl; //decltype推导 decltype(r1) r3 = n; r3 = 99; cout \u0026lt;\u0026lt; n \u0026lt;\u0026lt; \u0026#34;, \u0026#34; \u0026lt;\u0026lt; r1 \u0026lt;\u0026lt; \u0026#34;, \u0026#34; \u0026lt;\u0026lt; r3 \u0026lt;\u0026lt; endl; return 0; } 运行结果：\n1 2 10, 10, 20 99, 99, 99 总结 从运行结果可以发现，给 r2 赋值并没有改变 n 的值，这说明 r2 没有指向 n，而是自立门户，单独拥有了一块内存，这就证明 r 不再是引用类型，它的引用类型被 auto 抛弃了。\n给 r3 赋值，n 的值也跟着改变了，这说明 r3 仍然指向 n，它的引用类型被 decltype 保留了。\nauto 虽然在书写格式上比 decltype 简单，但是它的推导规则复杂，有时候会改变表达式的原始类型；而 decltype 比较纯粹，它一般会坚持保留原始表达式的任何类型，让推导的结果更加原汁原味。\n从代码是否健壮的角度考虑，我推荐使用 decltype，它没有那么多是非；但是 decltype 总是显得比较麻烦，尤其是当表达式比较复杂时，例如：\n1 2 vector nums; decltype(nums.begin()) it = nums.begin(); 而如果使用 auto 就会清爽很多：\n1 2 vector nums; auto it = nums.begin(); 在实际开发中人们仍然喜欢使用 auto 关键字（我也这么干），因为它用起来简单直观，更符合人们的审美。如果你的表达式类型不复杂，我还是推荐使用 auto 关键字，优雅的代码总是叫人赏心悦目，沉浸其中。\nC++返回值类型后置（跟踪返回值类型） 在泛型编程中，可能需要通过参数的运算来得到返回值的类型。考虑下面这个场景：\n1 2 3 4 5 6 7 template \u0026lt;typename R, typename T, typename U\u0026gt; R add(T t, U u) { return t+u; } int a = 1; float b = 2.0; auto c = add\u0026lt;decltype(a + b)\u0026gt;(a, b); 我们并不关心 a+b 的类型是什么，因此，只需要通过 decltype(a+b) 直接得到返回值类型即可。但是像上面这样使用十分不方便，因为外部其实并不知道参数之间应该如何运算，只有 add 函数才知道返回值应当如何推导。\n那么，在 add 函数的定义上能不能直接通过 decltype 拿到返回值呢？\n1 2 3 4 5 template \u0026lt;typename T, typename U\u0026gt; decltype(t + u) add(T t, U u) // error: t、u尚未定义 { return t + u; } 当然，直接像上面这样写是编译不过的。因为 t、u 在参数列表中，而 C++ 的返回值是前置语法，在返回值定义的时候参数变量还不存在。\n可行的写法如下：\n1 2 3 4 5 template \u0026lt;typename T, typename U\u0026gt; decltype(T() + U()) add(T t, U u) { return t + u; } 考虑到 T、U 可能是没有无参构造函数的类，正确的写法应该是这样：\n1 2 3 4 5 template \u0026lt;typename T, typename U\u0026gt; decltype((*(T*)0) + (*(U*)0)) add(T t, U u) { return t + u; } 虽然成功地使用 decltype 完成了返回值的推导，但写法过于晦涩，会大大增加 decltype 在返回值类型推导上的使用难度并降低代码的可读性。\n因此，在 C++11 中增加了**返回类型后置（trailing-return-type，又称跟踪返回类型）**语法，将 decltype 和 auto 结合起来完成返回值类型的推导。\n返回类型后置语法是通过 auto 和 decltype 结合起来使用的。上面的 add 函数，使用新的语法可以写成：\n1 2 3 4 5 template \u0026lt;typename T, typename U\u0026gt; auto add(T t, U u) -\u0026gt; decltype(t + u) { return t + u; } 为了进一步说明这个语法，再看另一个例子：\n1 2 3 4 5 6 7 int\u0026amp; foo(int\u0026amp; i); float foo(float\u0026amp; f); template \u0026lt;typename T\u0026gt; auto func(T\u0026amp; val) -\u0026gt; decltype(foo(val)) { return foo(val); } 如果说前一个例子中的 add 使用 C++98/03 的返回值写法还勉强可以完成，那么这个例子对于 C++ 而言就是不可能完成的任务了。\n在这个例子中，使用 decltype 结合返回值后置语法很容易推导出了 foo(val) 可能出现的返回值类型，并将其用到了 func 上。\n返回值类型后置语法，是为了解决函数返回值类型依赖于参数而导致难以确定返回值类型的问题。有了这种语法以后，对返回值类型的推导就可以用清晰的方式（直接通过参数做运算）描述出来，而不需要像 C++98/03 那样使用晦涩难懂的写法。\nC++11对模板实例化中连续右尖括号\u0026raquo;的改进 在 C++98/03 的泛型编程中，模板实例化有一个很烦琐的地方，那就是连续两个右尖括号（\u0026raquo;）会被编译器解释成右移操作符，而不是模板参数表的结束。\n【实例】C++98/03 中不支持连续两个右尖括号的示例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 template \u0026lt;typename T\u0026gt; struct Foo { typedef T type; }; template \u0026lt;typename T\u0026gt; class A { // ... }; int main(void) { Foo\u0026lt;A\u0026lt;int\u0026gt;\u0026gt;::type xx; //编译出错 return 0; } 使用 gcc 编译时，会得到如下错误提示：\n1 error: ‘\u0026gt;\u0026gt;’ should be ‘\u0026gt;\u0026gt;’ within a nested template argument list Foo\u0026lt;A\u0026gt;::type xx; 意思就是，Foo\u0026lt;A\u0026lt;int\u0026gt;\u0026gt;这种写法是不被支持的，要写成这样Foo\u0026lt;A\u0026lt;int\u0026gt; \u0026gt;（注意两个右尖括号之间的空格）。\n这种限制无疑是很没有必要的。在 C++ 的各种成对括号中，目前只有右尖括号连续写两个会出现这种二义性。static_cast、reinterpret_cast 等 C++ 标准转换运算符，都是使用\u0026lt;\u0026gt;来获得待转换类型（type-id）的。若这个 type-id 本身是一个模板，用起来会很不方便。\n现在在 C++11 中，这种限制终于被取消了。在 C++11 标准中，要求编译器对模板的右尖括号做单独处理，使编译器能够正确判断出\u0026raquo;是一个右移操作符还是模板参数表的结束标记（delimiter，界定符）。\n不过这种自动化的处理在某些时候会与老标准不兼容，比如下面这个例子：\n1 2 3 4 5 6 7 8 9 10 template \u0026lt;int N\u0026gt; struct Foo { // ... }; int main(void) { Foo\u0026lt;100 \u0026gt;\u0026gt; 2\u0026gt; xx; return 0; } 在 C++98/03 的编译器中编译是没问题的，但 C++11 的编译器会显示：\nerror: expected unqualif?ied-id before ‘\u0026gt;’ token Foo\u0026lt;100 \u0026raquo; 2\u0026gt; xx;\n解决的方法是这样写：\nFoo\u0026lt;(100 \u0026raquo; 2)\u0026gt; xx; // 注意括号\n这种加括号的写法其实也是一个良好的编程习惯，使得在书写时倾向于写出无二义性的代码。\n扩展阅读\n各种 C++98/03 编译器除了支持标准（ISO/IEC 14882：2003 及其之前的标准）之外，还自行做了不少的拓展。这些拓展中的一部分，后来经过了 C++ 委员会的斟酌和完善，进入了 C++11。\n所以有一部分 C++11 的新特征，在一些 C++98/03 的老编译器下也是可以支持的，只是由于没有标准化，无法保证各种平台/编译器下的兼容性。比如像 Microsoft Visual C++2005 这种不支持 C++11 的编译器，在对模板右尖括号的处理上和现在的 C++11 是一致的。\nC++11使用using定义别名（替代typedef） 大家都知道，在 C++ 中可以通过 typedef 重定义一个类型：\n1 typedef unsigned int uint_t; 被重定义的类型并不是一个新的类型，仅仅只是原有的类型取了一个新的名字。因此，下面这样将不是合法的函数重载：\n1 2 void func(unsigned int); void func(uint_t); // error: redefinition 使用 typedef 重定义类型是很方便的，但它也有一些限制，比如，无法重定义一个模板。\n想象下面这个场景：\n1 2 3 4 typedef std::map\u0026lt;std::string, int\u0026gt; map_int_t; // … typedef std::map\u0026lt;std::string, std::string\u0026gt; map_str_t; // … 我们需要的其实是一个固定以 std::string 为 key 的 map，它可以映射到 int 或另一个 std::string。然而这个简单的需求仅通过 typedef 却很难办到。\n因此，在 C++98/03 中往往不得不这样写：\n1 2 3 4 5 6 7 8 template \u0026lt;typename Val\u0026gt; struct str_map { typedef std::map\u0026lt;std::string, Val\u0026gt; type; }; // ... str_map\u0026lt;int\u0026gt;::type map1; // ... 一个虽然简单但却略显烦琐的 str_map 外敷类是必要的。这明显让我们在复用某些泛型代码时非常难受。\n现在，在 C++11 中终于出现了可以重定义一个模板的语法。请看下面的示例：\n1 2 3 4 template \u0026lt;typename Val\u0026gt; using str_map_t = std::map\u0026lt;std::string, Val\u0026gt;; // ... str_map_t\u0026lt;int\u0026gt; map1; 这里使用新的 using 别名语法定义了 std::map 的模板别名 str_map_t。比起前面使用外敷模板加 typedef 构建的 str_map，它完全就像是一个新的 map 类模板，因此，简洁了很多。\n实际上，using 的别名语法覆盖了 typedef 的全部功能。先来看看对普通类型的重定义示例，将这两种语法对比一下：\n1 2 3 4 5 6 // 重定义unsigned int typedef unsigned int uint_t; using uint_t = unsigned int; // 重定义std::map typedef std::map\u0026lt;std::string, int\u0026gt; map_int_t; using map_int_t = std::map\u0026lt;std::string, int\u0026gt;; 可以看到，在重定义普通类型上，两种使用方法的效果是等价的，唯一不同的是定义语法。\ntypedef 的定义方法和变量的声明类似：像声明一个变量一样，声明一个重定义类型，之后在声明之前加上 typedef 即可。这种写法凸显了 C/C++ 中的语法一致性，但有时却会增加代码的阅读难度。比如重定义一个函数指针时：\n1 typedef void (*func_t)(int, int); 与之相比，using 后面总是立即跟随新标识符（Identifier），之后使用类似赋值的语法，把现有的类型（type-id）赋给新类型：\n1 using func_t = void (*)(int, int); 从上面的对比中可以发现，C++11 的 using 别名语法比 typedef 更加清晰。因为 typedef 的别名语法本质上类似一种解方程的思路。而 using 语法通过赋值来定义别名，和我们平时的思考方式一致。\n下面再通过一个对比示例，看看新的 using 语法是如何定义模板别名的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 /* C++98/03 */ template \u0026lt;typename T\u0026gt; struct func_t { typedef void (*type)(T, T); }; // 使用 func_t 模板 func_t\u0026lt;int\u0026gt;::type xx_1; /* C++11 */ template \u0026lt;typename T\u0026gt; using func_t = void (*)(T, T); // 使用 func_t 模板 func_t\u0026lt;int\u0026gt; xx_2; 从示例中可以看出，通过 using 定义模板别名的语法，只是在普通类型别名语法的基础上增加 template 的参数列表。使用 using 可以轻松地创建一个新的模板别名，而不需要像 C++98/03 那样使用烦琐的外敷模板。\n需要注意的是，using 语法和 typedef 一样，并不会创造新的类型。也就是说，上面示例中 C++11 的 using 写法只是 typedef 的等价物。虽然 using 重定义的 func_t 是一个模板，但 func_t 定义的 xx_2 并不是一个由类模板实例化后的类，而是 void(*)(int, int) 的别名。\n因此，下面这样写：\n1 2 void foo(void (*func_call)(int, int)); void foo(func_t func_call); // error: redefinition 同样是无法实现重载的，func_t 只是 void(*)(int, int) 类型的等价物。\n细心的读者可以发现，using 重定义的 func_t 是一个模板，但它既不是类模板也不是函数模板（函数模板实例化后是一个函数），而是一种新的模板形式：模板别名（alias template）。\n其实，通过 using 可以轻松定义任意类型的模板表达方式。比如下面这样：\n1 2 3 4 template using type_t = T; // … type_t i; type_t 实例化后的类型和它的模板参数类型等价。这里，type_t 将等价于 int。\nC++11支持函数模板的默认模板参数 在 C++98/03 标准中，类模板可以有默认的模板参数，如下：\n1 2 3 4 5 template \u0026lt;typename T, typename U = int, U N = 0\u0026gt; struct Foo { // ... }; 但是却不支持函数的默认模板参数：\n1 2 3 4 5 template \u0026lt;typename T = int\u0026gt; // error in C++98/03: default template arguments void func() { // ... } 现在这一限制在 C++11 中被解除了。上面的 func 函数在 C++11 中可以直接使用，代码如下：\n1 2 3 4 5 int main(void) { func(); //T = int return 0; } 此时模板参数 T 的类型就为默认值 int。从上面的例子中可以看出，当所有模板参数都有默认参数时，函数模板的调用如同一个普通函数。但对于类模板而言，哪怕所有参数都有默认参数，在使用时也必须在模板名后跟随\u0026lt;\u0026gt;来实例化。\n除了上面提到的部分之外，函数模板的默认模板参数在使用规则上和其他的默认参数也有一些不同，它没有必须写在参数表最后的限制。甚至于，根据实际场景中函数模板被调用的情形，编译器还可以自行推导出部分模板参数的类型。\n这意味着，当默认模板参数和编译器自行推导出模板参数类型的能力一起结合使用时，代码的书写将变得异常灵活。我们可以指定函数中的一部分模板参数采用默认参数，而另一部分使用自动推导，比如下面的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 template \u0026lt;typename R = int, typename U\u0026gt; R func(U val) { return val; } int main() { func(97); // R=int, U=int func\u0026lt;char\u0026gt;(97); // R=char, U=int func\u0026lt;double, int\u0026gt;(97); // R=double, U=int return 0; } C++11 标准中，我们可以像 func(97) 这样调用模板函数，因为编译器可以根据实参 97 自行推导出模板参数 U 的类型为 int，并且根据返回值 val=97 推导出 R 的类型也为 int；而 func(97) 手动指定了模板参数 R 的类型为 char（默认模板参数将无效），并通过实参 97 推导出了 U = int；最后 func\u0026lt;double,int\u0026gt;(97) 手动指定的 R 和 U 的类型值，因此无需编译器自行推导。\n再次强调，当默认模板参数和自行推导的模板参数同时使用时，若无法推导出函数模板参数的类型，编译器会选择使用默认模板参数；如果模板参数即无法推导出来，又未设置其默认值，则编译器直接报错。例如：\n1 2 3 4 5 6 7 8 9 10 11 12 template \u0026lt;typename T, typename U = double\u0026gt; void func(T val1 = 0, U val2 = 0) { //... } int main() { func(\u0026#39;c\u0026#39;); //T=char, U=double func(); //编译报错 return 0; } 其中，func(‘c’) 的这种调用方式，编译器通过实参 ‘c’ 可以推导出 T=char，但由于未传递第 2 个实参，因此模板参数 U 使用的是默认参数 double；但 func() 的调用方式是不行的，虽然 val1 设置有默认值，但编译器无法通过该默认值推导出模板参数 T 的类型。由此不难看出，编译器的自动推导能力并没有想象的那么强大。\n总的来说，C++11 支持为函数模板中的参数设置默认值，在实际使用过程中，我们可以选择使用默认值，也可以尝试由编译器自行推导得到，还可以亲自指定各个模板参数的类型。\nC++11在函数模板和类模板中使用可变参数 所谓可变参数，指的是参数的个数和类型都可以是任意的。提到参数，大家会第一时间想到函数参数，除此之外 C++ 的模板（包括函数模板和类模板）也会用到参数。\n对于函数参数而言，C++ 一直都支持为函数设置可变参数，最典型的代表就是 printf() 函数，它的语法格式为：\n1 int printf ( const char * format, ... ); ...就表示的是可变参数，即 printf() 函数可以接收任意个参数，且各个参数的类型可以不同，例如：\n1 printf(\u0026#34;%d\u0026#34;, 10);printf(\u0026#34;%d %c\u0026#34;,10, \u0026#39;A\u0026#39;);printf(\u0026#34;%d %c %f\u0026#34;,10, \u0026#39;A\u0026#39;, 1.23); 我们通常将容纳多个参数的可变参数称为参数包。借助 format 字符串，printf() 函数可以轻松判断出参数包中的参数个数和类型。\n下面的程序中，自定义了一个简单的可变参数函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstdarg\u0026gt; //可变参数的函数 void vair_fun(int count, ...){ va_list args; va_start(args, count); for (int i = 0; i \u0026lt; count; ++i) { int arg = va_arg(args, int); std::cout \u0026lt;\u0026lt; arg \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } va_end(args); } int main(){ //可变参数有 4 个，分别为 10、20、30、40 vair_fun(4, 10, 20, 30,40); return 0; } 程序中的 vair_fun() 函数有 2 个参数，一个是 count，另一个就是 … 可变参数。我们可以很容易在函数内部使用 count 参数，但要想使用参数包中的参数，需要借助头文件中的 va_start、va_arg 以及 va_end 这 3 个带参数的宏：\nva_start(args, count)：args 是 va_list 类型的变量，我们可以简单的将其视为 char * 类型。借助 count 参数，找到可变参数的起始位置并赋值给 args； va_arg(args, int)：调用 va_start 找到可变参数起始位置的前提下，通过指明参数类型为 int，va_arg 就可以将可变参数中的第一个参数返回； va_end(args)：不再使用 args 变量后，应及时调用 va_end 宏清理 args 变量。 注意，借助 va_arg 获取参数包中的参数时，va_arg 不具备自行终止的能力，所以程序中借助 count 参数控制 va_arg 的执行次数，继而将所有的参数读取出来。控制 va_arg 执行次数还有其他方法，比如读取到指定数据时终止。\n使用 … 可变参数的过程中，需注意以下几点：\n… 可变参数必须作为函数的最后一个参数，且一个函数最多只能拥有 1 个可变参数。 可变参数的前面至少要有 1 个有名参数（例如上面例子中的 count 参数）； 当可变参数中包含 char 类型的参数时，va_arg 宏要以 int 类型的方式读取；当可变参数中包含 short 类型的参数时，va_arg 宏要以 double 类型的方式读取。 需要注意的是，…可变参数的方法仅适用于函数参数，并不适用于模板参数。C++11 标准中，提供了一种实现\u0026lt;/font color=red\u0026gt;可变模板参数的方法。\n可变参数模板\nC++ 11 标准发布之前，函数模板和类模板只能设定固定数量的模板参数。C++11 标准对模板的功能进行了扩展，允许模板中包含任意数量的模板参数，这样的模板又称可变参数模板。\n（1）可变参数函数模板\n先讲解函数模板，如下定义了一个可变参数的函数模板：\n1 2 3 4 template\u0026lt;typename... T\u0026gt; void vair_fun(T...args) { //函数体 } 模板参数中， typename（或者 class）后跟 … 就表明 T 是一个可变模板参数，它可以接收多种数据类型，又称模板参数包。vair_fun() 函数中，args 参数的类型用 T… 表示，表示 args 参数可以接收任意个参数，又称函数参数包。\n这也就意味着，此函数模板最终实例化出的 vair_fun() 函数可以指定任意类型、任意数量的参数。例如，我们可以这样使用这个函数模板：\n1 2 3 vair_fun(); vair_fun(1, \u0026#34;abc\u0026#34;); vair_fun(1, \u0026#34;abc\u0026#34;, 1.23); 使用可变参数模板的难点在于，如何在模板函数内部“解开”参数包（使用包内的数据），这里给大家介绍两种简单的方法。\n[递归方式解包]\n先看一个实例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u0026lt;iostream\u0026gt; using namespace std; //模板函数递归的出口 void vir_fun() { } template \u0026lt;typename T, typename... args\u0026gt; void vir_fun(T argc, args... argv) { cout \u0026lt;\u0026lt; argc \u0026lt;\u0026lt; endl; //开始递归，将第一个参数外的 argv 参数包重新传递给 vir_fun vir_fun(argv...); } int main() { vir_fun(1, \u0026#34;http://www.biancheng.net\u0026#34;, 2.34); return 0; } 执行结果为：\n1 2 3 1 http://www.biancheng.net 2.34 分析一个程序的执行流程：\n首先，main() 函数调用 vir_fun() 模板函数时，根据所传实参的值，可以很轻易地判断出模板参数 T 的类型为 int，函数参数 argc 的值为 1，剩余的模板参数和函数参数都分别位于 args 和 argv 中； vir_fun() 函数中，首先输出了 argc 的值（为 1），然后重复调用自身，同时将函数参数包 argv 中的数据作为实参传递给形参 argc 和 argv； 再次执行 vir_fun() 函数，此时模板参数 T 的类型为 char*，输出 argc 的值为 “http:www.biancheng.net”。再次调用自身，继续将 argv 包中的数据作为实参； 再次执行 vir_fun() 函数，此时模板参数 T 的类型为 double，输出 argc 的值为 2.34。再次调用自身，将空的 argv 包作为实参； 由于 argv 包没有数据，此时会调用无任何形参、函数体为空的 vir_fun() 函数，最终执行结束。 以递归方式解包，一定要设置递归结束的出口。例如本例中，无形参、函数体为空的 vir_fun() 函数就是递归结束的出口。\n[非递归方法解包]\n借助逗号表达式和初始化列表，也可以解开参数包。\n以 vir_fun() 函数为例，下面程序演示了非递归方法解包的过程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u0026lt;iostream\u0026gt; using namespace std; template \u0026lt;typename T\u0026gt; void dispaly(T t) { cout \u0026lt;\u0026lt; t \u0026lt;\u0026lt; endl; } template \u0026lt;typename... args\u0026gt; void vir_fun(args... argv) { //逗号表达式+初始化列表 int arr[] = { (dispaly(argv),0)... }; } int main() { vir_fun(1, \u0026#34;http://www.biancheng.net\u0026#34;, 2.34); return 0; } 这里重点分析一下第 13 行代码，我们以{ }初始化列表的方式对数组 arr 进行了初始化， (display(argv),0)… 会依次展开为 (display(1),0)、(display(“http://www.biancheng.net”),0) 和 (display(2.34),0)。也就是说，第 13 行代码和如下代码是等价的：\n1 int arr[] = { (dispaly(1),0), (dispaly(\u0026#34;http://www.biancheng.net\u0026#34;),0), (dispaly(2.34),0) }; 可以看到，每个元素都是一个逗号表达式，以 (display(1), 0) 为例，它会先计算 display(1)，然后将 0 作为整个表达式的值返回给数组，因此 arr 数组最终存储的都是 0。arr 数组纯粹是为了将参数包展开，没有发挥其它作用。\n(2) 可变参数类模板\nC++11 标准中，类模板中的模板参数也可以是一个可变参数。C++ 11 标准提供的 typle 元组类就是一个典型的可变参数模板类，它的定义如下：\n1 2 template \u0026lt;typename... Types\u0026gt; class tuple; 和固定模板参数的类不同，typle 模板类实例化时，可以接收任意数量、任意类型的模板参数，例如：\n1 2 3 4 5 std:tuple\u0026lt;\u0026gt; tp0; std::tuple\u0026lt;int\u0026gt; tp1 = std::make_tuple(1); std::tuple\u0026lt;int, double\u0026gt; tp2 = std::make_tuple(1, 2.34); std::tuple\u0026lt;int, double, string\u0026gt; tp3 = std::make_tuple(1, 2.34, \u0026#34;http://www.biancheng.net\u0026#34;); 如下代码展示了一个支持可变参数的类模板：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;iostream\u0026gt; //声明模板类demo template\u0026lt;typename... Values\u0026gt; class demo; //继承式递归的出口 template\u0026lt;\u0026gt; class demo\u0026lt;\u0026gt; {}; //以继承的方式解包 template\u0026lt;typename Head, typename... Tail\u0026gt; class demo\u0026lt;Head, Tail...\u0026gt; : private demo\u0026lt;Tail...\u0026gt; { public: demo(Head v, Tail... vtail) : m_head(v), demo\u0026lt;Tail...\u0026gt;(vtail...) { dis_head(); } void dis_head() { std::cout \u0026lt;\u0026lt; m_head \u0026lt;\u0026lt; std::endl; } protected: Head m_head; }; int main() { demo\u0026lt;int, float, std::string\u0026gt; t(1, 2.34, \u0026#34;http://www.biancheng.net\u0026#34;); return 0; } 程序中，demo 模板参数中的 Tail 就是一个参数包，解包的方式是以“递归+继承”的方式实现的。具体来讲，demo\u0026lt;Head, Tail…\u0026gt; 类实例化时，由于其继承自 demo\u0026lt;Tail…\u0026gt; 类，因此父类也会实例化，一直递归至 Tail 参数包为空，此时会调用模板参数列表为空的 demo 模板类。\n程序的输出结果为：\n1 2 3 http://www.biancheng.net 2.34 1 可变参数模板类还有其它的解包方法，这里不再一一赘述，感兴趣的读者可以自行做深入的研究。\nC++11 tuple元组详解 C++11 标准新引入了一种类模板，命名为 tuple（中文可直译为元组）。tuple 最大的特点是：实例化的对象可以存储任意数量、任意类型的数据。\ntuple 的应用场景很广泛，例如当需要存储多个不同类型的元素时，可以使用 tuple；当函数需要返回多个数据时，可以将这些数据存储在 tuple 中，函数只需返回一个 tuple 对象即可。\n本节，我们将给大家详细地讲解 tuple 的用法。\ntuple对象的创建\ntuple 本质是一个以可变模板参数定义的类模板，它定义在 头文件并位于 std 命名空间中。因此要想使用 tuple 类模板，程序中需要首先引入以下代码：\n1 2 #include \u0026lt;tuple\u0026gt; using std::tuple; 实例化 tuple 模板类对象常用的方法有两种，一种是借助该类的构造函数，另一种是借助 make_tuple() 函数。\n(1) 类的构造函数\ntuple 模板类提供有很多构造函数，包括:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 1) 默认构造函数 constexpr tuple(); 2) 拷贝构造函数 tuple (const tuple\u0026amp; tpl); 3) 移动构造函数 tuple (tuple\u0026amp;\u0026amp; tpl); 4) 隐式类型转换构造函数 template \u0026lt;class... UTypes\u0026gt; tuple (const tuple\u0026lt;UTypes...\u0026gt;\u0026amp; tpl); //左值方式 template \u0026lt;class... UTypes\u0026gt; tuple (tuple\u0026lt;UTypes...\u0026gt;\u0026amp;\u0026amp; tpl); //右值方式 5) 支持初始化列表的构造函数 explicit tuple (const Types\u0026amp;... elems); //左值方式 template \u0026lt;class... UTypes\u0026gt; explicit tuple (UTypes\u0026amp;\u0026amp;... elems); //右值方式 6) 将pair对象转换为tuple对象 template \u0026lt;class U1, class U2\u0026gt; tuple (const pair\u0026lt;U1,U2\u0026gt;\u0026amp; pr); //左值方式 template \u0026lt;class U1, class U2\u0026gt; tuple (pair\u0026lt;U1,U2\u0026gt;\u0026amp;\u0026amp; pr); //右值方式 举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \u0026lt;iostream\u0026gt; // std::cout #include \u0026lt;tuple\u0026gt; // std::tuple using std::tuple; int main() { std::tuple\u0026lt;int, char\u0026gt; first; // 1) first{} std::tuple\u0026lt;int, char\u0026gt; second(first); // 2) second{} std::tuple\u0026lt;int, char\u0026gt; third(std::make_tuple(20, \u0026#39;b\u0026#39;)); // 3) third{20,\u0026#39;b\u0026#39;} std::tuple\u0026lt;long, char\u0026gt; fourth(third); // 4)的左值方式, fourth{20,\u0026#39;b\u0026#39;} std::tuple\u0026lt;int, char\u0026gt; fifth(10, \u0026#39;a\u0026#39;); // 5)的右值方式, fifth{10.\u0026#39;a\u0026#39;} std::tuple\u0026lt;int, char\u0026gt; sixth(std::make_pair(30, \u0026#39;c\u0026#39;)); // 6)的右值方式, sixth{30,\u0026#39;\u0026#39;c} return 0; } (2) make_tuple()函数\n上面程序中，我们已经用到了 make_tuple() 函数，它以模板的形式定义在 头文件中，功能是创建一个 tuple 右值对象（或者临时对象）。\n对于 make_tuple() 函数创建了 tuple 对象，我们可以上面程序中那样作为移动构造函数的参数，也可以这样用：\n1 2 3 auto first = std::make_tuple (10,\u0026#39;a\u0026#39;); // tuple \u0026lt; int, char \u0026gt; const int a = 0; int b[3]; auto second = std::make_tuple (a,b); // tuple \u0026lt; int, int* \u0026gt; 程序中分别创建了 first 和 second 两个 tuple 对象，它们的类型可以直接用 auto 表示。\ntuple常用函数\n为了方便您在实际开发中使用 tuple 对象，tupe 模板类提供了一个功能实用的成员函数， 头文件中也提供了一些和操作 tuple 对象相关的函数模板和类模板，如表 1 所示。\n函数或类模板 描 述 tup1.swap(tup2) swap(tup1, tup2) tup1 和 tup2 表示类型相同的两个 tuple 对象，tuple 模板类中定义有一个 swap() 成员函数， 头文件还提供了一个同名的 swap() 全局函数。 swap() 函数的功能是交换两个 tuple 对象存储的内容。 get(tup) tup 表示某个 tuple 对象，num 是一个整数，get() 是 头文件提供的全局函数，功能是返回 tup 对象中第 num+1 个元素。 tuple_size::value tuple_size 是定义在 头文件的类模板，它只有一个成员变量 value，功能是获取某个 tuple 对象中元素的个数，type 为该tuple 对象的类型。 tuple_element\u0026lt;I, type\u0026gt;::type tuple_element 是定义在 头文件的类模板，它只有一个成员变量 type，功能是获取某个 tuple 对象第 I+1 个元素的类型。 forward_as_tuple\u0026lt;args…\u0026gt; args… 表示 tuple 对象存储的多个元素，该函数的功能是创建一个 tuple 对象，内部存储的 args… 元素都是右值引用形式的。 tie(args…) = tup tup 表示某个 tuple 对象，tie() 是 头文件提供的，功能是将 tup 内存储的元素逐一赋值给 args… 指定的左值变量。 tuple_cat(args…) args… 表示多个 tuple 对象，该函数是 头文件提供的，功能是创建一个 tuple 对象，此对象包含 args… 指定的所有 tuple 对象内的元素。 tuple 模板类对赋值运算符 = 进行了重载，使得同类型的 tuple 对象可以直接赋值。此外，tuple 模板类还重载了 ==、!=、\u0026lt;、\u0026gt;、\u0026gt;=、\u0026lt;= 这几个比较运算符，同类型的 tuple 对象可以相互比较（逐个比较各个元素）。\n下面的程序给您演示了表 1 中一部分函数模板和类模板的功能：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #include \u0026lt;iostream\u0026gt; #include \u0026lt;tuple\u0026gt; int main() { int size; //创建一个 tuple 对象存储 10 和 \u0026#39;x\u0026#39; std::tuple\u0026lt;int, char\u0026gt; mytuple(10, \u0026#39;x\u0026#39;); //计算 mytuple 存储元素的个数 size = std::tuple_size\u0026lt;decltype(mytuple)\u0026gt;::value; //输出 mytuple 中存储的元素 std::cout \u0026lt;\u0026lt; std::get\u0026lt;0\u0026gt;(mytuple) \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; std::get\u0026lt;1\u0026gt;(mytuple) \u0026lt;\u0026lt; std::endl; //修改指定的元素 std::get\u0026lt;0\u0026gt;(mytuple) = 100; std::cout \u0026lt;\u0026lt; std::get\u0026lt;0\u0026gt;(mytuple) \u0026lt;\u0026lt; std::endl; //使用 makde_tuple() 创建一个 tuple 对象 auto bar = std::make_tuple(\u0026#34;test\u0026#34;, 3.1, 14); //拆解 bar 对象，分别赋值给 mystr、mydou、myint const char* mystr = nullptr; double mydou; int myint; //使用 tie() 时，如果不想接受某个元素的值，实参可以用 std::ignore 代替 std::tie(mystr, mydou, myint) = bar; //std::tie(std::ignore, std::ignore, myint) = bar; //只接收第 3 个整形值 //将 mytuple 和 bar 中的元素整合到 1 个 tuple 对象中 auto mycat = std::tuple_cat(mytuple, bar); size = std::tuple_size\u0026lt;decltype(mycat)\u0026gt;::value; std::cout \u0026lt;\u0026lt; size \u0026lt;\u0026lt; std::endl; return 0; } 程序执行结果为：\n1 2 3 10 x 100 5 C++11列表初始化（统一了初始化方式） 我们知道，在 C++98/03 中的对象初始化方法有很多种，请看下面的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 //初始化列表 int i_arr[3] = { 1, 2, 3 }; //普通数组 struct A { int x; struct B { int i; int j; } b; } a = { 1, { 2, 3 } }; //POD类型 //拷贝初始化（copy-initialization） int i = 0; class Foo { public: Foo(int) {} } foo = 123; //需要拷贝构造函数 //直接初始化（direct-initialization） int j(0); Foo bar(123); 这些不同的初始化方法，都有各自的适用范围和作用。最关键的是，这些种类繁多的初始化方法，没有一种可以通用所有情况。\n为了统一初始化方式，并且让初始化行为具有确定的效果，C++11 中提出了列表初始化（List-initialization）的概念。\nPOD 类型即 plain old data 类型，简单来说，是可以直接使用 memcpy 复制的对象。\n统一的初始化 在上面我们已经看到了，对于普通数组和 POD 类型，C++98/03 可以使用初始化列表（initializer list）进行初始化:\n1 2 3 4 5 6 7 int i_arr[3] = { 1, 2, 3 }; long l_arr[] = { 1, 3, 2, 4 }; struct A { int x; int y; } a = { 1, 2 }; 但是这种初始化方式的适用性非常狭窄，只有上面提到的这两种数据类型可以使用初始化列表。\n在 C++11 中，初始化列表的适用性被大大增加了，它现在可以用于任何类型对象的初始化。 请看下面的代码。\n【实例】通过初始化列表初始化对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Foo { public: Foo(int) {} private: Foo(const Foo \u0026amp;); }; int main(void) { Foo a1(123); Foo a2 = 123; //error: \u0026#39;Foo::Foo(const Foo \u0026amp;)\u0026#39; is private Foo a3 = { 123 }; Foo a4 { 123 }; int a5 = { 3 }; int a6 { 3 }; return 0; } 在上例中，a3、a4 使用了新的初始化方式来初始化对象，效果如同 a1 的直接初始化。\na5、a6 则是基本数据类型的列表初始化方式。可以看到，它们的形式都是统一的。\n这里需要注意的是，a3 虽然使用了等于号，但它仍然是列表初始化，因此，私有的拷贝构造并不会影响到它。\na4 和 a6 的写法，是 C++98/03 所不具备的。在 C++11 中，可以直接在变量名后面跟上初始化列表，来进行对象的初始化。\n这种变量名后面跟上初始化列表方法同样适用于普通数组和 POD 类型的初始化：\n1 2 3 4 5 6 7 8 9 10 int i_arr[3] { 1, 2, 3 }; //普通数组 struct A { int x; struct B { int i; int j; } b; } a { 1, { 2, 3 } }; //POD类型 在初始化时，{}前面的等于号是否书写对初始化行为没有影响。\n另外，如同读者所想的那样，new 操作符等可以用圆括号进行初始化的地方，也可以使用初始化列表：\n1 2 3 int* a = new int { 123 }; double b = double { 12.12 }; int* arr = new int[3] { 1, 2, 3 }; 指针 a 指向了一个 new 操作符返回的内存，通过初始化列表方式在内存初始化时指定了值为 123。\nb 则是对匿名对象使用列表初始化后，再进行拷贝初始化。\n这里让人眼前一亮的是 arr 的初始化方式。堆上动态分配的数组终于也可以使用初始化列表进行初始化了。\n除了上面所述的内容之外，列表初始化还可以直接使用在函数的返回值上：\n1 2 3 4 5 6 7 8 struct Foo { Foo(int, double) {} }; Foo func(void) { return { 123, 321.0 }; } 这里的 return 语句就如同返回了一个 Foo(123, 321.0)。\n由上面的这些例子可以看到，在 C++11 中使用初始化列表是非常便利的。它不仅统一了各种对象的初始化方式，而且还使代码的书写更加简单清晰。\nC++11 lambda匿名函数用法详解 lambda 源自希腊字母表中第 11 位的 λ，在计算机科学领域，它则是被用来表示一种匿名函数。所谓匿名函数，简单地理解就是没有名称的函数，又常被称为 lambda 函数或者 lambda 表达式。\n继 Python、Java、C#、PHP 等众多高级编程语言都支持 lambda 匿名函数后，C++11 标准终于引入了 lambda，本节将带领大家系统地学习 lambda 表达式的具体用法。\nlambda匿名函数的定义\n定义一个 lambda 匿名函数很简单，可以套用如下的语法格式：\n1 2 3 4 [外部变量访问方式说明符] (参数) mutable noexcept/throw() -\u0026gt; 返回值类型 { 函数体; }; 其中各部分的含义分别为：\n1. [外部变量方位方式说明符] [ ] 方括号用于向编译器表明当前是一个 lambda 表达式，其不能被省略。在方括号内部，可以注明当前 lambda 函数的函数体中可以使用哪些“外部变量”。 \u0026gt; 所谓外部变量，指的是和当前 lambda 表达式位于同一作用域内的所有局部变量。\u0026lt;/br\u0026gt; 2. (参数) 和普通函数的定义一样，lambda 匿名函数也可以接收外部传递的多个参数。和普通函数不同的是，如果不需要传递参数，可以连同 () 小括号一起省略； 3. mutable 此关键字可以省略，如果使用则之前的 () 小括号将不能省略（参数个数可以为 0）。默认情况下，对于以值传递方式引入的外部变量，不允许在 lambda 表达式内部修改它们的值（可以理解为这部分变量都是 const 常量）。而如果想修改它们，就必须使用 mutable 关键字。 \u0026gt; 对于以值传递方式引入的外部变量，lambda 表达式修改的是拷贝的那一份，并不会修改真正的外部变量； 4. noexcept/throw() 可以省略，如果使用，在之前的 () 小括号将不能省略（参数个数可以为 0）。默认情况下，lambda 函数的函数体中可以抛出任何类型的异常。而标注 noexcept 关键字，则表示函数体内不会抛出任何异常；使用 throw() 可以指定 lambda 函数内部可以抛出的异常类型。\u0026lt;/br\u0026gt; 值得一提的是，如果 lambda 函数标有 noexcept 而函数体内抛出了异常，又或者使用 throw() 限定了异常类型而函数体内抛出了非指定类型的异常，这些异常无法使用 try-catch 捕获，会导致程序执行失败（本节后续会给出实例）。 5. -\u0026gt; 返回值类型 指明 lambda 匿名函数的返回值类型。值得一提的是，如果 lambda 函数体内只有一个 return 语句，或者该函数返回 void，则编译器可以自行推断出返回值类型，此情况下可以直接省略-\u0026gt; 返回值类型。 6. 函数体 和普通函数一样，lambda 匿名函数包含的内部代码都放置在函数体中。该函数体内除了可以使用指定传递进来的参数之外，还可以使用指定的外部变量以及全局范围内的所有全局变量。 需要注意的是，外部变量会受到以值传递还是以引用传递方式引入的影响，而全局变量则不会。换句话说，在 lambda 表达式内可以使用任意一个全局变量，必要时还可以直接修改它们的值。\n其中，红色标识的参数是定义 lambda 表达式时必须写的，而绿色标识的参数可以省略。\n比如，如下就定义了一个最简单的 lambda 匿名函数：\n1 []{} 显然，此 lambda 匿名函数未引入任何外部变量（[] 内为空），也没有传递任何参数，没有指定 mutable、noexcept 等关键字，没有返回值和函数体。所以，这是一个没有任何功能的 lambda 匿名函数。\nlambda匿名函数中的[外部变量]\n对于 lambda 匿名函数的使用，令多数初学者感到困惑的就是 [外部变量] 的使用。其实很简单，无非表 1 所示的这几种编写格式。\n外部变量格式 功能 [] 空方括号表示当前 lambda 匿名函数中不导入任何外部变量。 [=] 只有一个 = 等号，表示以值传递的方式导入所有外部变量； [\u0026amp;] 只有一个 \u0026amp; 符号，表示以引用传递的方式导入所有外部变量； [val1, val2, \u0026hellip;] 表示以值传递的方式导入 val1、val2 等指定的外部变量，同时多个变量之间没有先后次序； [\u0026amp;val1, \u0026amp;val2, \u0026hellip;] 表示以引用传递的方式导入 val1、val2等指定的外部变量，多个变量之间没有前后次序； [val, \u0026amp;val2,\u0026hellip;] 以上 2 种方式还可以混合使用，变量之间没有前后次序。 [=， \u0026amp;val1,\u0026hellip;] 表示除 val1 以引用传递的方式导入外，其它外部变量都以值传递的方式导入。 [this] 表示以值传递的方式导入当前的 this 指针。 注意，单个外部变量不允许以相同的传递方式导入多次。例如 [=，val1] 中，val1 先后被以值传递的方式导入了 2 次，这是非法的。\n【例 1】lambda 匿名函数的定义和使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; using namespace std; int main() { int num[4] = {4, 2, 3, 1}; //对 a 数组中的元素进行排序 sort(num, num+4, [=](int x, int y) -\u0026gt; bool{ return x \u0026lt; y; } ); for(int n : num){ cout \u0026lt;\u0026lt; n \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } return 0; } 程序执行结果为：\n1 1 2 3 4 程序第 9 行通过调用 sort() 函数实现了对 num 数组中元素的升序排序，其中就用到了 lambda 匿名函数。而如果使用普通函数，需以如下代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; using namespace std; //自定义的升序排序规则 bool sort_up(int x,int y){ return x \u0026lt; y; } int main() { int num[4] = {4, 2, 3, 1}; //对 a 数组中的元素进行排序 sort(num, num+4, sort_up); for(int n : num){ cout \u0026lt;\u0026lt; n \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } return 0; } 此程序中 sort_up() 函数的功能和上一个程序中的 lambda 匿名函数完全相同。显然在类似的场景中，使用 lambda 匿名函数更有优势。\n除此之外，虽然 lambda 匿名函数没有函数名称，但我们仍可以为其手动设置一个名称，比如：\n1 2 3 4 5 6 7 8 9 10 #include \u0026lt;iostream\u0026gt; using namespace std; int main() { //display 即为 lambda 匿名函数的函数名 auto display = [](int a,int b) -\u0026gt; void{cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; b;}; //调用 lambda 函数 display(10,20); return 0; } 程序执行结果为：\n1 10 20 可以看到，程序中使用 auto 关键字为 lambda 匿名函数设定了一个函数名，由此我们即可在作用域内调用该函数。\n【例 2】值传递和引用传递的区别\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #include \u0026lt;iostream\u0026gt; using namespace std; //全局变量 int all_num = 0; int main() { //局部变量 int num_1 = 1; int num_2 = 2; int num_3 = 3; cout \u0026lt;\u0026lt; \u0026#34;lambda1:\\n\u0026#34;; auto lambda1 = [=]{ //全局变量可以访问甚至修改 all_num = 10; //函数体内只能使用外部变量，而无法对它们进行修改 cout \u0026lt;\u0026lt; num_1 \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; num_2 \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; num_3 \u0026lt;\u0026lt; endl; }; lambda1(); cout \u0026lt;\u0026lt; all_num \u0026lt;\u0026lt;endl; cout \u0026lt;\u0026lt; \u0026#34;lambda2:\\n\u0026#34;; auto lambda2 = [\u0026amp;]{ all_num = 100; num_1 = 10; num_2 = 20; num_3 = 30; cout \u0026lt;\u0026lt; num_1 \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; num_2 \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; num_3 \u0026lt;\u0026lt; endl; }; lambda2(); cout \u0026lt;\u0026lt; all_num \u0026lt;\u0026lt; endl; return 0; } 程序执行结果为：\n1 2 3 4 5 6 lambda1: 1 2 3 10 lambda2: 10 20 30 100 可以看到，在创建 lambda1 和 lambda2 匿名函数的作用域中，有 num_1、num_2 和 num_3 这 3 个局部变量，另外还有 all_num 全局变量。\n其中，lambda1 匿名函数是以 [=] 值传递的方式导入的局部变量，这意味着默认情况下，此函数内部无法修改这 3 个局部变量的值，但全局变量 all_num 除外。相对地，lambda2 匿名函数以 [\u0026amp;] 引用传递的方式导入这 3 个局部变量，因此在该函数的内部不就可以访问这 3 个局部变量，还可以任意修改它们。同样，也可以访问甚至修改全局变量。\n感兴趣的读者，可自行尝试在 lambda1 匿名函数中修改 num_1、num_2 或者 num_3 的值，观察编译器的报错信息。\n当然，如果我们想在 lambda1 匿名函数的基础上修改外部变量的值，可以借助 mutable 关键字，例如：\n1 2 3 4 5 6 7 8 9 auto lambda1 = [=]() mutable{ num_1 = 10; num_2 = 20; num_3 = 30; //函数体内只能使用外部变量，而无法对它们进行修改 cout \u0026lt;\u0026lt; num_1 \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; num_2 \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; num_3 \u0026lt;\u0026lt; endl; }; 由此，就可以在 lambda1 匿名函数中修改外部变量的值。但需要注意的是，这里修改的仅是 num_1、num_2、num_3 拷贝的那一份的值，真正外部变量的值并不会发生改变。\n【例 3】执行抛出异常类型\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #include \u0026lt;iostream\u0026gt; using namespace std; int main() { auto except = []()throw(int) { throw 10; }; try { except(); } catch (int) { cout \u0026lt;\u0026lt; \u0026#34;捕获到了整形异常\u0026#34;; } return 0; } 程序执行结果为：\n1 捕获到了整形异常 可以看到，except 匿名数组中指定函数体中可以抛出整形异常，因此当函数体中真正发生整形异常时，可以借助 try-catch 块成功捕获并处理。\n在此基础上，在看一下反例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \u0026lt;iostream\u0026gt; using namespace std; int main() { auto except1 = []()noexcept{ throw 100; }; auto except2 = []()throw(char){ throw 10; }; try{ except1(); except2(); }catch(int){ cout \u0026lt;\u0026lt; \u0026#34;捕获到了整形异常\u0026#34;\u0026lt;\u0026lt; endl; } return 0; } 此程序运行会直接崩溃，原因很简单，except1 匿名函数指定了函数体中不发生任何异常，但函数体中却发生了整形异常；except2 匿名函数指定函数体可能会发生字符异常，但函数体中却发生了整形异常。由于指定异常类型和真正发生的异常类型不匹配，导致 try-catch 无法捕获，最终程序运行崩溃。\n如果不使用 noexcept 或者 throw()，则 lambda 匿名函数的函数体中允许发生任何类型的异常。\nC++11非受限联合体（union） 在 C/C++ 中，联合体（Union）是一种构造数据类型。在一个联合体内，我们可以定义多个不同类型的成员，这些成员将会共享同一块内存空间。老版本的 C++ 为了和C语言保持兼容，对联合体的数据成员的类型进行了很大程度的限制，这些限制在今天看来并没有必要，因此 C++11 取消了这些限制。\nC++11 标准规定，任何非引用类型都可以成为联合体的数据成员，这种联合体也被称为非受限联合体。例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 class Student{ public: Student(bool g, int a): gender(g), age(a) {} private: bool gender; int age; }; union T{ Student s; // 含有非POD类型的成员，gcc-5.1.0 版本报错 char name[10]; }; int main(){ return 0; } 上面的代码中，因为 Student 类带有自定义的构造函数，所以是一个非 POD 类型的，这导致编译器报错。这种规定只是 C++ 为了兼容C语言而制定，然而在长期的编程实践中发现，这种规定是没有必要的。\n关于 POD 类型稍后我们会讲解，大家先不要着急。\n接下来，我们具体看一下 C++11 对 C++98 的改进。\n1.C++11 允许非 POD 类型\nC++98 不允许联合体的成员是非 POD 类型，但是 C++1 1 取消了这种限制。\nPOD 是 C++ 中一个比较重要的概念，在这里我们做一个简单介绍。POD 是英文 Plain Old Data 的缩写，用来描述一个类型的属性。\nPOD 类型一般具有以下几种特征（包括 class、union 和 struct等）: 1. 没有用户自定义的构造函数、析构函数、拷贝构造函数和移动构造函数。 2. 不能包含虚函数和虚基类。 3. 非静态成员必须声明为 public。 4. 类中的第一个非静态成员的类型与其基类不同，例如： c++ class B1{}; class B2 : B1 { B1 b; }; class B2 的第一个非静态成员 b 是基类类型，所以它不是 POD 类型。 5. 类或者结构体继承时，满足以下两种情况之一： - 派生类中有非静态成员，且只有一个仅包含静态成员的基类； - 基类有非静态成员，而派生类没有非静态成员。 c++ class B1 { static int n; }; class B2 : B1 { int n1; }; class B3 : B2 { static int n2; }; 对于 B2，派生类 B2 中有非静态成员，且只有一个仅包含静态成员的基类 B1，所以它是 POD 类型。对于 B3，基类 B2 有非静态成员，而派生类 B3 没有非静态成员，所以它也是 POD 类型。 6. 所有非静态数据成员均和其基类也符合上述规则（递归定义），也就是说 POD 类型不能包含非 POD 类型的数据。 7. 此外，所有兼容C语言的数据类型都是 POD 类型（struct、union 等不能违背上述规则）。\n2.C++11 允许联合体有静态成员\nC++11 删除了联合体不允许拥有静态成员的限制。例如：\n1 2 3 4 5 6 union U { static int func() { int n = 3; return n; } }; 需要注意的是，静态成员变量只能在联合体内定义，却不能在联合体外使用，这使得该规则很没用。\n非受限联合体的赋值注意事项\nC++11 规定，如果非受限联合体内有一个非 POD 的成员，而该成员拥有自定义的构造函数，那么这个非受限联合体的默认构造函数将被编译器删除；其他的特殊成员函数，例如默认拷贝构造函数、拷贝赋值操作符以及析构函数等，也将被删除。\n这条规则可能导致对象构造失败，请看下面的例子：\n1 2 3 4 5 6 7 8 9 10 #include \u0026lt;string\u0026gt; using namespace std; union U { string s; int n; }; int main() { U u; // 构造失败，因为 U 的构造函数被删除 return 0; } 在上面的例子中，因为 string 类拥有自定义的构造函数，所以 U 的构造函数被删除；定义 U 的类型变量 u 需要调用默认构造函数，所以 u 也就无法定义成功。\n解决上面问题的一般需要用到 placement new（稍后会讲解这个概念），代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \u0026lt;string\u0026gt; using namespace std; union U { string s; int n; public: U() { new(\u0026amp;s) string; } ~U() { s.~string(); } }; int main() { U u; return 0; } 构造时，采用 placement new 将 s 构造在其地址 \u0026amp;s 上，这里 placement new 的唯一作用只是调用了一下 string 类的构造函数。注意，在析构时还需要调用 string 类的析构函数。\nplacement new 是什么？ placement new 是 new 关键字的一种进阶用法，既可以在栈（stack）上生成对象，也可以在堆（heap）上生成对象。相对应地，我们把常见的 new 的用法称为 operator new，它只能在 heap 上生成对象。\nplacement new 的语法格式如下：\n1 new(address) ClassConstruct(…) address 表示已有内存的地址，该内存可以在栈上，也可以在堆上；ClassConstruct(…) 表示调用类的构造函数，如果构造函数没有参数，也可以省略括号。\nplacement new 利用已经申请好的内存来生成对象，它不再为对象分配新的内存，而是将对象数据放在 address 指定的内存中。在本例中，placement new 使用的是 s 的内存空间。\n非受限联合体的匿名声明和“枚举式类”\n匿名联合体是指不具名的联合体（也即没有名字的联合体），一般定义如下：\n1 2 3 union U{ union { int x; }; //此联合体为匿名联合体 }; 可以看到，联合体 U 内定义了一个不具名的联合体，该联合体包含一个 int 类型的成员变量，我们称这个联合体为匿名联合体。\n同样的，非受限联合体也可以匿名，而当非受限的匿名联合体运用于类的声明时，这样的类被称为“枚举式类”。示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #include \u0026lt;cstring\u0026gt; using namespace std; class Student{ public: Student(bool g, int a): gender(g), age(a){} bool gender; int age; }; class Singer { public: enum Type { STUDENT, NATIVE, FOREIGENR }; Singer(bool g, int a) : s(g, a) { t = STUDENT; } Singer(int i) : id(i) { t = NATIVE; } Singer(const char* n, int s) { int size = (s \u0026gt; 9) ? 9 : s; memcpy(name , n, size); name[s] = \u0026#39;\\0\u0026#39;; t = FOREIGENR; } ~Singer(){} private: Type t; union { Student s; int id; char name[10]; }; }; int main() { Singer(true, 13); Singer(310217); Singer(\u0026#34;J Michael\u0026#34;, 9); return 0; } 上面的代码中使用了一个匿名非受限联合体，它作为类 Singer 的“变长成员”来使用，这样的变长成员给类的编写带来了更大的灵活性，这是 C++98 标准中无法达到的（编译器会报member \u0026lsquo;Student Singer::::s\u0026rsquo; with constructor not allowed in union错误）。\nC++11 for循环（基于范围的循环）详解 C++ 11标准之前（C++ 98/03 标准），如果要用 for 循环语句遍历一个数组或者容器，只能套用如下结构：\n1 2 3 for (表达式 1; 表达式 2; 表达式 3) { //循环体 } 例如，下面程序演示了用上述结构遍历数组和容器的具体实现过程（实例一）:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;string.h\u0026gt; using namespace std; int main() { char arc[] = \u0026#34;http://c.biancheng.net/cplus/11/\u0026#34;; int i; //for循环遍历普通数组 for (i = 0; i \u0026lt; strlen(arc); i++) { cout \u0026lt;\u0026lt; arc[i]; } cout \u0026lt;\u0026lt; endl; vector\u0026lt;char\u0026gt;myvector(arc,arc+23); vector\u0026lt;char\u0026gt;::iterator iter; //for循环遍历 vector 容器 for (iter = myvector.begin(); iter != myvector.end(); ++iter) { cout \u0026lt;\u0026lt; *iter; } return 0; } 程序执行结果为：\n1 2 http://c.biancheng.net/cplus/11/ http://c.biancheng.net/ 此示例中，vector 为 STL 标准库提供的序列式容器，关于该容器的具体用法，可阅读《C++ STL vector容器详解》一节，这里不再做重复赘述。\n而 C++ 11 标准中，除了可以沿用前面介绍的用法外，还为 for 循环添加了一种全新的语法格式，如下所示：\n1 2 3 for (declaration : expression){ //循环体 } 其中，两个参数各自的含义如下:\ndeclaration：表示此处要定义一个变量，该变量的类型为要遍历序列中存储元素的类型。需要注意的是，C++ 11 标准中，declaration参数处定义的变量类型可以用 auto 关键字表示，该关键字可以使编译器自行推导该变量的数据类型。 expression：表示要遍历的序列，常见的可以为事先定义好的普通数组或者容器，还可以是用 {} 大括号初始化的序列。 可以看到，同 C++ 98/03 中 for 循环的语法格式相比较，此格式并没有明确限定 for 循环的遍历范围，这是它们最大的区别，即旧格式的 for 循环可以指定循环的范围，而 C++11 标准增加的 for 循环，只会逐个遍历 expression 参数处指定序列中的每个元素。\n下面程序演示了如何用 C++ 11 标准中的 for 循环遍历实例一定义的 arc 数组和 myvector 容器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; using namespace std; int main() { char arc[] = \u0026#34;http://c.biancheng.net/cplus/11/\u0026#34;; //for循环遍历普通数组 for (char ch : arc) { cout \u0026lt;\u0026lt; ch; } cout \u0026lt;\u0026lt; \u0026#39;!\u0026#39; \u0026lt;\u0026lt; endl; vector\u0026lt;char\u0026gt;myvector(arc, arc + 23); //for循环遍历 vector 容器 for (auto ch : myvector) { cout \u0026lt;\u0026lt; ch; } cout \u0026lt;\u0026lt; \u0026#39;!\u0026#39;; return 0; } 程序执行结果为：\n1 2 http://c.biancheng.net/cplus/11/ ! http://c.biancheng.net/! 这里有以下 2 点需要说明： 1. 程序中在遍历 myvector 容器时，定义了 auto 类型的 ch 变量，当编译器编译程序时，会通过 myvector 容器中存储的元素类型自动推导出 ch 为 char 类型。注意，这里的 ch 不是迭代器类型，而表示的是 myvector 容器中存储的每个元素。 2. 仔细观察程序的输出结果，其中第一行输出的字符串和 “!” 之间还输出有一个空格，这是因为新格式的 for 循环在遍历字符串序列时，不只是遍历到最后一个字符，还会遍历位于该字符串末尾的 ‘\\0’（字符串的结束标志）。之所以第二行输出的字符串和 “!” 之间没有空格，是因为 myvector 容器中没有存储 ‘\\0’。\n除此之外，新语法格式的 for 循环还支持遍历用{ }大括号初始化的列表，比如：\n1 2 3 4 5 6 7 8 #include \u0026lt;iostream\u0026gt; using namespace std; int main() { for (int num : {1, 2, 3, 4, 5}) { cout \u0026lt;\u0026lt; num \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } return 0; } 程序执行结果为：\n1 1 2 3 4 5 另外值得一提的是，在使用新语法格式的 for 循环遍历某个序列时，如果需要遍历的同时修改序列中元素的值，实现方案是在 declaration 参数处定义引用形式的变量。举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; using namespace std; int main() { char arc[] = \u0026#34;abcde\u0026#34;; vector\u0026lt;char\u0026gt;myvector(arc, arc + 5); //for循环遍历并修改容器中各个字符的值 for (auto \u0026amp;ch : myvector) { ch++; } //for循环遍历输出容器中各个字符 for (auto ch : myvector) { cout \u0026lt;\u0026lt; ch; } return 0; } 程序执行结果为：\n1 bcdef 此程序中先后使用了 2 个新语法格式的 for 循环，其中前者用于修改 myvector 容器中各个元素的值，后者用于输出修改后的 myvector 容器中的各个元素。\n有读者可能会问，declaration 参数既可以定义普通形式的变量，也可以定义引用形式的变量，应该如何选择呢？其实很简单，如果需要在遍历序列的过程中修改器内部元素的值，就必须定义引用形式的变量；反之，建议定义const \u0026amp;（常引用）形式的变量（避免了底层复制变量的过程，效率更高），也可以定义普通变量。\nC++11 for循环使用注意事项 《C++11 for循环》一节已经详细介绍了 C++11 标准中 for 循环的基本用法。在此基础上，本节将介绍一些 for 循环的使用注意事项，帮助读者更准确高效地使用基于范围的 for 循环。\n首先需要明确的一点是，当使用 for 循环遍历某个序列时，无论该序列是普通数组、容器还是用{ }大括号包裹的初始化列表，遍历序列的变量都表示的是当前序列中的各个元素。 举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; using namespace std; int main() { //for循环遍历初始化列表 for (int ch : {1,2,3,4,5}) { cout \u0026lt;\u0026lt; ch; } cout \u0026lt;\u0026lt; endl; //for循环遍历普通数组 char arc[] = \u0026#34;http://c.biancheng.net/cplus/11/\u0026#34;; for (char ch : arc) { cout \u0026lt;\u0026lt; ch; } cout \u0026lt;\u0026lt; endl; //for循环遍历 vector 容器 vector\u0026lt;char\u0026gt;myvector(arc, arc + 23); for (auto ch : myvector) { cout \u0026lt;\u0026lt; ch; } return 0; } 程序执行结果为：\n1 2 3 12345 http://c.biancheng.net/cplus/11/ http://c.biancheng.net/ 上面程序演示了用 for 循环遍历 3 种序列的过程，其中前两种情况很容易理解，但对于用基于范围的 for 循环遍历容器中的元素，很多读者会将 ch 误认为指向各个元素的迭代器，其实不然，它表示的仍是容器中的各个元素。\n为了加深读者对遍历容器的理解，下面程序以 map 容器为例，再举一个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \u0026lt;iostream\u0026gt; #include \u0026lt;map\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; int main() { map\u0026lt;string, string\u0026gt;mymap{ {\u0026#34;C++11\u0026#34;,\u0026#34;http://c.biancheng.net/cplus/11/\u0026#34;}, {\u0026#34;Python\u0026#34;,\u0026#34;http://c.biancheng.net/python/\u0026#34;}, {\u0026#34;Java\u0026#34;,\u0026#34;http://c.biancheng.net/java/\u0026#34;} }; for (pair\u0026lt;string,string\u0026gt; ch : mymap) { cout \u0026lt;\u0026lt; ch.first \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; ch.second \u0026lt;\u0026lt; endl; } return 0; } 程序执行结果为：\n1 2 3 C++11 http://c.biancheng.net/cplus/11/ Java http://c.biancheng.net/java/ Python http://c.biancheng.net/python/ 要知道，map 容器中存储的不再是普通数据类型的数据，而是 pair 类型的数据，因此程序中在使用基于范围的 for 循环遍历 map 容器时，定义的是 pair 类型的变量。\n值得初学者注意的一点是，基于范围的 for 循环也可以直接遍历某个字符串，比如：\n1 2 3 for (char ch : \u0026#34;http://c.biancheng.net/cplus/11/\u0026#34;) { cout \u0026lt;\u0026lt; ch; } 前面提到，普通数组可以作为被遍历的序列。拿此程序中的字符串来说，其数据类型为const char[33]，即在编译器看来字符串就是一个普通数组，因此完全可以直接作为被遍历的序列。\n当然，基于范围的 for 循环也可以遍历 string 类型的字符串，这种情况下冒号前定义 char 类型的变量即可。\n总的来说，基于范围的 for 循环可以遍历普通数组、string字符串、容器以及初始化列表。除此之外，for 循环冒号后还可以放置返回 string 字符串以及容器对象的函数，比如： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; string str = \u0026#34;http://c.biancheng.net/cplus/11/\u0026#34;; vector\u0026lt;int\u0026gt; myvector = { 1,2,3,4,5 }; string retStr() { return str; } vector\u0026lt;int\u0026gt; retVector() { return myvector; } int main() { //遍历函数返回的 string 字符串 for (char ch : retStr()) { cout \u0026lt;\u0026lt; ch; } cout \u0026lt;\u0026lt; endl; //遍历函数返回的 vector 容器 for (int num : retVector()) { cout \u0026lt;\u0026lt; num \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } return 0; } 程序执行结果为：\n1 2 http://c.biancheng.net/cplus/11/ 1 2 3 4 5 注意，基于范围的 for 循环不支持遍历函数返回的以指针形式表示的数组，比如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 //错误示例 #include \u0026lt;iostream\u0026gt; using namespace std; char str[] = \u0026#34;http://c.biancheng.net/cplus/11/\u0026#34;; char* retStr() { return str; } int main() { for (char ch : retStr()) //直接报错 { cout \u0026lt;\u0026lt; ch; } return 0; } 原因很简单，此格式的 for 循环只能遍历有明确范围的一组数据，上面程序中 retStr() 函数返回的是指针变量，遍历范围并未明确指明，所以编译失败。\n值得一提的是，当基于范围的 for 循环遍历的是某函数返回的 string 对象或者容器时，整个遍历过程中，函数只会执行一次。 举个例子:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; string str= \u0026#34;http://c.biancheng.net/cplus/11/\u0026#34;; string retStr() { cout \u0026lt;\u0026lt; \u0026#34;retStr:\u0026#34; \u0026lt;\u0026lt; endl; return str; } int main() { //遍历函数返回的 string 字符串 for (char ch : retStr()) { cout \u0026lt;\u0026lt; ch; } return 0; } 程序执行结果为：\n1 2 retStr: http://c.biancheng.net/cplus/11/ 借助执行结果不难分析出，整个 for 循环遍历 str 字符串对象的过程中，retStr() 函数仅在遍历开始前执行了 1 次。\n系统学过 STL 标准库的读者应该知道，基于关联式容器（包括哈希容器）底层存储机制的限制： 不允许修改 map、unordered_map、multimap 以及 unordered_multimap 容器存储的键的值； 不允许修改 set、unordered_set、multiset 以及 unordered_multiset 容器中存储的元素的值。 关于以上各个容器的具体用法，读者可猛击《C++ STL教程》进行系统学习。\n因此，当使用基于范围的 for 循环遍历此类型容器时，切勿修改容器中不允许被修改的数据部分，否则会导致程序的执行出现各种 Bug。\n另外，基于范围的 for 循环完成对容器的遍历，其底层也是借助容器的迭代器实现的。举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; int main(void) { std::vector\u0026lt;int\u0026gt;arr = { 1, 2, 3, 4, 5 }; for (auto val : arr) { std::cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; std::endl; arr.push_back(10); //向容器中添加元素 } return 0; } 程序执行结果可能为（输出结果不唯一）：\n1 2 3 4 5 1 -572662307 -572662307 4 5 可以看到，程序的执行结果并不是我们想要的。就是因为在 for 循环遍历 arr 容器的同时向该容器尾部添加了新的元素（对 arr 容器进行了扩增），致使遍历容器所使用的迭代器失效，整个遍历过程出现错误。\n如果读者想要彻底搞清楚程序执行失败的原因，读了解 vector 容器的底层存储机制，可阅读《C++ vector容器底层实现机制》一文。\n因此，在使用基于范围的 for 循环遍历容器时，应避免在循环体中修改容器存储元素的个数。\nC++11 constexpr：验证是否为常量表达式（长篇神文） constexpr 是 C++ 11 标准新引入的关键字，不过在讲解其具体用法和功能之前，读者需要先搞清楚 C++ 常量表达式的含义。\n所谓常量表达式，指的就是由多个（≥1）常量组成的表达式。换句话说，如果表达式中的成员都是常量，那么该表达式就是一个常量表达式。这也意味着，常量表达式一旦确定，其值将无法修改。\n实际开发中，我们经常会用到常量表达式。以定义数组为例，数组的长度就必须是一个常量表达式:\n1 2 3 4 5 6 7 // 1) int url[10];//正确 // 2) int url[6 + 4];//正确 // 3) int length = 6; int url[length];//错误，length是变量 上述代码演示了 3 种定义 url 数组的方式，其中第 1、2 种定义 url 数组时，长度分别为 10 和 6+4，显然它们都是常量表达式，可以用于表示数组的长度；第 3 种 url 数组的长度为 length，它是变量而非常量，因此不是一个常量表达式，无法用于表示数组的长度。\n常量表达式的应用场景还有很多，比如匿名枚举、switch-case 结构中的 case 表达式等，感兴趣的读者可自行编码测试，这里不再过多举例。\n我们知道，C++ 程序的执行过程大致要经历编译、链接、运行这 3 个阶段。值得一提的是，常量表达式和非常量表达式的计算时机不同，非常量表达式只能在程序运行阶段计算出结果；而常量表达式的计算往往发生在程序的编译阶段，这可以极大提高程序的执行效率，因为表达式只需要在编译阶段计算一次，节省了每次程序运行时都需要计算一次的时间。\n对于用 C++ 编写的程序，性能往往是永恒的追求。那么在实际开发中，如何才能判定一个表达式是否为常量表达式，进而获得在编译阶段即可执行的“特权”呢？除了人为判定外，C++11 标准还提供有 constexpr 关键字。\nconstexpr 关键字的功能是使指定的常量表达式获得在程序编译阶段计算出结果的能力，而不必等到程序运行阶段。C++ 11 标准中，constexpr 可用于修饰普通变量、函数（包括模板函数）以及类的构造函数。\n注意，获得在编译阶段计算出结果的能力，并不代表 constexpr 修饰的表达式一定会在程序编译阶段被执行，具体的计算时机还是编译器说了算。\nconstexpr修饰普通变量\nC++11 标准中，定义变量时可以用 constexpr 修饰，从而使该变量获得在编译阶段即可计算出结果的能力。\n值得一提的是，使用 constexpr 修改普通变量时，变量必须经过初始化且初始值必须是一个常量表达式。举个例子：\n1 2 3 4 5 6 7 8 9 #include \u0026lt;iostream\u0026gt; using namespace std; int main() { constexpr int num = 1 + 2 + 3; int url[num] = {1,2,3,4,5,6}; couts\u0026lt;\u0026lt; url[1] \u0026lt;\u0026lt; endl; return 0; } 程序执行结果为：\n1 2 读者可尝试将 constexpr 删除，此时编译器会提示“url[num] 定义中 num 不可用作常量”。\n可以看到，程序第 6 行使用 constexpr 修饰 num 变量，同时将 “1+2+3” 这个常量表达式赋值给 num。由此，编译器就可以在编译时期对 num 这个表达式进行计算，因为 num 可以作为定义数组时的长度。\n有读者可能发现，将此示例程序中的 constexpr 用 const 关键字替换也可以正常执行，这是因为 num 的定义同时满足“num 是 const 常量且使用常量表达式为其初始化”这 2 个条件，由此编译器会认定 num 是一个常量表达式。\n注意，const 和 constexpr 并不相同，关于它们的区别，我们会在下一节做详细讲解。\n另外需要重点提出的是，当常量表达式中包含浮点数时，考虑到程序编译和运行所在的系统环境可能不同，常量表达式在编译阶段和运行阶段计算出的结果精度很可能会受到影响，因此 C++11 标准规定，浮点常量表达式在编译阶段计算的精度要至少等于（或者高于）运行阶段计算出的精度。\nconstexpr修饰函数\nconstexpr 还可以用于修饰函数的返回值，这样的函数又称为“常量表达式函数”。\n注意，constexpr 并非可以修改任意函数的返回值。换句话说，一个函数要想成为常量表达式函数，必须满足如下 4 个条件。\n整个函数的函数体中，除了可以包含 using 指令、typedef 语句以及 static_assert 断言外，只能包含一条 return 返回语句。 举个例子：\n1 2 3 4 constexpr int display(int x) { int ret = 1 + 2 + x; return ret; } 注意，这个函数是无法通过编译的，因为该函数的返回值用 constexpr 修饰，但函数内部包含多条语句。\n如下是正确的定义 display() 常量表达式函数的写法：\n1 2 3 4 constexpr int display(int x) { //可以添加 using 执行、typedef 语句以及 static_assert 断言 return 1 + 2 + x; } 可以看到，display() 函数的返回值是用 constexpr 修饰的 int 类型值，且该函数的函数体中只包含一个 return 语句。\n该函数必须有返回值，即函数的返回值类型不能是 void。 举个例子：\n1 2 3 4 constexpr void display() { //函数体 } 像上面这样定义的返回值类型为 void 的函数，不属于常量表达式函数。原因很简单，因为通过类似的函数根本无法获得一个常量。\n函数在使用之前，必须有对应的定义语句。我们知道，函数的使用分为“声明”和“定义”两部分，普通的函数调用只需要提前写好该函数的声明部分即可（函数的定义部分可以放在调用位置之后甚至其它文件中），但常量表达式函数在使用前，必须要有该函数的定义。 举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #include \u0026lt;iostream\u0026gt; using namespace std; //普通函数的声明 int noconst_dis(int x); //常量表达式函数的声明 constexpr int display(int x); //常量表达式函数的定义 constexpr int display(int x){ return 1 + 2 + x; } int main() { //调用常量表达式函数 int a[display(3)] = { 1,2,3,4 }; cout \u0026lt;\u0026lt; a[2] \u0026lt;\u0026lt; endl; //调用普通函数 cout \u0026lt;\u0026lt; noconst_dis(3) \u0026lt;\u0026lt; endl; return 0; } //普通函数的定义 int noconst_dis(int x) { return 1 + 2 + x; } 程序执行结果为：\n1 2 3 6 读者可自行将 display() 常量表达式函数的定义调整到 main() 函数之后，查看编译器的报错信息。\n可以看到，普通函数在调用时，只需要保证调用位置之前有相应的声明即可；而常量表达式函数则不同，调用位置之前必须要有该函数的定义，否则会导致程序编译失败。\nreturn 返回的表达式必须是常量表达式，举个例子： 1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;iostream\u0026gt; using namespace std; int num = 3; constexpr int display(int x){ return num + x; } int main() { //调用常量表达式函数 int a[display(3)] = { 1,2,3,4 }; return 0; } 该程序无法通过编译，编译器报“display(3) 的结果不是常量”的异常。\n常量表达式函数的返回值必须是常量表达式的原因很简单，如果想在程序编译阶段获得某个函数返回的常量，则该函数的 return 语句中就不能包含程序运行阶段才能确定值的变量。\n注意，在常量表达式函数的 return 语句中，不能包含赋值的操作（例如 return x=1 在常量表达式函数中不允许的）。另外，用 constexpr 修改函数时，函数本身也是支持递归的，感兴趣的读者可自行尝试编码测试。\nconstexpr修饰类的构造函数\n对于 C++ 内置类型的数据，可以直接用 constexpr 修饰，但如果是自定义的数据类型（用 struct 或者 class 实现），直接用 constexpr 修饰是不行的。\n举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 #include \u0026lt;iostream\u0026gt; using namespace std; //自定义类型的定义 constexpr struct myType { const char* name; int age; //其它结构体成员 }; int main() { constexpr struct myType mt { \u0026#34;zhangsan\u0026#34;, 10 }; cout \u0026lt;\u0026lt; mt.name \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; mt.age \u0026lt;\u0026lt; endl; return 0; } 此程序是无法通过编译的，编译器会抛出“constexpr不能修饰自定义类型”的异常。\n当我们想自定义一个可产生常量的类型时，正确的做法是在该类型的内部添加一个常量构造函数。例如，修改上面的错误示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #include \u0026lt;iostream\u0026gt; using namespace std; //自定义类型的定义 struct myType { constexpr myType(char *name,int age):name(name),age(age){}; const char* name; int age; //其它结构体成员 }; int main() { constexpr struct myType mt { \u0026#34;zhangsan\u0026#34;, 10 }; cout \u0026lt;\u0026lt; mt.name \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; mt.age \u0026lt;\u0026lt; endl; return 0; } 程序执行结果为：\n1 zhangsan 10 可以看到，在 myType 结构体中自定义有一个构造函数，借助此函数，用 constexpr 修饰的 myType 类型的 my 常量即可通过编译。\n注意，constexpr 修饰类的构造函数时，要求该构造函数的函数体必须为空，且采用初始化列表的方式为各个成员赋值时，必须使用常量表达式。\n前面提到，constexpr 可用于修饰函数，而类中的成员方法完全可以看做是“位于类这个命名空间中的函数”，所以 constexpr 也可以修饰类中的成员函数，只不过此函数必须满足前面提到的 4 个条件。\n举个例子:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #include \u0026lt;iostream\u0026gt; using namespace std; //自定义类型的定义 class myType { public: constexpr myType(const char *name,int age):name(name),age(age){}; constexpr const char * getname(){ return name; } constexpr int getage(){ return age; } private: const char* name; int age; //其它结构体成员 }; int main() { constexpr struct myType mt { \u0026#34;zhangsan\u0026#34;, 10 }; constexpr const char * name = mt.getname(); constexpr int age = mt.getage(); cout \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; age \u0026lt;\u0026lt; endl; return 0; } 程序执行结果为：\n1 zhangsan 10 constexpr修饰模板函数\nC++11 语法中，constexpr 可以修饰模板函数，但由于模板中类型的不确定性，因此模板函数实例化后的函数是否符合常量表达式函数的要求也是不确定的。\n针对这种情况下，C++11 标准规定，如果 constexpr 修饰的模板函数实例化结果不满足常量表达式函数的要求，则 constexpr 会被自动忽略，即该函数就等同于一个普通函数。\n举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include \u0026lt;iostream\u0026gt; using namespace std; //自定义类型的定义 struct myType { const char* name; int age; //其它结构体成员 }; //模板函数 template\u0026lt;typename T\u0026gt; constexpr T dispaly(T t){ return t; } int main() { struct myType stu{\u0026#34;zhangsan\u0026#34;,10}; //普通函数 struct myType ret = dispaly(stu); cout \u0026lt;\u0026lt; ret.name \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; ret.age \u0026lt;\u0026lt; endl; //常量表达式函数 constexpr int ret1 = dispaly(10); cout \u0026lt;\u0026lt; ret1 \u0026lt;\u0026lt; endl; return 0; } 程序执行结果为:\n1 2 zhangsan 10 10 可以看到，示例程序中定义了一个模板函数 display()，但由于其返回值类型未定，因此在实例化之前无法判断其是否符合常量表达式函数的要求：\n第 20 行代码处，当模板函数中以自定义结构体 myType 类型进行实例化时，由于该结构体中没有定义常量表达式构造函数，所以实例化后的函数不是常量表达式函数，此时 constexpr 是无效的； 第 23 行代码处，模板函数的类型 T 为 int 类型，实例化后的函数符合常量表达式函数的要求，所以该函数的返回值就是一个常量表达式。 C++11 constexpr和const的区别 《C++11 constexpr》一节中，详细讲解了 constexpr 关键字的功能和用法。一些读者在学习过程中，经常会把 const 和 constexpr 搞混，不知道什么时候用 const，什么时候用 constexpr。本节就带领大家对 const 和 constexpr 做系统地区分。\n我们知道，constexpr 是 C++ 11 标准新添加的关键字，在此之前（C++ 98/03标准）只有 const 关键字，其在实际使用中经常会表现出两种不同的语义。举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \u0026lt;iostream\u0026gt; #include \u0026lt;array\u0026gt; using namespace std; void dis_1(const int x){ //错误，x是只读的变量 array \u0026lt;int,x\u0026gt; myarr{1,2,3,4,5}; cout \u0026lt;\u0026lt; myarr[1] \u0026lt;\u0026lt; endl; } void dis_2(){ const int x = 5; array \u0026lt;int,x\u0026gt; myarr{1,2,3,4,5}; cout \u0026lt;\u0026lt; myarr[1] \u0026lt;\u0026lt; endl; } int main() { dis_1(5); dis_2(); } 可以看到，dis_1() 和 dis_2() 函数中都包含一个 const int x，但 dis_1() 函数中的 x 无法完成初始化 array 容器的任务，而 dis_2() 函数中的 x 却可以。\n这是因为，dis_1() 函数中的“const int x”只是想强调 x 是一个只读的变量，其本质仍为变量，无法用来初始化 array 容器；而 dis_2() 函数中的“const int x”，表明 x 是一个只读变量的同时，x 还是一个值为 5 的常量，所以可以用来初始化 array 容器。\nC++ 11标准中，为了解决 const 关键字的双重语义问题，保留了 const 表示“只读”的语义，而将“常量”的语义划分给了新添加的 constexpr 关键字。因此 C++11 标准中，建议将 const 和 constexpr 的功能区分开，即凡是表达“只读”语义的场景都使用 const，表达“常量”语义的场景都使用 constexpr。\n在上面的实例程序中，dis_2() 函数中使用 const int x 是不规范的，应使用 constexpr 关键字。\n有读者可能会问，“只读”不就意味着其不能被修改吗？答案是否定的，“只读”和“不允许被修改”之间并没有必然的联系，举个例子：\n1 2 3 4 5 6 7 8 9 10 #include \u0026lt;iostream\u0026gt; using namespace std; int main() { int a = 10; const int \u0026amp; con_b = a; cout \u0026lt;\u0026lt; con_b \u0026lt;\u0026lt; endl; a = 20; cout \u0026lt;\u0026lt; con_b \u0026lt;\u0026lt; endl; } 程序执行结果为：\n1 2 10 20 可以看到，程序中用 const 修饰了 con_b 变量，表示该变量“只读”，即无法通过变量自身去修改自己的值。但这并不意味着 con_b 的值不能借助其它变量间接改变，通过改变 a 的值就可以使 con_b 的值发生变化。\n在大部分实际场景中，const 和 constexpr 是可以混用的，例如：\n1 2 const int a = 5 + 4; constexpr int a = 5 + 4; 它们是完全等价的，都可以在程序的编译阶段计算出结果。但在某些场景中，必须明确使用 constexpr，例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #include \u0026lt;iostream\u0026gt; #include \u0026lt;array\u0026gt; using namespace std; constexpr int sqr1(int arg){ return arg*arg; } const int sqr2(int arg){ return arg*arg; } int main() { array\u0026lt;int,sqr1(10)\u0026gt; mylist1;//可以，因为sqr1时constexpr函数 array\u0026lt;int,sqr2(10)\u0026gt; mylist1;//不可以，因为sqr2不是constexpr函数 return 0; } 其中，因为 sqr2() 函数的返回值仅有 const 修饰，而没有用更明确的 constexpr 修饰，导致其无法用于初始化 array 容器（只有常量才能初始化 array 容器）。\n总的来说在 C++ 11 标准中，const 用于为修饰的变量添加“只读”属性；而 constexpr 关键字则用于指明其后是一个常量（或者常量表达式），编译器在编译程序时可以顺带将其结果计算出来，而无需等到程序运行阶段，这样的优化极大地提高了程序的执行效率。\nC++11 long long超长整形详解 C++ 11 标准中，基于整数大小的考虑，共提供了如表 1 所示的这些数据类型。与此同时，标准中还明确限定了各个数据类型最少占用的位数。\n整数类型 等价类型 C++11标准规定占用最少位数 |short|short int(有符号短整型)|至少 16 位（2 个字节）| |signed short||| |signed short int||| |unsigned short|unsigned short int（无符号短整型）|| |unsigned short int||| |int|int(有符号整形)|至少 16 位（2 个字节）| |signed||| |signed int||| |unsigned|unsigned int(无符号整形)|| |unsigned int||| |long|long int(有符号长整形)|至少 32 位（4 个字节）| |long int||| |signed long||| |signed long int||| |unsigned long|unsigned long int(无符号长整形)|| |unsigned long int||| |long long (C++11)|long long int（有符号超长整形）|至少 64 位(8 个字节)| |long long int (C++11)||| |signed long long (C++11)||| |signed long long int (C++11)||| |unsigned long long (C++11)|unsigned long long int（无符号超长整型）|| |unsigned long long int (C++11)|||\nC++11 标准规定，每种整数类型必须同时具备有符号（signed）和无符号（unsigned）两种类型，且每种具体的有符号整形和无符号整形所占用的存储空间（也就是位数）必须相同。注意，C++11 标准中只限定了每种类型最少占用多少存储空间，不同的平台可以占用不同的存储空间。\n在表 1 罗列的这些数据类型中，long long 超长整型是 C++ 11 标准新添加的，接下来就对该整数类型做具体的介绍。\n说道 C++ 标准委员会将 long long 整形写入 C++ 11 标准中，其实早在 1995 年，就有人提议将 long long 整形写入 C++ 98 标准，但被委员会拒绝了。而后 long long 整形被 C99 标准（C语言标准之一）采纳，并逐渐被很多编译器支持，于是 C++ 标准委员会重新决定将 long long 整形写入 C++ 11 标准中。\n如同 long 类型整数需明确标注 “L” 或者 “l” 后缀一样，要使用 long long 类型的整数，也必须标注对应的后缀：\n对于有符号 long long 整形，后缀用 “LL” 或者 “ll” 标识。例如，“10LL” 就表示有符号超长整数 10； 对于无符号 long long 整形，后缀用 “ULL”、“ull”、“Ull” 或者 “uLL” 标识。例如，“10ULL” 就表示无符号超长整数 10； 如果不添加任何标识，则所有的整数都会默认为 int 类型。\n对于任意一种数据类型，读者可能更关心的是此类型的取值范围。对于 long long 类型来说，如果想了解当前平台上 long long 整形的取值范围，可以使用\u0026lt;climits\u0026gt;头文件中与 long long 整形相关的 3 个宏，分别为 LLONG_MIN、LLONG_MAX 和 ULLONG_MIN：\n1.LLONG_MIN：代表当前平台上最小的 long long 类型整数； 2.LLONG_MAX：代表当前平台上最大的 long long 类型整数； 3.ULLONG_MIN：代表当前平台上最大的 unsigned long long 类型整数（无符号超长整型的最小值为 0）；\n举个例子：\n1 2 3 4 5 6 7 8 9 10 11 #include \u0026lt;iostream\u0026gt; #include \u0026lt;iomanip\u0026gt; #include \u0026lt;climits\u0026gt; using namespace std; int main() { cout \u0026lt;\u0026lt;\u0026#34;long long最大值：\u0026#34; \u0026lt;\u0026lt; LLONG_MIN \u0026lt;\u0026lt;\u0026#34; \u0026#34;\u0026lt;\u0026lt; hex \u0026lt;\u0026lt; LLONG_MIN \u0026lt;\u0026lt;\u0026#34;\\n\u0026#34;; cout \u0026lt;\u0026lt; dec \u0026lt;\u0026lt;\u0026#34;long long最小值：\u0026#34; \u0026lt;\u0026lt; LLONG_MAX \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; hex \u0026lt;\u0026lt; LLONG_MAX \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; cout \u0026lt;\u0026lt; dec \u0026lt;\u0026lt; \u0026#34;unsigned long long最大值：\u0026#34; \u0026lt;\u0026lt; ULLONG_MAX \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; hex \u0026lt;\u0026lt; ULLONG_MAX; return 0; } 程序执行结果为（不唯一）：\nlong long最大值：-9223372036854775808 8000000000000000 long long最小值：9223372036854775807 7fffffffffffffff unsigned long long最大值：18446744073709551615 ffffffffffffffff\n关于整形在内存中到底是如何存储的，读者可阅读《整数在内存中是如何存储的，为什么它堪称天才般的设计》一节。\n此程序中，输出了各最大值和最小值对应的十六进制，显然在当前平台（Windows10 64位操作系统）上，long long 超长整型占用 64 位（也就是 16 个字节）的存储空间。读者可自行在自己的机器上运行此段代码，即可轻松得知 long long 类型在自己机器上所占用的字节数。\nC++11右值引用（一看即懂） (《C++11是什么》)[http://c.biancheng.net/view/7751.html]一节中提到，在 C++98/03 标准的基础上，C++11 标准对 C++ 语言增添了约 140 个新特性。本节要讲的右值引用就是众多新特性中的一个，同时也是最重要的特性之一。\n很多初学者都感觉右值引用晦涩难懂，其实不然。右值引用只不过是一种新的 C++ 语法，真正理解起来有难度的是基于右值引用引申出的 2 种 C++ 编程技巧，分别为移动语义和完美转发。本节先给读者讲解什么是右值引用以及它的基本用法，至于移动语义和完美转发则放到后续章节讲解。\n在 C++ 或者 C 语言中，一个表达式（可以是字面量、变量、对象、函数的返回值等）根据其使用场景不同，分为左值表达式和右值表达式。确切的说 C++ 中左值和右值的概念是从 C 语言继承过来的。\n值得一提的是，左值的英文简写为“lvalue”，右值的英文简写为“rvalue”。很多人认为它们分别是\u0026quot;left value\u0026rdquo;、“right value” 的缩写，其实不然。lvalue 是“loactor value”的缩写，可意为存储在内存中、有明确存储地址（可寻址）的数据，而 rvalue 译为 “read value”，指的是那些可以提供数据值的数据（不一定可以寻址，例如存储于寄存器中的数据）。\n通常情况下，判断某个表达式是左值还是右值，最常用的有以下 2 种方法。\n可位于赋值号（=）左侧的表达式就是左值；反之，只能位于赋值号右侧的表达式就是右值。举个例子: 1 2 3 4 5 6 7 int a = 5; 5 = a; //错误，5 不能为左值 其中，变量 a 就是一个左值，而字面量 5 就是一个右值。值得一提的是，C++ 中的左值也可以当做右值使用，例如： int b = 10; // b 是一个左值 a = b; // a、b 都是左值，只不过将 b 可以当做右值使用 有名称的、可以获取到存储地址的表达式即为左值；反之则是右值。 以上面定义的变量 a、b 为例，a 和 b 是变量名，且通过 \u0026amp;a 和 \u0026amp;b 可以获得他们的存储地址，因此 a 和 b 都是左值；反之，字面量 5、10，它们既没有名称，也无法获取其存储地址（字面量通常存储在寄存器中，或者和代码存储在一起），因此 5、10 都是右值。\n注意，以上 2 种判定方法只适用于大部分场景。由于本节主要讲解右值引用，因此这里适可而止，不再对 C++ 左值和右值做深度剖析，感兴趣的读者可自行研究。\nC++右值引用\n前面提到，其实 C++98/03 标准中就有引用，使用 “\u0026amp;” 表示。但此种引用方式有一个缺陷，即正常情况下只能操作 C++ 中的左值，无法对右值添加引用。举个例子：\n1 2 3 int num = 10; int \u0026amp;b = num; //正确 int \u0026amp;c = 10; //错误 如上所示，编译器允许我们为 num 左值建立一个引用，但不可以为 10 这个右值建立引用。因此，C++98/03 标准中的引用又称为左值引用。\n注意，虽然 C++98/03 标准不支持为右值建立非常量左值引用，但允许使用常量左值引用操作右值。也就是说，常量左值引用既可以操作左值，也可以操作右值，例如：\n1 2 3 int num = 10; const int \u0026amp;b = num; const int \u0026amp;c = 10; 我们知道，右值往往是没有名称的，因此要使用它只能借助引用的方式。这就产生一个问题，实际开发中我们可能需要对右值进行修改（实现移动语义时就需要），显然左值引用的方式是行不通的。\n为此，C++11 标准新引入了另一种引用方式，称为右值引用，用 “\u0026amp;\u0026amp;” 表示。\n话说，C++标准委员会在选定右值引用符号时，既希望能选用现有 C++ 内部已有的符号，还不能与 C++ 98 /03 标准产生冲突，最终选定了 2 个 ‘\u0026amp;’ 表示右值引用。\n需要注意的，和声明左值引用一样，右值引用也必须立即进行初始化操作，且只能使用右值进行初始化，比如：\n1 2 3 int num = 10; const int \u0026amp;b = num; const int \u0026amp;c = 10; 和常量左值引用不同的是，右值引用还可以对右值进行修改。例如：\n1 2 3 int num = 10; //int \u0026amp;\u0026amp; a = num; //右值引用不能初始化为左值 int \u0026amp;\u0026amp; a = 10; 程序输出结果为 100。\n另外值得一提的是，C++ 语法上是支持定义常量右值引用的，例如：\n1 2 3 int \u0026amp;\u0026amp; a = 10; a = 100; cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; 但这种定义出来的右值引用并无实际用处。一方面，右值引用主要用于移动语义和完美转发，其中前者需要有修改右值的权限；其次，常量右值引用的作用就是引用一个不可修改的右值，这项工作完全可以交给常量左值引用完成。\n学到这里，一些读者可能无法记清楚左值引用和右值引用各自可以引用左值还是右值，这里给大家一张表格，方便大家记忆：\n引用类型 可以引用的值类型 使用场景 非常量左值 常量左值 非常量右值 常量右值 非常量左值引用 Y N N N 无 常量左值引用 Y Y Y Y 常用于类中构建拷贝构造函数 非常量右值引用 N N Y N 移动语义、完美转发 常量右值引用 N N Y Y 无实际用途 表中，Y 表示支持，N 表示不支持。\n其实，C++11 标准中对右值做了更细致的划分，分别称为纯右值（Pure value，简称 pvalue）和将亡值（eXpiring value，简称 xvalue ）。其中纯右值就是 C++98/03 标准中的右值（本节中已经做了大篇幅的讲解），而将亡值则指的是和右值引用相关的表达式（比如某函数返回的 T \u0026amp;\u0026amp; 类型的表达式）。对于纯右值和将亡值，都属于右值，读者知道即可，不必深究。\nC++11移动构造函数的功能和用法 《C++11右值引用》一节中，给读者详细介绍了 C++ 右值引用的含义和用法，同时还提到“右值引用主要用于实现移动（move）语义和完美转发”。有关完美转发，后续章节会做详细介绍，本节主要讲解移动语义的含义以及实现它的方式。\nC++11移动语义是什么\n在 C++ 11 标准之前（C++ 98/03 标准中），如果想用其它对象初始化一个同类的新对象，只能借助类中的复制（拷贝）构造函数。通过《C++拷贝构造函数》一节的学习我们知道，拷贝构造函数的实现原理很简单，就是为新对象复制一份和其它对象一模一样的数据。\n需要注意的是，当类中拥有指针类型的成员变量时，拷贝构造函数中需要以深拷贝（而非浅拷贝）的方式复制该指针成员。有关深拷贝和浅拷贝以及它们的区别，读者可阅读《C++深拷贝和浅拷贝》一文做详细了解。\n举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include \u0026lt;iostream\u0026gt; using namespace std; class demo{ public: demo():num(new int(0)){ cout\u0026lt;\u0026lt;\u0026#34;construct!\u0026#34;\u0026lt;\u0026lt;endl; } //拷贝构造函数 demo(const demo \u0026amp;d):num(new int(*d.num)){ cout\u0026lt;\u0026lt;\u0026#34;copy construct!\u0026#34;\u0026lt;\u0026lt;endl; } ~demo(){ cout\u0026lt;\u0026lt;\u0026#34;class destruct!\u0026#34;\u0026lt;\u0026lt;endl; } private: int *num; }; demo get_demo(){ return demo(); } int main(){ demo a = get_demo(); return 0; } 如上所示，我们为 demo 类自定义了一个拷贝构造函数。该函数在拷贝 d.num 指针成员时，必须采用深拷贝的方式，即拷贝该指针成员本身的同时，还要拷贝指针指向的内存资源。否则一旦多个对象中的指针成员指向同一块堆空间，这些对象析构时就会对该空间释放多次，这是不允许的。\n可以看到，程序中定义了一个可返回 demo 对象的 get_demo() 函数，用于在 main() 主函数中初始化 a 对象，其整个初始化的流程包含以下几个阶段：\n执行 get_demo() 函数内部的 demo() 语句，即调用 demo 类的默认构造函数生成一个匿名对象； 执行 return demo() 语句，会调用拷贝构造函数复制一份之前生成的匿名对象，并将其作为 get_demo() 函数的返回值（函数体执行完毕之前，匿名对象会被析构销毁）； 执行 a = get_demo() 语句，再调用一次拷贝构造函数，将之前拷贝得到的临时对象复制给 a（此行代码执行完毕，get_demo() 函数返回的对象会被析构）； 程序执行结束前，会自行调用 demo 类的析构函数销毁 a。 注意，目前多数编译器都会对程序中发生的拷贝操作进行优化，因此如果我们使用 VS 2017、codeblocks 等这些编译器运行此程序时，看到的往往是优化后的输出结果：\n1 2 construct! class destruct! 而同样的程序，如果在 Linux 上使用g++ demo.cpp -fno-elide-constructors命令运行（其中 demo.cpp 是程序文件的名称），就可以看到完整的输出结果：\n1 2 3 4 5 6 construct! \u0026lt;-- 执行 demo() copy construct! \u0026lt;-- 执行 return demo() class destruct! \u0026lt;-- 销毁 demo() 产生的匿名对象 copy construct! \u0026lt;-- 执行 a = get_demo() class destruct! \u0026lt;-- 销毁 get_demo() 返回的临时对象 class destruct! \u0026lt;-- 销毁 a 如上所示，利用拷贝构造函数实现对 a 对象的初始化，底层实际上进行了 2 次拷贝（而且是深拷贝）操作。当然，对于仅申请少量堆空间的临时对象来说，深拷贝的执行效率依旧可以接受，但如果临时对象中的指针成员申请了大量的堆空间，那么 2 次深拷贝操作势必会影响 a 对象初始化的执行效率。\n事实上，此问题一直存留在以 C++ 98/03 标准编写的 C++ 程序中。由于临时变量的产生、销毁以及发生的拷贝操作本身就是很隐晦的（编译器对这些过程做了专门的优化），且并不会影响程序的正确性，因此很少进入程序员的视野。\n那么当类中包含指针类型的成员变量，使用其它对象来初始化同类对象时，怎样才能避免深拷贝导致的效率问题呢？C++11 标准引入了解决方案，该标准中引入了右值引用的语法，借助它可以实现移动语义。\nC++移动构造函数（移动语义的具体实现）\n所谓移动语义，指的就是以移动而非深拷贝的方式初始化含有指针成员的类对象。简单的理解，移动语义指的就是将其他对象（通常是临时对象）拥有的内存资源“移为已用”。\n以前面程序中的 demo 类为例，该类的成员都包含一个整形的指针成员，其默认指向的是容纳一个整形变量的堆空间。当使用 get_demo() 函数返回的临时对象初始化 a 时，我们只需要将临时对象的 num 指针直接浅拷贝给 a.num，然后修改该临时对象中 num 指针的指向（通常另其指向 NULL），这样就完成了 a.num 的初始化。\n事实上，对于程序执行过程中产生的临时对象，往往只用于传递数据（没有其它的用处），并且会很快会被销毁。因此在使用临时对象初始化新对象时，我们可以将其包含的指针成员指向的内存资源直接移给新对象所有，无需再新拷贝一份，这大大提高了初始化的执行效率。\n例如，下面程序对 demo 类进行了修改：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #include \u0026lt;iostream\u0026gt; using namespace std; class demo{ public: demo():num(new int(0)){ cout\u0026lt;\u0026lt;\u0026#34;construct!\u0026#34;\u0026lt;\u0026lt;endl; } demo(const demo \u0026amp;d):num(new int(*d.num)){ cout\u0026lt;\u0026lt;\u0026#34;copy construct!\u0026#34;\u0026lt;\u0026lt;endl; } //添加移动构造函数 demo(demo \u0026amp;\u0026amp;d):num(d.num){ d.num = NULL; cout\u0026lt;\u0026lt;\u0026#34;move construct!\u0026#34;\u0026lt;\u0026lt;endl; } ~demo(){ cout\u0026lt;\u0026lt;\u0026#34;class destruct!\u0026#34;\u0026lt;\u0026lt;endl; } private: int *num; }; demo get_demo(){ return demo(); } int main(){ demo a = get_demo(); return 0; } 可以看到，在之前 demo 类的基础上，我们又手动为其添加了一个构造函数。和其它构造函数不同，此构造函数使用右值引用形式的参数，又称为移动构造函数。并且在此构造函数中，num 指针变量采用的是浅拷贝的复制方式，同时在函数内部重置了 d.num，有效避免了“同一块对空间被释放多次”情况的发生。\n在 Linux 系统中使用g++ demo.cpp -o demo.exe -std=c++0x -fno-elide-constructors命令执行此程序，输出结果为：\n1 2 3 4 5 6 construct! move construct! class destruct! move construct! class destruct! class destruct! 通过执行结果我们不难得知，当为 demo 类添加移动构造函数之后，使用临时对象初始化 a 对象过程中产生的 2 次拷贝操作，都转由移动构造函数完成。\n我们知道，非 const 右值引用只能操作右值，程序执行结果中产生的临时对象（例如函数返回值、lambda 表达式等）既无名称也无法获取其存储地址，所以属于右值。当类中同时包含拷贝构造函数和移动构造函数时，如果使用临时对象初始化当前类的对象，编译器会优先调用移动构造函数来完成此操作。只有当类中没有合适的移动构造函数时，编译器才会退而求其次，调用拷贝构造函数。\n在实际开发中，通常在类中自定义移动构造函数的同时，会再为其自定义一个适当的拷贝构造函数，由此当用户利用右值初始化类对象时，会调用移动构造函数；使用左值（非右值）初始化类对象时，会调用拷贝构造函数。\n读者可能会问，如果使用左值初始化同类对象，但也想调用移动构造函数完成，有没有办法可以实现呢？\n默认情况下，左值初始化同类对象只能通过拷贝构造函数完成，如果想调用移动构造函数，则必须使用右值进行初始化。C++11 标准中为了满足用户使用左值初始化同类对象时也通过移动构造函数完成的需求，新引入了 std::move() 函数，它可以将左值强制转换成对应的右值，由此便可以使用移动构造函数。\n有关 std::move() 函数的用法，后续章节会做详细讲解。\nC++11 move()函数：将左值强制转换为右值 通过学习 《C++11移动构造函数》一节我们知道，C++11 标准中借助右值引用可以为指定类添加移动构造函数，这样当使用该类的右值对象（可以理解为临时对象）初始化同类对象时，编译器会优先选择移动构造函数。\n注意，移动构造函数的调用时机是：用同类的右值对象初始化新对象。那么，用当前类的左值对象（有名称，能获取其存储地址的实例对象）初始化同类对象时，是否就无法调用移动构造函数了呢？当然不是，C++11 标准中已经给出了解决方案，即调用 move() 函数。\nmove 本意为 “移动”，但该函数并不能移动任何数据，它的功能很简单，就是将某个左值强制转化为右值。\n基于 move() 函数特殊的功能，其常用于实现移动语义。\nmove() 函数的用法也很简单，其语法格式如下：\n1 move(arg) 其中，arg 表示指定的左值对象。该函数会返回 arg 对象的右值形式。\n【例 1】move() 函数的基础应用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #include \u0026lt;iostream\u0026gt; using namespace std; class movedemo{ public: movedemo():num(new int(0)){ cout\u0026lt;\u0026lt;\u0026#34;construct!\u0026#34;\u0026lt;\u0026lt;endl; } //拷贝构造函数 movedemo(const movedemo \u0026amp;d):num(new int(*d.num)){ cout\u0026lt;\u0026lt;\u0026#34;copy construct!\u0026#34;\u0026lt;\u0026lt;endl; } //移动构造函数 movedemo(movedemo \u0026amp;\u0026amp;d):num(d.num){ d.num = NULL; cout\u0026lt;\u0026lt;\u0026#34;move construct!\u0026#34;\u0026lt;\u0026lt;endl; } public: //这里应该是 private，使用 public 是为了更方便说明问题 int *num; }; int main(){ movedemo demo; cout \u0026lt;\u0026lt; \u0026#34;demo2:\\n\u0026#34;; movedemo demo2 = demo; //cout \u0026lt;\u0026lt; *demo2.num \u0026lt;\u0026lt; endl; //可以执行 cout \u0026lt;\u0026lt; \u0026#34;demo3:\\n\u0026#34;; movedemo demo3 = std::move(demo); //此时 demo.num = NULL，因此下面代码会报运行时错误 //cout \u0026lt;\u0026lt; *demo.num \u0026lt;\u0026lt; endl; return 0; } 程序执行结果为：\n1 2 3 4 5 construct! demo2: copy construct! demo3: move construct! 通过观察程序的输出结果，以及对比 demo2 和 demo3 初始化操作不难得知，demo 对象作为左值，直接用于初始化 demo2 对象，其底层调用的是拷贝构造函数；而通过调用 move() 函数可以得到 demo 对象的右值形式，用其初始化 demo3 对象，编译器会优先调用移动构造函数。\n注意，调用拷贝构造函数，并不影响 demo 对象，但如果调用移动构造函数，由于函数内部会重置 demo.num 指针的指向为 NULL，所以程序中第 30 行代码会导致程序运行时发生错误。\n【例 2】灵活使用 move() 函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #include \u0026lt;iostream\u0026gt; using namespace std; class first { public: first() :num(new int(0)) { cout \u0026lt;\u0026lt; \u0026#34;construct!\u0026#34; \u0026lt;\u0026lt; endl; } //移动构造函数 first(first \u0026amp;\u0026amp;d) :num(d.num) { d.num = NULL; cout \u0026lt;\u0026lt; \u0026#34;first move construct!\u0026#34; \u0026lt;\u0026lt; endl; } public: //这里应该是 private，使用 public 是为了更方便说明问题 int *num; }; class second { public: second() :fir() {} //用 first 类的移动构造函数初始化 fir second(second \u0026amp;\u0026amp; sec) :fir(move(sec.fir)) { cout \u0026lt;\u0026lt; \u0026#34;second move construct\u0026#34; \u0026lt;\u0026lt; endl; } public: //这里也应该是 private，使用 public 是为了更方便说明问题 first fir; }; int main() { second oth; second oth2 = move(oth); //cout \u0026lt;\u0026lt; *oth.fir.num \u0026lt;\u0026lt; endl; //程序报运行时错误 return 0; } 程序执行结果为：\n1 2 3 construct! first move construct! second move construct 程序中分别构建了 first 和 second 这 2 个类，其中 second 类中包含一个 first 类对象。如果读者仔细观察不难发现，程序中使用了 2 此 move() 函数：\n程序第 31 行：由于 oth 为左值，如果想调用移动构造函数为 oth2 初始化，需先利用 move() 函数生成一个 oth 的右值版本； 程序第 22 行：oth 对象内部还包含一个 first 类对象，对于 oth.fir 来说，其也是一个左值，所以在初始化 oth.fir 时，还需要再调用一次 move() 函数。 C++11引用限定符的用法 在《C++右值引用》一节中，我们给您介绍了左值和右值。值得一提的是，左值和右值的区分也同样适用于类对象，本节中将左值的类对象称为左值对象，将右值的类对象称为右值对象。\n默认情况下，对于类中用 public 修饰的成员函数，既可以被左值对象调用，也可以被右值对象调用。举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u0026lt;iostream\u0026gt; using namespace std; class demo { public: demo(int num):num(num){} int get_num(){ return this-\u0026gt;num; } private: int num; }; int main() { demo a(10); cout \u0026lt;\u0026lt; a.get_num() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; move(a).get_num() \u0026lt;\u0026lt; endl; return 0; } 可以看到，demo 类中的 get_num() 成员函数既可以被 a 左值对象调用，也可以被 move(a) 生成的右值 demo 对象调用，运行程序会输出两个 10。\n某些场景中，我们可能需要限制调用成员函数的对象的类型（左值还是右值），为此 C++11 新添加了引用限定符。所谓引用限定符，就是在成员函数的后面添加 “\u0026amp;” 或者 “\u0026amp;\u0026amp;”，从而限制调用者的类型（左值还是右值）。\n修改上面程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u0026lt;iostream\u0026gt; using namespace std; class demo { public: demo(int num):num(num){} int get_num()\u0026amp;{ return this-\u0026gt;num; } private: int num; }; int main() { demo a(10); cout \u0026lt;\u0026lt; a.get_num() \u0026lt;\u0026lt; endl; // 正确 //cout \u0026lt;\u0026lt; move(a).get_num() \u0026lt;\u0026lt; endl; // 错误 return 0; } 和之前的程序相比，我们仅在 get_num() 成员函数的后面添加了 “\u0026amp;”，它可以限定调用该函数的对象必须是左值对象。因此第 16 行代码中，move(a) 生成的右值对象是不允许调用 get_num() 函数的。\n同理，我们再次修改程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u0026lt;iostream\u0026gt; using namespace std; class demo { public: demo(int num):num(num){} int get_num()\u0026amp;\u0026amp;{ return this-\u0026gt;num; } private: int num; }; int main() { demo a(10); //cout \u0026lt;\u0026lt; a.get_num() \u0026lt;\u0026lt; endl; // 错误 cout \u0026lt;\u0026lt; move(a).get_num() \u0026lt;\u0026lt; endl; // 正确 return 0; } 和先前程序不同的是，get_num() 函数后根有 “\u0026amp;\u0026amp;” 限定符，它可以限定调用该函数的对象必须是一个右值对象。\n注意，引用限定符不适用于静态成员函数和友元函数。\nconst和引用限定符\n我们知道，const 也可以用于修饰类的成员函数，我们习惯称为常成员函数，例如：\n1 2 3 4 class demo{ public: int get_num() const; } 这里的 get_num() 就是一个常成员函数。\nconst 和引用限定符修饰类的成员函数时，都位于函数的末尾。C++11 标准规定，当引用限定符和 const 修饰同一个类的成员函数时，const 必须位于引用限定符前面。\n需要注意的一点是，当 const \u0026amp;\u0026amp; 修饰类的成员函数时，调用它的对象只能是右值对象；当 const \u0026amp; 修饰类的成员函数时，调用它的对象既可以是左值对象，也可以是右值对象。无论是 const \u0026amp;\u0026amp; 还是 const \u0026amp; 限定的成员函数，内部都不允许对当前对象做修改操作。\n举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #include \u0026lt;iostream\u0026gt; using namespace std; class demo { public: demo(int num,int num2) :num(num),num2(num2) {} //左值和右值对象都可以调用 int get_num() const \u0026amp;{ return this-\u0026gt;num; } //仅供右值对象调用 int get_num2() const \u0026amp;\u0026amp; { return this-\u0026gt;num2; } private: int num; int num2; }; int main() { demo a(10,20); cout \u0026lt;\u0026lt; a.get_num() \u0026lt;\u0026lt; endl; // 正确 cout \u0026lt;\u0026lt; move(a).get_num() \u0026lt;\u0026lt; endl; // 正确 //cout \u0026lt;\u0026lt; a.get_num2() \u0026lt;\u0026lt; endl; // 错误 cout \u0026lt;\u0026lt; move(a).get_num2() \u0026lt;\u0026lt; endl; // 正确 return 0; } C++11完美转发及其实现 C++11 标准为 C++ 引入右值引用语法的同时，还解决了一个 C++ 98/03 标准长期存在的短板，即使用简单的方式即可在函数模板中实现参数的完美转发。那么，什么是完美转发？它为什么是 C++98/03 标准存在的一个短板？C++11 标准又是如何为 C++ 弥补这一短板的？别急，本节将就这些问题给读者做一一讲解。\n首先解释一下什么是完美转发，它指的是函数模板可以将自己的参数“完美”地转发给内部调用的其它函数。所谓完美，即不仅能准确地转发参数的值，还能保证被转发参数的左、右值属性不变。\n在 C++ 中，一个表达式不是左值就是右值。有关如何判断一个表达式是左值还是右值，可阅读《C++右值引用》一文做详细了解。\n举个例子：\n1 2 3 4 template\u0026lt;typename T\u0026gt; void function(T t) { otherdef(t); } 如上所示，function() 函数模板中调用了 otherdef() 函数。在此基础上，完美转发指的是：如果 function() 函数接收到的参数 t 为左值，那么该函数传递给 otherdef() 的参数 t 也是左值；反之如果 function() 函数接收到的参数 t 为右值，那么传递给 otherdef() 函数的参数 t 也必须为右值。\n显然，function() 函数模板并没有实现完美转发。一方面，参数 t 为非引用类型，这意味着在调用 function() 函数时，实参将值传递给形参的过程就需要额外进行一次拷贝操作；另一方面，无论调用 function() 函数模板时传递给参数 t 的是左值还是右值，对于函数内部的参数 t 来说，它有自己的名称，也可以获取它的存储地址，因此它永远都是左值，也就是说，传递给 otherdef() 函数的参数 t 永远都是左值。总之，无论从那个角度看，function() 函数的定义都不“完美”。\n读者可能会问，完美转发这样严苛的参数传递机制，很常用吗？C++98/03 标准中几乎不会用到，但 C++11 标准为 C++ 引入了右值引用和移动语义，因此很多场景中是否实现完美转发，直接决定了该参数的传递过程使用的是拷贝语义（调用拷贝构造函数）还是移动语义（调用移动构造函数）。\n事实上，C++98/03 标准下的 C++ 也可以实现完美转发，只是实现方式比较笨拙。通过前面的学习我们知道，C++ 98/03 标准中只有左值引用，并且可以细分为非 const 引用和 const 引用。其中，使用非 const 引用作为函数模板参数时，只能接收左值，无法接收右值；而 const 左值引用既可以接收左值，也可以接收右值，但考虑到其 const 属性，除非被调用函数的参数也是 const 属性，否则将无法直接传递。\n这也就意味着，单独使用任何一种引用形式，可以实现转发，但无法保证完美。因此如果使用 C++ 98/03 标准下的 C++ 语言，我们可以采用函数模板重载的方式实现完美转发，例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #include \u0026lt;iostream\u0026gt; using namespace std; //重载被调用函数，查看完美转发的效果 void otherdef(int \u0026amp; t) { cout \u0026lt;\u0026lt; \u0026#34;lvalue\\n\u0026#34;; } void otherdef(const int \u0026amp; t) { cout \u0026lt;\u0026lt; \u0026#34;rvalue\\n\u0026#34;; } //重载函数模板，分别接收左值和右值 //接收右值参数 template \u0026lt;typename T\u0026gt; void function(const T\u0026amp; t) { otherdef(t); } //接收左值参数 template \u0026lt;typename T\u0026gt; void function(T\u0026amp; t) { otherdef(t); } int main() { function(5);//5 是右值 int x = 1; function(x);//x 是左值 return 0; } 程序执行结果为：\n1 2 rvalue lvalue 从输出结果中可以看到，对于右值 5 来说，它实际调用的参数类型为 const T\u0026amp; 的函数模板，由于 t 为 const 类型，所以 otherdef() 函数实际调用的也是参数用 const 修饰的函数，所以输出“rvalue”；对于左值 x 来说，2 个重载模板函数都适用，C++编译器会选择最适合的参数类型为 T\u0026amp; 的函数模板，进而 therdef() 函数实际调用的是参数类型为非 const 的函数，输出“lvalue”。\n显然，使用重载的模板函数实现完美转发也是有弊端的，此实现方式仅适用于模板函数仅有少量参数的情况，否则就需要编写大量的重载函数模板，造成代码的冗余。为了方便用户更快速地实现完美转发，C++ 11 标准中允许在函数模板中使用右值引用来实现完美转发。\nC++11 标准中规定，通常情况下右值引用形式的参数只能接收右值，不能接收左值。但对于函数模板中使用右值引用语法定义的参数来说，它不再遵守这一规定，既可以接收右值，也可以接收左值（此时的右值引用又被称为“万能引用”）。\n仍以 function() 函数为例，在 C++11 标准中实现完美转发，只需要编写如下一个模板函数即可：\n1 2 3 4 template \u0026lt;typename T\u0026gt; void function(T\u0026amp;\u0026amp; t) { otherdef(t); } 此模板函数的参数 t 既可以接收左值，也可以接收右值。但仅仅使用右值引用作为函数模板的参数是远远不够的，还有一个问题继续解决，即如果调用 function() 函数时为其传递一个左值引用或者右值引用的实参，如下所示：\n1 2 3 4 5 int n = 10; int \u0026amp; num = n; function(num); // T 为 int\u0026amp; int \u0026amp;\u0026amp; num2 = 11; function(num2); // T 为 int \u0026amp;\u0026amp; 其中，由 function(num) 实例化的函数底层就变成了 function(int \u0026amp; \u0026amp; t)，同样由 function(num2) 实例化的函数底层则变成了 function(int \u0026amp;\u0026amp; \u0026amp;\u0026amp; t)。要知道，C++98/03 标准是不支持这种用法的，而 C++ 11标准为了更好地实现完美转发，特意为其指定了新的类型匹配规则，又称为引用折叠规则（假设用 A 表示实际传递参数的类型）：\n当实参为左值或者左值引用（A\u0026amp;）时，函数模板中 T\u0026amp;\u0026amp; 将转变为 A\u0026amp;（A\u0026amp; \u0026amp;\u0026amp; = A\u0026amp;）； 当实参为右值或者右值引用（A\u0026amp;\u0026amp;）时，函数模板中 T\u0026amp;\u0026amp; 将转变为 A\u0026amp;\u0026amp;（A\u0026amp;\u0026amp; \u0026amp;\u0026amp; = A\u0026amp;\u0026amp;）。 读者只需要知道，在实现完美转发时，只要函数模板的参数类型为 T\u0026amp;\u0026amp;，则 C++ 可以自行准确地判定出实际传入的实参是左值还是右值。\n通过将函数模板的形参类型设置为 T\u0026amp;\u0026amp;，我们可以很好地解决接收左、右值的问题。但除此之外，还需要解决一个问题，即无论传入的形参是左值还是右值，对于函数模板内部来说，形参既有名称又能寻址，因此它都是左值。那么如何才能将函数模板接收到的形参连同其左、右值属性，一起传递给被调用的函数呢？\nC++11 标准的开发者已经帮我们想好的解决方案，该新标准还引入了一个模板函数 forword()，我们只需要调用该函数，就可以很方便地解决此问题。仍以 function 模板函数为例，如下演示了该函数模板的用法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #include \u0026lt;iostream\u0026gt; using namespace std; //重载被调用函数，查看完美转发的效果 void otherdef(int \u0026amp; t) { cout \u0026lt;\u0026lt; \u0026#34;lvalue\\n\u0026#34;; } void otherdef(const int \u0026amp; t) { cout \u0026lt;\u0026lt; \u0026#34;rvalue\\n\u0026#34;; } //实现完美转发的函数模板 template \u0026lt;typename T\u0026gt; void function(T\u0026amp;\u0026amp; t) { otherdef(forward\u0026lt;T\u0026gt;(t)); } int main() { function(5); int x = 1; function(x); return 0; } 程序执行结果为：\n1 2 rvalue lvalue 注意程序中第 12~16 行，此 function() 模板函数才是实现完美转发的最终版本。可以看到，forword() 函数模板用于修饰被调用函数中需要维持参数左、右值属性的参数。\n总的来说，在定义模板函数时，我们采用右值引用的语法格式定义参数类型，由此该函数既可以接收外界传入的左值，也可以接收右值；其次，还需要使用 C++11 标准库提供的 forword() 模板函数修饰被调用函数中需要维持左、右值属性的参数。由此即可轻松实现函数模板中参数的完美转发。\nC++11 nullptr：初始化空指针 实际开发中，避免产生“野指针”最有效的方法，就是在定义指针的同时完成初始化操作，即便该指针的指向尚未明确，也要将其初始化为空指针。\n所谓“野指针”，又称“悬挂指针”，指的是没有明确指向的指针。野指针往往指向的是那些不可用的内存区域，这就意味着像操作普通指针那样使用野指针（例如 \u0026amp;p），极可能导致程序发生异常。\nC++98/03 标准中，将一个指针初始化为空指针的方式有 2 种：\n1 2 int *p = 0; int *p = NULL; //推荐使用 可以看到，我们可以将指针明确指向 0（0x0000 0000）这个内存空间。一方面，明确指针的指向可以避免其成为野指针；另一方面，大多数操作系统都不允许用户对地址为 0 的内存空间执行写操作，若用户在程序中尝试修改其内容，则程序运行会直接报错。\n相比第一种方式，我们更习惯将指针初始化为 NULL。值得一提的是，NULL 并不是 C++ 的关键字，它是 C++ 为我们事先定义好的一个宏，并且它的值往往就是字面量 0（#define NULL 0）。\nC++ 中将 NULL 定义为字面常量 0，虽然能满足大部分场景的需要，但个别情况下，它会导致程序的运行和我们的预期不符。例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \u0026lt;iostream\u0026gt; using namespace std; void isnull(void *c){ cout \u0026lt;\u0026lt; \u0026#34;void*c\u0026#34; \u0026lt;\u0026lt; endl; } void isnull(int n){ cout \u0026lt;\u0026lt; \u0026#34;int n\u0026#34; \u0026lt;\u0026lt; endl; } int main() { isnull(0); isnull(NULL); return 0; } 程序执行结果为：\n1 2 int n int n 对于 isnull(0) 来说，显然它真正调用的是参数为整形的 isnull() 函数；而对于 isnull(NULL)，我们期望它实际调用的是参数为 void*c 的 isnull() 函数，但观察程序的执行结果不难看出，并不符合我们的预期。\nC++ 98/03 标准中，如果我们想令 isnull(NULL) 实际调用的是 isnull(void* c)，就需要对 NULL（或者 0）进行强制类型转换：\n1 2 isnull( (void*)NULL ); isnull( (void*)0 ); 如此，才会成功调用我们预期的函数（读者可自行执行此代码，观察输出结果）。\n由于 C++ 98 标准使用期间，NULL 已经得到了广泛的应用，出于兼容性的考虑，C++11 标准并没有对 NULL 的宏定义做任何修改。为了修正 C++ 存在的这一 BUG，C++ 标准委员会最终决定另其炉灶，在 C++11 标准中引入一个新关键字，即 nullptr。\n在使用 nullptr 之前，读者需保证自己使用的编译器支持该关键字。以 Visual Studio 和 codeblocks 为例，前者早在 2010 版本就对 C++ 11 标准中的部分特性提供了支持，其中就包括 nullptr；如果使用后者，读者需将其 G++ 编译器版本至少升级至 4.6.1（同时开启 -std=c++0x 编译选项）。\nnullptr 是 nullptr_t 类型的右值常量，专用于初始化空类型指针。nullptr_t 是 C++11 新增加的数据类型，可称为“指针空值类型”。也就是说，nullpter 仅是该类型的一个实例对象（已经定义好，可以直接使用），如果需要我们完全定义出多个同 nullptr 完全一样的实例对象。\n值得一提的是，nullptr 可以被隐式转换成任意的指针类型。举个例子：\n1 2 3 int * a1 = nullptr; char * a2 = nullptr; double * a3 = nullptr; 显然，不同类型的指针变量都可以使用 nullptr 来初始化，编译器分别将 nullptr 隐式转换成 int*、char* 以及 double* 指针类型。\n另外，通过将指针初始化为 nullptr，可以很好地解决 NULL 遗留的问题，比如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \u0026lt;iostream\u0026gt; using namespace std; void isnull(void *c){ cout \u0026lt;\u0026lt; \u0026#34;void*c\u0026#34; \u0026lt;\u0026lt; endl; } void isnull(int n){ cout \u0026lt;\u0026lt; \u0026#34;int n\u0026#34; \u0026lt;\u0026lt; endl; } int main() { isnull(NULL); isnull(nullptr); return 0; } 程序执行结果为：\n1 2 int n void*c 借助执行结果不难看出，由于 nullptr 无法隐式转换为整形，而可以隐式匹配指针类型，因此执行结果和我们的预期相符。\n总之在 C++11 标准下，相比 NULL 和 0，使用 nullptr 初始化空指针可以令我们编写的程序更加健壮。\nC++11 shared_ptr智能指针（超级详细） 在实际的 C++ 开发中，我们经常会遇到诸如程序运行中突然崩溃、程序运行所用内存越来越多最终不得不重启等问题，这些问题往往都是内存资源管理不当造成的。比如：\n有些内存资源已经被释放，但指向它的指针并没有改变指向（成为了野指针），并且后续还在使用； 有些内存资源已经被释放，后期又试图再释放一次（重复释放同一块内存会导致程序运行崩溃）； 没有及时释放不再使用的内存资源，造成内存泄漏，程序占用的内存资源越来越多。 针对以上这些情况，很多程序员认为 C++ 语言应该提供更友好的内存管理机制，这样就可以将精力集中于开发项目的各个功能上。\n事实上，显示内存管理的替代方案很早就有了，早在 1959 年前后，就有人提出了“垃圾自动回收”机制。所谓垃圾，指的是那些不再使用或者没有任何指针指向的内存空间，而“回收”则指的是将这些“垃圾”收集起来以便再次利用。\n如今，垃圾回收机制已经大行其道，得到了诸多编程语言的支持，例如 Java、Python、C#、PHP 等。而 C++ 虽然从来没有公开得支持过垃圾回收机制，但 C++98/03 标准中，支持使用 auto_ptr 智能指针来实现堆内存的自动回收；C++11 新标准在废弃 auto_ptr 的同时，增添了 unique_ptr、shared_ptr 以及 weak_ptr 这 3 个智能指针来实现堆内存的自动回收。\n所谓智能指针，可以从字面上理解为“智能”的指针。具体来讲，智能指针和普通指针的用法是相似的，不同之处在于，智能指针可以在适当时机自动释放分配的内存。也就是说，使用智能指针可以很好地避免“忘记释放内存而导致内存泄漏”问题出现。由此可见，C++ 也逐渐开始支持垃圾回收机制了，尽管目前支持程度还有限。\nC++ 智能指针底层是采用引用计数的方式实现的。简单的理解，智能指针在申请堆内存空间的同时，会为其配备一个整形值（初始值为 1），每当有新对象使用此堆内存时，该整形值 +1；反之，每当使用此堆内存的对象被释放时，该整形值减 1。当堆空间对应的整形值为 0 时，即表明不再有对象使用它，该堆空间就会被释放掉。\n接下来，我们将分别对 shared_ptr、unique_ptr 以及 weak_ptr 这 3 个智能指针的特性和用法做详细的讲解，本节先介绍 shared_ptr 智能指针。\nC++11 shared_ptr智能指针 实际上，每种智能指针都是以类模板的方式实现的，shared_ptr 也不例外。shared_ptr（其中 T 表示指针指向的具体数据类型）的定义位于头文件，并位于 std 命名空间中，因此在使用该类型指针时，程序中应包含如下 2 行代码：\n1 2 #include \u0026lt;memory\u0026gt; using namespace std; 注意，第 2 行代码并不是必须的，也可以不添加，则后续在使用 shared_ptr 智能指针时，就需要明确指明std::。\n值得一提的是，和 unique_ptr、weak_ptr 不同之处在于，多个 shared_ptr 智能指针可以共同使用同一块堆内存。并且，由于该类型智能指针在实现上采用的是引用计数机制，即便有一个 shared_ptr 指针放弃了堆内存的“使用权”（引用计数减 1），也不会影响其他指向同一堆内存的 shared_ptr 指针（只有引用计数为 0 时，堆内存才会被自动释放）。\n1、shared_ptr智能指针的创建\nshared_ptr 类模板中，提供了多种实用的构造函数，这里给读者列举了几个常用的构造函数（以构建指向 int 类型数据的智能指针为例）。\n1.1 通过如下 2 种方式，可以构造出 shared_ptr 类型的空智能指针：\n1 2 std::shared_ptr\u0026lt;int\u0026gt; p1; //不传入任何实参std::shared_ptr\u0026lt;int\u0026gt; p2(nullptr); //传入空指针 nullptr 注意，空的 shared_ptr 指针，其初始引用计数为 0，而不是 1。\n1.2 在构建 shared_ptr 智能指针，也可以明确其指向。例如：\n1 std::shared_ptr\u0026lt;int\u0026gt; p3(new int(10)); 由此，我们就成功构建了一个 shared_ptr 智能指针，其指向一块存有 10 这个 int 类型数据的堆内存空间。\n同时，C++11 标准中还提供了 std::make_shared 模板函数，其可以用于初始化 shared_ptr 智能指针，例如：\n1 std::shared_ptr\u0026lt;int\u0026gt; p3 = std::make_shared\u0026lt;int\u0026gt;(10); 以上 2 种方式创建的 p3 是完全相同。\n1.3 除此之外，shared_ptr 模板还提供有相应的拷贝构造函数和移动构造函数，例如：\n1 2 3 4 //调用拷贝构造函数 std::shared_ptr\u0026lt;int\u0026gt; p4(p3);//或者 std::shared_ptr\u0026lt;int\u0026gt; p4 = p3; //调用移动构造函数 std::shared_ptr\u0026lt;int\u0026gt; p5(std::move(p4)); //或者 std::shared_ptr\u0026lt;int\u0026gt; p5 = std::move(p4); 有关拷贝构造函数，读者可阅读《C++拷贝构造函数》一节做系统了解；有关移动构造函数，读者可阅读《C++移动构造函数》做详细了解；有关 move() 函数的功能和用法，读者可阅读《C++11 move()》一节。\n如上所示，p3 和 p4 都是 shared_ptr 类型的智能指针，因此可以用 p3 来初始化 p4，由于 p3 是左值，因此会调用拷贝构造函数。需要注意的是，如果 p3 为空智能指针，则 p4 也为空智能指针，其引用计数初始值为 0；反之，则表明 p4 和 p3 指向同一块堆内存，同时该堆空间的引用计数会加 1。\n而对于 std::move(p4) 来说，该函数会强制将 p4 转换成对应的右值，因此初始化 p5 调用的是移动构造函数。另外和调用拷贝构造函数不同，用 std::move(p4) 初始化 p5，会使得 p5 拥有了 p4 的堆内存，而 p4 则变成了空智能指针。\n注意，同一普通指针不能同时为多个 shared_ptr 对象赋值，否则会导致程序发生异常。例如：\n1 2 3 int* ptr = new int; std::shared_ptr\u0026lt;int\u0026gt; p1(ptr); std::shared_ptr\u0026lt;int\u0026gt; p2(ptr);//错误 1.4 在初始化 shared_ptr 智能指针时，还可以自定义所指堆内存的释放规则，这样当堆内存的引用计数为 0 时，会优先调用我们自定义的释放规则。\n在某些场景中，自定义释放规则是很有必要的。比如，对于申请的动态数组来说，shared_ptr 指针默认的释放规则是不支持释放数组的，只能自定义对应的释放规则，才能正确地释放申请的堆内存。\n对于申请的动态数组，释放规则可以使用 C++11 标准中提供的 default_delete 模板类，我们也可以自定义释放规则：\n1 2 3 4 5 6 7 8 //指定 default_delete 作为释放规则 std::shared_ptr\u0026lt;int\u0026gt; p6(new int[10], std::default_delete\u0026lt;int[]\u0026gt;()); //自定义释放规则 void deleteInt(int*p) { delete []p; } //初始化智能指针，并自定义释放规则 std::shared_ptr\u0026lt;int\u0026gt; p7(new int[10], deleteInt); 实际上借助 lambda 表达式，我们还可以像如下这样初始化 p7，它们是完全相同的：\n1 std::shared_ptr\u0026lt;int\u0026gt; p7(new int[10], [](int* p) {delete[]p; }); shared_ptr 模板类还提供有其它一些初始化智能指针的方法，感兴趣的读者可前往讲解 shared_ptr 的官网做系统了解。\n2、shared_ptr模板类提供的成员方法\n为了方便用户使用 shared_ptr 智能指针，shared_ptr 模板类还提供有一些实用的成员方法，它们各自的功能如表 1 所示。\n成员方法名 功 能 operator=() 重载赋值号，使得同一类型的 shared_ptr 智能指针可以相互赋值。 operator*() 重载 * 号，获取当前 shared_ptr 智能指针对象指向的数据。 operator-\u0026gt;() 重载 -\u0026gt; 号，当智能指针指向的数据类型为自定义的结构体时，通过 -\u0026gt; 运算符可以获取其内部的指定成员。 swap() 交换 2 个相同类型 shared_ptr 智能指针的内容。 reset() 当函数没有实参时，该函数会使当前 shared_ptr 所指堆内存的引用计数减 1，同时将当前对象重置为一个空指针；当为函数传递一个新申请的堆内存时，则调用该函数的 shared_ptr 对象会获得该存储空间的所有权，并且引用计数的初始值为 1。 get() 获得 shared_ptr 对象内部包含的普通指针。 use_count() 返回同当前 shared_ptr 对象（包括它）指向相同的所有 shared_ptr 对象的数量。 unique() 判断当前 shared_ptr 对象指向的堆内存，是否不再有其它 shared_ptr 对象再指向它。 operator bool() 判断当前 shared_ptr 对象是否为空智能指针，如果是空指针，返回 false；反之，返回 true。 除此之外，C++11 标准还支持同一类型的 shared_ptr 对象，或者 shared_ptr 和 nullptr 之间，进行 ==，!=，\u0026lt;，\u0026lt;=，\u0026gt;，\u0026gt;= 运算。\n下面程序给大家演示了 shared_ptr 智能指针的基本用法，以及该模板类提供了一些成员方法的用法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; using namespace std; int main() { //构建 2 个智能指针 std::shared_ptr\u0026lt;int\u0026gt; p1(new int(10)); std::shared_ptr\u0026lt;int\u0026gt; p2(p1); //输出 p2 指向的数据 cout \u0026lt;\u0026lt; *p2 \u0026lt;\u0026lt; endl; p1.reset();//引用计数减 1,p1为空指针 if (p1) { cout \u0026lt;\u0026lt; \u0026#34;p1 不为空\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;p1 为空\u0026#34; \u0026lt;\u0026lt; endl; } //以上操作，并不会影响 p2 cout \u0026lt;\u0026lt; *p2 \u0026lt;\u0026lt; endl; //判断当前和 p2 同指向的智能指针有多少个 cout \u0026lt;\u0026lt; p2.use_count() \u0026lt;\u0026lt; endl; return 0; } 程序执行结果为：\n1 2 3 4 10 p1 为空 10 1 C++11 unique_ptr智能指针 在《C++11 shared_ptr智能指针》的基础上，本节继续讲解 C++11 标准提供的另一种智能指针，即 unique_ptr 智能指针。\n作为智能指针的一种，unique_ptr 指针自然也具备“在适当时机自动释放堆内存空间”的能力。和 shared_ptr 指针最大的不同之处在于，unique_ptr 指针指向的堆内存无法同其它 unique_ptr 共享，也就是说，每个 unique_ptr 指针都独自拥有对其所指堆内存空间的所有权。\n这也就意味着，每个 unique_ptr 指针指向的堆内存空间的引用计数，都只能为 1，一旦该 unique_ptr 指针放弃对所指堆内存空间的所有权，则该空间会被立即释放回收。\nunique_ptr 智能指针是以模板类的形式提供的，unique_ptr（T 为指针所指数据的类型）定义在头文件，并位于 std 命名空间中。因此，要想使用 unique_ptr 类型指针，程序中应首先包含如下 2 条语句：\n1 2 #include \u0026lt;memory\u0026gt; using namespace std; 第 2 句并不是必须的，可以不添加，则后续在使用 unique_ptr 指针时，必须标注std::。\nunique_ptr智能指针的创建\n考虑到不同实际场景的需要，unique_ptr 模板类提供了多个实用的构造函数，这里给读者列举了几种常用的构造 unique_ptr 智能指针的方式。\n通过以下 2 种方式，可以创建出空的 unique_ptr 指针： 1 2 std::unique_ptr\u0026lt;int\u0026gt; p1(); std::unique_ptr\u0026lt;int\u0026gt; p2(nullptr); 创建 unique_ptr 指针的同时，也可以明确其指向。例如： 1 std::unique_ptr\u0026lt;int\u0026gt; p3(new int); 由此就创建出了一个 p3 智能指针，其指向的是可容纳 1 个整数的堆存储空间。\n和可以用 make_shared() 模板函数初始化 shared_ptr 指针不同，C++11 标准中并没有为 unique_ptr 类型指针添加类似的模板函数。\n基于 unique_ptr 类型指针不共享各自拥有的堆内存，因此 C++11 标准中的 unique_ptr 模板类没有提供拷贝构造函数，只提供了移动构造函数。例如： 1 2 3 std::unique_ptr\u0026lt;int\u0026gt; p4(new int); std::unique_ptr\u0026lt;int\u0026gt; p5(p4);//错误，堆内存不共享 std::unique_ptr\u0026lt;int\u0026gt; p5(std::move(p4));//正确，调用移动构造函数 值得一提的是，对于调用移动构造函数的 p4 和 p5 来说，p5 将获取 p4 所指堆空间的所有权，而 p4 将变成空指针（nullptr）。\n默认情况下，unique_ptr 指针采用 std::default_delete 方法释放堆内存。当然，我们也可以自定义符合实际场景的释放规则。值得一提的是，和 shared_ptr 指针不同，为 unique_ptr 自定义释放规则，只能采用函数对象的方式。例如： 1 2 3 4 5 6 7 8 9 //自定义的释放规则 struct myDel { void operator()(int *p) { delete p; } }; std::unique_ptr\u0026lt;int, myDel\u0026gt; p6(new int); //std::unique_ptr\u0026lt;int, myDel\u0026gt; p6(new int, myDel()); unique_ptr模板类提供的成员方法\n为了方便用户使用 unique_ptr 智能指针，unique_ptr 模板类还提供有一些实用的成员方法，它们各自的功能如表 1 所示。\n成员函数名 功能 operator*() 获取当前 unique_ptr 指针指向的数据。 operator-\u0026gt;() 重载 -\u0026gt; 号，当智能指针指向的数据类型为自定义的结构体时，通过 -\u0026gt; 运算符可以获取其内部的指定成员。 operator =() 重载了 = 赋值号，从而可以将 nullptr 或者一个右值 unique_ptr 指针直接赋值给当前同类型的 unique_ptr 指针。 operator 重载了 [] 运算符，当 unique_ptr 指针指向一个数组时，可以直接通过 [] 获取指定下标位置处的数据。 get() 获取当前 unique_ptr 指针内部包含的普通指针。 get_deleter() 获取当前 unique_ptr 指针释放堆内存空间所用的规则。 operator bool() unique_ptr 指针可直接作为 if 语句的判断条件，以判断该指针是否为空，如果为空，则为 false；反之为 true。 release() 释放当前 unique_ptr 指针对所指堆内存的所有权，但该存储空间并不会被销毁。 reset() 其中 p 表示一个普通指针，如果 p 为 nullptr，则当前 unique_ptr 也变成空指针；反之，则该函数会释放当前 unique_ptr 指针指向的堆内存（如果有），然后获取 p 所指堆内存的所有权（p 为 nullptr）。 swap(x) 交换当前 unique_ptr 指针和同类型的 x 指针。 除此之外，C++11标准还支持同类型的 unique_ptr 指针之间，以及 unique_ptr 和 nullptr 之间，做 ==，!=，\u0026lt;，\u0026lt;=，\u0026gt;，\u0026gt;= 运算。\n下面程序给大家演示了 unique_ptr 智能指针的基本用法，以及该模板类提供了一些成员方法的用法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; using namespace std; int main() { std::unique_ptr\u0026lt;int\u0026gt; p5(new int); *p5 = 10; // p 接收 p5 释放的堆内存 int * p = p5.release(); cout \u0026lt;\u0026lt; *p \u0026lt;\u0026lt; endl; //判断 p5 是否为空指针 if (p5) { cout \u0026lt;\u0026lt; \u0026#34;p5 is not nullptr\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;p5 is nullptr\u0026#34; \u0026lt;\u0026lt; endl; } std::unique_ptr\u0026lt;int\u0026gt; p6; //p6 获取 p 的所有权 p6.reset(p); cout \u0026lt;\u0026lt; *p6 \u0026lt;\u0026lt; endl;; return 0; } 程序执行结果为：\n1 2 3 10 p5 is nullptr 10 C++11 weak_ptr智能指针 在 C++98/03 的基础上，C++11 标准新引入了 shared_ptr、unique_ptr 以及 weak_ptr 这 3 个智能指针。其中，shared_ptr 和 unique_ptr 已经在前面章节做了详细地介绍，本节重点讲解 weak_ptr 智能指针的特性和用法。\n注意学习 weak_ptr 智能指针之前，读者必须对 shared_ptr 智能指针有一定的了解，可阅读《C++11 shared_ptr智能指针》一节；关于 unique_ptr 指针，读者可阅读《C++11 unique_ptr智能指针》一节做系统学习。\nC++11 weak_ptr智能指针\n和 shared_ptr、unique_ptr 类型指针一样，weak_ptr 智能指针也是以模板类的方式实现的。weak_ptr（ T 为指针所指数据的类型）定义在头文件，并位于 std 命名空间中。因此，要想使用 weak_ptr 类型指针，程序中应首先包含如下 2 条语句：\n1 2 #include \u0026lt;memory\u0026gt; using namespace std; 第 2 句并不是必须的，可以不添加，则后续在使用 unique_ptr 指针时，必须标注std::。\n需要注意的是，C++11标准虽然将 weak_ptr 定位为智能指针的一种，但该类型指针通常不单独使用（没有实际用处），只能和 shared_ptr 类型指针搭配使用。甚至于，我们可以将 weak_ptr 类型指针视为 shared_ptr 指针的一种辅助工具，借助 weak_ptr 类型指针， 我们可以获取 shared_ptr 指针的一些状态信息，比如有多少指向相同的 shared_ptr 指针、shared_ptr 指针指向的堆内存是否已经被释放等等。\n需要注意的是，当 weak_ptr 类型指针的指向和某一 shared_ptr 指针相同时，weak_ptr 指针并不会使所指堆内存的引用计数加 1；同样，当 weak_ptr 指针被释放时，之前所指堆内存的引用计数也不会因此而减 1。也就是说，weak_ptr 类型指针并不会影响所指堆内存空间的引用计数。\n除此之外，weak_ptr 模板类中没有重载 * 和 -\u0026gt; 运算符，这也就意味着，weak_ptr 类型指针只能访问所指的堆内存，而无法修改它。\nweak_ptr指针的创建 创建一个 weak_ptr 指针，有以下 3 种方式：\n1.1 可以创建一个空 weak_ptr 指针，例如：\n1 std::weak_ptr\u0026lt;int\u0026gt; wp1; 1.2 凭借已有的 weak_ptr 指针，可以创建一个新的 weak_ptr 指针，例如：\n1 std::weak_ptr\u0026lt;int\u0026gt; wp2 (wp1); 若 wp1 为空指针，则 wp2 也为空指针；反之，如果 wp1 指向某一 shared_ptr 指针拥有的堆内存，则 wp2 也指向该块存储空间（可以访问，但无所有权）。\n1.3 weak_ptr 指针更常用于指向某一 shared_ptr 指针拥有的堆内存，因为在构建 weak_ptr 指针对象时，可以利用已有的 shared_ptr 指针为其初始化。例如：\n1 2 std::shared_ptr\u0026lt;int\u0026gt; sp (new int); std::weak_ptr\u0026lt;int\u0026gt; wp3 (sp); 由此，wp3 指针和 sp 指针有相同的指针。再次强调，weak_ptr 类型指针不会导致堆内存空间的引用计数增加或减少。\nweak_ptr模板类提供的成员方法 和 shared_ptr、unique_ptr 相比，weak_ptr 模板类提供的成员方法不多，表 1 罗列了常用的成员方法及各自的功能。\n成员方法 功 能 operator=() 重载 = 赋值运算符，是的 weak_ptr 指针可以直接被 weak_ptr 或者 shared_ptr 类型指针赋值。 swap(x) 其中 x 表示一个同类型的 weak_ptr 类型指针，该函数可以互换 2 个同类型 weak_ptr 指针的内容。 reset() 将当前 weak_ptr 指针置为空指针。 use_count() 查看指向和当前 weak_ptr 指针相同的 shared_ptr 指针的数量。 expired() 判断当前 weak_ptr 指针为否过期（指针为空，或者指向的堆内存已经被释放）。 lock() 如果当前 weak_ptr 已经过期，则该函数会返回一个空的 shared_ptr 指针；反之，该函数返回一个和当前 weak_ptr 指向相同的 shared_ptr 指针。 再次强调，weak_ptr 模板类没有重载 * 和 -\u0026gt; 运算符，因此 weak_ptr 类型指针只能访问某一 shared_ptr 指针指向的堆内存空间，无法对其进行修改。\n下面的样例演示了 weak_ptr 指针以及表 1 中部分成员方法的基本用法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; using namespace std; int main() { std::shared_ptr\u0026lt;int\u0026gt; sp1(new int(10)); std::shared_ptr\u0026lt;int\u0026gt; sp2(sp1); std::weak_ptr\u0026lt;int\u0026gt; wp(sp2); //输出和 wp 同指向的 shared_ptr 类型指针的数量 cout \u0026lt;\u0026lt; wp.use_count() \u0026lt;\u0026lt; endl; //释放 sp2 sp2.reset(); cout \u0026lt;\u0026lt; wp.use_count() \u0026lt;\u0026lt; endl; //借助 lock() 函数，返回一个和 wp 同指向的 shared_ptr 类型指针，获取其存储的数据 cout \u0026lt;\u0026lt; *(wp.lock()) \u0026lt;\u0026lt; endl; return 0; } 程序执行结果为：\n1 2 3 2 1 10 有关表 1 中其它成员函数的用法，感兴趣的读者可直接查看 weak_ptr 官网。\nC++ 14 新特性总结 函数返回值类型推导 C++14对函数返回类型推导规则做了优化，先看一段代码：\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;iostream\u0026gt; using namespace std; auto func(int i) { return i; } int main() { cout \u0026lt;\u0026lt; func(4) \u0026lt;\u0026lt; endl; return 0; } 使用C++11编译：\n1 2 3 4 5 ~/test$ g++ test.cc -std=c++11 test.cc:5:16: error: ‘func’ function uses ‘auto’ type specifier without trailing return type auto func(int i) { ^ test.cc:5:16: note: deduced return type only available with -std=c++14 or -std=gnu++14 上面的代码使用C++11是不能通过编译的，通过编译器输出的信息也可以看见这个特性需要到C++14才被支持。\n返回值类型推导也可以用在模板中：\n1 2 3 4 5 6 7 8 9 10 #include \u0026lt;iostream\u0026gt; using namespace std; template\u0026lt;typename T\u0026gt; auto func(T t) { return t; } int main() { cout \u0026lt;\u0026lt; func(4) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; func(3.4) \u0026lt;\u0026lt; endl; return 0; } 注意：\n函数内如果有多个return语句，它们必须返回相同的类型，否则编译失败。 1 2 3 4 5 auto func(bool flag) { if (flag) return 1; else return 2.3; // error } // inconsistent deduction for auto return type: ‘int’ and then ‘double’ 如果return语句返回初始化列表，返回值类型推导也会失败 1 2 3 auto func() { return {1, 2, 3}; // error returning initializer list } 如果函数是虚函数，不能使用返回值类型推导 1 2 3 4 struct A { // error: virtual function cannot have deduced return type virtual auto func() { return 1; } } 返回类型推导可以用在前向声明中，但是在使用它们之前，翻译单元中必须能够得到函数定义 1 2 3 4 5 6 auto f(); // declared, not yet defined auto f() { return 42; } // defined, return type is int int main() { cout \u0026lt;\u0026lt; f() \u0026lt;\u0026lt; endl; } 返回类型推导可以用在递归函数中，但是递归调用必须以至少一个返回语句作为先导，以便编译器推导出返回类型。 1 2 3 4 5 6 auto sum(int i) { if (i == 1) return i; // return int else return sum(i - 1) + i; // ok } lambda参数auto 在C++11中，lambda表达式参数需要使用具体的类型声明：\n1 auto f = [] (int a) { return a; } 在C++14中，对此进行优化，lambda表达式参数可以直接是auto：\n1 2 3 auto f = [] (auto a) { return a; }; cout \u0026lt;\u0026lt; f(1) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; f(2.3f) \u0026lt;\u0026lt; endl; 变量模板 C++14支持变量模板：\n1 2 3 4 5 6 7 8 template\u0026lt;class T\u0026gt; constexpr T pi = T(3.1415926535897932385L); int main() { cout \u0026lt;\u0026lt; pi\u0026lt;int\u0026gt; \u0026lt;\u0026lt; endl; // 3 cout \u0026lt;\u0026lt; pi\u0026lt;double\u0026gt; \u0026lt;\u0026lt; endl; // 3.14159 return 0; } 别名模板 C++14也支持别名模板：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 template\u0026lt;typename T, typename U\u0026gt; struct A { T t; U u; }; template\u0026lt;typename T\u0026gt; using B = A\u0026lt;T, int\u0026gt;; int main() { B\u0026lt;double\u0026gt; b; b.t = 10; b.u = 20; cout \u0026lt;\u0026lt; b.t \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; b.u \u0026lt;\u0026lt; endl; return 0; } constexpr的限制 C++14相较于C++11对constexpr减少了一些限制：\nC++11中constexpr函数可以使用递归，在C++14中可以使用局部变量和循环 1 2 3 constexpr int factorial(int n) { // C++14 和 C++11均可 return n \u0026lt;= 1 ? 1 : (n * factorial(n - 1)); } 在C++14中可以这样做：\n1 2 3 4 5 6 7 constexpr int factorial(int n) { // C++11中不可，C++14中可以 int ret = 0; for (int i = 0; i \u0026lt; n; ++i) { ret += i; } return ret; } C++11中constexpr函数必须必须把所有东西都放在一个单独的return语句中，而constexpr则无此限制： 1 2 3 constexpr int func(bool flag) { // C++14 和 C++11均可 return 0; } 在C++14中可以这样：\n1 2 3 4 5 constexpr int func(bool flag) { // C++11中不可，C++14中可以 if (flag) return 1; else return 0; } [[deprecated]]标记 C++14中增加了deprecated标记，修饰类、变、函数等，当程序中使用到了被其修饰的代码时，编译时被产生警告，用户提示开发者该标记修饰的内容将来可能会被丢弃，尽量不要使用。\n1 2 3 4 5 6 struct [[deprecated]] A { }; int main() { A a; return 0; } 当编译时，会出现如下警告：\n1 2 3 4 5 6 7 ~/test$ g++ test.cc -std=c++14 test.cc: In function ‘int main()’: test.cc:11:7: warning: ‘A’ is deprecated [-Wdeprecated-declarations] A a; ^ test.cc:6:23: note: declared here struct [[deprecated]] A { 二进制字面量与整形字面量分隔符 C++14引入了二进制字面量，也引入了分隔符，防止看起来眼花哈~\n1 2 int a = 0b0001\u0026#39;0011\u0026#39;1010; double b = 3.14\u0026#39;1234\u0026#39;1234\u0026#39;1234; std::make_unique 我们都知道C++11中有std::make_shared，却没有std::make_unique，在C++14已经改善。\n1 2 struct A {}; std::unique_ptr\u0026lt;A\u0026gt; ptr = std::make_unique\u0026lt;A\u0026gt;(); std::shared_timed_mutex与std::shared_lock C++14通过std::shared_timed_mutex和std::shared_lock来实现读写锁，保证多个线程可以同时读，但是写线程必须独立运行，写操作不可以同时和读操作一起进行。\n实现方式如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 struct ThreadSafe { mutable std::shared_timed_mutex mutex_; int value_; ThreadSafe() { value_ = 0; } int get() const { std::shared_lock\u0026lt;std::shared_timed_mutex\u0026gt; loc(mutex_); return value_; } void increase() { std::unique_lock\u0026lt;std::shared_timed_mutex\u0026gt; lock(mutex_); value_ += 1; } }; 为什么是timed的锁呢，因为可以带超时时间，具体可以自行查询相关资料哈，网上有很多。\nstd::integer_sequence 1 2 3 4 5 6 7 8 9 10 11 12 13 14 template\u0026lt;typename T, T... ints\u0026gt; void print_sequence(std::integer_sequence\u0026lt;T, ints...\u0026gt; int_seq) { std::cout \u0026lt;\u0026lt; \u0026#34;The sequence of size \u0026#34; \u0026lt;\u0026lt; int_seq.size() \u0026lt;\u0026lt; \u0026#34;: \u0026#34;; ((std::cout \u0026lt;\u0026lt; ints \u0026lt;\u0026lt; \u0026#39; \u0026#39;), ...); std::cout \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } int main() { print_sequence(std::integer_sequence\u0026lt;int, 9, 2, 5, 1, 9, 1, 6\u0026gt;{}); return 0; } 输出：7 9 2 5 1 9 1 6 std::integer_sequence和std::tuple的配合使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 template \u0026lt;std::size_t... Is, typename F, typename T\u0026gt; auto map_filter_tuple(F f, T\u0026amp; t) { return std::make_tuple(f(std::get\u0026lt;Is\u0026gt;(t))...); } template \u0026lt;std::size_t... Is, typename F, typename T\u0026gt; auto map_filter_tuple(std::index_sequence\u0026lt;Is...\u0026gt;, F f, T\u0026amp; t) { return std::make_tuple(f(std::get\u0026lt;Is\u0026gt;(t))...); } template \u0026lt;typename S, typename F, typename T\u0026gt; auto map_filter_tuple(F\u0026amp;\u0026amp; f, T\u0026amp; t) { return map_filter_tuple(S{}, std::forward\u0026lt;F\u0026gt;(f), t); } std::exchange 直接看代码吧：\n1 2 3 4 5 6 7 8 9 int main() { std::vector\u0026lt;int\u0026gt; v; std::exchange(v, {1,2,3,4}); cout \u0026lt;\u0026lt; v.size() \u0026lt;\u0026lt; endl; for (int a : v) { cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } return 0; } 看样子貌似和std::swap作用相同，那它俩有什么区别呢？\n可以看下exchange的实现：\n1 2 3 4 5 6 template\u0026lt;class T, class U = T\u0026gt; constexpr T exchange(T\u0026amp; obj, U\u0026amp;\u0026amp; new_value) { T old_value = std::move(obj); obj = std::forward\u0026lt;U\u0026gt;(new_value); return old_value; } 可以看见new_value的值给了obj，而没有对new_value赋值，这里相信您已经知道了它和swap的区别了吧！\nstd::quoted C++14引入std::quoted用于给字符串添加双引号，直接看代码：\n1 2 3 4 5 6 int main() { string str = \u0026#34;hello world\u0026#34;; cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; std::quoted(str) \u0026lt;\u0026lt; endl; return 0; } 编译\u0026amp;输出：\n1 2 3 4 ~/test$ g++ test.cc -std=c++14 ~/test$ ./a.out hello world \u0026#34;hello world\u0026#34; C++ 17 新特性总结 主要新特性如下：\n构造函数模板推导 结构化绑定 if-switch语句初始化 内联变量 折叠表达式 constexpr lambda表达式 namespace嵌套 __has_include预处理表达式 在lambda表达式用*this捕获对象副本 新增Attribute 字符串转换 std::variant std::optional std::any std::apply std::make_from_tuple as_const std::string_view file_system std::shared_mutex 构造函数模板推导 在C++17前构造一个模板类对象需要指明类型：\n1 pair\u0026lt;int, double\u0026gt; p(1, 2.2); // before c++17 C++17就不需要特殊指定，直接可以推导出类型，代码如下：\n1 2 pair p(1, 2.2); // c++17 自动推导 vector v = {1, 2, 3}; // c++17 结构化绑定 通过结构化绑定，对于tuple、map等类型，获取相应值会方便很多，看代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 std::tuple\u0026lt;int, double\u0026gt; func() { return std::tuple(1, 2.2); } int main() { auto[i, d] = func(); //是C++11的tie吗？更高级 cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; d \u0026lt;\u0026lt; endl; } //========================== void f() { map\u0026lt;int, string\u0026gt; m = { {0, \u0026#34;a\u0026#34;}, {1, \u0026#34;b\u0026#34;}, }; for (const auto \u0026amp;[i, s] : m) { cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; s \u0026lt;\u0026lt; endl; } } // ==================== int main() { std::pair a(1, 2.3f); auto[i, f] = a; cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; // 1 cout \u0026lt;\u0026lt; f \u0026lt;\u0026lt; endl; // 2.3f return 0; } 结构化绑定还可以改变对象的值，使用引用即可：\n1 2 3 4 5 6 7 // 进化，可以通过结构化绑定改变对象的值 int main() { std::pair a(1, 2.3f); auto\u0026amp; [i, f] = a; i = 2; cout \u0026lt;\u0026lt; a.first \u0026lt;\u0026lt; endl; // 2 } 注意结构化绑定不能应用于constexpr\n1 constexpr auto[x, y] = std::pair(1, 2.3f); // compile error, C++20可以 结构化绑定不止可以绑定pair和tuple，还可以绑定数组和结构体等\n1 2 3 4 5 6 7 8 9 10 11 12 13 int array[3] = {1, 2, 3}; auto [a, b, c] = array; cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; b \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; c \u0026lt;\u0026lt; endl; // 注意这里的struct的成员一定要是public的 struct Point { int x; int y; }; Point func() { return {1, 2}; } const auto [x, y] = func(); 这里其实可以实现自定义类的结构化绑定，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // 需要实现相关的tuple_size和tuple_element和get\u0026lt;N\u0026gt;方法。 class Entry { public: void Init() { name_ = \u0026#34;name\u0026#34;; age_ = 10; } std::string GetName() const { return name_; } int GetAge() const { return age_; } private: std::string name_; int age_; }; template \u0026lt;size_t I\u0026gt; auto get(const Entry\u0026amp; e) { if constexpr (I == 0) return e.GetName(); else if constexpr (I == 1) return e.GetAge(); } namespace std { template\u0026lt;\u0026gt; struct tuple_size\u0026lt;Entry\u0026gt; : integral_constant\u0026lt;size_t, 2\u0026gt; {}; template\u0026lt;\u0026gt; struct tuple_element\u0026lt;0, Entry\u0026gt; { using type = std::string; }; template\u0026lt;\u0026gt; struct tuple_element\u0026lt;1, Entry\u0026gt; { using type = int; }; } int main() { Entry e; e.Init(); auto [name, age] = e; cout \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; age \u0026lt;\u0026lt; endl; // name 10 return 0; } if-switch语句初始化 C++17前if语句需要这样写代码：\n1 2 3 4 int a = GetValue(); if (a \u0026lt; 101) { cout \u0026lt;\u0026lt; a; } C++17之后可以这样：\n1 2 3 4 5 6 7 8 9 10 // if (init; condition) if (int a = GetValue()); a \u0026lt; 101) { cout \u0026lt;\u0026lt; a; } string str = \u0026#34;Hi World\u0026#34;; if (auto [pos, size] = pair(str.find(\u0026#34;Hi\u0026#34;), str.size()); pos != string::npos) { std::cout \u0026lt;\u0026lt; pos \u0026lt;\u0026lt; \u0026#34; Hello, size is \u0026#34; \u0026lt;\u0026lt; size; } 使用这种方式可以尽可能约束作用域，让代码更简洁，可读性可能略有下降，但是还好\n内联变量 C++17前只有内联函数，现在有了内联变量，我们印象中C++类的静态成员变量在头文件中是不能初始化的，但是有了内联变量，就可以达到此目的：\n1 2 3 4 5 6 7 8 9 10 // header file struct A { static const int value; }; inline int const A::value = 10; // ==========或者======== struct A { inline static const int value = 10; } 折叠表达式 C++17引入了折叠表达式使可变参数模板编程更方便：\n1 2 3 4 5 6 7 8 template \u0026lt;typename ... Ts\u0026gt; auto sum(Ts ... ts) { return (ts + ...); } int a {sum(1, 2, 3, 4, 5)}; // 15 std::string a{\u0026#34;hello \u0026#34;}; std::string b{\u0026#34;world\u0026#34;}; cout \u0026lt;\u0026lt; sum(a, b) \u0026lt;\u0026lt; endl; // hello world constexpr lambda表达式 C++17前lambda表达式只能在运行时使用，C++17引入了constexpr lambda表达式，可以用于在编译期进行计算。\n1 2 3 4 int main() { // c++17可编译 constexpr auto lamb = [] (int n) { return n * n; }; static_assert(lamb(3) == 9, \u0026#34;a\u0026#34;); } 注意：constexpr函数有如下限制：\n函数体不能包含汇编语句、goto语句、label、try块、静态变量、线程局部存储、没有初始化的普通变量，不能动态分配内存，不能有new delete等，不能虚函数。\nnamespace嵌套 1 2 3 4 5 6 7 8 9 10 11 12 namespace A { namespace B { namespace C { void func(); } } } // c++17，更方便更舒适 namespace A::B::C { void func();) } __has_include预处理表达式 可以判断是否有某个头文件，代码可能会在不同编译器下工作，不同编译器的可用头文件有可能不同，所以可以使用此来判断：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #if defined __has_include #if __has_include(\u0026lt;charconv\u0026gt;) #define has_charconv 1 #include \u0026lt;charconv\u0026gt; #endif #endif std::optional\u0026lt;int\u0026gt; ConvertToInt(const std::string\u0026amp; str) { int value{}; #ifdef has_charconv const auto last = str.data() + str.size(); const auto res = std::from_chars(str.data(), last, value); if (res.ec == std::errc{} \u0026amp;\u0026amp; res.ptr == last) return value; #else // alternative implementation... 其它方式实现 #endif return std::nullopt; } 在lambda表达式用*this捕获对象副本 正常情况下，lambda表达式中访问类的对象成员变量需要捕获this，但是这里捕获的是this指针，指向的是对象的引用，正常情况下可能没问题，但是如果多线程情况下，函数的作用域超过了对象的作用域，对象已经被析构了，还访问了成员变量，就会有问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 struct A { int a; void func() { auto f = [this] { cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; }; f(); } }; int main() { A a; a.func(); return 0; } 所以C++17增加了新特性，捕获*this，不持有this指针，而是持有对象的拷贝，这样生命周期就与对象的生命周期不相关啦。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 struct A { int a; void func() { auto f = [*this] { // 这里 cout \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; }; f(); } }; int main() { A a; a.func(); return 0; } 新增Attribute 我们可能平时在项目中见过__declspec, attribute , #pragma指示符，使用它们来给编译器提供一些额外的信息，来产生一些优化或特定的代码，也可以给其它开发者一些提示信息。\n例如:\n1 2 3 struct A { short f[3]; } __attribute__((aligned(8))); void fatal() __attribute__((noreturn)); 在C++11和C++14中有更方便的方法：\n1 2 3 4 5 6 7 [[carries_dependency]] 让编译期跳过不必要的内存栅栏指令 [[noreturn]] 函数不会返回 [[deprecated]] 函数将弃用的警告 [[noreturn]] void terminate() noexcept; [[deprecated(\u0026#34;use new func instead\u0026#34;)]] void func() {} C++17又新增了三个：\n[[fallthrough]]，用在switch中提示可以直接落下去，不需要break，让编译期忽略警告\n1 2 3 4 5 6 7 8 9 10 switch (i) {} case 1: xxx; // warning case 2: xxx; [[fallthrough]]; // 警告消除 case 3: xxx; break; } 使得编译器和其它开发者都可以理解开发者的意图。\n[[nodiscard]] ：表示修饰的内容不能被忽略，可用于修饰函数，标明返回值一定要被处理\n1 2 3 4 [[nodiscard]] int func(); void F() { func(); // warning 没有处理函数返回值 } [[maybe_unused]] ：提示编译器修饰的内容可能暂时没有使用，避免产生警告\n1 2 3 4 5 6 void func1() {} [[maybe_unused]] void func2() {} // 警告消除 void func3() { int x = 1; [[maybe_unused]] int y = 2; // 警告消除 } 字符串转换 新增from_chars函数和to_chars函数，直接看代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;charconv\u0026gt; int main() { const std::string str{\u0026#34;123456098\u0026#34;}; int value = 0; const auto res = std::from_chars(str.data(), str.data() + 4, value); if (res.ec == std::errc()) { cout \u0026lt;\u0026lt; value \u0026lt;\u0026lt; \u0026#34;, distance \u0026#34; \u0026lt;\u0026lt; res.ptr - str.data() \u0026lt;\u0026lt; endl; } else if (res.ec == std::errc::invalid_argument) { cout \u0026lt;\u0026lt; \u0026#34;invalid\u0026#34; \u0026lt;\u0026lt; endl; } str = std::string(\u0026#34;12.34); double val = 0; const auto format = std::chars_format::general; res = std::from_chars(str.data(), str.data() + str.size(), value, format); str = std::string(\u0026#34;xxxxxxxx\u0026#34;); const int v = 1234; res = std::to_chars(str.data(), str.data() + str.size(), v); cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; \u0026#34;, filled \u0026#34; \u0026lt;\u0026lt; res.ptr - str.data() \u0026lt;\u0026lt; \u0026#34; characters \\n\u0026#34;; // 1234xxxx, filled 4 characters } std::variant C++17增加std::variant实现类似union的功能，但却比union更高级，举个例子union里面不能有string这种类型，但std::variant却可以，还可以支持更多复杂类型，如map等，看代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 int main() { // c++17可编译 std::variant\u0026lt;int, std::string\u0026gt; var(\u0026#34;hello\u0026#34;); cout \u0026lt;\u0026lt; var.index() \u0026lt;\u0026lt; endl; var = 123; cout \u0026lt;\u0026lt; var.index() \u0026lt;\u0026lt; endl; try { var = \u0026#34;world\u0026#34;; std::string str = std::get\u0026lt;std::string\u0026gt;(var); // 通过类型获取值 var = 3; int i = std::get\u0026lt;0\u0026gt;(var); // 通过index获取对应值 cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; } catch(...) { // xxx; } return 0; } 注意：一般情况下variant的第一个类型一般要有对应的构造函数，否则编译失败：\n1 2 3 4 5 6 struct A { A(int i){} }; int main() { std::variant\u0026lt;A, int\u0026gt; var; // 编译失败 } 如何避免这种情况呢，可以使用std::monostate来打个桩，模拟一个空状态。\n1 std::variant\u0026lt;std::monostate, A\u0026gt; var; // 可以编译成功 std::optional 我们有时候可能会有需求，让函数返回一个对象，如下：\n1 2 3 4 5 6 7 8 struct A {}; A func() { if (flag) return A(); else { // 异常情况下，怎么返回异常值呢，想返回个空呢 } } 有一种办法是返回对象指针，异常情况下就可以返回nullptr啦，但是这就涉及到了内存管理，也许你会使用智能指针，但这里其实有更方便的办法就是std::optional。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 std::optional\u0026lt;int\u0026gt; StoI(const std::string \u0026amp;s) { try { return std::stoi(s); } catch(...) { return std::nullopt; } } void func() { std::string s{\u0026#34;123\u0026#34;}; std::optional\u0026lt;int\u0026gt; o = StoI(s); if (o) { cout \u0026lt;\u0026lt; *o \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;error\u0026#34; \u0026lt;\u0026lt; endl; } } std::any C++17引入了any可以存储任何类型的单个值，见代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 int main() { // c++17可编译 std::any a = 1; cout \u0026lt;\u0026lt; a.type().name() \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; std::any_cast\u0026lt;int\u0026gt;(a) \u0026lt;\u0026lt; endl; a = 2.2f; cout \u0026lt;\u0026lt; a.type().name() \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; std::any_cast\u0026lt;float\u0026gt;(a) \u0026lt;\u0026lt; endl; if (a.has_value()) { cout \u0026lt;\u0026lt; a.type().name(); } a.reset(); if (a.has_value()) { cout \u0026lt;\u0026lt; a.type().name(); } a = std::string(\u0026#34;a\u0026#34;); cout \u0026lt;\u0026lt; a.type().name() \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; std::any_cast\u0026lt;std::string\u0026gt;(a) \u0026lt;\u0026lt; endl; return 0; } std::apply 使用std::apply可以将tuple展开作为函数的参数传入，见代码：\n1 2 3 4 5 6 7 8 9 int add(int first, int second) { return first + second; } auto add_lambda = [](auto first, auto second) { return first + second; }; int main() { std::cout \u0026lt;\u0026lt; std::apply(add, std::pair(1, 2)) \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; std::cout \u0026lt;\u0026lt; add(std::pair(1, 2)) \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; // error std::cout \u0026lt;\u0026lt; std::apply(add_lambda, std::tuple(2.0f, 3.0f)) \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } std::make_from_tuple 使用make_from_tuple可以将tuple展开作为构造函数参数\n1 2 3 4 5 6 7 8 9 struct Foo { Foo(int first, float second, int third) { std::cout \u0026lt;\u0026lt; first \u0026lt;\u0026lt; \u0026#34;, \u0026#34; \u0026lt;\u0026lt; second \u0026lt;\u0026lt; \u0026#34;, \u0026#34; \u0026lt;\u0026lt; third \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } }; int main() { auto tuple = std::make_tuple(42, 3.14f, 0); std::make_from_tuple\u0026lt;Foo\u0026gt;(std::move(tuple)); } std::string_view 通常我们传递一个string时会触发对象的拷贝操作，大字符串的拷贝赋值操作会触发堆内存分配，很影响运行效率，有了string_view就可以避免拷贝操作，平时传递过程中传递string_view即可。\n1 2 3 4 5 6 7 8 9 10 11 void func(std::string_view stv) { cout \u0026lt;\u0026lt; stv \u0026lt;\u0026lt; endl; } int main(void) { std::string str = \u0026#34;Hello World\u0026#34;; std::cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; std::endl; std::string_view stv(str.c_str(), str.size()); cout \u0026lt;\u0026lt; stv \u0026lt;\u0026lt; endl; func(stv); return 0; } as_const C++17使用as_const可以将左值转成const类型\n1 2 std::string str = \u0026#34;str\u0026#34;; const std::string\u0026amp; constStr = std::as_const(str); file_system C++17正式将file_system纳入标准中，提供了关于文件的大多数功能，基本上应有尽有，这里简单举几个例子：\n1 2 3 4 5 namespace fs = std::filesystem; fs::create_directory(dir_path); fs::copy_file(src, dst, fs::copy_options::skip_existing); fs::exists(filename); fs::current_path(err_code); std::shared_mutex C++17引入了shared_mutex，可以实现读写锁\nC++ 20 新特性总结 新增关键字(keywords) concept requires constinit consteval co_await co_return co_yield char8_t 新增标识符(Identifies) import module 模块(Modules) 优点\n没有头文件 声明实现仍然可分离, 但非必要 可以显式指定那些导出(类, 函数等) 不需要头文件重复引入宏 (include guards) 模块之间名称可以相同不会冲突 模块只处理一次, 编译更快 (头文件每次引入都需要处理) 预处理宏只在模块内有效 模块引入顺序无关紧要 创建模块 1 2 3 4 5 6 // cppcon.cpp export module cppcon; namespace CppCon { auto GetWelcomeHelper() { return \u0026#34;Welcome to CppCon 2019!\u0026#34;; } export auto GetWelcome() { return GetWelcomeHelper();} } 引用模块 1 2 3 4 5 // main.cpp import cppcon; int main(){ std::cout \u0026lt;\u0026lt; CppCon::GetWelcome(); } import 头文件 import 隐式地将 iostream 转换为模块 加速构建, 因为 iostream 只会处理一次 和预编译头 (PCH) 具有相似的效果 Ranges Ranges 是什么 ?\nRange 代表一串元素, 或者一串元素中的一段，类似 begin/end 对 好处:\n简化语法和方便使用 1 2 3 vector\u0026lt;int\u0026gt; data{11, 22, 33}; sort(begin(data), end(data)); sort(data); // 使用 Ranges 防止 begin/end 不配对 使变换/过滤等串联操作成为可能 相关功能\n视图(View): 延迟计算, 不持有, 不改写 Actions: 即时处理(eagerly evaluated), 改写 Algorithms: 所有接受 begin/end 对的算法都可用 Views 和 actions 使用管道符|串联 例子\n串联视图 1 2 3 4 5 6 vector\u0026lt;int\u0026gt; data {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}; auto result = data | views::remove_if([](int i) { return i % 2 == 1;}) | views::transform([](int i) { return to_string(i);}); // result = {\u0026#34;2\u0026#34;, \u0026#34;4\u0026#34;, \u0026#34;6\u0026#34;, \u0026#34;8\u0026#34;, \u0026#34;10\u0026#34; }; // 注意 以上操作被延迟, 当你遍历result的时候才触发 串联actions 1 2 vector\u0026lt;int\u0026gt; data{4, 3, 4, 1, 8, 0, 8}; vector\u0026lt;int\u0026gt; result = data | actions::sort | actions::unique; 排序然后去重 操作会原地对data进行更改, 然后返回 过滤和变换 1 2 3 4 5 int total = accumulate ( view::ints(1) | view::transform([](int i) {return i * i;}) | view::take(10), 0); view::ints(1) 产生一个无限的整型数列 平方 取前10个元素, 然后累加(accumulate) 所有的计算延迟到accumulate累加遍历的时候发生 协程(Coroutines) 什么是协程\n它是一个函数 具备如下关键字之一: co_wait: 挂起协程, 等待其它计算完成 co_return: 从协程返回 (协程 return 禁止使用) co_yield: 同 python yield, 弹出一个值, 挂起协程, 下一次调用继续协程的运行 for co_await 循环体 1 for co_await (for-range-declaration: expression) statement 用处\n简化如下问题的实现:\ngenerator 异步I/O 延迟计算 事件驱动的程序 例子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 experimental::generator\u0026lt;int\u0026gt; GetSequenceGenerator( int startValue, size_t numberOfValues) { for (int i = 0 startValue; i \u0026lt; startValue + numberOfValues; ++i){ time_t t = system_clock::to_time_t(system_clock::now()); cout \u0026lt;\u0026lt; std:: ctime(\u0026amp;t); co_yield i; } } int main() { auto gen = GetSequenceGenerator(10, 5); for (const auto\u0026amp; value : gen) { cout \u0026lt;\u0026lt; value \u0026lt;\u0026lt; \u0026#34;(Press enter for next value)\u0026#34; \u0026lt;\u0026lt; endl; cin.ignore(); } } Concepts 对模板类和函数的模板形参的约束 编译期断言 可声明多个 如何定义\n1 template\u0026lt;typename T\u0026gt; concept Incrementable = requires(T x) {x++; ++x;}; 使用\n1 2 3 4 5 6 7 8 9 10 template\u0026lt;Incrementable T\u0026gt; void Foo(T t); template\u0026lt;typename T\u0026gt; requires Incrementable\u0026lt;T\u0026gt; void Foo(T t); template\u0026lt;typename T\u0026gt; void Foo(T t) requires Incrementable\u0026lt;T\u0026gt;; void Foo(Incrementable auto t); 例子\n具备size() 方法, 且返回size_t 1 2 3 template \u0026lt;typename T\u0026gt; concept HasSize = requires (T x){ {x.size()} -\u0026gt; std::convertible_to\u0026lt;std::size_t\u0026gt;; }; 组合concept 1 2 3 4 5 6 7 8 9 template\u0026lt;typename T\u0026gt; requires Incrementable\u0026lt;T\u0026gt; \u0026amp;\u0026amp; Decrementable\u0026lt;T\u0026gt; void Foo(T t); // or template\u0026lt;typename T\u0026gt; concept Incr_Decrementable = Incrementable\u0026lt;T\u0026gt; \u0026amp;\u0026amp; Decrementable\u0026lt;T\u0026gt;; template\u0026lt;Incr_Decrementable T\u0026gt; void Foo(T t); Lambda 表达式的更新 [=, this] 需要显式捕获this变量\nC++20 之前 [=] 隐式捕获this C++20 开始 需要显式捕获this: [=, this] 模板形式的 Lambda 表达式\n可以在lambda表达式中使用模板语法\n1 2 3 []template\u0026lt;T\u0026gt;(T x) {/* ... */}; []template\u0026lt;T\u0026gt;(T* p) {/* ... */}; []template\u0026lt;T, int N\u0026gt;(T (\u0026amp;a)[N]) {/* ... */}; 原因1\nC++20之前: 获取 vector 元素类型, 你需要这么写 1 2 3 auto func = [](auto vec){ using T = typename decltype(vec)::value_type; } C++20 你可以: 1 2 3 auto func = []\u0026lt;typename T\u0026gt;(vector\u0026lt;T\u0026gt; vec){ // ... } 原因2: 方便获取通用lambda形参类型, 访问静态函数\nc++20 以前 1 2 3 4 5 auto func = [](auto const\u0026amp; x){ using T = std::decay_t\u0026lt;decltype(x)\u0026gt;; T copy = x; T::static_function(); using Iterator = typename T::iterator; } C++20 开始 1 2 3 4 auto func = []\u0026lt;typename T\u0026gt;(const T\u0026amp; x){ T copy = x; T::static_function(); using Iterator = typename T::iterator; } 原因3: 完美转发\npre c++20 1 2 3 auto func = [](auto\u0026amp;\u0026amp; ...args) { return foo(std::forward\u0026lt;decltype(args)\u0026gt;(args)...); } since c++20 1 2 3 auto func = []\u0026lt;typename …T\u0026gt;(T\u0026amp;\u0026amp; …args){ return foo(std::forward(args)...); } Lambda 表达式捕获支持打包展开(Pack Expansion)\nPre C++20\n1 2 3 4 5 6 template\u0026lt;class F, class... Args\u0026gt; auto delay_invoke(F f, Args... args){ return [f, args...]{ return std::invoke(f, args...); } } Since c++20\n1 2 3 4 5 6 7 template\u0026lt;class F, class... Args\u0026gt; auto delay_invoke(F f, Args... args){ // Pack Expansion: args = std::move(args)... return [f = std::move(f), args = std::move(args)...](){ return std::invoke(f, args...); } } 常量表达式(constexpr) 的更新 constexpr 虚函数\nconstexpr 的虚函数可以重写非 constexpr 的虚函数 非 constexpr 虚函数可以重写 constexpr 的虚函数 constexpr 函数可以:\n使用 dynamic_cast() 和 typeid 动态内存分配 更改union成员的值 包含 try/catch 但是不允许****throw语句 在触发常量求值的时候 try/catch 不发生作用 需要开启 constexpr std::vector constexpr string \u0026amp; vector - std::string 和 std::vector 类型现在可以作为 constexpr - 未来需要支持 constexpr 反射\n原子(Atomic)智能指针 智能指针(shared_ptr)线程安全吗?\n是: 引用计数控制单元线程安全, 保证对象只被释放一次 否: 对于数据的读写没有线程安全 如何将智能指针变成线程安全?\n使用 mutex 控制智能指针的访问\n使用全局非成员原子操作函数访问, 诸如: std::atomic_load(), atomic_store(), …\n缺点: 容易出错, 忘记使用这些操作 C++20: atomic\u0026lt;shared_ptr\u0026gt;, atomic\u0026lt;weak_ptr\u0026gt;\n内部原理可能使用了mutex 全局非成员原子操作函数标记为不推荐使用(deprecated) 例子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 template\u0026lt;typename T\u0026gt; class concurrent_stack { struct Node { T t; shared_ptr\u0026lt;Node\u0026gt; next; }; atomic_shared_ptr\u0026lt;Node\u0026gt; head; // C++11: 去掉 \u0026#34;atomic_\u0026#34; 并且在访问时, 需要用 // 特殊的函数控制线程安全, 例如用std::tomic_load public: class reference { shared_ptr\u0026lt;Node\u0026gt; p; \u0026lt;snip\u0026gt; }; auto find(T t) const { auto p = head.load(); // C++11: atomic_load(\u0026amp;head) while (p \u0026amp;\u0026amp; p-\u0026gt;t != t) p = p-\u0026gt;next; return reference(move(p)); } auto front() const { return reference(head); } void push_front(T t) { auto p = make_shared\u0026lt;Node\u0026gt;(); p-\u0026gt;t = t; p-\u0026gt;next = head; while (!head.compare_exchange_weak(p-\u0026gt;next, p)){ } // C++11: atomic_compare_exchange_weak(\u0026amp;head, \u0026amp;p-\u0026gt;next, p); } void pop_front() { auto p = head.load(); while (p \u0026amp;\u0026amp; !head.compare_exchange_weak(p, p-\u0026gt;next)) { } // C++11: atomic_compare_exchange_weak(\u0026amp;head, \u0026amp;p, p-\u0026gt;next); } }; 自动合流(Joining), 可中断(Cancellable) 的线程 std::jthread\n头文件 支持中断 析构函数中自动 Join 析构函数调用 stop_source.request_stop() 然后 join() 中断线程执行\n头文件 \u0026lt;stop_token\u0026gt; std::stop_token 用来查询线程是否中断 可以和condition_variable_any配合使用 std::stop_source 用来请求线程停止运行 stop_resources 和 stop_tokens 都可以查询到停止请求 std::stop_callback 如果对应的stop_token 被要求终止, 将会触发回调函数 用法: std::stop_callback myCallback(myStopToken, []{ /* … */ }); 例子\n自动合流 Join std::thread 在析构函数中如果线程 joinable() 会直接调用 std::terminate() 直接导致程序退出\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void DoWorkPreCpp20() { std::thread job([] { /* ... */ }); try { // ... Do something else ... } catch (...) { job.join(); throw; // rethrow } job.join(); } void DoWork() { std::jthread job([] { /* ... */ }); // ... Do something else ... } // jthread destructor automatically calls join() 中断 1 2 3 4 5 6 7 8 std::jthread job([](std::stop_token token) { while (!token.stop_requested()) { //... } }); //... job.request_stop(); // auto source = job.get_stop_source() // auto token = job.get_stop_token() C++20 同步(Synchronization)库 信号量(Semaphore), 维基百科请走这里 头文件 轻量级的同步原语 可用来实现任何其他同步概念, 如: mutex, latches, barriers, … 两种类型: 多元信号量(counting semaphore): 建模非负值资源计数 二元信号量(binary semaphore): 只有一个插孔, 两种状态, 最适合实现mutex std::atomic 等待和通知接口 等待/阻塞在原子对象直到其值发生改变, 通过通知函数发送通知 比轮训(polling)来的更高效 方法 wait() notify_one() notify_all() 锁存器(Latch)和屏障(Barrier) 头文件 线程的同步点 线程将阻塞在这个位置, 直到到达的线程个数达标才放行, 放行之后不再关闭 锁存器只会作用一次 屏障(Barriers) 在每个阶段中 一个参与者运行至屏障点时被阻塞，需要等待其他参与者都到达屏障点, 当到达线程数达标之后 阶段完成的回调将被执行 线程计数器被重置 开启下一阶段 线程得以继续执行 std::atomic_ref 头文件 Atomic 引用 通过引用访问变为原子操作, 被引用对象可以为非原子类型 指定初始化(Designated Initializers) 1 2 3 4 5 struct Data { int anInt = 0; std::string aString; }; Data d{ .aString = \u0026#34;Hello\u0026#34; }; 航天飞机操作符 \u0026lt;=\u0026gt; 正规名称: 三路比较运算符\n三路比较结果如下\n(a \u0026lt;=\u0026gt; b) \u0026lt; 0 // 如果 a \u0026lt; b 则为 true (a \u0026lt;=\u0026gt; b) \u0026gt; 0 // 如果 a \u0026gt; b 则为 true (a \u0026lt;=\u0026gt; b) == 0 // 如果 a 与 b 相等或者等价 则为 true 类似于C的strcmp 函数返回-1, 0, 1\n一般情况: 自动生成所有的比较操作符, 如果对象是结构体则逐个比较, 可以用下面代码代替所有的比较运算符\n1 auto X::operator\u0026lt;=\u0026gt;(const Y\u0026amp;) = default; 高级情况: 指定返回类型(支持6种所有的比较运算符)\n示例:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class Point { int x; int y; public: friend bool operator==(const Point\u0026amp; a, const Point\u0026amp; b){ return a.x==b.x \u0026amp;\u0026amp; a.y==b.y; } friend bool operator\u0026lt; (const Point\u0026amp; a, const Point\u0026amp; b){ return a.x \u0026lt; b.x || (a.x == b.x \u0026amp;\u0026amp; a.y \u0026lt; b.y); } friend bool operator!=(const Point\u0026amp; a, const Point\u0026amp; b) { return !(a==b); } friend bool operator\u0026lt;=(const Point\u0026amp; a, const Point\u0026amp; b) { return !(b\u0026lt;a); } friend bool operator\u0026gt; (const Point\u0026amp; a, const Point\u0026amp; b) { return b\u0026lt;a; } friend bool operator\u0026gt;=(const Point\u0026amp; a, const Point\u0026amp; b) { return !(a\u0026lt;b); } // ... 其他非比较函数 ... }; #include \u0026lt;compare\u0026gt; class Point { int x; int y; public: auto operator\u0026lt;=\u0026gt;(const Point\u0026amp;) const = default; // 比较操作符自动生成 // ... 其他非比较函数 ... }; 标准库类型支持 \u0026lt;=\u0026gt;\nvector, string, map, set, sub_match, … 范围 for 循环语句支持初始化语句 switch 语句初始化 (C++17):\n1 2 3 4 5 6 7 8 9 10 11 12 13 struct Foo { int value; int result; }; Foo GetData() { return Foo(); } int main() { switch (auto data = GetData(); data.value) { case 1: return data.result; } } if 语句初始化 (C++17):\n1 2 3 4 5 6 7 8 9 10 11 12 struct Foo { int value; int result; }; Foo* GetData() { return new Foo(); } int main() { if (auto data = GetData(); data) { // Use \u0026#39;data’ } } 创建完整的日期\n1 2 3 year_mouth_day fulldate1{2019y, September, 18d}; auto fulldate2 = 2019y / September / 18d; year_mouth_day fulldate3{Monday[3]/September/2019}; // Monday[3] 表示第三个星期一 新的事件间隔单位, 类似于秒, 分钟, …\n1 2 3 4 using days = duration\u0026lt;signed interger type of at least 25bits, ratio_multiply\u0026lt;ratio\u0026lt;24\u0026gt;, hours::period\u0026gt;\u0026gt;; using weeks = ...; using mouths = ...; using years = ...; 例子\n1 2 weeks w{1}; // 1 周 days d{w}; // 将 1 周 转换成天数 新的时钟类型, (之前有 system_clock, steady_clock, high_resolution_clock):\nutc_clock: represents Coordinated Universal Time (UTC), measures time since 00:00:00 UTC, Thursday, 1 January 1970, including leap seconds tai_clock: represents International Atomic Time (TAI), measures time since 00:00:00, 1 January 1958, and was offseted 10 seconds ahead of UTC at that date, it does not include leap seconds gps_clock: represents Global Positioning System (GPS) time, measures time since 00:00:00, 6 January 1980 UTC, it does not include leap seconds file_clock: alias for the clock used for std::filesystem::file_time_type, epoch is unspecified 新增system_clock相关的别名\n1 2 3 4 5 6 7 template\u0026lt;class Duration\u0026gt; using sys_time = std::chrono::time_point\u0026lt;std::chrono::system_clock, Duration\u0026gt;; using sys_seconds = sys_time\u0026lt;std::chrono::seconds\u0026gt;; using sys_days = sys_time\u0026lt;std::chrono::days\u0026gt;; // 用例: system_clock::time_point t = sys_days{ 2019y / September / 18d }; // date -\u0026gt; time_point auto yearmonthday = year_month_day{ floor\u0026lt;days\u0026gt;(t) }; // time_point -\u0026gt; date 日期 + 事件\n1 auto t = sys_days{2019y/September/18d} + 9h + 35min + 10s; // 2019-09-18 09:35:10 UTC 时区转换\n1 2 3 4 5 6 7 8 // Convert UTC to Denver time: zoned_time denver = { \u0026#34;America/Denver\u0026#34;, t }; // Construct a local time in Denver: auto t = zoned_time{ \u0026#34;America/Denver\u0026#34;, local_days{Wednesday[3] / September / 2019} + 9h }; // Get current local time: auto t = zoned_time{ current_zone(), system_clock::now() }; std::span 头文件\n某段连续数据的”视图”\n不持有数据, 不分配和销毁数据\n拷贝非常快, 推荐复制的方式传参(类似 string_view)\n不支持数据跨步(stride)\n可通过运行期确定长度也可编译器确定长度\n1 2 3 4 int data[42]; span\u0026lt;int, 42\u0026gt; a {data}; // fixed-size: 42 ints span\u0026lt;int\u0026gt; b {data}; // dynamic-size: 42 ints span\u0026lt;int, 50\u0026gt; c {data}; // compilation error span\u0026lt;int\u0026gt; d{ ptr, len }; // dynamic-size: len ints 特性测试宏 通过它可以判断编译器是否支持某个功能, 例如\n语言特性 __has_cpp_attribute(fallthrough) __cpp_binary_literals __cpp_char8_t __cpp_coroutines 标准库特性 __cpp_lib_concepts __cpp_lib_ranges __cpp_lib_scoped_lock 包含 C++ 标准库版本, 发布日期, 版权证书, 特性宏等\nconsteval函数 constexpr 函数可能编译期执行, 也可以在运行期执行, consteval 只能在编译器执行, 如果不满足要求编译不通过。\nconstinit 强制指定以常量方式初始化\n1 2 3 4 5 6 7 8 9 10 const char* GetStringDyn() { return \u0026#34;dynamic init\u0026#34;; } constexpr const char* GetString(bool constInit) { return constInit ? \u0026#34;constant init\u0026#34; : GetStringDyn(); } constinit const char* a = GetString(true); // ✔ constinit const char* b = GetString(false); // ❌ 用 using 引用 enum 类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 enum class CardTypeSuit { Clubs, Diamonds, Hearts, Spades }; std::string_view GetString(const CardTypeSuit cardTypeSuit) { switch (cardTypeSuit) { case CardTypeSuit::Clubs: return \u0026#34;Clubs\u0026#34;; case CardTypeSuit::Diamonds: return \u0026#34;Diamonds\u0026#34;; case CardTypeSuit::Hearts: return \u0026#34;Hearts\u0026#34;; case CardTypeSuit::Spades: return \u0026#34;Spades\u0026#34;; } } std::string_view GetString(const CardTypeSuit cardTypeSuit) { switch (cardTypeSuit) { using enum CardTypeSuit; // 这里 case Clubs: return \u0026#34;Clubs\u0026#34;; case Diamonds: return \u0026#34;Diamonds\u0026#34;; case Hearts: return \u0026#34;Hearts\u0026#34;; case Spades: return \u0026#34;Spades\u0026#34;; } } 格式化库(std::format) 不展开, 类似Python 的格式化,\n1 std::string s = std::format(\u0026#34;Hello CppCon {}!\u0026#34;, 2019); 增加数学常量 再也不用为 M_PI 发愁啦\n头文件 包含 e, log2e, log10e pi, inv_pi, inv_sqrt pi ln2, ln10 sqrt2, sqrt3, inv_sqrt3 egamma std::source_location 用于获取代码位置, 对于日志和错误信息尤其有用\n[[nodiscard(reason)]] 表明返回值不可抛弃, 加入理由的支持\n1 2 [[nodiscard(\u0026#34;Ignoring the return value will result in memory leaks.\u0026#34;)]] void* GetData() { /* ... */ } 位运算 加入循环移位, 计数0和1位等功能\n一些小更新 字符串支持 starts_with, ends_with map 支持 contains 查询是否存在某个键 list 和 forward list 的 remove, remove_if 和 unique 操作返回 size_type 表明删除个数 增加 shift_left, shift_right midpoint 计算中位数, 可避免溢出 lerp 线性插值 lerp( float a, float b, float t ) 返回 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-SIYwBQJu-1628786141278)(https://www.zhihu.com/equation?tex=a+%2B+t(b-a)]) 新的向量化策略 unsequenced_policy(execution::unseq) 1 2 3 4 std::string str = \u0026#34;Hello world!\u0026#34;; bool b = str.starts_with(\u0026#34;Hello\u0026#34;); // starts_with, ends_with std::map myMap{ std::pair{1, \u0026#34;one\u0026#34;s}, {2, \u0026#34;two\u0026#34;s}, {3, \u0026#34;three\u0026#34;s} }; bool result = myMap.contains(2); // contains, 再也不用 .find() == .end() 了 [1]. https://blog.csdn.net/qq_41854911/article/details/119657617\n","permalink":"https://jianye0428.github.io/en/posts/notes/c++/2022-12-14_c++_newfeature/","summary":"ref: [1]. https://blog.csdn.net/qq_41854911/article/details/119657617 C++ 11 新特性总结 C++ 11是什么，C++ 11标准的由来 C++ 这门编程语言的历史可以追溯至 1979 年，当时的 Bjarne Stroustrup（C++ 之父，后续简称","title":"C++11、C++14、C++17、C++20新特性总结"},{"content":"ref: [1]. https://blog.csdn.net/Yangy_Jiaojiao/article/details/127588598 [2]. https://blog.csdn.net/Yangy_Jiaojiao/article/details/128145609\n1. 基础知识（一） 1.1 C++语言的特点 ①C++在C的基础上引入了面向对象机制，同时也兼容C语言； ②C++三大特性：封装、继承、多态； ③C++程序结构清晰、易于扩充、程序可读性好； ④C++代码质量高，运行效率高、仅比汇编语言慢10%~20%； ⑥C++可复用性高，C++引入了模板的概念，有专门的模板库(STL)； ⑦C++是不断发展的语言，C++11中新引入了nullptr、auto变量、Lambda匿名函数、右值引用、智能指针。\nC++面向对象的三大特征\n封装性： 将客观事物抽象成类，每个类对自身的数据和方法实行访问控制，包括（private，protected，public）。 继承性： 广义的继承有三种实现形式：实现继承（使用基类的属性和方法而无需额外编码的能力)、可视继承(子窗体使用父窗体的外观和实现代码)、接口继承(仅使用属性和方法,实现滞后到子类实现)。 多态性： 是将父类对象设置成为和一个或更多它的子对象相等的技术。用子类对象给父类对象赋值之后，父类对象就可以根据当前赋值给它的子对象的特性以不同的方式运作。\n1.2 C++和C语言的区别 ①C语言是C++的子集，C++可以很好兼容C语言。但是C++又有很多新特性，如引用、智能指针、auto变量等； ②C++是面对对象的编程语言；C语言是面对过程的编程语言； ③C语言有一些不安全的语言特性，如指针使用的潜在危险、强制转换的不确定性、内存泄露等。而C++对此增加了不少新特性来改善安全性，如const常量、引用、cast转换、智能指针、try—catch等等； ④C++可复用性高，C++引入了模板的概念，后面在此基础上，实现了方便开发的标准模板库STL。C++的STL库相对于C语言的函数库更灵活、更通用。\n1.3 C++中 struct 和 class 的区别 ①struct 一般用于描述一个数据结构集合，而 class 是对一个对象数据的封装； ②struct 中默认的访问控制权限是 public 的，而 class 中默认的访问控制权限是 private 的； ③在继承关系中，struct 默认是公有继承，而 class 是私有继承； ④class关键字可以用于定义模板参数，就像typename，而 struct 不能用于定义模板参数。\n1.4 include头文件的顺序以及双引号\u0026quot;\u0026ldquo;和尖括号\u0026lt;\u0026gt;的区别 区别： ①尖括号\u0026lt; \u0026gt;的头文件是系统文件，双引号\u0026quot; \u0026quot;的头文件是自定义文件； ②编译器预处理阶段查找头文件的路径不一样； 查找路径： ①使用尖括号\u0026lt; \u0026gt;(系统文件)的头文件的查找路径：编译器设置的头文件路径–\u0026gt;系统变量; ②使用双引号\u0026quot; \u0026quot;(自定义文件)的头文件的查找路径：当前头文件目录–\u0026gt;编译器设置的头文件路径–\u0026gt;系统变量。\n1.5 C++结构体和C结构体的区别 ①C的结构体内不允许有函数存在，C++允许有内部成员函数，且允许该函数是虚函数； ②C的结构体对内部成员变量的访问权限只能是public，而C++允许public,protected,private三种； ③C 中使用结构体需要加上 struct 关键字，或者对结构体使用 typedef 取别名，而 C++ 中可以省略 struct 关键字直接使用； ④C语言的结构体是不可以继承的，C++的结构体是可以从其他的结构体或者类继承过来的。\n1.6 导入C函数的关键字是什么，C++编译时和C有什么不同？ 关键字： 在C++中，导入C函数的关键字是extern，表达形式为extern “C”， extern \u0026ldquo;C\u0026quot;的主要作用就是为了能够正确实现C++代码调用其他C语言代码。加上extern \u0026ldquo;C\u0026quot;后，会指示编译器这部分代码按C语言的进行编译，而不是C++的。\n编译区别： 由于C++支持函数重载，因此编译器编译函数的过程中会将函数的参数类型也加到编译后的代码中，而不仅仅是函数名；而C语言并不支持函数重载，因此编译C语言代码的函数时不会带上函数的参数类型，一般只包括函数名。 总结: 区别在于在编译过程中是否带上函数的参数类型，c++带，c不带。\n1.7 简述C++从代码到可执行二进制文件的过程 预编译、编译、汇编、链接 ①预编译：这个过程主要的处理操作如下： （1） 将所有的#define删除，并且展开所有的宏定义 （2） 处理所有的条件预编译指令，如#if、#ifdef （3） 处理#include预编译指令，将被包含的文件插入到该预编译指令的位置。 （4） 过滤所有的注释 （5） 添加行号和文件名标识 ②编译：这个过程主要的处理操作如下： （1） 词法分析：将源代码的字符序列分割成一系列的记号。 （2） 语法分析：对记号进行语法分析，产生语法树。 （3） 语义分析：判断表达式是否有意义。 （4） 代码优化： （5） 目标代码生成：生成汇编代码。 （6） 目标代码优化 ③汇编：这个过程主要是将汇编代码转变成机器可以执行的指令。 ④链接：将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。 ​ 链接分为静态链接和动态链接。 ​ (1) 静态链接，是在链接的时候就已经把要调用的函数或者过程链接到了生成的可执行文件中，就算你再去把静态库删除也不会影响可执行程序的执行；生成的静态链接库，Windows下以.lib为后缀，Linux下以.a为后缀。 ​ (2) 动态链接，是在链接的时候没有把调用的函数代码链接进去，而是在执行的过程中，再去找要链接的函数，生成的可执行文件中没有函数代码，只包含函数的重定位信息，所以当你删除动态库时，可执行程序就不能运行。生成的动态链接库，Windows下以.dll为后缀，Linux下以.so为后缀。\n1.8 static关键字的作用 ①定义全局静态变量和局部静态变量：在变量前面加上static关键字。static的变量默认初始化为0。（static变量）初始化的静态变量会在数据段分配内存，未初始化的静态变量会在BSS段分配内存。直到程序结束，静态变量始终会维持前值。只不过全局静态变量(在整个工程文件有效)和局部静态变量(在当前定义的文件内有效)的作用域不一样； ②定义静态函数：在函数返回类型前加上static关键字，函数即被定义为静态函数。静态函数只能在本源文件中使用； ③在变量类型前加上static关键字，变量即被定义为静态变量。静态变量只能在本源文件中使用； ④在c++中，static关键字可以用于定义类中的静态成员变量：使用静态数据成员，它既可以被当成全局变量那样去存储，但又被隐藏在类的内部。类中的static静态数据成员拥有一块单独的存储区，而不管创建了多少个该类的对象。所有这些对象的静态数据成员都共享这一块静态存储空间，static修饰的变量要在类外初始化。 ⑤在c++中，static关键字可以用于定义类中的静态成员函数：与静态成员变量类似，类里面同样可以定义静态成员函数。只需要在函数前加上关键字static即可。如静态成员函数也是类的一部分，而不是对象的一部分。所有这些对象的静态数据成员都共享这一块静态存储空间，只能访问类的static成员变量，static修饰的变量要在类外初始化。\n1.9 数组和指针的区别 概念： (1）数组：数组是用于储存多个相同类型数据的集合。数组名是首元素的地址。 (2）指针：指针相当于一个变量，但是它和不同变量不一样，它存放的是其它变量在内存中的地址。指针名指向了内存的首地址。 区别： 赋值：同类型指针变量可以相互赋值；数组不行，只能一个一个元素的赋值或拷贝； 存储方式： 数组：数组在内存中是连续存放的，开辟一块连续的内存空间。数组是根据数组的下标进行访问的，数组的存储空间，不是在静态区就是在栈上。 指针：指针很灵活，它可以指向任意类型的数据。指针的类型说明了它所指向地址空间的内存。由于指针本身就是一个变量，再加上它所存放的也是变量，所以指针的存储空间不能确定。\n1.10 什么是函数指针，如何定义函数指针，有什么使用场景 概念： 函数指针就是指向函数的指针变量。每一个函数都有一个入口地址，该函数入口地址就是函数指针所指向的地址。\n定义形式：\n1 2 3 int func(int a); int (*f)(int a); f = \u0026amp;func; 使用场景： 回调（callback）。我们调用别人提供的 API函数(Application Programming Interface,应用程序编程接口)，称为Call；如果别人的库里面调用我们的函数，就叫Callback。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //以库函数qsort排序函数为例，它的原型如下： void qsort(void *base,//void*类型，代表原始数组 size_t nmemb, //第二个是size_t类型，代表数据数量 size_t size, //第三个是size_t类型，代表单个数据占用空间大小 int(*compar)(const void *,const void *)//第四个参数是函数指针 ); //第四个参数告诉qsort，应该使用哪个函数来比较元素，即只要我们告诉qsort比较大小的规则，它就可以帮我们对任意数据类型的数组进行排序。在库函数qsort调用我们自定义的比较函数，这就是回调的应用。 //示例 int num[100]; int cmp_int(const void* _a , const void* _b){//参数格式固定 int* a = (int*)_a; //强制类型转换 int* b = (int*)_b; return *a - *b;　} qsort(num,100,sizeof(num[0]),cmp_int); //回调 1.11 静态变量什么时候初始化 对于C语言的全局和静态变量，初始化发生在任何代码执行之前，属于编译期初始化。 而C++标准规定：全局或静态对象当且仅当对象首次用到时才进行构造。\n1.12 nullptr调用成员函数可以吗？为什么？ 可以。因为在编译时对象就绑定了函数地址，和指针空不空没关系。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 //给出实例 class animal { public: void sleep() { cout \u0026lt;\u0026lt; \u0026#34;animal sleep\u0026#34; \u0026lt;\u0026lt; endl; } void breathe() { cout \u0026lt;\u0026lt; \u0026#34;animal breathe haha\u0026#34; \u0026lt;\u0026lt; endl; } }; class fish :public animal { public: void breathe(){ cout \u0026lt;\u0026lt; \u0026#34;fish bubble\u0026#34; \u0026lt;\u0026lt; endl; } }; int main() { animal *pAn=nullptr; //类指针 pAn-\u0026gt;breathe(); // 输出：animal breathe haha fish *pFish = nullptr; pFish-\u0026gt;breathe(); // 输出：fish bubble return 0; } // 原因：因为在编译时对象就绑定了函数地址，和指针空不空没关系。 // pAn-\u0026gt;breathe();编译的时候，函数的地址就和指针pAn绑定了； // 调用breath(*this), this就等于pAn。由于函数中没有需要解引用this的地方，所以函数运行不会出错， // 但是若用到this，因为this=nullptr，运行出错。 1.13 什么是野指针，怎么产生的，如何避免？ 概念： 野指针就是指针指向的位置是不可知的（随机的、不正确的、没有明确限制的）；\n产生原因：释放内存后指针不及时置空（野指针），依然指向了该内存，那么可能出现非法访问的错误。这些我们都要注意避免。(内存泄露)\n避免办法： （1）初始化置NULL （2）申请内存后判空 （3）指针释放后置NULL （4）使用智能指针\n1.14 静态局部变量，全局变量，局部变量的特点，以及使用场景 ①首先从作用域考虑： C++里作用域可分为6种：全局，局部，类，语句，命名空间和文件作用域。 全局变量：全局作用域，可以通过extern作用于其他非定义的源文件。 静态全局变量 ：全局作用域+文件作用域，所以无法在其他文件中使用。 局部变量：局部作用域，比如函数的参数，函数内的局部变量等等。 静态局部变量 ：局部作用域，只被初始化一次，直到程序结束。\n②从所在空间考虑：除了局部变量在栈上外，其他都在静态存储区。因为静态变量都在静态存储区，所以下次调用函数的时候还是能取到原来的值。\n③生命周期： 局部变量在栈上，出了作用域就回收内存；而全局变量、静态全局变量、静态局部变量都在静态存储区，直到程序结束才会回收内存。\n④使用场景：从它们各自特点就可以看出各自的应用场景，不再赘述。\n1.15 C++继承 ①公有继承public：基类的公有成员和保护成员作为派生类的成员时，它们都保持原有的状态，而基类的私有成员仍然是私有的，不能被这个派生类的子类所访问。 ②私有继承private：私有继承的特点是基类的公有成员和保护成员都作为派生类的私有成员，并且不能被这个派生类的子类所访问。 ③保护继承protect：保护继承的特点是基类的所有公有成员和保护成员都成为派生类的保护成员，并且只能被它的派生类成员函数或友元访问，基类的私有成员仍然是私有的\n1.16 常量指针和指针常量 常量指针: 内存里的值不变 指针常量: 指针指向的内存地址不变\n1 2 3 4 5 6 1. const int a; //指的是a是一个常量，不允许修改。 2. const int *a; //a指针所指向的内存里的值不变，即（*a）不变 常量指针 3. int const *a; //同const int *a; 4. int *const a; //a指针所指向的内存地址不变，即a不变 指针常量 5. const int *const a; //都不变，即（*a）不变，a也不变 1.17 内联函数和函数的区别 ①内联函数比普通函数多了关键字inline； ②内联函数避免了函数调用的开销；普通函数有调用的开销； ③普通函数在被调用的时候，需要寻址（函数入口地址）；内联函数不需要寻址。 ④内联函数有一定的限制，内联函数体要求代码简单，不能包含复杂的结构控制语句(内联函数内不允许用循环语句和开关语句。)；普通函数没有这个要求。\n1.18 简述C++有几种传值方式，之间的区别是什么？ 值传递、引用传递、指针传递 ①值传递：形参即使在函数体内值发生变化，也不会影响实参的值； ②引用传递：形参在函数体内值发生变化，会影响实参的值； ③指针传递：在指针指向没有发生改变的前提下，形参在函数体内值发生变化，会影响实参的值；\n1.19 内联函数和宏函数的区别 宏常量\u0026amp;宏函数\n定义:\n1 2 3 4 5 6 // a. 定义一个宏常量 #define MAX 1024 // 宏常量 MAX称为符号常量 // b. 定义一个宏函数 // 宏函数:宏函数就是使用宏定义定义出来的函数,并不是真正意义上的函数。 #define GETSUM(x, y) ((x) + (y)) // 宏函数 使用宏函数的注意事项: 要保证运算的完整性； 宏函数的使用场景:频繁调用和短小的函数,封装成宏函数； 使用宏函数的优点:以空间换时间； 宏定义和函数的区别:\n宏在预处理阶段完成替换，之后被替换的文本参与编译，相当于直接插入了代码，运行时不存在函数调用，执行起来更快；函数调用在运行时需要跳转到具体调用函数； 宏定义属于在结构中插入代码，没有返回值；函数调用具有返回值； 宏定义参数没有类型，不进行类型检查；函数参数具有类型，需要检查类型； 宏定义不要在最后加分号； 宏定义和typedef的区别:\n宏主要用于定义常量及书写复杂的内容；typedef主要用于定义类型别名； 宏替换发生在预编译阶段之前，属于文本插入替换；typedef是编译的一部分； 宏不检查类型；typedef会检查数据类型； 宏不是语句，不在在最后加分号；typedef是语句，要加分号标识结束； 注意对指针的操作，typedef char * p_char和#define p_char char *区别巨大； 宏函数和内联函数的区别:\n1.在使用时，宏只做简单字符串替换（编译前）。而内联函数可以进行参数类型检查（编译时），且具有返回值； 2.内联函数在编译时直接将函数代码嵌入到目标代码中，省去函数调用的开销来提高执行效率，并且进行参数类型检查，具有返回值，可以实现重载； 3.宏定义时要注意书写（参数要括起来）否则容易出现歧义(保证运算的完整性)，内联函数不会产生歧义； 4.内联函数有类型检测、语法判断等功能，而宏没有；\ndefine宏定义和const的区别:\n处理阶段：define是在编译的预处理阶段起作用，而const是在编译、运行的时候起作用；\n安全性：\ndefine只做替换，不做类型检查和计算，也不求解，容易产生错误，一般最好加上一个大括号包含住全部的内容，要不然很容易出错； const常量有数据类型，编译器可以对其进行类型安全检查； 内存占用：\ndefine只是将宏名称进行替换，在内存中会产生多份相同的备份。const在程序运行中只有一份备份，且可以执行常量折叠，能将复杂的的表达式计算出结果放入常量表； 宏定义的数据没有分配内存空间，只是插入替换掉；const定义的变量只是值不能改变，但要分配内存空间； 1.20 四种cast类型转换 作用：克服c中强制类型转化带来的风险，C++引入四种更加安全的强制类型转换运算符（明确转换的目的，便于程序的维护和分析）\nconst_cast： 1 2 3 4 // 1.去除const属性，将只读变为只读写 // 2.针对常量指针、常量引用和常量对象 const char *p; char *p1 = const_cast\u0026lt;char*\u0026gt;(p); static_cast 内置数据类型之间的转换，int转double，char转int 基类指针与派生类之间的转换，只能转换有继承或派生关系的类。用于类层次结构之间基类和派生类指针和引用之间的转换，进行向上转型是安全的，但是进行向下转型是不安全的，但是是可以转换的; 向上转型：我们知道基类的引用和指针都可以指向派生类的对象，那么将派生类的指针或者引用强转为基类的指针或者引用，那么这就是向上转型，也就是向父类转; 向下转型：向下转型就和向上转型相反，它是将父类的指针或者引用，强制转换为子类的指针或者引用 把void类型指针转换为目标类型的指针 任何类型的表达式转化为void类型 1 2 3 4 5 6 7 8 9 10 // 整形转浮点型 int a = 10; double b = static_cast\u0026lt;double\u0026gt;a; //基类指针转派生类 class A{}; class B : public A{}; A *pA = new A; B *pB = static_cast\u0026lt;B*\u0026gt;(pA); reinterpret_cast 可以将一个类型的指针转换为其它任意类型的指针，也可以用在指针和整形数据之间的转换。它是很危险的，如果我们没有使用它的充分理由，那么就不要使用它 为运算对象的位模式提供较低层次上的重新解释 用于底层的强制转换，依赖于机器，一般使用较少 dynamic_cast dynamic_cast是运行时处理的，运行时进行类型检查，其他三种是编译时处理的 不能用于内置数据类型之间的转换 dynamic_cast在进行上行转换时和static_cast效果是一样的，但是进行下行转换时会进行类型检查，比static_cast更加安全，下行转换是否成功取决于转换对象的实际类型与目标类型是否相同 要求基类必须具有虚函数，否则编译不通过 若转换成功，返回的是指向目标的指针或引用，不成功返回NULL 2. 基础知识（二） 2.1 写出 int 、bool、 float 、指针变量与 “零值”比较的if 语句 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 //int与零值比较 if ( n == 0 ) if ( n != 0 ) //bool与零值比较 if (flag) // 表示flag为真 if (!flag) // 表示flag为假 //float与零值比较 const float EPSINON = 0.00001; if ((x \u0026gt;= - EPSINON) \u0026amp;\u0026amp; (x \u0026lt;= EPSINON) //其中EPSINON是允许的误差（即精度）。 //指针变量与零值比较 if (p == nullptr) if (p != nullptr) 2.2 变量的声明和定义有什么区别 ① 变量的定义为变量分配地址和存储空间， 变量的声明不分配地址。 ② 一个变量可以在多个地方声明， 但是只在一个地方定义。声明多次，定义一次。 ③ 加入extern 修饰的是变量的声明，说明此变量将在文件外部或在文件后面部分定义。 ④ 说明：很多时候一个变量，只是声明不分配内存空间，直到具体使用时才初始化，分配内存空间， 如外部变量。\n1 2 3 4 5 6 7 8 int main() { extern int A; //这是个声明而不是定义，声明A是一个已经定义了的外部变量 //注意：声明外部变量时可以把变量类型去掉如：extern A; dosth(); //执行函数 } int A; //是定义，定义了A为整型的外部变量 2.3 简述 #ifdef、#else、#endif和#ifndef的作用 利用 #ifdef、#endif 将某程序功能模块包括进去，以向特定用户提供该功能。在不需要时用户可轻易将其屏蔽。\n1 2 3 4 5 6 7 8 9 #ifdef MATH #include “math.c” #endif //在子程序前加上标记，以便于追踪和调试。 #ifdef DEBUG printf (“Indebugging…!”); #endif 应对硬件的限制。由于一些具体应用环境的硬件不一样，限于条件，本地缺乏这种设备，只能绕过硬件，直接写出预期结果。 注意：虽然不用条件编译命令而直接用if语句也能达到要求，但那样做目标程序长（因为所有语句都编译），运行时间长（因为在程序运行时间对if语句进行测试）。而采用条件编译，可以减少被编译的语句，从而减少目标程序的长度，减少运行时间。\n2.4 结构体可以直接赋值吗 ①结构体声明时可以直接初始化，同一结构体的不同对象之间也可以直接赋值，但是当结构体中含有指针“成员”时一定要小心。 ②注意：当有多个指针指向同一段内存时，某个指针释放这段内存可能会导致其他指针的非法操作。因此在释放前一定要确保其他指针不再使用这段内存空间。\n2.5 sizeof 和strlen 的区别 ①sizeof是一个操作符，strlen是库函数。 ②sizeof的参数可以是数据的类型，也可以是变量，而strlen只能以结尾为‘\\0’的字符串作参数。 ③编译器在编译时就计算出了sizeof的结果，而strlen函数必须在运行时才能计算出来。并且sizeof计算的是数据类型占内存的大小，而strlen计算的是字符串实际的长度。 ④数组做sizeof的参数不退化，传递给strlen就退化为指针了\n2.6 sizeof求类型大小 ①类的大小为类的非静态成员数据的类型大小之和，也就是说静态成员数据不作考虑。 普通成员函数与sizeof无关。 ②虚函数由于要维护在虚函数表，所以要占据一个指针大小，也就是4字节。 类的总大小也遵守类似class字节对齐的，调整规则。\nref:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 (32 位) 指针都是 4个字节 char 1个字节 short 两个字节 int 4个字节 long 4个字节 long int 4个字节 float 4个字节 double 8个字节 long double 8个字节 (64 字节) 指针都是一个字长, 8个字节 char 1个字节 short 2个字节 int 4个字节 long 8个字节 long int 8个字节 double 8个字节 long double 也可以变长了, 16个字节 例如有如下结构体：\n1 2 3 4 5 6 struct Stu //自定义的数据类型，允许用户存储不同的数据类型 { int id; char sex; float hight; }; 那么一个这样的结构体变量占多大内存呢？也就是 cout\u0026laquo;sizeof(Stu)\u0026laquo;endl; 会输出什么？ 在了解字节对齐方式之前想当然的会以为：sizeof(Stu) = sizeof(int)+sizeof(char)+sizeof(float) = 9. 然而事实并非如此！\n字节对齐原则: 在系统默认的对齐方式下：每个成员相对于这个结构体变量地址的偏移量正好是该成员类型所占字节的整数倍，且最终占用字节数为成员类型中最大占用字节数的整数倍。\n在这个例子中，id的偏移量为0（0=40），sex的偏移量为4（4=14），hight的偏移量为8（8=24），此时占用12字节，也同时满足12=34.所以sizeof(Stu)=12.\n总结： ①最终大小一定是最大数据类型的整数倍； ②静态变量不占空间 ③每种类型的偏移量为自身的n倍； 详细请查阅：struct/class等内存字节对齐问题详解\nref: struct地址偏移量计算\n2.7 C 语言的关键字 static 和 C++ 的关键字 static 有什么区别 ①在 C 中 static 用来修饰局部静态变量和外部静态变量、函数。而 C++中除了上述功能外，还用来定义类的成员变量和函数。即静态成员和静态成员函数。 ②注意：编程时 static 的记忆性和全局性的特点可以让在不同时期调用的函数进行通信，传递信息，而 C++的静态成员则可以在多个对象实例间进行通信，传递信息。\n2.8 Ｃ 语言的 malloc 和 Ｃ＋＋ 中的 new 有什么区别 ①new 、delete 是操作符，可以重载，只能在C++ 中使用。 ②malloc、free 是函数，可以覆盖，C、C++ 中都可以使用。 ③new 可以调用对象的构造函数，对应的delete 调用相应的析构函数。 ④malloc 仅仅分配内存，free 仅仅回收内存，并不执行构造和析构函数。 ⑤new 、delete 返回的是某种数据类型指针，malloc、free 返回的是void 指针。 注意：malloc 申请的内存空间要用free 释放，而new 申请的内存空间要用delete 释放，不要混用。 2.11 new 和 malloc的区别\n2.9 写一个 “标准” 宏MIN 1 #define min(a,b) ((a)\u0026lt;=(b)?(a):(b)) 2.10 ++i和i++的区别 ++i先自增1，再返回；i++先返回i,再自增1 前置版本将对象本身作为左值返回，后置版本将对象原始值的副本最有右值返回。\n2.11 new和malloc的区别，各自底层实现原理 (delete 和 free类似) ①new是操作符，而malloc是函数。 ②new在调用的时候先分配内存，再调用构造函数，释放的时候调用析构函数；而malloc没有构造函数和析构函数。 ③malloc需要给定申请内存的大小，返回的指针需要强转；new会调用构造函数，不用指定内存的大小，返回指针不用强转。 ④new可以被重载；malloc不行 ⑤new分配内存更直接和安全。 ⑥new发生错误抛出异常，malloc返回null\n2.12 const 和 define 的区别 区别\n（1）就起作用的阶段而言： #define是在编译的预处理阶段起作用，而const是在 编译、运行的时候起作用。 （2）就起作用的方式而言： #define只是简单的字符串替换，没有类型检查。而const有对应的数据类型，是要进行判断的，可以避免一些低级的错误。 （3）就存储方式而言：#define只是进行展开，有多少地方使用，就替换多少次，它定义的宏常量在内存中有若干个备份；const定义的只读变量在程序运行过程中只有一份备份。 （4）从代码调试的方便程度而言： const常量可以进行调试的，define是不能进行调试的，因为在预编译阶段就已经替换掉了。\nconst优点：\n（1）const常量有数据类型，而宏常量没有数据类型。编译器可以对前者进行类型安全检查。而对后者只进行字符替换，没有类型安全检查，并且在字符替换可能会产生意料不到的错误。 （2）有些集成化的调试工具可以对const常量进行调试，但是不能对宏常量进行调试。 （3）const可节省空间，避免不必要的内存分配，提高效率\n2.13 C++中函数指针和指针函数的区别 定义不同 指针函数本质是一个函数，其返回值为指针。 函数指针本质是一个指针，其指向一个函数。\n写法不同 指针函数：int *fun(int x,int y); 函数指针：int (*fun)(int x,int y);\n用法不同 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 //指针函数示例 typedef struct _Data{ int a; int b; }Data; //指针函数 Data* f(int a,int b){ Data * data = new Data; //... return data; } int main(){ //调用指针函数 Data * myData = f(4,5); //Data * myData = static_cast\u0026lt;Data*\u0026gt;(f(4,5)); //... } //函数指针示例 int add(int x,int y){ return x+y; } //函数指针 int (*fun)(int x,int y); //赋值 fun = add; //调用 cout \u0026lt;\u0026lt; \u0026#34;(*fun)(1,2) = \u0026#34; \u0026lt;\u0026lt; (*fun)(1,2) ; //输出结果 //(*fun)(1,2) = 3 2.14 使用指针需要注意什么？ ①定义指针时，先初始化为NULL。 ②用malloc或new申请内存之后，应该立即检查指针值是否为NULL。防止使用指针值为NULL的内存。 ③不要忘记为数组和动态内存赋初值。防止将未被初始化的内存作为右值使用。 ④避免数字或指针的下标越界，特别要当心发生“多1”或者“少1”操作。 ⑤动态内存的申请与释放必须配对，防止内存泄漏。 ⑥用free或delete释放了内存之后，立即将指针设置为NULL，防止“野指针”。\n2.15 volatile有什么作用 ①volatile为状态寄存器一类的并行设备硬件寄存器。 ②一个中断服务子程序会访问到的非自动变量。 ③多线程间被几个任务共享的变量。 注意：虽然volatile在嵌入式方面应用比较多，但是在PC软件的多线程中，volatile修饰的临界变量也是非常实用的。\nC++中volatile的作用: 总结: 建议编译器不要对该变量进行优化\nvolatile是“易变/不稳定”的意思。volatile是C的一个较为少用的关键字，解决变量在“共享”环境下容易出现读取错误的问题。\n定义为volatile的变量是说这变量可能会被意想不到地改变，即在你程序运行过程中一直会变，你希望这个值被正确地处理，每次从内存中去读这个值，而不是因编译器优化从缓存的地方读取，比如读取缓存在寄存器中的数值，从而保证volatile变量被正确的读取。\n在单任务的环境中，一个函数体内部，如果在两次读取变量的值之间的语句没有对变量的值进行修改，那么编译器就会设法对可执行代码进行优化。由于访问寄存器的速度要快过RAM（从RAM中读取变量的值到寄存器），以后只要变量的值没有改变，就一直从寄存器中读取变量的值，而不对RAM进行访问。\n而在多任务环境中，虽然在一个函数体内部，在两次读取变量之间没有对变量的值进行修改，但是该变量仍然有可能被其他的程序（如中断程序、另外的线程等）所修改。如果这时还是从寄存器而不是从RAM中读取，就会出现被修改了的变量值不能得到及时反应的问题。如下程序对这一现象进行了模拟。\n2.16 一个参数可以既是const又是volatile吗 可以，用const和volatile同时修饰变量，表示这个变量在程序内部是只读的，不能改变的，只在程序外部条件变化下改变，并且编译器不会优化这个变量。每次使用这个变量时，都要小心地去内存读取这个变量的值，而不是去寄存器读取它的备份。 注意：在此一定要注意const的意思，const只是不允许程序中的代码改变某一变量，其在编译期发挥作用，它并没有实际地禁止某段内存的读写特性\n2.17 a 和\u0026amp;a 有什么区别 \u0026lt;1\u0026gt; \u0026amp;a：其含义就是“变量a的地址”。 \u0026lt;2\u0026gt; *a：用在不同的地方，含义也不一样。\n①在声明语句中，*a只说明a是一个指针变量，如int *a； ②在其他语句中，*a前面没有操作数且a是一个指针时，*a代表指针a指向的地址内存放的数据(解引用)，如b=*a； ③*a前面有操作数且a是一个普通变量时，a代表乘以a，如c=ba 2.18 用C 编写一个死循环程序 1 2 3 while(1) { } 注意：很多种途径都可实现同一种功能，但是不同的方法时间和空间占用度不同，特别是对于嵌入式软件，处理器速度比较慢，存储空间较小，所以时间和空间优势是选择各种方法的首要考虑条件。\n2.19 全局变量和局部变量有什么区别？是怎么实现的？操作系统和编译器是怎么知道的？ ①全局变量是整个程序都可访问的变量，谁都可以访问，生存期在整个程序从运行到结束（在程序结束时所占内存释放）； ②而局部变量存在于模块（子程序，函数）中，只有所在模块可以访问，其他模块不可直接访问，模块结束（函数调用完毕），局部变量消失，所占据的内存释放。 ③操作系统和编译器，可能是通过内存分配的位置来知道的，全局变量分配在全局数据段并且在程序开始运行的时候被加载.局部变量则分配在堆栈里面。\n2.20 结构体内存对齐问题 请写出以下代码的输出结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #include \u0026lt;stdio.h\u0026gt; using namespace std; /************************************************************** *\t结构体内存对⻬问题 * 从偏移为0的位置开始存储； *\t如果没有定义 #pragma pack(n) *\tsizeof 的最终结果必然是结构内部最⼤成员的整数倍，不够补⻬； *\t结构内部各个成员的⾸地址必然是⾃身⼤⼩的整数倍； * ***************************************************************/ struct S1 { int i ; //起始偏移0，sizeof(i)=4; 地址0、1、2、3分配给成员i char j ; //起始偏移4，sizeof(j)=1; int a ;\t//sizeof(a)=4,内存对齐到8个字节，从偏移量为8处存放a; double b;//sizeof(b)=8,内存对齐到16个字节，再存放b,结构体总大小24; }; //结构体成员的首地址必须是自身大小的整数倍 struct S3 { char j;//起始偏移0，sizeof(j)=1; float i;//sizeof(i)=4，内存对齐到4，起始偏移量为4,再存放i double b;//当前地址为8，是b大小的整数倍，无需对齐，直接存放成员b 8个字节 int a;//sizeof(a)=4,内存对齐到20，再存放a,总大小24字节； }; int main() { printf(\u0026#34;%d\\n\u0026#34;, sizeof(S1)); printf(\u0026#34;%d\\n\u0026#34;, sizeof(S3)); return 0; } 输出:\n1 2 24 24 说明：\n①结构体作为一种复合数据类型，其构成元素既可以是基本数据类型的变量，也可以是一些复合型类型数据。对此，编译器会自动进行成员变量的对齐以提高运算效率。 ②默认情况下，按自然对齐条件分配空间。各个成员按照它们被声明的顺序在内存中顺序存储，第一个成员的地址和整个结构的地址相同，向结构体成员中size最大的成员对齐。 ③许多实际的计算机系统对基本类型数据在内存中存放的位置有限制，它们会要求这些数据的首地址的值是某个数k（通常它为4或8）的倍数，而这个k则被称为该数据类型的对齐模数。\n3 基础知识（三） 3.1 简述C、C++程序编译的内存分配情况 ①从静态存储区域分配： 内存在程序编译时就已经分配好，这块内存在程序的整个运行期间都存在。速度快、不容易出错， 因为有系统会善后。例如全局变量，static 变量，常量字符串等。\n②在栈上分配： 在执行函数时，函数内局部变量的存储单元都在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。大小为2M。\n③从堆上分配： 即动态内存分配。程序在运行的时候用 malloc 或new 申请任意大小的内存，程序员自己负责在何 时用free 或delete 释放内存。动态内存的生存期由程序员决定，使用非常灵活。如果在堆上分配了空间，就有责任回收它，否则运行的程序会出现内存泄漏，另外频繁地分配和释放不同大小的堆空间将会产生 堆内碎块。\n一个C、C++程序编译时内存分为5大存储区：堆区、栈区、全局区、文字常量区、程序代码区。\n3.2 简述strcpy、sprintf 与memcpy 的区别 ①操作对象不同，strcpy 的两个操作对象均为字符串，sprintf 的操作源对象可以是多种数据类型， 目的操作对象是字符串，memcpy 的两个对象就是两个任意可操作的内存地址，并不限于何种数据类型。 ②执行效率不同，memcpy 最高，strcpy 次之，sprintf 的效率最低。 ③实现功能不同，strcpy 主要实现字符串变量间的拷贝，sprintf 主要实现其他数据类型格式到字符串的转化，memcpy 主要是内存块间的拷贝。 注意：strcpy、sprintf 与memcpy 都可以实现拷贝的功能，但是针对的对象不同，根据实际需求，来 选择合适的函数实现拷贝功能。\n请解析((void ()( ) )0)( )的含义 void (0)( ) ：是一个返回值为void，参数为空的函数指针0。 (void ()( ))0：把0转变成一个返回值为void，参数为空的函数指针。 ((void ()( ))0()：在上句的基础上加表示整个是一个返回值为void，无参数，并且起始地址为0的函数的名字。 ((void (*)( ))0)( )：这就是上句的函数名所对应的函数的调用。\n3.4 typedef 和define 有什么区别 ①用法不同： typedef 用来定义一种数据类型的别名，增强程序的可读性。define 主要用来定义常量，以及书写复杂使用频繁的宏。 ②执行时间不同： typedef 是编译过程的一部分，有类型检查的功能。define 是宏定义，是预编译的部分，其发生在编译之前，只是简单的进行字符串的替换，不进行类型的检查。 ③作用域不同： typedef 有作用域限定：define 不受作用域约束，只要在define 声明后的引用都是正确的。 ④对指针的操作不同： typedef 和define 定义的指针时有很大的区别。 注意：typedef 定义是语句，因为句尾要加上分号。而define 不是语句，千万不能在句尾加分号。\n3.5 指针常量与常量指针区别 指针常量是指定义了一个指针，这个指针的值只能在定义时初始化，其他地方不能改变。 常量指针是指定义了一个指针，这个指针指向一个只读的对象，不能通过常量指针来改变这个对象的值。\n指针常量强调的是指针的不可改变性，而常量指针强调的是指针对其所指对象的不可改变性。\n注意：无论是指针常量还是常量指针，其最大的用途就是作为函数的形式参数，保证实参在被调用函数中的不可改变特性。\n3.6 简述队列和栈的异同 队列和栈都是线性存储结构，但是两者的插入和删除数据的操作不同，队列是“先进先出”，栈是 “后进先出”。 注意：区别栈区和堆区。堆区的存取是“顺序随意”，而栈区是“后进先出”。栈由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈。堆一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS 回收。分配方式类似于链表。 它与本题中的堆和栈是两回事。堆栈只是一种数据结构，而堆区和栈区是程序的不同内存存储区域。\n3.7 设置地址为0x67a9 的整型变量的值为0xaa66 1 2 3 int *ptr; ptr = (int *)0x67a9; *ptr = 0xaa66; 注意：这道题就是强制类型转换的典型例子，无论在什么平台，地址长度和整型数据的长度是一样的， 即一个整型数据可以强制转换成地址指针类型，只要有意义即可。\n3.8 编码实现字符串转化为数字 编码实现函数atoi()，设计一个程序，把一个字符串转化为一个整型数值。例如数字：“5486321 ”， 转化成字符：5486321。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 int myAtoi(const char * str) { int num = 0; //保存转换后的数值 int isNegative = 0; //记录字符串中是否有负号 int n =0; char *p = str; if(p == NULL) //判断指针的合法性 { return -1; } while(*p++ != \u0026#39;\\0\u0026#39;) //计算数字符串度 { n++; } p = str; if(p[0] == \u0026#39;-\u0026#39;) //判断数组是否有负号 { isNegative = 1; } char temp = \u0026#39;0\u0026#39;; for(int i = 0 ; i \u0026lt; n; i++) { char temp = *p++; if(temp \u0026gt; \u0026#39;9\u0026#39; ||temp \u0026lt; \u0026#39;0\u0026#39;) //滤除非数字字符 { continue; } if(num !=0 || temp != \u0026#39;0\u0026#39;) //滤除字符串开始的0 字符 { temp -= 0x30; //将数字字符转换为数值 num += temp *int( pow(10 , n - 1 -i) ); } } if(isNegative) //如果字符串中有负号，将数值取反 { return (0 - num); } else { return num; //返回转换后的数值 } } 3.9 C语言的结构体和C++的有什么区别 ①C语言的结构体是不能有函数成员的，而C++的类可以有。 ②C语言的结构体中数据成员是没有private、public和protected访问限定的。而C++的类的成员有这些访问权限限定。 ③C语言的结构体是没有继承关系的，而C++的类却有丰富的继承关系。 注意：虽然C的结构体和C++的类有很大的相似度，但是类是实现面向对象的基础。而结构体只可以简单地理解为类的前身。\n3.10 简述指针常量与常量指针的区别 ①指针常量是指定义了一个指针，这个指针的值只能在定义时初始化，其他地方不能改变。常量指针是指定义了一个指针，这个指针指向一个只读的对象，不能通过常量指针来改变这个对象的值。指针常量的质疑智能在定义时初始化，常量指针指向一个只读的对象 ②指针常量强调的是指针的不可改变性，而常量指针强调的是指针对其所指对象的不可改变性。 注意：无论是指针常量还是常量指针，其最大的用途就是作为函数的形式参数，保证实参在被调用函数中的不可改变特性。\n3.11 如何避免“野指针” ①指针变量声明时没有被初始化。解决办法：指针声明时初始化，可以是具体的地址值，也可让它指向NULL。 ②指针p被free或者delete之后，没有置为NULL。解决办法：指针指向的内存空间被释放后指针应该指向NULL。 ③指针操作超越了变量的作用范围。解决办法：在变量的作用域结束前释放掉变量的地址空间并且让指针指向NULL。\n3.12 句柄和指针的区别和联系是什么？ 句柄和指针其实是两个截然不同的概念。Windows系统用句柄标记系统资源，隐藏系统的信息。你只要知道有这个东西，然后去调用就行了，它是个32it的uint。指针则标记某个物理内存地址，两者是不同的概念。\n3.13 new/delete与malloc/free的区别是什么 new能自动计算需要分配的内存空间，而malloc需要手工计算字节数。\n1 2 int *p = new int[2]; int *q = (int )malloc(2sizeof(int)); ①new与delete直接带具体类型的指针，malloc和free返回void类型的指针。 ②new类型是安全的，而malloc不是。例如int *p = new float[2];就会报错；而int p = malloc(2sizeof(int))编译时编译器就无法指出错误来。 ③new一般分为两步：new操作和构造。new操作对应与malloc，但new操作可以重载，可以自定义内存分配策略，不做内存分配，甚至分配到非内存设备上，而malloc不行。 ④new调用构造函数，malloc不能；delete调用析构函数，而free不能。 ⑤malloc/free需要库文件stdlib.h的支持，new/delete则不需要！ 注意：delete和free被调用后，内存不会立即回收，指针也不会指向空，delete或free仅仅是告诉操作系统，这一块内存被释放了，可以用作其他用途。但是由于没有重新对这块内存进行写操作，所以内存中的变量数值并没有发生变化，出现野指针的情况。因此，释放完内存后，应该讲该指针指向NULL。\n3.14 说一说extern“C” extern \u0026ldquo;C\u0026quot;的主要作用就是为了能够正确实现C++代码调用其他C语言代码。加上extern \u0026ldquo;C\u0026quot;后，会指示编译器这部分代码按C语言（而不是C++）的方式进行编译。由于C++支持函数重载，因此编译器编译函数的过程中会将函数的参数类型也加到编译后的代码中，而不仅仅是函数名；而C语言并不支持函数重载，因此编译C语言代码的函数时不会带上函数的参数类型，一般只包括函数名。\n这个功能十分有用处，因为在C++出现以前，很多代码都是C语言写的，而且很底层的库也是C语言写的，为了更好的支持原来的C代码和已经写好的C语言库，需要在C++中尽可能的支持C，而extern \u0026ldquo;C\u0026quot;就是其中的一个策略。\nC++代码调用C语言代码在C++的头文件中使用在多个人协同开发时，可能有的人比较擅长C语言，而有的人擅长C++，这样的情况下也会有用到。\n3.15 请你来说一下C++中struct和class的区别 在C++中，class和struct做类型定义是只有两点区别：\n①默认继承权限不同，class继承默认是private继承，而struct默认是public继承 ②class还可用于定义模板参数，像typename，但是关键字struct不能同于定义模板参数 ③C++保留struct关键字，原因：保证与C语言的向下兼容性，C++必须提供一个struct ④C++中的struct定义必须百分百地保证与C语言中的struct的向下兼容性，把C++中的最基本的对象单元规定为class而不是struct，就是为了避免各种兼容性要求的限制 ⑤对struct定义的扩展使C语言的代码能够更容易的被移植到C++中\n3.16 C++类内可以定义引用数据成员吗？ 可以，必须通过成员函数初始化列表初始化。\n3.17 C++中类成员的访问权限 ①C++通过 public、protected、private 三个关键字来控制成员变量和成员函数的访问权限，它们分别表示公有的、受保护的、私有的，被称为成员访问限定符。 ②在类的内部（定义类的代码内部），无论成员被声明为 public、protected 还是 private，都是可以互相访问的，没有访问权限的限制。 ③在类的外部（定义类的代码之外），只能通过对象访问成员，并且通过对象只能访问 public 属性的成员，不能访问 private、protected 属性的成员\n3.18 什么是右值引用，跟左值又有什么区别？ 左值和右值的概念：\n①左值： 能取地址，或者具名对象，表达式结束后依然存在的持久对象； 右值：不能取地址，匿名对象，表达式结束后就不再存在的临时对象； ②区别： 左值能寻址，右值不能； 左值能赋值，右值不能； 左值可变，右值不能（仅对基础类型适用，用户自定义类型右值引用可以通过成员函数改变）；\n3.19 面向对象的三大特征 封装性：将客观事物抽象成类，每个类对自身的数据和方法实行 protection （private ， protected ， public ）。 继承性：广义的继承有三种实现形式：实现继承（使用基类的属性和方法而无需额外编码的能力)、可视继承(子窗体使用父窗体的外观和实现代码)、接口继承(仅使用属性和方法,实现滞后到子类实现)。 多态性：是将父类对象设置成为和一个或更多它的子对象相等的技术。用子类对象给父类对象赋值之后，父类对象就可以根据当前赋值给它的子对象的特性以不同的方式运作。\n3.20 C++的空类有哪些成员函数 C++空类成员函数：\n缺省构造函数。 缺省拷贝构造函数。 缺省析构函数。 缺省赋值运算符。 缺省取址运算符。 缺省取址运算符 const 。 注意：有些书上只是简单的介绍了前四个函数。没有提及后面这两个函数。但后面这两个函数也是空类的默认函数。另外需要注意的是，只有当实际使用这些空类成员函数的时候，编译器才会去定义它们。\n4. 基础知识（四） 4.1 说一说c++中四种cast转换 C++中四种类型转换是：static_cast, dynamic_cast, const_cast, reinterpret_cast\n1、const_cast 用于将const变量转为非const 2、static_cast 用于各种隐式转换，比如非const转const，void*转指针等, static_cast能用于多态向上转化，如果向下转能成功但是不安全，结果未知； 3、dynamic_cast 用于动态类型转换。只能用于含有虚函数的类，用于类层次间的向上和向下转化。只能转指针或引用。向下转化时，如果是非法的对于指针返回NULL，对于引用抛异常。要深入了解内部转换的原理。\n向上转换：指的是子类向基类的转换 向下转换：指的是基类向子类的转换 它通过判断在执行到该语句的时候变量的运行时类型和要转换的类型是否相同来判断是否能够进行向下转换。 4、reinterpret_cast 几乎什么都可以转，比如将int转指针，可能会出问题，尽量少用； 5、为什么不使用C的强制转换？ C的强制转换表面上看起来功能强大什么都能转，但是转化不够明确，不能进行错误检查，容易出错。\n4.2 对c++中的smart pointer四个智能指针的理解：shared_ptr,unique_ptr,weak_ptr,auto_ptr ①C++里面的四个智能指针: auto_ptr, shared_ptr, weak_ptr, unique_ptr 其中后三个是c++11支持，并且第一个已经被C++11弃用。 ②智能指针的作用是管理一个指针，因为存在以下这种情况： 申请的空间在函数结束时忘记释放，造成内存泄漏。使用智能指针可以很大程度上的避免这个问题，因为智能指针就是一个类，当超出了类的作用域是，类会自动调用析构函数，析构函数会自动释放资源。所以智能指针的作用原理就是在函数结束时自动释放内存空间，不需要手动释放内存空间。 ③auto_ptr（c++98的方案，cpp11已经抛弃）\n采用所有权模式。\n1 2 3 unique_ptr p3 (new string (“auto”)); //#4 unique_ptr p4； //#5 p4 = p3;//此时会报错！！ 编译器认为p4=p3非法，避免了p3不再指向有效数据的问题。因此，unique_ptr比auto_ptr更安全。\n另外unique_ptr还有更聪明的地方：当程序试图将一个 unique_ptr 赋值给另一个时，如果源 unique_ptr 是个临时右值，编译器允许这么做；如果源 unique_ptr 将存在一段时间，编译器将禁止这么做，比如：\n1 2 3 4 5 unique_ptr pu1(new string (“hello world”)); unique_ptr pu2; pu2 = pu1; // #1 not allowed unique_ptr pu3; pu3 = unique_ptr(new string (“You”)); // #2 allowed 其中#1留下悬挂的 unique_ptr(pu1)，这可能导致危害。而#2不会留下悬挂的unique_ptr，因为它调用 unique_ptr 的构造函数，该构造函数创建的临时对象在其所有权让给 pu3 后就会被销毁。这种随情况而已的行为表明，unique_ptr 优于允许两种赋值的auto_ptr 。\n注：如果确实想执行类似与#1的操作，要安全的重用这种指针，可给它赋新值。C++有一个标准库函数std::move()，让你能够将一个unique_ptr赋给另一个。例如：\n1 2 3 4 5 unique_ptr ps1, ps2; ps1 = demo(“hello”); ps2 = move(ps1); ps1 = demo(“alexia”); cout \u0026lt;\u0026lt; *ps2 \u0026lt;\u0026lt; *ps1 \u0026lt;\u0026lt; endl; shared_ptr实现共享式拥有概念。多个智能指针可以指向相同对象，该对象和其相关资源会在“最后一个引用被销毁”时候释放。从名字share就可以看出了资源可以被多个指针共享，它使用计数机制来表明资源被几个指针共享。可以通过成员函数use_count()来查看资源的所有者个数。除了可以通过new来构造，还可以通过传入auto_ptr, unique_ptr,weak_ptr来构造。当我们调用release()时，当前指针会释放资源所有权，计数减一。当计数等于0时，资源会被释放。\nshared_ptr 是为了解决 auto_ptr 在对象所有权上的局限性(auto_ptr 是独占的), 在使用引用计数的机制上提供了可以共享所有权的智能指针。\n成员函数：\nuse_count 返回引用计数的个数 unique 返回是否是独占所有权( use_count 为 1) swap 交换两个 shared_ptr 对象(即交换所拥有的对象) reset 放弃内部对象的所有权或拥有对象的变更, 会引起原有对象的引用计数的减少 get 返回内部对象(指针), 由于已经重载了()方法, 因此和直接使用对象是一样的.如 shared_ptrsp(new int(1)); sp 与 sp.get()是等价的\nweak_ptr:\nweak_ptr 是一种不控制对象生命周期的智能指针, 它指向一个 shared_ptr 管理的对象. 进行该对象的内存管理的是那个强引用的shared_ptr. weak_ptr只是提供了对管理对象的一个访问手段。 weak_ptr 设计的目的是为配合 shared_ptr 而引入的一种智能指针来协助 shared_ptr 工作, 它只可以从一个 shared_ptr 或另一个 weak_ptr 对象构造, 它的构造和析构不会引起引用记数的增加或减少。 weak_ptr是用来解决shared_ptr相互引用时的死锁问题,如果说两个shared_ptr相互引用,那么这两个指针的引用计数永远不可能下降为0,资源永远不会释放。它是对对象的一种弱引用，不会增加对象的引用计数，和shared_ptr之间可以相互转化，shared_ptr可以直接赋值给它，它可以通过调用lock函数来获得shared_ptr。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 class B; class A { public: shared_ptr\u0026lt;B\u0026gt; pb_; ~A(){ cout\u0026lt;\u0026lt;\u0026#34;A delete\u0026#34;; } }; class B { public: shared_ptr\u0026lt;A\u0026gt; pa_; ~B(){ cout\u0026lt;\u0026lt;\u0026#34;B delete\u0026#34;; } }; void fun() { shared_ptr\u0026lt;B\u0026gt; pb(new B()); shared_ptr\u0026lt;A\u0026gt; pa(new A()); pb-\u0026gt;pa_ = pa; pa-\u0026gt;pb_ = pb; cout \u0026lt;\u0026lt; pb.use_count() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; pa.use_count() \u0026lt;\u0026lt; endl; } int main() { fun(); return 0; } 可以看到fun函数中pa ，pb之间互相引用，两个资源的引用计数为2，当要跳出函数时，智能指针pa，pb析构时两个资源引用计数会减一，但是两者引用计数还是为1，导致跳出函数时资源没有被释放（A B的析构函数没有被调用），如果把其中一个改为weak_ptr就可以了，我们把类A里面的shared_ptr pb_; 改为weak_ptr pb_; 运行结果如下，这样的话，资源B的引用开始就只有1，当pb析构时，B的计数变为0，B得到释放，B释放的同时也会使A的计数减一，同时pa析构时使A的计数减一，那么A的计数为0，A得到释放。\n注意：不能通过weak_ptr直接访问对象的方法，比如B对象中有一个方法print(),我们不能这样访问，pa-\u0026gt;pb_-\u0026gt;print(); 英文pb_是一个weak_ptr，应该先把它转化为shared_ptr,如：shared_ptr p = pa-\u0026gt;pb_.lock(); p-\u0026gt;print();\n4.3 说说强制类型转换运算符 ①static_cast 用于非多态类型的转换\n用于非多态类型的转换 不执行运行时类型检查（转换安全性不如 dynamic_cast） 通常用于转换数值数据类型（如 float -\u0026gt; int） 可以在整个类层次结构中移动指针，子类转化为父类安全（向上转换），父类转化为子类不安全（因为子类可能有不在父类的字段或方法）\n②dynamic_cast 用于多态类型的转换\n用于多态类型的转换 执行行运行时类型检查 只适用于指针或引用 对不明确的指针的转换将失败（返回 nullptr），但不引发异常 可以在整个类层次结构中移动指针，包括向上转换、向下转换\n③const_cast\n用于删除 const、volatile 和 __unaligned 特性（如将 const int 类型转换为 int 类型 ）\n④reinterpret_cast\n用于位的简单重新解释 滥用 reinterpret_cast 运算符可能很容易带来风险。除非所需转换本身是低级别的，否则应使用其他强制转换运算符之一。 允许将任何指针转换为任何其他指针类型（如 char* 到 int* 或 One_class* 到 Unrelated_class* 之类的转换，但其本身并不安全） 也允许将任何整数类型转换为任何指针类型以及反向转换。 reinterpret_cast 运算符不能丢掉 const、volatile 或 __unaligned 特性。 reinterpret_cast 的一个实际用途是在哈希函数中，即，通过让两个不同的值几乎不以相同的索引结尾的方式将值映射到索引。 ⑤bad_cast\n由于强制转换为引用类型失败，dynamic_cast 运算符引发 bad_cast 异常。 bad_cast 使用:\n1 2 3 4 5 6 try { Circle\u0026amp; ref_circle = dynamic_cast\u0026lt;Circle\u0026amp;\u0026gt;(ref_shape); } catch (bad_cast b) { cout \u0026lt;\u0026lt; \u0026#34;Caught: \u0026#34; \u0026lt;\u0026lt; b.what(); } 4.4 谈谈你对拷贝构造函数和赋值运算符的认识 拷贝构造函数和赋值运算符重载有以下两个不同之处：\n①拷贝构造函数生成新的类对象，而赋值运算符不能。 ②由于拷贝构造函数是直接构造一个新的类对象，所以在初始化这个对之前不用检验原对象是否和新建对象相同，而赋值运算符则需要这个操作， ③另外赋值运算中如果原来的对象中有内存分配要先把内存释放掉。 注意：当有类中有指针类型的成员变量时，一定要重写拷贝构造函数和赋值运算符，不要使用默认的。\n4.5 在C++中，使用malloc申请的内存能否通过delete释放？使用new申请的内存能否用free？ 不能，malloc /free主要为了兼容C，new和delete 完全可以取代malloc /free的。 ①malloc /free的操作对象都是必须明确大小的。而且不能用在动态类上。 ②new 和delete会自动进行类型检查和大小，malloc/free不能执行构造函数与析构函数，所以动态对象它是不行的。\n当然从理论上说使用malloc申请的内存是可以通过delete释放的。不过一般不这样写的。而且也不能保证每个C++的运行时都能正常。\n4.6 用C++设计一个不能被继承的类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 template \u0026lt;typename T\u0026gt; class A { friend T; private: A() {} ~A() {} }; class B : virtual public A\u0026lt;B\u0026gt; { public: B() {} ~B() {} }; class C : virtual public B { public: C() {} ~C() {} }; void main( void ) { B b; //C c; return; } 注意：构造函数是继承实现的关键，每次子类对象构造时，首先调用的是父类的构造函数，然后才 是自己的。\n4.8 访问基类的私有虚函数 写出以下程序的输出结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #include \u0026lt;iostream.h\u0026gt; class A { virtual void g() { cout \u0026lt;\u0026lt; \u0026#34;A::g\u0026#34; \u0026lt;\u0026lt; endl; } private: virtual void f() { cout \u0026lt;\u0026lt; \u0026#34;A::f\u0026#34; \u0026lt;\u0026lt; endl; } }; class B : public A { void g() { cout \u0026lt;\u0026lt; \u0026#34;B::g\u0026#34; \u0026lt;\u0026lt; endl; } virtual void h() { cout \u0026lt;\u0026lt; \u0026#34;B::h\u0026#34; \u0026lt;\u0026lt; endl; } }; typedef void( *Fun )( void ); void main() { B b; Fun pFun; for(int i = 0 ; i \u0026lt; 3; i++) { pFun = ( Fun )*( ( int* ) * ( int* )( \u0026amp;b ) + i ); pFun(); } } 输出结果:\n1 2 3 B::g A::f B::h 注意：考察了面试者对虚函数的理解程度。一个对虚函数不了解的人很难正确的做出本题。 在学习面向对象的多态性时一定要深刻理解虚函数表的工作原理。\n虚函数：通过基类访问派生类定义的函数，多态时使用，使用虚函数加上virtual关键字。 虚函数就是在基类定义一个未实现的函数名，为了提高程序的可读性 虚函数详解 C++虚函数详解_疯狂的麦克斯_max的博客-CSDN博客_c++虚函数\n菱形继承1 菱形继承2\n4.9 对虚函数和多态的理解 ①多态的实现主要分为静态多态和动态多态，静态多态主要是重载，在编译的时候就已经确定；动态多态是用虚函数机制实现的，在运行期间动态绑定。 举个例子: 一个父类类型的指针指向一个子类对象时候，使用父类的指针去调用子类中重写了的父类中的虚函数的时候，会调用子类重写过后的函数，在父类中声明为加了virtual关键字的函数，在子类中重写时候不需要加virtual也是虚函数。 ②虚函数的实现: 在有虚函数的类中，类的最开始部分是一个虚函数表的指针，这个指针指向一个虚函数表，表中放了虚函数的地址，实际的虚函数在代码段(.text)中。当子类继承了父类的时候也会继承其虚函数表，当子类重写父类中虚函数时候，会将其继承到的虚函数表中的地址替换为重新写的函数地址。使用了虚函数，会增加访问内存开销，降低效率。\n4.10 简述类成员函数的重写(overwrite)、重载(overload)和隐藏的区别 （1）重写和重载主要有以下几点不同。\n①范围的区别：被重写的和重写的函数在两个类中，而重载和被重载的函数在同一个类中。 ②参数的区别：被重写函数和重写函数的参数列表一定相同，而被重载函数和重载函数的参数列表一 定不同。 ③virtual 的区别：重写的基类中被重写的函数必须要有virtual 修饰，而重载函数和被重载函数可以被 virtual 修饰，也可以没有。\n（2）隐藏和重写、重载有以下几点不同。\n与重载的范围不同：和重写一样，隐藏函数和被隐藏函数不在同一个类中。 参数的区别：隐藏函数和被隐藏的函数的参数列表可以相同，也可不同，但是函数名肯定要相同。 当参数不相同时，无论基类中的参数是否被virtual 修饰，基类的函数都是被隐藏，而不是被重写。 注意：虽然重载和覆盖都是实现多态的基础，但是两者实现的技术完全不相同，达到的目的也是完全不同的，覆盖是动态态绑定的多态，而重载是静态绑定的多态。\n4.11 链表和数组有什么区别 存储形式:\n数组是一块连续的空间，声明时就要确定长度。 链表是一块可不连续的动态空间， 长度可变，每个结点要保存相邻结点指针。\n数据查找:\n数组的线性查找速度快，查找操作直接使用偏移地址。 链表需要按顺序检索结点， 效率低。 数据插入或删除：链表可以快速插入和删除结点，而数组则可能需要大量数据移动。\n越界问题：\n链表不存在越界问题，数组有越界问题。\n注意：\n在选择数组或链表数据结构时，一定要根据实际需要进行选择。数组便于查询，链表便于插入删除。数组节省空间但是长度固定，链表虽然变长但是占了更多的存储空间。\n4.12 用两个栈实现一个队列的功能 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 typedef struct node { int data; node *next; }node,*LinkStack; //创建空栈： LinkStack CreateNULLStack( LinkStack \u0026amp;S) { S = (LinkStack)malloc( sizeof( node ) ); // 申请新结点 if( NULL == S) { printf(\u0026#34;Fail to malloc a new node.\\n\u0026#34;); return NULL; } S-\u0026gt;data = 0; //初始化新结点 S-\u0026gt;next = NULL; return S; } //栈的插入函数： LinkStack Push( LinkStack \u0026amp;S, int data) { if( NULL == S) //检验栈 { printf(\u0026#34;There no node in stack!\u0026#34;); return NULL; } LinkStack p = NULL; p = (LinkStack)malloc( sizeof( node ) ); // 申请新结点 if( NULL == p) { printf(\u0026#34;Fail to malloc a new node.\\n\u0026#34;); return S; } if( NULL == S-\u0026gt;next) { p-\u0026gt;next = NULL; } else { p-\u0026gt;next = S-\u0026gt;next; } p-\u0026gt;data = data; //初始化新结点 S-\u0026gt;next = p; //插入新结点 return S; } //出栈函数： node Pop( LinkStack \u0026amp;S) { node temp; temp.data = 0; temp.next = NULL; if( NULL == S) //检验栈 { printf(\u0026#34;There no node in stack!\u0026#34;); return temp; } temp = *S; if( S-\u0026gt;next == NULL ) { printf(\u0026#34;The stack is NULL,can\u0026#39;t pop!\\n\u0026#34;); return temp; } LinkStack p = S -\u0026gt;next; //节点出栈 S-\u0026gt;next = S-\u0026gt;next-\u0026gt;next; temp = *p; free( p ); p = NULL; return temp; } //双栈实现队列的入队函数： LinkStack StackToQueuPush( LinkStack \u0026amp;S, int data) { node n; LinkStack S1 = NULL; CreateNULLStack( S1 ); //创建空栈 while( NULL != S-\u0026gt;next ) //S 出栈入S1 { n = Pop( S ); Push( S1, n.data ); } Push( S1, data ); //新结点入栈 while( NULL != S1-\u0026gt;next ) //S1 出栈入S { n = Pop( S1 ); Push( S, n.data ); } return S; } 注意：用两个栈能够实现一个队列的功能，那用两个队列能否实现一个队列的功能呢？结果是否定的，因为栈是先进后出，将两个栈连在一起，就是先进先出。而队列是现先进先出，无论多少个连在一起都是先进先出，而无法实现先进后出。\n4.13 共享数据的保护 ①常引用：使所引用的形参不能被更新\n1 void display(const double\u0026amp; a); ②常对象：在生存期内不能被更新，但必须被初始化\n1 A const a(3,4); ③常成员函数： 不能修改对象中数据成员，也不能调用类中没有被const 修饰的成员函数（常对象唯一的对外接口）.如果声明了一个常对象，则该对象只能调用他的常函数！-\u0026gt;可以用于对重载函数的区分;\n1 2 void print(); void print() const; ④extern int a:使其他文件也能访问该变量 声明一个函数或定义函数时，冠以static的话，函数的作用域就被限制在了当前编译单元，当前编译单元内也必须包含函数的定义，也只在其编译单元可见，其他单元不能调用这个函数(每一个cpp 文件就是一个编译单元)。\n4.14 程序内存分配方式以及它们的区别 内存分配大致上可以分成5块：\n栈区（stack） 栈，就是那些由编译器在需要时分配，在不需要的时候自动清除的变量的存储区。里面的变量通常是局部变量、函数参数等。（由编译器管理） 堆区（heap） 一般由程序员分配、释放，若程序员不释放，程序结束时可能由系统回收。注意，它与数据结构中的堆是两回事，分配方式类似于链表。 全局区（静态区）（static） 全局变量和静态变量被分配到同一块内存中。程序结束后由系统释放。 常量存储区 常量字符串就是放在这里的，不允许修改，程序结束后由系统释放。 程序代码区 存放函数体的二进制代码。\nC++程序在执行时，将内存大方向划分为4个区域:\n程序运行前\n代码区：存放函数体的二进制代码，由操作系统进行管理的 全局区：存放全局变量和静态变量以及常量 程序运行后\n栈区：由编译器自动分配释放, 存放函数的参数值,局部变量等 堆区：由程序员分配和释放,若程序员不释放,程序结束时由操作系统回收 内存四区意义：\n不同区域存放的数据，赋予不同的生命周期, 给我们更大的灵活编程\n4.15 explicit 函数声明时加上explicit可以阻止函数参数被隐式转换。\n1 2 3 4 5 6 7 8 9 Class A { explicit A(int a); } Void main() { A a1=12; //不加explicit时会被隐式转换位 A a1=A(12);加了此时编译器会报错。 } 被声明为explicit的构造函数通常比non-explicit 函数更受欢迎。\n4.16 mutable关键字 mutable的中文意思是“可变的，易变的”，跟constant（既C++中的const）是反义词。在C++中，mutable也是为了突破const的限制而设置的。 被mutable修饰的变量(mutable只能由于修饰类的非静态数据成员)，将永远处于可变的状态，即使在一个const函数中。 我们知道，假如类的成员函数不会改变对象的状态，那么这个成员函数一般会声明为const。但是，有些时候，我们需要在const的函数里面修改一些跟类状态无关的数据成员，那么这个数据成员就应该被mutalbe来修饰。（使用mutable修饰的数据成员可以被const成员函数修改）。\n4.17 用const修饰函数的返回值 如果给以“指针传递”方式的函数返回值加const修饰，那么函数返回值（即指针）的内容不能被修改，该返回值只能被赋给加const修饰的同类型指针。例如函数：\n1 2 3 4 5 Const char * GetString(void); // 如下语句将出现编译错误： char*str = GetString(); // 正确的用法是 Const char *str =GetString(); 4.18 宏、const和enum #define 不被视为语言的一部分。对于单纯常量，最好用const对象或者enum替换#define。 对于类似函数的宏，尽量使用内联函数inline替换掉#define enum枚举类型是被当做 int 或者 unsigned int 类型来处理的。\n4.19 stack的生存期 ①C++中的static对象是指存储区不属于stack和heap、\u0026ldquo;寿命\u0026quot;从被构造出来直至程序结束为止的对象。 ②这些对象包括全局对象，定义于namespace作用域的对象，在class、function以及file作用域中被声明为static的对象。 ③其中，函数内的static对象称为local static对象，而其它static对象称为non-local static对象。\n这两者在何时被初始化(构造)这个问题上存在细微的差别：\n①对于local static对象，在其所属的函数被调用之前，该对象并不存在，即只有在第一次调用对应函数时，local static对象才被构造出来。 ②而对于non-local static对象，在main()函数开始前就已经被构造出来，并在main()函数结束后被析构。\n\u0026lt;/font color=red\u0026gt;建议：\n1.对内置对象进行手工初始化，因为C++不保证初始化它们。 2.构造函数最好使用成员初值列，而不要在构造函数本体中使用赋值操作。初值列中列出的成员变量，其排序次序应该和它们在class中的声明次序相同(初始化顺序与声明变量顺序一致)。 3.为免除“跨编译单元的初始化次序问题”，尽量以local static对象替换non-local static对象。\n4.20 全局变量和static变量的区别 ①全局变量本身就是静态存储方式， 静态全局变量当然也是静态存储方式。 这两者在存储方式上并无不同。 ②这两者的区别在于非静态全局变量的作用域是整个源程序， 当一个源程序由多个源文件组成时，非静态的全局变量在各个源文件中都是有效的。 ③而静态全局变量则限制了其作用域， 即只在定义该变量的源文件内有效， 在同一源程序的其它源文件中不能使用它。 ④由于静态全局变量的作用域局限于一个源文件内，只能为该源文件内的函数公用， 因此可以避免在其它源文件中引起错误。\n5 基础知识（五） 5.1 为什么栈要比堆速度要快 ①首先, 栈是本着LIFO原则的存储机制, 对栈数据的定位相对比较快速, 而堆则是随机分配的空间, 处理的数据比较多, 无论如何, 至少要两次定位. ②其次, 栈是由CPU提供指令支持的, 在指令的处理速度上, 对栈数据进行处理的速度自然要优于由操作系统支持的堆数据. ③再者, 栈是在一级缓存中做缓存的, 而堆则是在二级缓存中, 两者在硬件性能上差异巨大. 最后, 各语言对栈的优化支持要优于对堆的支持, 比如swift语言中, 三个字及以内的struct结构, 可以在栈中内联, 从而达到更快的处理速度.\n5.2 c++ 析构函数调用时间 对象生命周期结束，被销毁时 delete指向对象的指针时，或delete指向对象的基类类型指针，而其基类虚构函数是虚函数时 对象i是对象o的成员，o的析构函数被调用时，对象i的析构函数也被调用\n5.3 静态绑定 动态绑定 （也叫动态连编，静态连编） 如果父类中存在有虚函数，那么编译器便会为之生成虚表（属于类）与虚指针（属于某个对象），在程序运行时，根据虚指针的指向，来决定调用哪个虚函数，这称之与动态绑定，与之相对的是静态绑定，静态绑定在编译期就决定了。\nclass和template都支持接口与多态； ①对classes而言，接口是显式的，以函数签名为中心。多态则是通过virtual函数(虚函数)发生于运行期； ②对template参数而言，接口是隐式的，奠基于有效表达式。多态则是通过template具现化和函数重载解析发生于编译期。 泛型 泛型是通过参数化类型来实现在同一份代码上操作多种数据类型。利用“参数化类型”将类型抽象化，从而实现灵活的复用。\n5.4 C语言的指针和c++的引用有什么区别？ 指针有自己的一块空间，指针是一个变量，只不过这个变量存储的是一个地址，指向内存的一个存储单元，即指针是一个实体。而引用只是一个别名； 使用sizeof看一个指针的大小是4，而引用则是被引用对象的大小； 指针可以被初始化为NULL，而引用必须被初始化且必须是一个已有对象的引用； 作为参数传递时，指针需要被解引用才可以对对象进行操作，而直接对引用的修改都会改变引用所指向的对象； 5.5 请你说说C语言是怎么进行函数调用的 每一个函数调用都会分配函数栈，在栈内进行函数执行过程。调用前，先把返回地址压栈，然后把当前函数的esp指针压栈。（ESP（Extended Stack Pointer）为扩展栈指针寄存器，是指针寄存器的一种，用于存放函数栈顶指针）\nC语言参数压栈顺序？：从右到左\n5.6 C++中拷贝赋值函数的形参能否进行值传递？ 不能。如果是这种情况下，调用拷贝构造函数的时候，首先要将实参传递给形参，这个传递的时候又要调用拷贝构造函数(aa = ex.aa; //此处调用拷贝构造函数)。如此循环，无法完成拷贝，栈也会满。\n5.7 include头文件的顺序以及双引号””和尖括号\u0026lt;\u0026gt;的区别 编译器预处理阶段查找头文件的路径不一样\n使用双引号包含的头文件，查找头文件路径的顺序为： ①当前头文件目录 ②编译器设置的头文件路径（编译器可使用-I显式指定搜索路径） ③系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径 对于使用尖括号包含的头文件，查找头文件的路径顺序为： ①编译器设置的头文件路径（编译器可使用-I显式指定搜索路径） ②系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径\n5.8 一个C++源文件从文本到可执行文件经历的过程 对于C/C++编写的程序，从源代码到可执行文件，一般经过下面四个步骤：\n预编译，预编译的时候做一些简单的文本替换，比如宏替换，而不进行语法的检查； 编译，在编译阶段，编译器将检查一些语法错误，但是，如果使用的函数事先没有定义这种情况，不再这一阶段检查，编译后，得到.s文件 汇编，将C/C++代码变为汇编代码，得到.o或者.obj文件 链接，将所用到的外部文件链接在一起，在这一阶段，就会检查使用的函数有没有定义 链接过后，形成可执行文件.exe 详细请参阅: 一个C++源文件从文本到可执行文件经历的过程\n5.9 内存泄漏原因和判断方法 内存泄漏通常是因为调用了malloc/new等内存申请操作，但是缺少了对应的free/delete。 为了判断内存是否泄漏，我们一方面可以使用Linux环境下的内存泄漏检查工具Valgrind，另一方面我们写代码的时候，可以添加内存申请和释放的统计功能，统计当前申请和释放的内存是否一致，以此来判断内存是否有泄漏。\n内存泄漏分类：\n堆内存泄漏（heap leak）。堆内存值得是程序运行过程中根据需要分配通过malloc\\realloc\\new等从堆中分配的一块内存，再完成之后必须要通过调用对应的free或者delete删除。 如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak。 系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap，handle，SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。 没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确的释放，从而造成内存泄漏。 5.10 段错误的产生原因\n段错误是什么?\n一句话来说，段错误是指访问的内存超出了系统给这个程序所设定的内存空间，例如访问了不存在的内存地址、访问了系统保护的内存地址、访问了只读的内存地址等等情况。这里贴一个对于“段错误”的准确定义。\n段错误产生的原因\n访问不存在的内存地址 访问系统保护的内存地址 访问只读的内存地址 栈溢出 详细请参阅：Linux环境下段错误的产生原因及调试方法小结\n5.11 C++ 函数调用过程 总结起来整个过程就三步：\n1）根据调用的函数名找到函数入口； 2）在栈中申请调用函数中的参数及函数体内定义的变量的内存空间 3）函数执行完后，释放函数在栈中的申请的参数和变量的空间，最后返回值（如果有的话）\n详细请查阅：函数调用过程 / C/C++函数调用过程分析\n5.12 如何调试c++多线程程序？ 打印日志，日志中加上线程ID；（简单粗暴） gdb有thread相关命令，如infothread（简写infoth）显示线程消息，bxxthreadyy可以 对某个thread设置断点，threadxx（简写成thrxx）切换到某个thread。再配合frame（简写f）相关的命令（比如up，down在不同frame间跳转），基本可以处理若干个不同的线程间的debug…… 详细请查阅：C++(vs)多线程调试 （转） 5.13 面向对象和面向过程的区别 ①面向对象方法中，把数据和数据操作放在一起，组成对象；对同类的对象抽象出其共性组成类；类通过简单的接口与外界发生联系，对象和对象之间通过消息进行通信。 ②面向对象的三大特性是\u0026quot;封装、“多态”、“继承”，五大原则是\u0026quot;单一职责原则\u0026rdquo;、“开放封闭原则”、“里氏替换原则”、“依赖倒置原则”、“接口分离原则”。 ③而面向过程方法是以过程为中心的开发方法，它自顶向下顺序进行， 程序结构按照功能划分成若干个基本模块，这些模块形成树状结构。\n（过程）优点：\n性能比面向对象高，因为类调用时需要实例化，开销比较大，比较消耗源;比如嵌入式开发、Linux/Unix等一般采用面向过程开发，性能是最重要的因素。缺点：没有面向对象易维护、易复用、易扩展。\n（对象）优点：\n易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统。缺点：性能比面向过程低。\n5.14 关于引用赋值的多态： 1 2 3 4 5 6 7 8 Class B; Class D : public B; B\u0026amp; b; D\u0026amp; d; B\u0026amp; b1 = d ; //父类可以作为子类的引用，此时b1表现和指针形式一致（会调用B的非虚函数） D\u0026amp; d1 = b； //错误，不能将子类作为父类的引用 //父类可以作为子类的引用，此时b1表现和指针形式一致（会调用B的非虚函数） 5.15 模板的声明和实现不能分开的原因 链接的时候，需要实例化模板，这时候就需要找模板的具体实现了。假设在main函数中调用了一个模板函数，这时候就需要去实例化该类型的模板。注意main函数里面只包含了.h文件，也就是只有模板的声明，没有具体实现。就会报错。 而模板的实现.cpp里面，虽然有模板的具体实现，但是没有谁在该.cpp里面使用一个模板函数，就不会生成一个具体化的实例 详细请参阅：C++ 模板类的声明与实现分离问题 / ​​​​​​C++ 模板类的声明与实现分离问题（模板实例化）​​​​​​\n5.16 C++类中引用成员和常量成员的初始化（初始化列表） 如果一个类是这样定义的：\n1 2 3 4 5 6 7 8 9 10 Class A { public: A(int pram1, int pram2, int pram3); privite: int a; int \u0026amp;b; const int c; } 假如在构造函数中对三个私有变量进行赋值则通常会这样写：\n1 2 3 4 5 6 A::A(int pram1, int pram2, int pram3) { a=pram1; b=pram2; c=pram3; } 但是，这样是编译不过的。因为常量和引用初始化必须赋值。所以上面的构造函数的写法只是简单的赋值，并不是初始化。 正确写法应该是：\n1 2 3 4 A::A(int pram1, int pram2, int pram3):b(pram2),c(pram3) { a=pram1; } 采用初始化列表实现了对常量和引用的初始化。采用括号赋值的方法，括号赋值只能用在变量的初始化而不能用在定义之后的赋值。 凡是有引用类型的成员变量或者常量类型的变量的类，不能有缺省构造函数。默认构造函数没有对引用成员提供默认的初始化机制，也因此造成引用未初始化的编译错误。并且必须使用初始化列表进行初始化const对象、引用对象。\n5.17 memset为int型数组初始化问题： 头文件：#include \u0026lt;string.h\u0026gt; memset() 函数用来将指定内存的前n个字节设置为特定的值，其原型为：\n1 void * memset( void * ptr, int value, size_t num ); 参数说明： ptr 为要操作的内存的指针。 value 为要设置的值。你既可以向 value 传递 int 类型的值，也可以传递 char 类型的值，int 和 char 可以根据 ASCII 码相互转换。 num 为 ptr 的前 num 个字节，size_t 就是unsigned int。\n【函数说明】memset() 会将 ptr 所指的内存区域的前 num 个字节的值都设置为 value，然后返回指向 ptr 的指针。\n无法下面这样初始化，这样的结果是a被赋值成168430090，168430090\u0026hellip;..\n1 2 int a[10]; memset(a, 1, sizeof(a)); 这是因为int由4个字节(说)表示，并且不能得到数组a中整数的期望值。 但我经常看到程序员使用memset将int数组元素设置为0或-1。其他值不行！\n1 2 3 4 5 6 7 8 9 int a[10]; int b[10]; memset(a, 0, sizeof(a)); memset(b, -1, sizeof(b)); //假设a为int型数组： memset(a,0x7f,sizeof(a)); //a数组每个空间将被初始化为0x7f7f7f7f,原因是C函数传参过程中的指针降级，导致sizeof(a)，返回的是一个 something*指针类型大小的的字节数，如果是32位，就是4字节。所以memset按字节赋值。 memset(a,0xaf,sizeof(a)); //a数组每个空间将被初始化为0xafafafaf 5.18 编译器对 inline 函数的处理步骤 将 inline 函数体复制到 inline 函数调用点处； 为所用 inline 函数中的局部变量分配内存空间； 将 inline 函数的的输入参数和返回值映射到调用方法的局部变量空间中； 如果 inline 函数有多个返回点，将其转变为 inline 函数代码块末尾的分支（使用 GOTO）\n优点:\n内联函数同宏函数一样将在被调用处进行代码展开，省去了参数压栈、栈帧开辟与回收，结果返回等，从而提高程序运行速度。 内联函数相比宏函数来说，在代码展开时，会做安全检查或自动类型转换（同普通函数），而宏定义则不会。 在类中声明同时定义的成员函数，自动转化为内联函数，因此内联函数可以访问类的成员变量，宏定义则不能。 内联函数在运行时可调试，而宏定义不可以。\n缺点:\n代码膨胀。内联是以代码膨胀（复制）为代价，消除函数调用带来的开销。如果执行函数体内代码的时间，相比于函数调用的开销较大，那么效率的收获会很少。另一方面，每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。 inline 函数无法随着函数库升级而升级。inline函数的改变需要重新编译，不像 non-inline 可以直接链接。 是否内联，程序员不可控。内联函数只是对编译器的建议，是否对函数内联，决定权在于编译器。\n5.19 虚函数（virtual）可以是内联函数（inline）吗？ 虚函数可以是内联函数，内联是可以修饰虚函数的，但是当虚函数表现多态性的时候不能内联。 内联是在编译器建议编译器内联，而虚函数的多态性在运行期，编译器无法知道运行期调用哪个代码，因此虚函数表现为多态性时（运行期）不可以内联。 inline virtual 唯一可以内联的时候是：编译器知道所调用的对象是哪个类(如 Base::who())，这只有在编译器具有实际对象而不是对象的指针或引用时才会发生;\n5.20 静态库和动态库比较 静态库 (.a、.lib):\n将静态库的内容添加到程序中，此时程序的空间，变成了源程序空间大小+静态库空间大小。\n动态库（共享库）(.so、.dll):\n常驻内存，当程序需要调用相关函数时，会从内存调用。\n区别:\n静态库：对空间要求较低，而时间要求较高的核心程序中。(.a、.lib) 动态库：对时间要求较低，对空间要求较高。(.so、.dll) hash\n6 基础知识(六) 6.1 构造函数为什么不能定义为虚函数？ ⽽析构函数⼀般写成虚函数的原因 ？ 构造函数不能声明为虚函数的原因是:\n1 构造一个对象的时候，必须知道对象的实际类型，而虚函数行为是在运行期间确定实际类型的。而在构造一个对象时，由于对象还未构造成功。编译器无法知道对象 的实际类型，是该类本身，还是该类的一个派生类，或是更深层次的派生类。无法确定。。。 2 虚函数的执行依赖于虚函数表。而虚函数表在构造函数中进行初始化工作，即初始化vptr，让他指向正确的虚函数表。而在构造对象期间，虚函数表还没有被初始化，将无法进行。\n虚函数的意思就是开启动态绑定，程序会根据对象的动态类型来选择要调用的方法。然而在构造函数运行的时候，这个对象的动态类型还不完整，没有办法确定它到底是什么类型，故构造函数不能动态绑定。（动态绑定是根据对象的动态类型而不是函数名，在调用构造函数之前，这个对象根本就不存在，它怎么动态绑定？） 编译器在调用基类的构造函数的时候并不知道你要构造的是一个基类的对象还是一个派生类的对象。\n析构函数设为虚函数的作用: 解释：在类的继承中，如果有基类指针指向派生类，那么用基类指针delete时，如果不定义成虚函数，派生类中派生的那部分无法析构。\n","permalink":"https://jianye0428.github.io/en/posts/notes/c++/2022-12-04_c++_/","summary":"ref: [1]. https://blog.csdn.net/Yangy_Jiaojiao/article/details/127588598 [2]. https://blog.csdn.net/Yangy_Jiaojiao/article/details/128145609 1. 基础知识（一） 1.1 C++语言的特点 ①C++在C的基础上引入了面向对象机制，同时也兼容C语言； ②C++三大特性：封装、继承、多态； ③","title":"2022 12 04_C++_"},{"content":"第5章 共享内存和常量内存 了解数据在共享内存中是如何被安排的 掌握从二维共享内存到线性全局内存的索引转换 解决不同访问模式中存储体中的冲突 在共享内存中缓存数据以减少对全局内存的访问 使用共享内存避免非合并全局内存的访问 理解常量缓存和只读缓存之间的差异 使用线程束洗牌指令编程 5.1 CUDA共享内存概述 GPU中有两种类型的内存:\n板载内存: 全局内存是较大的板载内存，具有相对较高的延迟。 片上内存: 共享内存是较小的片上内存，具有相对较低的延迟，并且共享内存可以提供比全局内存高得多的带宽 共享内存通常的用途有:\n块内线程通信的通道 用于全局内存数据的可编程管理的缓存 高速暂存存储器，用于转换数据以优化全局内存访问模式 5.1.1 共享内存 共享内存（shared memory，SMEM）是GPU的一个关键部件。物理上，每个SM都有一个小的低延迟内存池，这个内存池被当前正在该SM上执行的线程块中的所有线程所共享。(共享内存就是SM上的一块低延迟内存池)\n共享内存使同一个线程块中的线程能够互相协作，便于重用片上数据，并可以大大降低核函数所需的全局内存带宽。由于共享内存中的内容是由应用程序显式管理的，所以它通常被描述为可编程管理的缓存。\n当每个线程块开始执行时，会分配给它一定数量的共享内存。这个共享内存的地址空间被线程块中所有的线程共享。它的内容和创建时所在的线程块具有相同生命周期。每个线程束发出共享内存访问请求。在理想的情况下，每个被线程束共享内存访问的请求在一个事务中完成。最坏的情况下，每个共享内存的请求在32个不同的事务中顺序执行。如果多个线程访问共享内存中的同一个字，一个线程读取该字后，通过多播把它发送给其他线程。\n共享内存被SM中的所有常驻线程块划分，因此，共享内存是限制设备并行性的关键资源。一个核函数使用的共享内存越多，处于并发活跃状态的线程块就越少。\n可编程管理的缓存\n共享内存是一个可编程管理的缓存。当数据移动到共享内存中以及数据被释放时,我们对它有充分的控制权。由于在CUDA中允许手动管理共享内存,所以通过在数据布局上提供更多的细粒度控制和改善片上数据的移动,使得对应用程序代码进行优化变得更简单了\n5.1.2 共享内存分配 有多种方法可以用来分配或声明由应用程序请求所决定的共享内存变量。可以静态或动态地分配共享内存变量。在CUDA的源代码文件中,共享内存可以被声明为一个本地的CUDA核函数或是一个全局的CUDA核函数。CUDA支持一维、二维和三维共享内存数组的声明。\n共享内存变量用下列修饰符进行声明: __shared__\n如果在核函数中进行声明,那么这个变量的作用域就局限在该内核中。如果在文件的任何核函数外进行声明,那么这个变量的作用域对所有核函数来说都是全局的。\n","permalink":"https://jianye0428.github.io/en/posts/notes/gpu_compute/cuda_c_notes/cuda_c_ch05/","summary":"第5章 共享内存和常量内存 了解数据在共享内存中是如何被安排的 掌握从二维共享内存到线性全局内存的索引转换 解决不同访问模式中存储体中的冲突 在共享内","title":"CUDA_C_CH05"},{"content":"CH04 全局内存 4.1 CUDA内存模型概述 在现有的硬件存储子系统下， 必须依靠内存模型获得最佳的延迟和带宽。 CUDA内存模结合了主机和设备的内存系统， 展现了完整的内存层次结构， 使你能显式地控制数据布以优化性能.s\n4.1.1 内存层次结构的优点 两种不同类型的局部性:\n时间局部性：时间局部性认为如果一个数据位置被引用， 那么该数据在较短的间周期内很可能会再次被引用， 随着时间流逝， 该数据被引用的可能性逐渐降低 空间局部性：空间局部性认为如果一个内存位置被引用， 则附近的位置也可能会被引用 现代计算机使用不断改进的低延迟低容量的内存层次结构来优化性能。 这种内存层次结构仅在支持局部性原则的情况下有效。 一个内存层次结构由具有不同延迟、 带宽容量的多级内存组成。 通常， 随着从处理器到内存延迟的增加， 内存的容量也在增加。\nCPU和GPU的主存都采用的是DRAM（动态随机存取存储器），而低延迟内存（如CPU一级缓存）使用的则是SRAM（静态随机存取存储器）。内存层次结构中最大且最慢的级别通常使用磁盘或闪存驱动来实现。在这种内存层次结构中，当数据被处理器频繁使用时，该数据保存在低延迟、低容量的存储器中；而当该数据被存储起来以备后用时，数据就存储在高延迟、大容量的存储器中。这种内存层次结构符合大内存低延迟的设想。\nGPU和CPU内存模型的主要区别是， CUDA编程模型能将内存层次结构更好地呈现给用户， 能让我们显式地控制它的行为.\n4.1.2 CUDA内存模型 对于程序员来说， 一般有两种类型的存储器：\n可编程的： 你需要显式地控制哪些数据存放在可编程内存中 不可编程的： 你不能决定数据的存放位置， 程序将自动生成存放位置以获得好的性能 在CPU内存层次结构中， 一级缓存和二级缓存都是不可编程的存储器。\nCUDA内存模型提出了多种可编程内存的类型:\n寄存器 (register) 共享内存 (shared memory) 本地内存 (local memory) 常量内存（constant memory） 纹理内存 () 全局内存(global memory) 一个核函数中的线程都有自己私有的本地内存。 一个线程块有自己的共享内存， 对同一线程块中所有线程都可见， 其内容持续线程块的整个生命周期。 所有线程都可以访问全局内存。 所有线程都能访问的只读内存空间有： 常量内存空间和纹理内存空间。 \u0026gt; 全局内存、 常量内存和纹理内存空间有不同的用途。 纹理内存为各种数据布局提供了不同的寻址模式和滤波模式。 对于一个应用程序来说， 全局内存、 常量内存和纹理内存中的内容具有相同的生命周期.\n4.1.2.1 寄存器 寄存器是GPU上运行速度最快的内存空间。\n核函数中声明的一个没有其他修饰符的自变量， 通常存储在寄存器中。 在核函数声明的数组中， 如果用于引用该数组的索引是常量且能在编译时确定， 那么该数组也存储在寄存器中。\n寄存器变量对于每个线程来说都是私有的， 一个核函数通常使用寄存器来保存需要频 繁访问的线程私有变量。 寄存器变量与核函数的生命周期相同。 一旦核函数执行完毕， 就不能对寄存器变量进行访问了。\n寄存器是一个在SM中由活跃线程束划分出的较少资源:\n在Fermi架构中，每个线程最多有63个寄存器； 在Kepler架构中，每个线程最多有255个寄存器；\n在核函数中使用较少的寄存器将使在SM上有更多的常驻线程块。 每个SM上并发线程块越多，使用率和性能就越高\n如果一个核函数使用了超过硬件限制数量的寄存器， 则会用本地内存替代多占用的寄 存器。\n4.1.2.2 本地内存（local memory） 编译器可能存放到本地内存中的变量有：\n在编译时使用未知索引引用的本地数组 可能会占用大量寄存器空间的较大本地结构体或数组 任何不满足核函数寄存器限定条件的变量 “本地内存”这一名词是有歧义的： 溢出到本地内存中的变量本质上与全局内存在同一 块存储区域， 因此本地内存访问的特点是高延迟和低带宽， 并且如在本章后面的4.3节中所描述的那样， 本地内存访问符合高效内存访问要求.\n4.1.2.3 共享内存 在核函数中使用如下修饰符修饰的变量存放在共享内存中： __shared__ 因为共享内存是片上内存， 所以与本地内存或全局内存相比， 它具有更高的带宽和更 低的延迟。 它的使用类似于CPU一级缓存， 但它是可编程的。\n每一个SM都有一定数量的由线程块分配的共享内存。 因此， 必须非常小心不要过度使用共享内存， 否则将在不经意间限制活跃线程束的数量。\n共享内存在核函数的范围内声明， 其生命周期伴随着整个线程块。 当一个线程块执行结束后， 其分配的共享内存将被释放并重新分配给其他线程块。\n共享内存是线程之间相互通信的基本方式。 一个块内的线程通过使用共享内存中的数 据可以相互合作。 访问共享内存必须同步使用如下调用， 该命令是在之前章节中介绍过的CUDA运行时调用： void __syncthreads();\n该函数设立了一个执行障碍点， 即同一个线程块中的所有线程必须在其他线程被允许 执行前达到该处。 为线程块里所有线程设立障碍点， 这样可以避免潜在的数据冲突。\nSM中的一级缓存和共享内存都使用64KB的片上内存， 它通过静态划分， 但在运行时 可以通过如下指令进行动态配置： cudaError_t cudaFuncSetCacheConfig(const void* func, enum cadaFuncCache cacheConfig)\n4.1.2.4 常量内存 常量内存驻留在设备内存中， 并在每个SM专用的常量缓存中缓存。 常量变量用如下 修饰符来修饰: __constant__\n常量变量必须在全局空间内和所有核函数之外进行声明。 对于所有计算能力的设备， 都只可以声明64KB的常量内存。 常量内存是静态声明的， 并对同一编译单元中的所有核函数可见。\n核函数只能从常量内存中读取数据。（不能往常量内存中写数据） 因此， 常量内存必须在主机端使用下面的函数来 初始化： cudaError_t cudaMemoryToSymbol(const void* symbol, const void* src, size_t count)\n这个函数将count个字节从src指向的内存复制到symbol指向的内存中， 这个变量存放在设备的全局内存或常量内存中。\n线程束中的所有线程从相同的内存地址中读取数据时， 常量内存表现最好。\n举个例子， 数学公式中的系数就是一个很好的使用常量内存的例子， 因为一个线程束中所有的线程使用相同的系数来对不同数据进行相同的计算。 如果线程束里每个线程都从不同的地址空间读取数据， 并且只读一次， 那么常量内存中就不是最佳选择， 因为每从一个常量内存中读取一次数据， 都会广播给线程束里的所有线程。\n4.1.2.5 纹理内存 纹理内存是一种通过指定的只读缓存访问的全局内存。 只读缓存包括硬件滤波的支持， 它可以将浮点插入作为读过程的一部分来执行。 纹理内存是对二维空间局部性的优化， 所以线程束里使用纹理内存访问二维数据的线程可以达到最优性能。\n4.1.2.6 全局内存 全局内存是GPU中最大、 延迟最高并且最常使用的内存。 global指的是其作用域和生命周期。 它的声明可以在任何SM设备上被访问到， 并且贯穿应用程序的整个生命周期。\n一个全局内存变量可以被静态声明或动态声明。 你可以使用如下修饰符在设备代码中 静态地声明一个变量：\n__device__\n在第2章的2.1节中， 你已经学习了如何动态分配全局内存。 在主机端使用cuda-Malloc 函数分配全局内存， 使用cudaFree函数释放全局内存。 然后指向全局内存的指针就会作为 参数传递给核函数。 全局内存分配空间存在于应用程序的整个生命周期中， 并且可以访问 所有核函数中的所有线程。 从多个线程访问全局内存时必须注意。 因为线程的执行不能跨 线程块同步， 不同线程块内的多个线程并发地修改全局内存的同一位置可能会出现问题， 这将导致一个未定义的程序行为。\n优化内存事务对于获得最优性能来说是至关重要的。 当一个线程束执行内存加载/ 存储时， 需要满足的传输数量通常取决于以下两个因素：\n跨线程的内存地址分布 每个事务内存地址的对齐方式 对于一个给定的线程束内存请求， 事务数量和数据吞吐率是由设备的计算能力来确定 的。 对于计算能力为1.0和1.1的设备， 全局内存访问的要求是非常严格的。 对于计算能力高于1.1的设备， 由于内存事务被缓存， 所以要求较为宽松。 缓存的内存事务利用数据局部性来提高数据吞吐率。\n4.1.2.7 GPU缓存 跟CPU缓存一样， GPU缓存是不可编程的内存。 在GPU上有4种缓存：\n一级缓存 二级缓存 只读常量缓存 只读纹理缓存 每个SM都有一个一级缓存， 所有的SM共享一个二级缓存。 一级和二级缓存都被用来在存储本地内存和全局内存中的数据， 也包括寄存器溢出的部分。对Fermi GPU和Kepler K40或其后发布的GPU来说， CUDA允许我们配置读操作的数据是使用一级和二级缓存，还是只使用二级缓存。\n在GPU上只有内存加载操作可以被缓存，内存存储操作不能被缓存。 每个SM也有一个只读常量缓存和只读纹理缓存， 它们用于在设备内存中提高来自于各自内存空间内的读取性能。\n4.1.2.8 CUDA变量声明总结 4.1.2.9 静态全局内存 4.2 内存管理 CUDA编程的内存管理与C语言的类似， 需要程序员显式地管理主机和设备之间的数 据移动。 随着CUDA版本的升级， NVIDIA正系统地实现主机和设备内存空间的统一， 但对于大多数应用程序来说， 仍需要手动移动数据。\n分配和释放设备内存 在主机和设备之间传输数据 4.2.1 内存分配和释放 CUDA编程模型假设了一个包含一个主机和一个设备的异构系统， 每一个异构系统都 有自己独立的内存空间。 核函数在设备内存空间中运行， CUDA运行时提供函数以分配和释放设备内存。\n你可以在主机上使用下列函数分配全局内存：\ncudaError_t cudaMalloc(void **devPrt, size_t count);\n这个函数在设备上分配了count字节的全局内存， 并用devptr指针返回该内存的地址。\n你需要用从主机上传输的数据来填充所分配的全局内存， 或用下列函数将其初始 化:\ncudaError_t cudaMemset(void *devPtr, int value, size_t count);\n这个函数用存储在变量value中的值来填充从设备内存地址devPtr处开始的count字节。\n一旦一个应用程序不再使用已分配的全局内存， 那么可以以下代码释放该内存空间： cudaError_t cudaFree(void *devPtr);\n这个函数释放了devPtr指向的全局内存， 该内存必须在此前使用了一个设备分配函数 （如cudaMalloc） 来进行分配。 否则， 它将返回一个错误cudaErrorInvalidDevicePointer。 如果地址空间已经被释放， 那么cudaFree也返回一个错误。\n4.2.2 内存传输 一旦分配好了全局内存， 你就可以使用下列函数从主机向设备传输数据：\ncudaError_t cudaMemory(void *dst, const void *src, size_t count, enum cudaMemcpyKind kind)\n这个函数从内存位置src复制了count字节到内存位置dst。 变量kind指定了复制的方向， 可以有下列取值：\ncudaMemcpyHostToHost cudaMemcpyHostToDevice cudaMemcpyDeviceToHost cudaMemcpyDeviceToDevice CUDA编程的一个基本原则应是尽可能地减少主机与设备之间的传输.\n4.2.3 固定内存 分配的主机内存默认是pageable（可分页） ， 它的意思也就是因页面错误导致的操 作， 该操作按照操作系统的要求将主机虚拟内存上的数据移动到不同的物理位置。 虚拟内存给人一种比实际可用内存大得多的假象， 就如同一级缓存好像比实际可用的片上内存大得多一样。\nGPU不能在可分页主机内存上安全地访问数据， 因为当主机操作系统在物理位置上移 动该数据时， 它无法控制。 当从可分页主机内存传输数据到设备内存时， CUDA驱动程序首先分配临时页面锁定的或固定的主机内存， 将主机源数据复制到固定内存中， 然后从固定内存传输数据给设备内存， 如图4-4左边部分所示\nCUDA运行时允许你使用如下指令直接分配固定主机内存： cudaError_t cudaMallocHost(void **devPtr, size_t count);\n这个函数分配了count字节的主机内存， 这些内存是页面锁定的并且对设备来说是可 访问的。 由于固定内存能被设备直接访问， 所以它能用比可分页内存高得多的带宽进行读写。 然而， 分配过多的固定内存可能会降低主机系统的性能， 因为它减少了用于存储虚拟内存数据的可分页内存的数量， 其中分页内存对主机系统是可用的。\n主机与设备间的内存传输\n与可分页内存相比， 固定内存的分配和释放成本更高， 但是它为大规模数据传输提供 了更高的传输吞吐量\n4.2.4 零拷贝内存 通常来说， 主机不能直接访问设备变量， 同时设备也不能直接访问主机变量。 但有一个例外： 零拷贝内存。 主机和设备都可以访问零拷贝内存。\nGPU线程可以直接访问零拷贝内存。 在CUDA核函数中使用零拷贝内存有以下几个优 势。\n当设备内存不足时可利用主机内存 避免主机和设备间的显式数据传输 提高PCIe传输率 当使用零拷贝内存来共享主机和设备间的数据时， 你必须同步主机和设备间的内存访 问， 同时更改主机和设备的零拷贝内存中的数据将导致不可预知的后果。\n零拷贝内存是固定（不可分页） 内存， 该内存映射到设备地址空间中。 你可以通过下列函数创建一个到固定内存的映射：\ncudaError_t cudaHostAlloc(void **pHost, size_t count, unsigned int flags);\n这个函数分配了count字节的主机内存， 该内存是页面锁定的且设备可访问的。 用这 个函数分配的内存必须用cudaFreeHost函数释放。 flags参数可以对已分配内存的特殊属性 进一步进行配置：\n- cudaHostAllocDefault - cudaHostAllocPortable - cudaHostAllocWriteCombined - cudaHostAllocMapped cudaHostAllocDefault函数使cudaHostAlloc函数的行为与cudaMallocHost函数一致。\n设置cudaHostAllocPortable函数可以返回能被所有CUDA上下文使用的固定内存， 而不仅是执 行内存分配的那一个。\n标志cudaHostAllocWriteCombined返回写结合内存， 该内存可以在某些系统配置上通过PCIe总线上更快地传输， 但是它在大多数主机上不能被有效地读取。因此， 写结合内存对缓冲区来说是一个很好的选择， 该内存通过设备使用映射的固定内存或主机到设备的传输。\n零拷贝内存的最明显的标志是cudaHostAllocMapped， 该标志返回， 可以实现主机写入和设备读取被映射到设备地址空间中的主机内存。\n你可以使用下列函数获取映射到固定内存的设备指针：\ncudaError_t cudaHostGetDevicePointer(void **pDevice, void *pHost, unsigned int flags);\n该函数返回了一个在pDevice中的设备指针， 该指针可以在设备上被引用以访问映射得到的固定主机内存。 如果设备不支持映射得到的固定内存， 该函数将失效。 flag将留作以后使用。 现在， 它必须被置为0。\n在进行频繁的读写操作时， 使用零拷贝内存作为设备内存的补充将显著降低性能。 因为每一次映射到内存的传输必须经过PCIe总线。 与全局内存相比， 延迟也显著增加。\n零拷贝内存\n有两种常见的异构计算系统架构： 集成架构和离散架构。\n在集成架构中， CPU和GPU集成在一个芯片上， 并且在物理地址上共享主存。 在这种架构中， 由于无须在PCIe总线上备份， 所以零拷贝内存在性能和可编程性方面可能更佳。\n对于通过PCIe总线将设备连接到主机的离散系统而言， 零拷贝内存只在特殊情况下有优势。\n因为映射的固定内存在主机和设备之间是共享的， 你必须同步内存访问来避免任何潜在的数据冲突， 这种数据冲突一般是由多线程异步访问相同的内存而引起的。\n注意不要过度使用零拷贝内存。 由于其延迟较高， 从零拷贝内存中读取设备核函数可能很慢。\n4.2.5 统一虚拟寻址 ","permalink":"https://jianye0428.github.io/en/posts/notes/gpu_compute/cuda_c_notes/cuda_c_ch04/","summary":"CH04 全局内存 4.1 CUDA内存模型概述 在现有的硬件存储子系统下， 必须依靠内存模型获得最佳的延迟和带宽。 CUDA内存模结合了主机和设备的内存系统， 展","title":"CUDA_C_CH04"},{"content":"CH03 CUDA执行模型 3.1 CUDA执行模型概述 CUDA执行模型能够提供有助于在指令吞吐量和内存访问方面编写高效代码的见解\n3.1.1 GPU架构概述 GPU架构是围绕一个流式多处理器（SM） (Stream Multiprocessor)的可扩展阵列搭建的,可以通过复制这种架构的构建块来实现GPU的硬件并行\nFermi SM的关键组件：\nCUDA核心 共享内存/一级缓存 寄存器文件 加载/存储单元 特殊功能单元 线程束调度器 GPU中的每一个SM都能支持数百个线程并发执行， 每个GPU通常有多个SM， 所以在一个GPU上并发执行数千个线程是有可能的。 当启动一个内核网格时， 它的线程块被分布在了可用的SM上来执行。 线程块一旦被调度到一个SM上， 其中的线程只会在那个指定的SM上并发执行。 多个线程块可能会被分配到同一个SM上， 而且是根据SM资源的可用性进行调度的。同一线程中的指令利用指令级并行性进行流水线化， 另外， 在CUDA中已经介绍了线程级并行。\nCUDA采用单指令多线程（SIMT）（single instruciton multi thread） 架构来管理和执行线程， 每32个线程为一组， 被称为线程束（warp） 。 线程束中的所有线程同时执行相同的指令。 每个线程都有自己的指令地址计数器和寄存器状态， 利用自身的数据执行当前的指令。 每个SM都将分配给它的线程块划分到包含32个线程的线程束中， 然后在可用的硬件资源上调度执行。\nSIMT架构与SIMD（单指令多数据） 架构相似。 两者都是将相同的指令广播给多个执行单元来实现并行。 一个关键的区别是SIMD要求同一个向量中的所有元素要在一个统一的同步组中一起执行， 而SIMT允许属于同一线程束的多个线程独立执行.\nSIMT确保可以编写独立的线程级并行代码、 标量线程以及用于协调线程的数据并行代码。\nSIMT模型包含3个SIMD所不具备的关键特征。\n每个线程都有自己的指令地址计数器 每个线程都有自己的寄存器状态 每个线程可以有一个独立的执行路径 一个神奇的数字： 32\n从概念上讲， 它是SM用SIMD方式所同时处理的工作粒度。 优化工作负载以适应线程束（一组有32个线程） 的边界， 一般这样会更有效地利用GPU计算资源。\n一个线程块只能在一个SM上被调度。 一旦线程块在一个SM上被调度， 就会保存在该SM上直到执行完成。 在同一时间， 一个SM可以容纳多个线程块.\n在SM中， 共享内存和寄存器是非常重要的资源。 共享内存被分配在SM上的常驻线程块中， 寄存器在线程中被分配。\n尽管线程块里的所有线程都可以逻辑地并行运行， 但是并不是所有线程都可以同时在物理层面执行。 因此， 线程块里的不同线程可能会以不同的速度前进。\n在并行线程中共享数据可能会引起竞争： 多个线程使用未定义的顺序访问同一个数据， 从而导致不可预测的程序行为。 CUDA提供了一种用来同步线程块里的线程的方法，从而保证所有线程在进一步动作之前都达到执行过程中的一个特定点。 然而， 没有提供块间同步的原语。\n当线程束由于任何理由闲置的时候（如等待从设备内存中读取数值） ， SM可以从同一SM上的常驻线程块中调度其他可用的线程束。 在并发的线程束间切换并没有开销， 因为硬件资源已经被分配到了SM上的所有线程和块中， 所以最新被调度的线程束的状态已经存储在SM上\nSM： GPU架构的核心*\nSM是GPU架构的核心。 寄存器和共享内存是SM中的稀缺资源。 CUDA将这些资源分配到SM中的所有常驻线程里。\n这些有限的资源限制了在SM上活跃的线程束数量，活跃的线程束数量对应于SM上的并行量。\n了解一些SM硬件组成的基本知识， 有助于组织线程和配置内核执行以获得最佳的性能\n3.1.2 Fermi架构 Fermi的特征是多达512个加速器核心， 这被称为CUDA核心。 每个CUDA核心都有一个全流水线的整数算术逻辑单元（ALU） 和一个浮点运算单元（FPU） ， 在这里每个时钟周期执行一个整数或是浮点数指令。 CUDA核心被组织到16个SM中， 每一个SM含有32个CUDA核心。 Fermi架构有6个384位的GDDR5 DRAM存储器接口， 支持多达6GB的全局机载内存， 这是许多应用程序关键的计算资源。 主机接口通过PCIe总线将GPU与CPU相连。 GigaThread引擎（图示左侧第三部分） 是一个全局调度器， 用来分配线程块到SM线程束调度器上。\n一个SM(Stream Multiprocessor)包含以下内容：\n执行单元（CUDA核心） 调度线程束的调度器和调度单元 共享内存、 寄存器文件和一级缓存 每一个多处理器有16个加载/存储单元（如图3-1所示） ， 允许每个时钟周期内有16个线程（线程束的一半） 计算源地址和目的地址。 特殊功能单元（SFU） 执行固有指令， 如正弦、 余弦、 平方根和插值。 每个SFU每个时钟周期内的每个线程上执行一个固有指令\n每个SM有两个线程束调度器和两个指令调度单元。 当一个线程块被指定给一个SM时， 线程块中的所有线程被分成了线程束。 两个线程束调度器选择两个线程束， 再把一个 指令从线程束中发送到一个组上， 组里有16个CUDA核心、 16个加载/存储单元或4个特殊功能单元（如图3-4所示） 。 Fermi架构， 计算性能2.x， 可以在每个SM上同时处理48个线程束， 即可在一个SM上同时常驻1536个线程。\n3.1.3 Kepler架构 发布于2012年秋季的Kepler GPU架构是一种快速、 高效、 高性能的计算架构。 Kepler 的特点使得混合计算更容易理解。 图3-6表示了Kepler K20X芯片框图， 它包含了15个SM 和6个64位的内存控制器。 以下是Kepler架构的3个重要的创新。\n强化的SM 动态并行 Hyper-Q技术 Kepler K20X的关键部分是有一个新的SM单元， 其包括一些结构的创新， 以提高编程效率和功率效率。 每个Kepler SM单元包含192个单精度CUDA核心， 64个双精度单元， 32个特殊功能单元（SFU） 以及32个加载/存储单元（LD/ST）\n3.1.4 配置文件驱动优化 配置文件驱动的发展对于CUDA编程尤为重要， 原因主要有以下几个方面。\n一个单纯的内核应用一般不会产生最佳的性能。 性能分析工具能帮助你找到代码中影响性能的关键部分， 也就是性能瓶颈。 CUDA将SM中的计算资源当前SM中的多个常驻线程块之间进行分配。 这种分配形式导致一些资源成为了性能限制者。 性能分析工具能帮助我们理解计算资源是如何被利用的。 CUDA提供了一个硬件架构的抽象， 它能够让用户控制线程并发。 性能分析工具可以检测和优化， 并将优化可视化。 3.2 理解线程束执行的本质 本章已经提到了把32个线程划分到一个执行单元中的概念： 线程束（warp）。 现在从硬件的角度来介绍线程束执行， 并能够获得指导内核设计的方法。\n3.2.1 线程束和线程块 线程束是SM中基本的执行单元。\n当一个线程块的网格被启动后， 网格中的线程块分布在SM中。 一旦线程块被调度到一个SM上， 线程块中的线程会被进一步划分为线程束。 一个线程束由32个连续的线程组成， 在一个线程束中， 所有的线程按照单指令多线程（SIMT） 方式执行； 也就是说， 所有线程都执行相同的指令， 每个线程在私有数据上进 行操作。\n一个给定的二维线程块， 在一个块中每个线程的独特标识符都可以用内置变量threadIdx和blockDim来计算： threadIdx.y * blockDim.x + threadIdx.x\n对于一个三维线程块， 计算如下：\nthreadIdx.x * blockDim.y * block.Dim.x + threadIdx.y * blockDim.x * threadIdx.x\n一个线程块的线程束的数量可以根据下式确定：\n$$一个线程块中线程束的数量 = 向正无穷取整（\\frac{一个线程块中线程的数量}{线程束大小}）$$\n因此， 硬件总是给一个线程块分配一定数量的线程束。 线程束不会在不同的线程块之间分离。 如果线程块的大小不是线程束大小的偶数倍， 那么在最后的线程束里有些线程就不会活跃。\n从逻辑角度来看， 线程块是线程的集合， 它们可以被组织为一维、 二维或三维布局。\n从硬件角度来看， 线程块是一维线程束的集合。 在线程块中线程被组织成一维布局，每32个连续线程组成一个线程束。\n3.2.2 线程束分化 GPU是相对简单的设备， 它没有复杂的分支预测机制。 一个线程束中的所有线程在同一周期中必须执行相同的指令， 如果一个线程执行一条指令， 那么线程束中的所有线程都必须执行该指令。 如果在同一线程束中的线程使用不同的路径通过同一个应用程序， 这可能会产生问题。\n如果一个线程束中的线程产生分化， 线程束将连续执行每一个分支路径， 而禁用不执行这一路径的线程。 线程束分化会导致性能明显地下降。\n重要提示:\n当一个分化的线程采取不同的代码路径时， 会产生线程束分化 不同的if-then-else分支会连续执行 尝试调整分支粒度以适应线程束大小的倍数， 避免线程束分化 不同的分化可以执行不同的代码且无须以牺牲性能为代价 3.2.3 资源分配 线程束的本地执行上下文主要由以下资源组成：\n程序计数器 寄存器 共享内存 由SM处理的每个线程束的执行上下文， 在整个线程束的生存期中是保存在芯片内的。 因此， 从一个执行上下文切换到另一个执行上下文没有损失。\n每个SM都有32位的寄存器组， 它存储在寄存器文件中， 并且可以在线程中进行分配， 同时固定数量的共享内存用来在线程块中进行分配。 对于一个给定的内核， 同时存在于同一个SM中的线程块和线程束的数量取决于在SM中可用的且内核所需的寄存器和共享内存的数量。\n若每个线程消耗的寄存器越多， 则可以放在一个SM中的线程束就越少。 如果可以减少内核消耗寄存器的数量， 那么就可以同时处理更多的线程束。\n若一个线程块消耗的共享内存越多， 则在一个SM中可以被同时处理的线程块就会变少。 如果每个线程块使用的共享内存数量变少， 那么可以同时处理更多的线程块。\n当计算资源（如寄存器和共享内存） 已分配给线程块时， 线程块被称为活跃的块。 它所包含的线程束被称为活跃的线程束。 活跃的线程束可以进一步被分为以下3种类型：\n选定的线程束 阻塞的线程束 符合条件的线程束 一个SM上的线程束调度器在每个周期都选择活跃的线程束， 然后把它们调度到执行 单元。 活跃执行的线程束被称为选定的线程束。 如果一个活跃的线程束准备执行但尚未执 行， 它是一个符合条件的线程束。 如果一个线程束没有做好执行的准备， 它是一个阻塞的 线程束。 如果同时满足以下两个条件则线程束符合执行条件。\n32个CUDA核心可用于执行 当前指令中所有的参数都已就绪 3.2.4 延迟隐藏 SM依赖线程级并行， 以最大化功能单元的利用率， 因此， 利用率与常驻线程束的数量直接相关。 在指令发出和完成之间的时钟周期被定义为指令延迟。 当每个时钟周期中所有的线程调度器都有一个符合条件的线程束时， 可以达到计算资源的完全利用。 这就可以保证， 通过在其他常驻线程束中发布其他指令， 可以隐藏每个指令的延迟。\n考虑到指令延迟， 指令可以被分为两种基本类型：\n算术指令: 一个算术操作从开始到它产生输出之间的时间； 内存指令: 指发送出的加载或存储操作和数据到达目的地之间的时间。 你可能想知道如何估算隐藏延迟所需要的活跃线程束的数量。 利特尔法则（Little’s Law） 可以提供一个合理的近似值。 它起源于队列理论中的一个定理， 它也可以应用于 GPU中：\n$$所需线程束数量 = 延迟 \\times 吞吐量$$\n吞吐量和带宽\n吞吐量和带宽都是用来度量性能的速度指标。\n带宽通常是指理论峰值， 而吞吐量是指已达到的值\n带宽通常是用来描述单位时间内最大可能的数据传输量， 而吞吐量是用来描述单位时 间内任何形式的信息或操作的执行速度， 例如， 每个周期完成多少个指令。\n吞吐量由SM中每个周期内的操作数量确定， 而执行一条指令的一个线程束对应32个 操作。\n这个简单的单位转换表明， 有两种方法可以提高并行：\n指令级并行（ILP） ： 一个线程中有很多独立的指令 线程级并行（TLP） ： 很多并发地符合条件的线程 延迟隐藏取决于每个SM中活跃线程束的数量， 这一数量由执行配置和资源约束隐式 决定（一个内核中寄存器和共享内存的使用情况） 。 选择一个最优执行配置的关键是在延 迟隐藏和资源利用之间找到一种平衡。\n显示充足的并行 因为GPU在线程间分配计算资源并在并发线程束之间切换的消耗（在一个或两个周期 命令上） 很小， 所以所需的状态可以在芯片内获得。 如果有足够的并发活跃线程， 那么可 以让GPU在每个周期内的每一个流水线阶段中忙碌。 在这种情况下， 一个线程束的延迟可 以被其他线程束的执行隐藏。 因此， 向SM显示足够的并行对性能是有利的\n3.2.5 占用率 在每个CUDA核心里指令是顺序执行的。 当一个线程束阻塞时， SM切换执行其他符 合条件的线程束。 理想情况下， 我们想要有足够的线程束占用设备的核心。 占用率是每个 SM中活跃的线程束占最大线程束数量的比值。\n$$占用率 = \\frac{活跃线程束数量}{最大线程束数量}$$\n极端地操纵线程块会限制资源的利用：\n小线程块： 每个块中线程太少， 会在所有资源被充分利用之前导致硬件达到每个SM的线程束数量的限制 大线程块： 每个块中有太多的线程， 会导致在每个SM中每个线程可用的硬件资源较少 网格和线程块大小的准则\n使用这些准则可以使应用程序适用于当前和将来的设备：\n保持每个块中线程数量是线程束大小（32） 的倍数 避免块太小： 每个块至少要有128或256个线程 根据内核资源的需求调整块大小 块的数量要远远多于SM的数量， 从而在设备中可以显示有足够的并行 通过实验得到最佳执行配置和资源使用情况 占用率唯一注重的是在每个SM中并发线程或线 程束的数量。 然而， 充分的占用率不是性能优化的唯一目标。 内核一旦达到一定级别的占 用率， 进一步增加占用率可能不会改进性能。 为了提高性能， 可以调整很多其他因素。\n3.2.6 同步 在CUDA中， 同步可以在两个级别执行：\n系统级： 等待主机和设备完成所有的工作 块级： 在设备执行过程中等待一个线程块中所有线程到达同一点 对于主机来说：\ncudaError_t cudaDeviceSynchronize(void):cudaDeviceSyn-chronize函数可以用来阻塞主机应用程序， 直到所有的CUDA操作（复制、核函数等） 完成; __device__ void __syncthreads(void);:CUDA提供了一个使用块局部栅栏来同步它们的执行的功能。 当__syncthreads被调用时， 在同一个线程块中每个线程都必须等待直至该线程块中所有其他线程都已经达到这个同步点。 线程块中的线程可以通过共享内存和寄存器来共享数据。\n在不同的块之间没有线程同步。 块间同步， 唯一安全的方法是在每个内核执行结束端使用全局同步点； 也就是说， 在全局同步之后， 终止当前的核函数， 开始执行新的核函数。 不同块中的线程不允许相互同步， 因此GPU可以以任意顺序执行块。 这使得CUDA程序在大规模并行GPU上是可扩展的。\n3.2.7 可扩展性 对于任何并行应用程序而言， 可扩展性是一个理想的特性。 可扩展性意味着为并行应用程序提供了额外的硬件资源， 相对于增加的资源， 并行应用程序会产生加速。 例如， 若一个CUDA程序在两个SM中是可扩展的， 则与在一个SM中运行相比， 在两个SM中运行会使运行时间减半。 一个可扩展的并行程序可以高效地使用所有的计算资源以提高性能。 可扩展性意味着增加的计算核心可以提高性能。 串行代码本身是不可扩展的， 因为在成千上万的内核上运行一个串行单线程应用程序， 对性能是没有影响的。 并行代码有可扩展的潜能， 但真正的可扩展性取决于算法设计和硬件特性。\n3.3 并行性的表现 3.6 动态并行 在本书中， 到目前为止， 所有核函数都是从主机线程中被调用的。 GPU的工作负载完 全在CPU的控制下。 CUDA的动态并行允许在GPU端直接创建和同步新的GPU内核。 在一 个核函数中在任意点动态增加GPU应用程序的并行性， 是一个令人兴奋的新功能。\n","permalink":"https://jianye0428.github.io/en/posts/notes/gpu_compute/cuda_c_notes/cuda_c_ch03/","summary":"CH03 CUDA执行模型 3.1 CUDA执行模型概述 CUDA执行模型能够提供有助于在指令吞吐量和内存访问方面编写高效代码的见解 3.1.1 GPU架构概述 GPU架构","title":"CUDA_C_CH03"},{"content":"CH02 CUDA编程模型 2.1 CUDA编程模型概述 CUDA编程模型提供了一个计算机架构抽象作为应用程序和其可用硬件之间的桥梁。\nCUDA编程模型还利用GPU架构的计算能力提供了以下几个特有功能:\n一种通过层次结构在GPU中组织线程的方法(2.3) 一种通过层次结构在GPU中访问内存的方法(4.5) 程序员可以通过以下几个不同层面来看待并行计算:\n领域层：如何解析数据和函数，以便在并行环境中正确高效的解决问题（在并行编程中高效的使用pthreads或者OpemMP技术显式地管理线程） 逻辑层：如何组织并发线程 硬件层：理解线程如何映射到核心以帮助提高其性能 2.1.1 CUDA编程 在一个异构环境中包含多个CPU和GPU， 每个GPU和CPU的内存都由一条PCI-Express总线分隔开。\n主机： CPU及其内存（主机内存） 设备： GPU及其内存（设备内存） “统一寻址”（Unified Memory） 的编程模型的改进， 它连接了主机内存和设备内存空间， 可使用单个指针访问CPU和GPU内存， 无须彼此之间手动拷贝数据。\n什么是“统一寻址”（Unified Memory)? CUDA 6.0提出了统一寻址， 使用一个指针来访问CPU和GPU的内存。(详见第4章)\n内核（kernel） 是CUDA编程模型的一个重要组成部分， 其代码在GPU上运行。\nCUDA编程模型主要是异步的， 因此在GPU上进行的运算可以与主机-设备通信重叠。 一个典型的CUDA程序包 括由并行代码互补的串行代码。\n串行代码在cpu上执行，并行代码在GPU上执行。\n一个典型的CUDA程序实现流程遵循以下模式：\n把数据从CPU内存拷贝到GPU内存； 调用核函数对存储在GPU内存中的数据进行操作； 将数据从GPU内存传送回到CPU内存。 2.1.2 内存管理 CUDA运行时负责分配与释放设备内存， 并且在主机内存和设备内存之间传输数据。\n表2-1 主机和设备内存函数\n标准c函数 CUDA C函数 标准c函数 CUDA C函数 malloc cudaMalloc memset cudaMemset memcpy cudaMemcpy free cudaFree cudaMalloc函数负责在GPU的内存里分配内存； cudaMemcpy函数负责主机和设备之间的数据传输；\n1 cudaError_t cudaMemcpy(void* dst, const void* src, size_t count, cudaMemcpyKind kind) 从src指向的源存储区复制一定数量的字节到dst指向的目标存储区 kind有以下几种: cudaMemcpyHostToHost cudaMemcpyHostToDevice cudaMemcpyDeviceToHost cudaMemcpyDeviceToDevice CUDA编程模型从GPU架构中抽象出一个内存层次结构：全局内存和共享内存。\n内存层次结构\n全局内存 共享内存 为什么CPU和GPU是异步的？ 当数据被转移到GPU的全局内存后， 主机端调用核函数在GPU上进行数组求和。 一旦内核被调用， 控制权立刻被传回主机， 这样的话， 当核函数在GPU上运行时， 主机可以执行其他函数。 因此， 内核与主机是异步的。\n不同的存储空间\n2.1.3 线程管理 当核函数在主机端启动时， 它的执行会移动到设备上， 此时设备中会产生大量的线程并且每个线程都执行由核函数指定的语句。\n由一个内核启动所产生的所有线程统称为一个网格。 同一网格中的所有线程共享相同的全局内存空间。 一个网格由多个线程块构成， 一个线程块包含一组线程， 同一线程块内的线程协作可以通过以下方式来实现：\n同步 共享内存 不同线程块内的线程不能协作。\n线程依靠以下两个坐标变量来区分彼此\nblockIdx(线程块在线程格内的索引) threadIdx(块内的线程索引) 些变量是核函数中需要预初始化的内置变量。 当执行一个核函数时， CUDA运行时为每个线程分配坐标变量blockIdx和threadIdx。 基于这些坐标， 你可以将部分数据分配给不同的线程。\n该坐标变量是基于uint3定义的CUDA内置的向量类型， 是一个包含3个无符号整数的结构， 可以通过x、 y、 z三个字段来指定：\nblockIdx.x blockIdx.y blockIdx.z threadIdx.x threadIdx.y threadIdx.z CUDA可以组织三维的网格和块.\n网格和块的维度由下列两个内置变量指定:\nblockDim(线程块的维度， 用每个线程块中的线程数来表示) gridDim(线程格的维度， 用每个线程格中的线程数来表示) 它们是dim3类型的变量， 是基于uint3定义的整数型向量， 用来表示维度。 当定义一个dim3类型的变量时， 所有未指定的元素都被初始化为1。 dim3类型变量中的每个组件可以通过它的x、 y、 z字段获得。 如下所示:\nblockDim.x blockDim.y blockDim.z 网格和线程块的维度\n一个线程格会被组织成线程块的二维数组形式， 一个线程块会被组织成线程的三维数组形式\n在CUDA程序中有两组不同的网格和块变量： 手动定义的dim3数据类型和预定义的uint3数据类型。\n手动定义的dim3类型的网格和块变量仅在主机端可见， 而unit3类型的内置预初始化的网格和块变量仅在设备端可见。\n从主机端和设备端访问网格/块变量\n区分主机端和设备端的网格和块变量的访问是很重要的。\n例如， 声明一个主机端的块变量， 你按如下定义它的坐标并对其进行访问：\nblock.x, block.y, block.z\n在设备端， 你已经预定义了内置块变量的大小：\nblockDim.x, blockDim.y, and blockDim.z\n在启动内核之前就定义了主机端的网格和块变量， 并从主机端通过由x、 y、 z三个字段决定的矢量结构来访问它们。 当内核启动时， 可以使用内核中预初始化的内置变量。\n总之， 在启动内核之前就定义了主机端的网格和块变量， 并从主机端通过由x、 y、 z三个字段决定的矢量结构来访问它们。 当内核启动时， 可以使用内核中预初始化的内置变量.\n对于一个给定的数据大小， 确定网格和块尺寸的一般步骤为：\n确定块的大小 在已知数据大小和块大小的基础上计算网格维度 要确定块尺寸， 通常需要考虑：\n内核的性能特性 GPU资源的限制 线程层次结构\nCUDA的特点之一就是通过编程模型揭示了一个两层的线程层次结构（grid-\u0026gt;block-\u0026gt;thread）。 由于一个内核 启动的网格和块的维数会影响性能， 这一结构为程序员优化程序提供了一个额外的途径。\n2.1.4 启动一个CUDA核函数 CUDA内核调用是对C语言函数调用语句的延伸， \u0026laquo;\u0026lt;\u0026raquo;\u0026gt;运算符内是核函数的执行配置。\nkernel_name \u0026lt;\u0026lt;\u0026lt;grid, block\u0026gt;\u0026gt;\u0026gt;(argument list)\n利用执行配置可以指定线程在GPU上调度运行的方式。 执行配置的第一个值是网格维度， 也就是启动块的数目。 第二个值是块维度， 也就是每个块中线程的数目。 通过指定网格和块的维度， 你可以进行以下 配置：\n内核中线程的数目 内核中使用的线程布局 同一个块(block)中的线程之间可以相互协作， 不同块内的线程不能协作。\n假设你有32个数据元素用于计算， 每8个元素一个块， 需要启动4个块：\nkernel_name\u0026lt;\u0026lt;\u0026lt;4, 8\u0026gt;\u0026gt;\u0026gt;(argument list)\n由于数据在全局内存中是线性存储的， 因此可以用变量blockIdx.x和threadId.x来进行以下操作。\n在网格中标识一个唯一的线程 建立线程和数据元素之间的映射关系 如果把所有32个元素放到一个块里， 那么只会得到一个块:\nkernel_name\u0026lt;\u0026lt;\u0026lt;1, 32\u0026gt;\u0026gt;\u0026gt;(argument list)\n如果每个块只含有一个元素， 那么会有32个块：\nkernel_name\u0026lt;\u0026lt;\u0026lt;32, 1\u0026gt;\u0026gt;\u0026gt;(argument list)\n核函数的调用与主机线程是异步的。 核函数调用结束后， 控制权立刻返回给主机端.\n你可以调用以下函数来强制主机端程序等待所有的核函数执行结束：\ncudaError_t cudaDeivceSynchronize(void);\n一些CUDA运行时API在主机和设备之间是隐式同步的。 当使用cudaMemcpy函数在主 机和设备之间拷贝数据时， 主机端隐式同步， 即主机端程序必须等待数据拷贝完成后才能 继续执行程序。\n异步行为\n不同于C语言的函数调用， 所有的CUDA核函数的启动都是异步的。 CUDA内核调用完成后， 控制权立刻返回给CPU。\n2.1.5 编写核函数 核函数是在设备端执行的代码。\n用__global__声明定义核函数:\n__global__ void kernel_name(argument list);\n核函数必须有一个void返回类型。\n表2-2总结了CUDA C程序中的函数类型限定符\n限定符 执行 调用 备注 global device host CUDA核函数的限制 以下限制适用于所有核函数:\n只能访问设备内存 必须具有void返回类型 不支持可变数量的参数 不支持静态变量 显示异步行为 2.3 组织并行线程 (以阅读为主) 从前面的例子可以看出， 如果使用了合适的网格和块大小来正确地组织线程， 那么可以对内核性能产生很大的影响。\n2.3.1 使用块和线程建立矩阵索引 在一个矩阵加法核函数中，一个线程通常被分配一个数据元素来处理。首先要完成的任务是使用块和线程索引从全局内存中访问指定的数据。\n","permalink":"https://jianye0428.github.io/en/posts/notes/gpu_compute/cuda_c_notes/cuda_c_ch02/","summary":"CH02 CUDA编程模型 2.1 CUDA编程模型概述 CUDA编程模型提供了一个计算机架构抽象作为应用程序和其可用硬件之间的桥梁。 CUDA编程模型还利用G","title":"CUDA_C_CH02"},{"content":"Ch01 基于CUDA的异构并行计算 1.1 并行计算 并行计算通常设计两个不同的计算机领域\n计算机架构(硬件)：在结构级别上支持并行性 并行程序设计(软件)：充分使用计算机架构的计算能力来并发地解决问题 1.1.1 串行编程和并行编程 1.1.2 并行性 并行性方式\n任务并行： 当许多任务或函数可以独立地、大规模地并行执行时，这就是任务并行。任务并行的核心是在于利用多核系统对任务进行分配。\n数据并行： 当可以处理许多数据的时候，就是数据并行。数据并行的重点是利用多核系统对数据进行分配。\nCUDA编程非常适合解决数据并行问题。\n数据划分方式：\n块划分： 每个线程作用于一部分数据， 通常这些数据具有相同大小。 一组连续数据被分到一个块内，每个数据块以任意次序被安排给一个线程，线程通常在同一时间只处理一个数据块。 周期划分： 每个线程作用于数据的多部分。 在周期划分中，更少的数据被分到一个块内。相邻的线程处理相邻的数据块，每个线程可以处理多个数据块。为一个待处理的线程选择一个新的块，就意味着要跳过和现有线程一样多的数据块。 1.1.3 计算机架构 计算机机构分类(弗林分类(Flynn\u0026rsquo;s Taxonomy))：根据指令和数据进入CPU的方式进行分类\n单指令单数据（SISD） 一种串行架构。 在这种计算机上只有一个核心。在任何时间点上只有一个指令流在处理一个数据流。 单指令多数据（SIMD） 一种并行架构类型。在这种计算机上有多个核心。 在任何时间点上所有的核心只有一个指令流处理不同的数据流，例如向量机。 优势: 在CPU上编写代码时， 程序员可以继续按串行逻辑思考但对并行数据操作实现并行加速，而其他细节则由编译器来负责。 多指令单数据（MISD） 比较少见, 每个核心通过使用多个指令流处理同一个数据流 多指令多数据（MIMD） 一种并行架构， 在这种架构中，多个核心使用多个指令流来异步处理多个数据流，从而实现空间上的并行性。 许多MIMD架构还包括SIMD执行的子组件。 计算机架构优劣的评价指标：\n降低延迟 延迟是一个操作从开始到完成所需要的时间， 常用微秒来表示 提高带宽 带宽是单位时间内可处理的数据量， 通常表示为MB/s或GB/s。 提高吞吐量 吞吐量是单位时间内成功处理的运算数量， 通常表示为gflops（即每秒十亿次的浮点运算数量） ， 特别是在重点使用浮点计算的科学计算领域经常用到 延迟用来衡量完成一次操作的时间， 而吞吐量用来衡量在给定的单位时间内处理的操作量 根据内存组织方式进一步划分计算机架构:\n分布式内存的多节点系统 大型计算引擎是由许多网络连接的处理器构成的。 每个处理器有自己的本地内存， 而且处理器之间可以通过网络进行通信(类似于多机多卡) 共享内存的多处理器系统 GPU代表了一种众核架构，几乎包括了前文描述的所有并行结构： 多线程、MIMD（多指令多数据）、 SIMD（单指令多数据）， 以及指令级并行。 NVIDIA公司称这 种架构为SIMT（单指令多线程）。\nGPU核心和CPU核心\n尽管可以使用多核和众核来区分CPU和GPU的架构， 但这两种核心是完全不同的。\nCPU核心比较重， 用来处理非常复杂的控制逻辑， 以优化串行程序执行。 GPU核心较轻， 用于优化具有简单控制逻辑的数据并行任务， 注重并行程序的吞吐量。 1.2 异构计算 CPU和GPU是两个独立的处理器， 它们通过单个计算节点中的PCI-Express总线相连。 在这种典型的架构中， GPU指的是离散的设备，从同构系统到异构系统的转变是高性能计算 史上的一个里程碑。 同构计算使用的是同一架构下的一个或多个处理器来执行一个应用。 而异构计算则使用一个处理器架构来执行一个应用，为任务选择适合它的架构，使其最终 对性能有所改进.\n1.2.1 异构架构 一个典型的异构计算节点包括两个多核CPU插槽和两个或更多个的众核GPU。 GPU不 是一个独立运行的平台而是CPU的协处理器。 因此， GPU必须通过PCIe总线与基于CPU的 主机相连来进行操作， 如图1-9所示。 这就是为什么CPU所在的位置被称作主机端(host)而GPU 所在的位置被称作设备端(device)。\n一个异构应用包括两部分：\n主机代码：在CPU上运行 设备代码：在GPU上运行. 描述GPU容量的两个重要特征\nCUDA核心数量 内存大小 相应的， 有两种不同的指标来评估GPU的性能:\n峰值计算性能：用来评估计算容量的一个指标， 通常定义为每秒能处理的单精度或双精度浮点运算的数量，通常用GFlops（每秒十亿次浮点运算） 或TFlops（每秒万 亿次浮点运算） 来表示 内存带宽：从内存中读取或写入数据的比率。 内存带宽通常用GB/s表示 计算能力\n1.2.2 异构计算范例 GPU与CPU结合后， 能有效提高大规模计算问题的处理速度与性能。 CPU针对动态工作负载进行了优化， 这些动态工作负载是由短序列的计算操作和不可预测的控制流程标 记的； 而GPU在其他领域内的目的是： 处理由计算任务主导的且带有简单控制流的工作负载。\nCPU线程与GPU线程\nCPU上的线程通常是重量级的实体。 操作系统必须交替线程使用启用或关闭CPU执行通道以提供多线程处理功能。 上下文的切换缓慢且开销大。\nGPU上的线程是高度轻量级的。 在一个典型的系统中会有成千上万的线程排队等待工作。 如果GPU必须等待一组线程执行结束， 那么它只要调用另一组线程执行其他任务即可\n1.2.3 CUDA： 一种异构计算平台 CUDA是一种通用的并行计算平台和编程模型，它利用NVIDIA GPU中的并行计算引擎能更有效地解决复杂的计算问题。通过使用CUDA，你可以像在CPU上那样，通过GPU来进行计算。\nCUDA提供了两层API来管理GPU设备和组织线程， 如图1-13所示。\nCUDA驱动API：驱动API是一种低级API， 它相对来说较难编程， 但是它对于在GPU设备使用上提供了更多的控制。 CUDA运行时API：运行时API是一个高级API， 它在驱动API的上层实现。 每个运行时API函数都被分解为更多传给驱动API的基本运算。 一个CUDA程序包含了以下两个部分:\n在CPU上运行的主机代码 在GPU上运行的设备代码 NVIDIA的CUDA nvcc编译器在编译过程中将设备代码从主机代码中分离出来. 主机代码是标准的C代码，使用C编译器进行编译。 设备代码，也就是核函数， 是用扩展的带有标记数据并行函数关键字的CUDA C语言编写的. 设备代码通过nvcc进行编译。 在链接阶段，在内核程序调用和显示GPU设备操作中添加CUDA运行时库。\n1.3 用GPU输出Hello World 用专用扩展名.cu来创建一个源文件\n使用CUDA nvcc编译器来编译程序\n从命令行运行可执行文件， 这个文件有可在GPU上运行的内核代码。 首先， 我们编写一个C语言程序来输出“Hello World”， 如下所示\n1 2 3 4 5 #include\u0026lt;stdio.h\u0026gt; int main(void) { printf(\u0026#34;Hello World from CPU!\\n\u0026#34;)； } 把代码保存到hello.cu中， 然后使用nvcc编译器来编译。 CUDA nvcc编译器和gcc编译器及其他编译器有相似的语义\n1 nvcc hello.cu -o hello 如果你运行可执行文件hello， 将会输出： Hello World from CPU!\n接下来， 编写一个内核函数， 命名为helloFromGPU， 用它来输出字符串“Hello World from GPU！ ”。\n1 2 3 __global__ void helloFromGPU(void) { printf(\u0026#34;Hello World from GPU!\\n\u0026#34;); } 修饰符__global__告诉编译器这个函数将会从CPU中调用， 然后在GPU上执行。用下面的代码启动内核函数.\n1 helloFromGPU \u0026lt;\u0026lt;\u0026lt;1, 10\u0026gt;\u0026gt;\u0026gt;() 三重尖括号意味着从主线程到设备端代码的调用。 一个内核函数通过一组线程来执行， 所有线程执行相同的代码。\n三重尖括号里面的参数是执行配置， 用来说明使用多少线程来执行内核函数。 在这个例子中，有10个GPU线程被调用。\ncudaDeviceReset()用来显式地释放和清空当前进程中与当前设备有关的所有资源。\n一个典型的CUDA编程结构包括5个主要步骤: 1. 分配GPU内存 2. 从CPU内存中拷贝数据到GPU内存 3. 调用CUDA内核函数来完成程序指定的运算 4. 将数据从GPU拷回CPU内存 5. 释放GPU内存空间\n1.4 使用CUDA C编程难吗 数据局部性: 指的是数据重用， 以降低内存访问的延迟\n时间局部性：指在相对较短的时间段内数据或资源的重用 空间局部性：指在相对较接近的存储空间内数据元素的重用。 CUDA中有内存层次和线程层次的概念\n内存层次结构 线程层次结构 CUDA核中有3个关键抽象\n线程组的层次结构 内存的层次结构 障碍同步 1.5 总结 CPU + GPU的异构系统成为高性能计算的主流架构: 在GPU上执行数据并行工作， 在CPU上执行串行和任务并行的工作。\n","permalink":"https://jianye0428.github.io/en/posts/notes/gpu_compute/cuda_c_notes/cuda_c_ch01/","summary":"Ch01 基于CUDA的异构并行计算 1.1 并行计算 并行计算通常设计两个不同的计算机领域 计算机架构(硬件)：在结构级别上支持并行性 并行程序设计(软件)：充","title":"CUDA_C_CH01"},{"content":"LaneGCN模型移植和部署 LaneGCN模型 一、数据处理 (1) read_argo_data():\ndata[\u0026lsquo;city\u0026rsquo;] data[\u0026rsquo;traj\u0026rsquo;]: shape: 32 x 50 x 2 data[\u0026lsquo;steps\u0026rsquo;]: shape: 32 x 50 (2) get_obj_feat(): data[\u0026lsquo;feat\u0026rsquo;]: 障碍物前20秒轨迹点的相对位置坐标（vector）(只有19个，当前时刻补零) data[\u0026lsquo;ctrs\u0026rsquo;]: 各个障碍物20帧的位置信息 data[\u0026lsquo;orig\u0026rsquo;]: agent在20帧时刻的位置，作为局部坐标的原点 data[\u0026rsquo;theta\u0026rsquo;]: agent在20帧的偏转角 data[\u0026lsquo;rot\u0026rsquo;]: 旋转矩阵以及坐标转换 data[\u0026lsquo;gt_preds\u0026rsquo;]: M x 30 x 20 各个障碍物在后3秒的真实轨迹运动信息 data[\u0026lsquo;has_preds\u0026rsquo;]: 标记在当前时刻真值是否被观测到 坐标转换 $$\\begin{bmatrix} x_g \u0026amp; y_g\\end{bmatrix}\\begin{bmatrix} cos\\theta \u0026amp; -sin\\theta \\ sin\\theta \u0026amp; cos\\theta \\end{bmatrix} =\\begin{bmatrix} x_l \u0026amp; y_l\\end{bmatrix}$$\n(3) get_lane_graph():\n以agent第20帧坐标为圆心，取boundingbox范围内的所有道路\n取lane_ids\n针对lane_id获得lane，然后通过lane.centerline获取道路中心点的位置，lane.centerline代表lane的一系列中心点 对中心点针对agent的坐标原点进行坐标转换 取ctrs、feat、turn、control、intersect = [], [], [], [], [] lane.centerline有10个点的坐标，相当于取9个lane node ctrs: 每条lane centerline的10个点的前后相加除以2，作为lane node的中心点 feat：lane.centerline的10个点的前后位置相减，相当于9个lane segment，feat指vector feat turn: [a, b] a=1: 左转 b=1： 右转 control: 是否有交通标志 intersect: 是否处于路口 获得lane node之间的拓扑关系\nnode_idcs: lane node index (0 ~ 9) (9~18) \u0026hellip; num_nodes: lane node 的总数量 lane node 之间的拓扑关系 pre[\u0026lsquo;u\u0026rsquo;]: 1 ~ 9 \u0026hellip; v 是 u 的 pre pre[\u0026lsquo;v\u0026rsquo;]: 0 ~ 8 \u0026hellip; suc[\u0026lsquo;u\u0026rsquo;]: 0 ~ 8 \u0026hellip; v 是 u 的 suc suc[\u0026lsquo;v\u0026rsquo;]: 1 ~ 9 \u0026hellip; 注意： pre[\u0026lsquo;u\u0026rsquo;] pre[\u0026lsquo;v\u0026rsquo;] suc[\u0026lsquo;u\u0026rsquo;] suc[\u0026lsquo;v\u0026rsquo;] 指的是lane node之间的关系\npre_pairs、 suc_pairs、 left_pairs、 right_pairs: 指的是lane 与 lane 之间的关系 总结:\ngraph[\u0026lsquo;ctrs\u0026rsquo;]: lane node 中心点的坐标 graph[\u0026rsquo;num_nodes\u0026rsquo;]: lane node 点的数量 graph[\u0026lsquo;feat\u0026rsquo;]: lane node 的前后相减 矢量特征 graph[\u0026rsquo;turn\u0026rsquo;]: 道路是否为左转或者右转 graph[\u0026lsquo;control\u0026rsquo;]: 道路是否有交通标志 graph[\u0026lsquo;intersect\u0026rsquo;]: 是否处于交通路口 graph[\u0026lsquo;pre\u0026rsquo;]: lane node 前后拓扑关系 graph[\u0026lsquo;suc\u0026rsquo;]: lane node 前后拓扑关系 graph[\u0026rsquo;lane_idcs\u0026rsquo;]: lane node index graph[\u0026lsquo;pre_pairs\u0026rsquo;]: lane 与 lane 之间的前后关系 graph[\u0026lsquo;suc_pairs\u0026rsquo;]: graph[\u0026rsquo;left_pairs\u0026rsquo;]:lane 与 lane 之间的左右关系 graph[\u0026lsquo;right_pairs\u0026rsquo;]: 二、数据前处理 (1) preprocess():\n主要针对lane graph的数据进行数据前处理工作 第一步: 根据lane_idc获得lane node数量和lane的数量 第二步: 计算lane node 两两之间的距离 第三步: 根据pre_pair、 suc_pair构建pre、suc矩阵 根据left_pair、 right_pair构建left、right矩阵 第四步: 取出角度(偏转角)$\\theta \u0026lt; \\pi/4$ 的lane node 节点 构建left[\u0026lsquo;u\u0026rsquo;] v 是 u 的左边lane node 节点 left[\u0026lsquo;v\u0026rsquo;] right[\u0026lsquo;u\u0026rsquo;] v 是 u 的右边lane node 节点 right[\u0026lsquo;v\u0026rsquo;] 三、LaneGCN 具体的网络结构 (1)、 data输入结构(以batch_size = 2 为例) 对于data[\u0026lsquo;feat\u0026rsquo;]类型为list，len(list) = 2, list[0]=\u0026gt;其中一个scenario 对于data[\u0026lsquo;graph\u0026rsquo;]类型为list，len(list) = 2, list[0]=\u0026gt;其中一个dict，dict中存储lane node信息 (2)、 对于actor_gather()和graph_gather()两个函数\nactor_gather(): 输入: list (data[\u0026lsquo;feat\u0026rsquo;]) 输出: actors (M x 3 x 20), actor_idcs 作用： 在此处，把batch输入的障碍物特征进行concatenation整合到一起，并完成转置，将时序放到第一维，维后续的FPN网络做准备 graph_gather() 输入：list (data[\u0026lsquo;graph\u0026rsquo;]) 输出: graph 作用: 把batch中输入的lane graph特征进行叠加(concatenation)，用于后续训练 (3)、ActorNet(): 提取障碍物actor的特征 输入: actors (M x 3 x 20) 输出: actor net output (M x 128) ActorNet 网络结果：\ngroups: 1 2 3 group: Res1d(3, 32) Res1d(32, 32) group: Res1d(32, 64) Res1d(64, 64) group: Res1d(128, 128) Res1d(128, 128) outputs [ groups[0], groups[1], groups[2]] lateral [conv1d[32, 128], conv1d[64, 128], conv1d[128, 128]] 整体结构: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 (31 x 128 x 5) (31 x 128 x 5) groups[2] Res1d(128, 128) =\u0026gt; conv1d(128, 128) ====\u0026gt; interpolate (31 x 128 x 10) Res1d(64, 128) || /\\ || || (31 x 64 x 10) (31 x 128 x 10) \\/ groups[2] Res1d(128, 128) =\u0026gt; conv1d(64, 128) ====\u0026gt; sum (31 x 128 x 10) Res1d(64, 128) || /\\ interpolate (31 x 128 x 20) || (31 x 32 x 20) (31 x 128 x 20) || groups[2] Res1d(128, 128) =\u0026gt; conv1d(32, 128) ====\u0026gt; sum (31 x 128 x 20) Res1d(64, 128) || /\\ res1d(128, 128) || || [:,:, -1] input: 31 x 3 x 20 output: 31 x 128 (4)、MapNet(): 提取lane node的特征\n输入: graph[\u0026lsquo;idcs\u0026rsquo;, \u0026lsquo;ctrs\u0026rsquo;, \u0026lsquo;feats\u0026rsquo;, \u0026rsquo;turn\u0026rsquo;, \u0026lsquo;control\u0026rsquo;, \u0026lsquo;intersect\u0026rsquo;, \u0026lsquo;pre\u0026rsquo;, \u0026lsquo;suc\u0026rsquo;, \u0026rsquo;left\u0026rsquo;, \u0026lsquo;right\u0026rsquo;]\n输出: feat, graph[\u0026lsquo;idcs\u0026rsquo;], graph[\u0026lsquo;ctrs\u0026rsquo;]\ngraph[\u0026lsquo;idcs\u0026rsquo;]: lane node 的index len(graph[\u0026lsquo;ctrs\u0026rsquo;][0]): 1206 len(graph[\u0026lsquo;ctrs\u0026rsquo;][1]): 954 graph[\u0026lsquo;ctrs\u0026rsquo;]: 2160 x 2 网络结构:\nself.input: Linear(2, 128) Linear(128, 128)\nself.seg: Linear(2, 128) Linear(128, 128)\nself.fuse() =\u0026gt; dict()\nself.fuse[\u0026lsquo;ctr\u0026rsquo;]: Linear(128, 128) self.fuse[\u0026rsquo;norm\u0026rsquo;]: nn.GroupNorm(gcd(1, 128), 128) self.fuse[\u0026lsquo;ctr2\u0026rsquo;]: Linear(128, 128), norm = groupNorm, ng = 1 self.fuse[\u0026rsquo;left\u0026rsquo;]: Linear(128, 128) self.fuse[\u0026lsquo;right\u0026rsquo;]: Linear(128, 128) self.fuse[\u0026lsquo;pre0\u0026rsquo;] ~ self.fuse[\u0026lsquo;pre5\u0026rsquo;]: Linear(128, 128) self.fuse[\u0026lsquo;suc0\u0026rsquo;] ~ self.fuse[\u0026lsquo;suc5\u0026rsquo;]: Linear(128, 128) 流程:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 lane node ctrs: n x 2 = self.input =\u0026gt; n x 128 lane node feats: n x 2 = self.seg =\u0026gt; n x 128 || relu n x 128 || =\u0026gt; resblock =============================\u0026gt; pre0 ~ pre5 suc0 ~ suc5 temp.index_add_(0, graph[pre][i][\u0026#39;u\u0026#39;], self.feat(graph[k1][k2][\u0026#39;v\u0026#39;])) 解释: 把feat的第v行(value)加到temp的第u行上 对pre0 ~ pre5 / suc0 ~ suc5 / left / right执行相同操作 (图注意力) || 然后经过self.fusr[\u0026#39;norm\u0026#39;] 和 relu模块加上 resblock || 得到输出: feat: n x 128 graph[\u0026#34;idcs\u0026#34;] graph[\u0026#34;ctrs\u0026#34;] (5)、A2M(): lane node 和 agent node 交互\n在A2M模块中，agent node 是 lane node, context node 是 vehicle node (以laen node为中心， actor node为context)\n输入: feat(nodes), graph, actors, actors_idcs, actor_ctrs\n输出: feat (n x n_agts)\n网络结构:\nmeta = torch.cat(graph[\u0026rsquo;turn\u0026rsquo;], graph[\u0026lsquo;control\u0026rsquo;], graph[\u0026lsquo;intersect\u0026rsquo;]) feat = self.meta(Linear(128, 128)) 针对feat(lane node feature), graph[\u0026lsquo;idcs\u0026rsquo;], graph[\u0026lsquo;ctrs\u0026rsquo;], actors, actor_idcsm, actor_ctrs 循环指行两次graph attention 操作 Atten网络结构；\n输入: agts, agts_idcs, agts_ctrs, ctx, ctx_idcs, ctx_ctrs， dist_th 流程: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 - agts ======================================\u0026gt; resblock || agts_ctrs 和 ctx_ctrs 两两求distance mask = dist \u0026lt; dist_th 求距离小于threshold的mask(筛选出距离小于threshold的车和道路) || idcs = torch.nonzero(mask) hi.append(idcs[:, 0]) =\u0026gt; row_idcs for agts wi.append(idcs[:, 1]) =\u0026gt; col_idcs for ctxs || dist = agt_cts[hi] - ctx_ctrs[wi] 根据threshold筛选出来的agent node 和context node 求distance || self.dist((2, n_ctx) (n_ctx, n_ctx)) dist = self.dist(dist): n x n_ctx || self.query(n_agts, n_ctx) query = self.query(agts[hi]): n x n_ctxs || ctx = ctx[wi]: n x n_ctx ctx = torch.cat((dist, query, ctx), 1) ||self.ctx(3 * n_ctx, n_agt) (n_agt, n_agt) cts = self.ctx(ctx): n x n_agt ||agts = self.agts(n_agt, n_agt) agts.index_add_(0, hi, ctx) 把context的特征根据hi (index) 加到agents上 || 加上resblock 输出： n x n_agt (6)、M2M(): map node 和 map node 交互\n输入： node graph 输出: N x 128 此处执行的操作和MapNet()相同 (7)、M2A(): map node 和 vehicle node交互\n输入: actors, actor_idcs, actor_ctrs, nodes, node_idcs, node_ctrs 输出: actors (n x 128) 以vehice node为agent，lane node为context nodes，执行Attention注意力机制 (8)、A2A(): vehicle node 和 vehicle node 交互 输入: actor, actor_idcs, actor_ctrs 输出: n_actos x 128 以vehicle node为agent nodes，同时以vehicle node为context nodes为context nodes，执行注意力机制 (9)、PredNet() 预测网络 输入：actor_feats, actor_idcs, actors_ctrs 输出: out[\u0026lsquo;cls\u0026rsquo;], out[\u0026lsquo;reg\u0026rsquo;] 网络结构: pred[0] [LinearRes(128, 128), Linear(128, 2 x 30)] pred[1] [LinearRes(128, 128), Linear(128, 2 x 30)] pred[2] [LinearRes(128, 128), Linear(128, 2 x 30)] pred[3] [LinearRes(128, 128), Linear(128, 2 x 30)] pred[4] [LinearRes(128, 128), Linear(128, 2 x 30)] pred[5] [LinearRes(128, 128), Linear(128, 2 x 30)] 流程: 1 2 3 4 5 6 7 8 9 10 11 12 13 根据actor_feats分别输入到PredNet中 `Preds[n* 120, n* 120, n* 120, n* 120, n* 120, n* 120]` || [n * 1 * 120, n * 1 * 120, n * 1 * 120, n * 1 * 120, n * 1 * 120] || torch.cat() n x 6 x 120 ||reg.resize() n x 6 x 30 x 2 || `dest_ctrs = reg[:, :, -1].detach()` (n x 6 x 2) || `self.dest(actors, actors_ctrs, dest_ctrs)`： 相当于把每个障碍物不同模态的轨迹终点与原点（20帧时刻轨迹点）之间的距离叠加到输出特征上中(叠加到actors上)，用到后面去求每个模态的概率(评分) || `self.cls(Linear(128, 128) Linear(128, 1))`: 作为cls的模态的打分 || `cls, sort_idcs = cls.sort(1, descend=true)` 按照1维降序排列(最后让预测结果中的每一个障碍物的6个模态按降序排列，即第一条的轨迹的打分最高) - 输出： out[\u0026#39;cls\u0026#39;]、 out[\u0026#39;reg\u0026#39;] (10) PredLoss的计算\n取出真值轨迹中有轨迹点的最后一个时间戳 根据真值轨迹是否有观测轨迹点的index取出需要进行比较的reg和cls (根据真实观测值取出相应的预测轨迹) dist指的是每一个真值最后一个可观测点位置与6个模态轨迹相应预测轨迹点的l2距离 把6个模态的l2距离叠加到一起，取出其中距离最小的轨迹点idx mgn = cls[row_idcs, min_idcs].unsqueeze() - cls 将cls最小的分值 减去 cls分值 mask0：筛选出每条距离fde最小的轨迹，fde \u0026lt; 2 的轨迹 mask1：筛选出距离减去fde最小轨迹距离 \u0026lt; 0.2 的轨迹 求出mgn[mask0 * mask1]: 取min_dist \u0026lt; 2 但是排除距离它比较近的轨迹点 mask = mgn \u0026lt; 0.2 最后计算cls和reg的loss cls_loss += self.config[\u0026ldquo;mgn\u0026rdquo;] * mask.sum() - mgn[mask].sum $\\text{cls}_\\text{loss} = max(0, {c_k} + \\epsilon - \\hat{c_k})$ reg_loss = self.reg_loss(reg[has_preds], gt_preds[has_preds]) # 预测值和真值的huber loss 在移植以及部署过程中，碰到的问题以及解决方法 (1). 由于模型应用场景的要求，对模型进行以下修改：\n道路节点的upsample()和downsample()的处理：由于高速场景下，直线路段比较多，且高精地图提供的道路节点比较稀疏，我们多lane node进行upsample处理，每间隔20m取一个lane node，增加道路的头铺信息；另一方面，在路口场景，由于道路节点比较密集，造成模型计算消耗过大，我们使用downsample的方式，每间隔5个lane node 选取一个lane node，来减少算例消耗 在原来的模型中，只关心focal agent的预测轨迹；在项目中，我们将ego vehicle的位置作为局部坐标原点，通过一次推理来获得周围车辆未来三秒的轨迹； 在高速场景下，考虑到ego vehicle在行车过程中更倾向于考虑自车前方的道路拓扑结构和障碍物，那么我们在选取道路结构时， 倾向于以自车前方40m， 半径为200m的区域来来构造lane graph。 同时，在筛选道路过程中，碰到单个lane过长的情况，采用直接提取lane node的方式，将超出范围内的lane node直接截断，来减少算力消耗 考虑在高速场景下，并不需要6个模态，倾向于想模型修改为2-3模态进行训练。 (2). 基于TensorRT模型推理方面遇到的问题以及解决方案\nscatterElement自定义算子的编写\n原因: torch.index_add_() 重复索引的实现 global 函数 1 2 3 4 5 __global__ void scatter_elements_op(float *output, const int *index, const float *update, const int ncolumns) { int idx = blockDim.x * blockIdx.x + threadIdx.x; int transformidx = index[idx] * ncolumns + idx % ncolumns; atomicAdd(\u0026amp;output[transformidx], update[idx]); } atomicAdd() 实现原理 torch.nonzero() 操作无法实现，注意力机制的修改\nL3 基于规则的预测模型开发 逻辑 执行prediction_actor.cc 执行PredictionActor::PredictionEndToEndProc()函数: 获取定位信息、感知信息 在MessageProcess::OnPerception()函数中执行一下两个函数: EvaluatorManager::Instance()-\u0026gt;Run(): 判断障碍物的运行意图，给相应的lane sequence赋值概率，确定障碍物将要运动的lane sequence PredictorManager::Instance()-\u0026gt;Run()：根据evaluator获得的lane sequence, 获得相应的轨迹点或者路径点 Evaluator 逻辑 EvaluatorManager::Run(): 根据obstacleContainer中的每一个障碍物执行EvaluateObstacle() EvaluateObstacle(): 针对障碍物的类型选择相应的Evaluator\n如果障碍物在道路上(OnLane() == true) ==\u0026gt; 执行Evaluate() 如果障碍物不在道路上，则通过ModifyPriorityForOffLane()给障碍修改谨慎等级 如果障碍不在道路上， 筛选障碍物BoundingBox最左边和最右边的点，如果其中有一个点在ego_sequence上，则认为障碍物侵占自车车道，将priority改为Caution 3.1. 如果障碍物在车道上，调用evaluator的纯虚函数，根据相应的Evaluator执行相应的Evaluator(), 在高速场景下对vehicle类型障碍物采用HighwayCVEvaluator.\n通过HighwayCVEvaluator()执行Evalute()函数 对障碍物设定相应的Evaluator type 执行checkEgoFailed(): 判断跟ego vehicle相关的pointer是否为空。如果相关ego vehicle的参数为nullpointer， 则设置current lane 的sequence概率为1. 认为障碍物会沿着当前道路行驶，因为无法参照自车进行预测。 执行obs_on_ego_lane = ObstacleOnEgoLane(): 通过obstacle sequence和ego sequence是否overlapped, 判断obstacle是否在ego vehicle的车道上 判断谨慎等级为ignore的车: 如果车在ego vehicle前方而谨慎等级为ignore，则判断 如果obstacle在自车车道上 如果obstacle在ego 左边车道上 如果obstacle在ego 右边车道上 则将障碍物的谨慎等级改为caution并且将障碍物当前道路sequence的概率设为1. 执行SetObstacleLateralLanePosition()：标定障碍物相对于ego的侧向位置 如果障碍物在ego lane 上，设lane type 为 LaneAssignType_same 如果障碍物不在ego lane上 把障碍物的pos投影到ego lane上，如果pro_l \u0026gt; 0 如果谨慎等级为ignore，则设obstacle的lane相对ego vehicle的位置为: left left 如果谨慎等级为caution，则设obstacle的lane相对ego vehicle的位置为: left 把障碍物的pos投影到ego lane上，如果pro_l \u0026lt; 0 如果谨慎等级为ignore，则设obstacle的lane相对ego vehicle的位置为: right right 如果谨慎等级为caution，则设obstacle的lane相对ego vehicle的位置为: right 当obstacle的current lane数量\u0026gt;1时，执行SetSplitLaneObstacle(): 对障碍物的每一条current lane进行判断: 判断当前的current lane是否corrected(纠偏而且是OneToTwo()) 如果当前道路是split类型而且不是OneToTwo纠偏， 则把当前道路改为split 当obstacle的current lane数量\u0026lt;=1时, 执行CheckSplitRampLatExceedDistance(): 针对障碍物当前(index = 0)的lane sequence中的每一条lane segment， 如果lane segment所处的lane 是ramp driving， 则修改l_exceed_lane_distance = 1.5m 执行GetLateralPointByLane()函数: 把障碍物boundingbox最左边的点和最右边的点投影到自车ego lane上 如果障碍物的左、右点都不在ego sequence上，而且ego vehicle 和 obstacle 不在同一条 lane上，且障碍物的谨慎等级不是ignore， 那么把障碍物的谨慎等级改为normal use_ramp_mode = true SetIsOnRamp(false) SetMergeSequenceIndex(-1) SetMergeRelativeDistance(Flag_param) SetProbabilityForMergeLane(obs, ego, left_neighbor, right_neighbor): 如果是merge车道而且不是OnToTwo纠偏，将障碍物的谨慎等级改为caution, 将当前lane sequence的概率设为1 SetIsOnRamp(true) ChangeIntent(): 根据speed来判断障碍物的纵向加减速意图 SetLaneType(MERGE) 如果障碍物的lane sequence和ego lane sequence相交， 或者障碍物lane sequence和ego vehicle的左侧或者右侧，则将当前的lane sequence和probability设为1 最后执行EvaluateProbabilityByLaneSequence(): 如果障碍物没有压左车道，也没有压右车道，或者障碍物和ego vehicle在同一车道,则将所有的current lane sequence的概率置1 如果障碍物压左车道且obstacle lane sequence与ego的left neighbor相交， 则将该left lane sequence的概率置1 如果障碍物压右车道且obstacle lane sequence与ego的left neighbor相交， 则将该right lane sequence的概率置1 Predictor 逻辑 3. PredictorManager::Run(): 根据obstacleContainer中的每一个障碍物执行PredicteObstacle()\n根据Obstacle的类型，调用相应的Predictor\n以vehicle为例: 执行RunVehiclePredictor() 对于静止或者ignore的obstacle， 执行RunEmptyPredictor() vehicle on lane =\u0026gt; 执行 move sequence predictor\nvehicle off lane =\u0026gt; 执行 lane sequence predictor\n以 move sequence predictor 为例\n确定预测轨迹时间长度 如果障碍物在匝道上，预测轨迹为12秒 如果障碍物不在匝道上，预测轨迹为7秒 执行FilterLaneSequenceWithMerge(): 对于障碍物的lane graph中的每一条lane sequence 如果lane sequence所在lane的类型为parking, 则把相应的enable_lane_sequence置为false, 相当于过滤该条lane sequence 如果lane sequence的类型既不是左转，也不是右转，也不是onto，也过滤掉该条lane sequence 执行distance = GetLaneChangeDistWithADC() =\u0026gt; 纵向距离 如果 distance 处于(-50, 200)之间 如果当前判断的sequence就是汇入的sequence 判断是否有碰撞风险 判断是否有侧向变道意图 如果有碰撞风险或者没有左右变道意图，则把当前的sequence过滤掉 如果distance小于threshold 如果车没有merge到ego sequence， 则过滤掉sequence 对于每一条sequence 如果enable_lane_sequence[i] 为true LaneSequenceWithMaxProb(设置不变道sequence的最大概率) LaneChangeWithMaxProb(设置变道sequence的最大概率) 对于每一条lane sequence 如果概率为0 或者 enable_lane_sequence[i] 为false， 则不生成轨迹 如果车要停止，则执行DrawConstantAccelerationTrajectory() 如果车不停止（保持巡航模式），则执行DrawMoveSequenceTrajectory() 对于DrawConstantAccelerationTrajectory()： 根据障碍物的position和相应的lane info得到障碍物的lane_l和lane_s total_num = (total_time) / period 计算轨迹点的数量 根据$lane_s = v \\times t + \\frac{1}{2} \\times a \\times t^2$ 和 $speed = at$ 求出相应的lane_s 和lane_l trajectory 由速度speed、lane_id、lane_s、 lane_l标记 对于DrawMoveSequenceTrajectory()： 首先获取障碍物当前帧的位置信息 通过侧向速度计算得出到侧向终点的时间 对于每条lane sequence中的每一块lane segment 计算distance_to_merge, 计算距离交汇点的纵向距离 如果有道路汇入，则更信time_to_lat_end_state 限制车辆加速度:如果加速度acc处于最大值与最小值之间， 大大取大， 小小取小 GetLaneStartPoint(): 根据position取得障碍物的起始点，用lane_s、lane_l表示 进行先横后纵规划: GetLateralPolynomial(): 获得侧向多项式的系数 (四个参数/三次多项式) GetLongitualPolynomial()：获得纵向的多项式系数 (五个参数/四次多项式) 对于每一个轨迹点，计算lane_l和lane_s 如果自车(ego vehicle) 比障碍物早到起始点，停止延伸轨迹 如果lane_s超多当前车道lane 的total_s, 停止延伸轨迹 定义lane_speed (四次多项式一阶导数) 和 lane_acc(四次多项式二阶导数) 最后生成轨迹点： 如果lane_s超过当前lane的total_s，lane_s截断并且lane segment index + 1 ","permalink":"https://jianye0428.github.io/en/posts/notes/work/zhito/","summary":"LaneGCN模型移植和部署 LaneGCN模型 一、数据处理 (1) read_argo_data(): data[\u0026lsquo;city\u0026rsquo;] data[\u0026rsquo;traj\u0026rsquo;]: shape: 32 x 50 x 2 data[\u0026lsquo;steps\u0026rsquo;]: shape: 32 x 50 (2) get_obj_feat(): data[\u0026lsquo;feat\u0026rsquo;]: 障碍物前20秒轨迹点的相对位置坐标（vecto","title":"Zhito"},{"content":"1. 概述 分布式训练服务框架与集合通信库的组合构成了分布式训练的整体服务软件栈，在第3篇、第4篇文章里已经剖析完集合通信的相关内容，而本文会以Horovod为例介绍数据并行下分布式训练服务框架的基本原理以及进行架构解析。当前，在分布式训练里分布式训练服务框架需要解决以下几个核心问题 ：\n计算与通信同步耦合问题：如果反向传播一产生一份梯度，就马上对其调用全局AllReduce，计算与通信同步耦合，容易造成死锁同时性能也会很不如意； 计算时间与通信时间串行问题：神经网络是分层的，梯度计算的过程是数据加载，然后前向传播算出损失值，再反向传播算出梯度，而反向计算时梯度是从输出层往输入层方向一层一层产生的，在有些模型里，如果需要等所有的梯度都计算完毕才能触发全局AllReduce，那么对性能的影响也会很大； 梯度生成的落后者问题：集群内每个计算节点的同一份梯度的产生不一定都是同一时刻的，如果梯度没有全部生成就发起对这个梯度的全局规约，否则容易造成训练出来的模型精度不达标或者不收敛的问题； 梯度融合问题：如果每一份梯度都触发一次全局AllReduce，在梯度Tensor较多的神经网络训练里，整体的训练系统性能会变得极低； 易用性问题：从TensorFlow，PyTorch迁移过来需要改的代码需要极少，从单卡训练迁移到多卡训练需要改动的代码也需要极少； 可移植问题：支持多种多样的深度学习训练框架，比如 TensorFlow、PyTorch、MxNet等，也能支持多种多样的通信库，比如openMPI、NCCL、Gloo、CCL、RCCL等； 可靠性问题：在集群训练的过程中网络时不可靠的、计算卡是会出故障的、服务器是会出故障的、系统软件也是会出Bug的，这些因素造成了分布式训练过程中还存在可靠性问题，如何解决这个问题也是一个难题。 软件是由人实现的，解析一个软件系统最难的地方在于从庞杂的代码里倒推出背后实现它的人的设计意图，为了更好的理解Horovod，本文会基于以上这几个分布式训练的核心问题，以Horovod为例介绍分布式训练服务框架的基本原理以及进行架构解析。\n2. 基础知识 2.1 单卡训练 神经网络的训练，本质上就是Y=F(x)的迭代，通过反复输入X、输出Y，使得神经网络的参数变化与输入输出间的复杂关系拟合。在神经网络训练的过程中，通过输入数据利用梯度下降的方法进行迭代从而优化神经网络参数，并最终输出神经网络模型。而神经网络可以看作一种运算模型，其由大量的神经元（节点）相互联接构成，其由输入层、隐藏层以及输出层组合而成（如下图左侧所示）。神经元(neuron)是神经网络的基本计算单元，也被称作节点(node)，它可以接受来自其他神经元或外部数据的输入，然后计算出一个输出（如下图右上角所示）。\n如上图右下角所示，在单卡训练迭代中，基于并行梯度下降法，会有以下操作：\n第一步，读取部分数据，并且将数据加载进训练卡的存储空间；\n第二步，对模型进行前向传播计算，从输入层往输出层一层一层的进行计算，得到损失差LOSS；\n第三步，对模型进行反向传播计算，从输出层往输入层一层一层的进行计算，得到梯度值，注意这一步会把每一层都计算出一个梯度张量（Gradient Tensor）出来；\n第四步，将新的到的梯度与部分数据 作为新的输入，重新开始以上步骤的迭代。\n在这一步里有一个很重要的与性能优化相关的信息是反向传播是每一层输出一个梯度张量，以及反向传播是从输出层往输入层一层一层的进行计算的，这一点信息可以用通信隐藏性能优化与梯度融合优化。\n2.2 多卡训练 以数据并行随机梯度下降法( SGD )为例，多卡神经网络的训练过程如下图，与单卡训练相比，多卡训练多了梯度全局规约的过程：\n第一步，通过Broadcast操作将第一个节点参数同步到集群内的所有的训练卡上，保证每个计算节点的初始参数是一致的，同时训练脚本在多个计算节点上运行，每个计算节点包含了整体的模型参数；\n第二步，将数据样本切片分发到整个集群内的个计算节点（训练卡）上并且通过数据流水技术将数据样本加载进训练卡的高速内存空间内，作为输入X;\n第三步，每个训练卡在其数据样本上运行前向传播，计算出损失差LOSSi；\n第四步，对计算出的LOSSi进行反向传播，得到梯度GRADi，这一步也需要注意得是每一层都会计算出一个梯度，同时梯度是以输出的Tensor来表示的；\n第五步，所有的训练卡计算出来的部分梯度，在主机内及主机之间通过集合通信进行全局归约(AllReduce)得到全局梯度；\n第六步，最后再将这个全局梯度作为参数进行更新，再进行以上2-5步骤的迭代从而获得新的梯度。\n以上2-6步骤就是多卡并行梯度下降的基本思想，即多个计算节点通过分片的数据样本进行梯度计算，得到分区梯度后，再通过全局梯度规约以及将这个聚合好的梯度作为新的参数进行更新，从而实现并行梯度下降。\n3. 几个核心问题 在本章节里会解读本文概述里提到的分布式服务框架需要解决的几个与性能、易用性等相关的几个核心问题，并且以Horovod为例讲述Horovod是如何解决这个几个难题的。\n3.1 计算与通信解耦 在神经网络的训练过程中，每一神经网络层都会计算出一个梯度，同时梯度是以输出Tensor来表示的，如果反向传播一计算出一个梯度就马上调用通信去做梯度规约，将计算与通信同步耦合，那么整体的性能的表现就会很差。比如一个ResNet-50 v3的梯度张量个数是153个，如果一计算出一个梯度就马上进行通信，假设计算梯度花了1ms，通信这个梯度花了 500ms，那么这个过程就是 501ms，总体上就需要501x153 = 76653ms，即近76.6s才能完成一次梯度迭代。而将计算与通信解耦，计算的归计算，通信的归通信，通过性能优化策略减少通信的次数，既能提升整体训练性能也能避免某些死锁问题，比如计算梯度grad i的时候花了很长时间，而通信线程一直在等待这个梯度，表现出来就是死锁现象。\nHorovod采用计算与通信分离的设计思想，解耦了计算过程与通信过程，从而提升了整体训练的性能与可靠性。如下图的Horovod逻辑架构图所示，从图中可以看出Horovod解耦了计算与通信，其将框架层计算出来的梯度request信息push 到一个消息队列message_queue里，同时将梯度信息push到一个Tensor_table里，再通过控制层在后台起一个loop线程，周期性的从消息队列里读取梯度消息，在控制层集群的节点之间协商达成一致后，再进行消息分发触发训练行为。\n如上图可看出，Horovod从下到上分为7层：物理层、链路层、数据传输层、控制层、消息层、框架层以及用户层。框架层，控制层以及数据传输层体现了Horovod的核心设计理念，即：框架层，用户可以自定义Op，以插件的形式hack进框架；在控制层，worker节点与master节点之间协商达成触发训练行为的约定；在数据传输层，服务器内以及服务器之间采用集合通信库传输数据。\n本质上Horovod的整体设计理念之一遵循的是生产者消费者模式，如下图所示：\n在Horovod里每个计算节点都会有有两个核心线程：Execution thread 和 Background thread ：\n生产者Execution Thread 是用来做梯度计算的，在TensorFlow、PyTorch之类的之类的训练框架计算出梯度Tensor后，将Tensor 信息push进tenor_table队列，同时将Tensor的request信息push进message_queue队列; 消费者Background thread 是做集合通讯以及全局Allreduce的，后台线程会每隔一段时间轮询消息队列，拿到一批Tensor信息之后，会进行相应的操作。 3.2 通信隐藏 神经网络是分层的，在训练的过程中，先是数据加载，然后前向传播算出LOSS，再反向传播算出梯度，而反向计算时梯度是从输出层往输入层方向一层一层产生的，如果需要等所有的梯度都计算完毕才能触发全局AllReduce，对性能不是很友好。如下图所示，计算时间与通信时间是串行的，如果能将全局梯度规约的通信时间与计算时间想办法并行起来，将通信时间隐藏在计算时间之内，那么就能节约梯度的训练时间从而提升分布式训练系统整体的训练性能。\n如下图所示，将计算出来的梯度进行分桶触发异步Allreduce，一边反向传播计算梯度，一边做部分梯度的全局规约通信，从而达到将通信时间隐藏在计算时间内的效果。而Horovod为达成这一效果，Background thread 会每隔一段时间轮询梯度消息队列里的梯度信息，获取了可以过全局规约的梯度后，就进行全局规约操作，而这个时间其他的梯度还在计算过程中，通过调整轮询的时间间隔从而达到调整梯度分桶的效果。\n3.3 梯度协商 神经网络的每一层对应一个梯度Tensor，在分布式训练集群里每张训练卡对同一份梯度计算产生的时间是有差异的，当集群内每个计算节点的同一神经网络层的同一梯度都产生时，才能发起对这个梯度的全局AllReduce规约，否则容易造成丢梯度，训练出来模型精度不达标或者模型不收敛。比如在一个128卡的训练集群里，同一份梯度是对应同一个神经网络模型里的同一层神经网络的，只有每张训练卡上都计算出了同一层神经网络的梯度 才能对这一层神经网络的梯度进行全局规约，如下图所示：\nHorovod设计了一种梯度状态协商机制，它将 计算节点Rank0 作为coordinator（master），其余的rank1-N节点进程为worker，由coordinator来协商确定同一份梯度是否在每个计算节点上都已经计算出来，只有在每个计算节点上都计算出来的同一梯度才可以进行全局规约操作。在Horovod里每个计算节点上都有一个message_queue以及tensor_table，而在coordinator节点上除此之外，还有一个message_table用于保存可以进行全局Allreduce的梯度请求次数信息。Horovod 控制面的ComputeResponseList 函数里实现了这一梯度的协商过程，在从message_queue获取了本节点生成的梯度信息后，coordinator会与其他节点协商这个梯度是否都计算出来，这一过程是阻塞进行的，这个协商过程如下图：\n一个梯度是否能满足全局规约AllReduce的协商过程如下：\n首先，集群内的每个计算节点进程都会往coordinator Rank0发送一个 tensor的请求request，表示说本节点这一层神经网络的梯度已经生成，比如tensor1，每个rank都会往rank0 发送一个本梯度tensor1已经计算出来的请求信息；\n第二步，coordinator接收到节点的梯度协商请求后（包括本节点），会把收到的tensor请求次数进行累加，并将这个信息记录在message_table里，当这个梯度的请求信息达到集群内节点的个数时，比如在N个节点的集群，一个神经网络层的梯度tensor的通信请求出现了N次，那就表示在本集群里所有的计算节点都已经发出了对该梯度tensor的通信request，这就表明这个梯度tensor是符合全局规约要求的，就能进行集合通信全局规约，不符合要求的梯度tensor将继续留在message_table中，直到条件符合为止；\n第三步，再接着coordinator会将满足全局allreduce规约条件的梯度Tensor通过response返回给其他节点，告诉其他节点这个梯度可以启动全局规约AllReduce。\n经过这几步的协商达成梯度全局状态一致的目的，从而避免梯度丢失造成的模型精度不达标、不收敛或者进程死锁问题。\n3.4 梯度融合 神经网络的每一层都能对应一个梯度，假设每生成一个梯度就进行一次全局规约时，100个梯度就需要进行100次全局通信100次全局规约，而通信对训练的性能有巨大的影响，这种情况表现出来的效果就是分布式训练集群的整体性能极差。通过梯度融合计算将多个梯度合成一个，从而减少全局规约的次数能大幅提高分布式训练的训练性能，如下图所示，将N个小梯度Tensor合成两个，能将全局通信的次数减少到2次，从而大幅提升训练性能，在Horovod里这个功能对TensorFusion特性。但这个特性也会与3.2通信隐藏特性相冲突，需要根据具体情况进行合理的调试优化。\n3.5 易用性 从TensorFlow，PyTorch等框架迁移到Horovod需要改的的代码极少，horovod接入方式比较简单，与原生训练框架对比，主要的区别在于：\n1，初始化 Horovod，包括机器资源的分配： horovod.init()\n2，向每个进程分配XPU资源， 典型的设置是 1 个 XPU 一个进程，即设置 local rank： config.gpu_options.visible_device_list = str(hvd.local_rank())\n3，对原优化器进行包装，分布式优化器将梯度计算委托给原始优化器，使用allreduce或allgather对梯度求平均，然后应用这些平均梯度： opt=hvd.DistributedOptimizer(opt)\n4， 将初始化参数从rank 0广播给其他进程(rank表示进程序号)，实现参数的初始化，确保所有节点的初始化参数保持一致： hvd.BroadcastGlobalVariablesHook(0)：\n3.6 可移植 可移植问题，Horovod通过 OP和OpKernels的插件化机制支持多种多样的深度学习训练框架，比如 TensorFlow、PyTorch、MxNet等。基于的opKernels的可定制化机制，Horovod自定义了Op然后hack了数据链路层的通信协议，从而达到在多个深度学习框架之间可移植。\n3.7 可靠性问题 在集群训练的过程中网络时不可靠的、计算卡是会出故障的、服务器是会出故障的的，这些因素造成了分布式训练过程中需要考虑训练集群的可靠性，Horovod结合集合通信库Gloo对外提供了弹性训练的特性，但可靠性不只是弹性训练就能完全解决的，它还有更多的系统级的问题需要解决，因此可靠性问题留着一个后续研究问题，不在本文阐述。\n4. 优点缺点、改进点 简单易用、可移植，并且支持弹性训练提升了可靠性； 不依赖于某个框架，其通过MPI机制独立建立了一套分布式训练服务系统； 将计算与通信分离，完成了allreduce、allgather等集合通信工作，实现了规模可扩展； 巧妙的通过间隔轮询的机制支持通信时间隐藏，并且完成了梯度协商从而保证训练出来的模型是可收敛、精度达标的； 支持梯度融合，支持将小的tensor合并成一个大的tensor再进行通信传递，从而减小通信操作的额外开销； 自带压缩算法，可以减少集合通信的数据量； 5. 思考题 问题1，将通信时间隐藏在计算时间内能有助于提升训练系统的整体性能，但这一特性是针对SIMT芯片的架构的进行性能优化的，如果DSA芯片不能支持这一特性，那应该如何优化Horovod从而大幅提升整体的训练性能？（可以确定这一定是能做到的） 问题2，梯度协商的过程中，每个梯度都需要协商一次，在梯度较多，网络规模较大的集群里，这一特性也会影响性能，如何进行优化才能有效提升Horovod性能？\\ 问题3，不同的模型对梯度融合有不同的要求，那么梯度融合需要融合到什么程度才能有效提升性能？ 可以说明的是，这三个问题解决后还能继续提升Horovod在DSA架构芯片上的整体的分布式训练系统级性能。\n6. 小结 本文介绍了分布式训练的基础知识以及剖析了分布式训练服务框架所面临的几个核心问题，以Horovod为例从计算与通信解耦、通信隐藏、梯度协商、梯度融合、易用性以及可移植这几个角度倒推了分布式训练服务框架背后的设计意图，从而帮助大家能更好的理解分布式训练服务框架。\nref: [1] https://www.changping.me [2] https://horovod.ai [3] https://www.cnblogs.com/rossiXYZ/p/14910959.html [4] https://zhuanlan.zhihu.com/p/374575049\n","permalink":"https://jianye0428.github.io/en/posts/tech/distributedtraining/2022_11_21_distributedtraining_5/","summary":"1. 概述 分布式训练服务框架与集合通信库的组合构成了分布式训练的整体服务软件栈，在第3篇、第4篇文章里已经剖析完集合通信的相关内容，而本文会以H","title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析"},{"content":"[1] https://blog.csdn.net/Augusdi/article/details/12187291\nCUDA编程 1.什么是CUDA CUDA(Compute Unified Device Architecture)，统一计算架构，是NVidia推出的并行计算平台。NVidia官方对其的解释是：一个并行计算平台和简单（简洁）地使用图像处理单元（GPU）进行通用计算的编程模型。利用GPU的能力在计算性能上有惊人的提升。\n简单地说CUDA是便于程序员利用NVidia GPU进行通用计算的开发环境及工具，目前支持C/C++语言，将来还会支持Fortran语言。\n2.为什么要用到CUDA CPU主频要比GPU高2-3倍左右，但是通常情况下GPU核心的数量要比CPU多2-3个数量级以上。因此GPU的计算能力要远大于CPU，充分发挥GPU的计算能力，可以有成倍的性能提升。\n早期利用GPU的计算能力是使用着色器和着色语言（GLSL等）。目前广泛使用的是CUDA和OpenCL。CUDA是针对NVidia GPU硬件设备设计的，而 OpenCL是针对跨平台设计的。因此CUDA可充分发挥NVidia GPU的计算性能。\nCUDA可以直接使用C/C++语言来开发GPU程序，省去了程序员重新学一种新语言的麻烦。\n3.CUDA环境搭建 CUDA环境主要分为四点：硬件（GPU设备）、操作系统、C/C++编译器和CUDA工具包。\n硬件（GPU设备），必须是支持CUDA的GPU。可到NVidia官网查询支持CUDA的GPU设备，具体地址为：http://www.nvidia.com/object/cuda_home_new.html 。\n操作系统，支持Microsoft Windows、Mac OS X和Linux。\nC/C++编译器，对不同的操作系统有不同的要求。\nCUDA工具包，NVidia提供了不同操作系统对应的CUDA Toolkit，可从https://developer.nvidia.com/cuda-downloads 下载对应的版本。\n本文只以Microsoft Windows为例介绍如何搭建CUDA环境。\n准备材料：\n·一台装有支持CUDA GPU的电脑。\n·Microsoft Windows操作系统（Microsoft Windows XP,Vista,7,or 8 or Windows Server 2003 or 2008）。\n·CUDA工具包（相应操作系统）。下载地址：https://developer.nvidia.com/cuda-downloads\n·C/C++编译器：Microsoft Visual Studio 2008 或 2010，或者对应版本的Microsoft Visual C++ Express产品。\n安装步骤：\n·在装有支持CUDA GPU的电脑上安装Microsoft Windows操作系统（一般情况下都已经完成这步骤）。\n·安装C/C++编译器，可只安装其中的C++编译器部分。\n·安装CUDA工具包。（CUDA工具包中有NVidia GPU的驱动程序，尚未安装的请选择安装。）\n安装验证：\nWindows XP系统：进入 C:\\Documents and Settings\\All Users\\Application Data\\NVIDIA Corporation\\CUDA Samples\\v5.0\\bin\\win32\\Release 目录运行deviceQuery.exe文件。\nWindows Vista, Windows 7, Windows 8, Windows Server 2003, and Windows Server 2008系统：进入 C:\\ProgramData\\NVIDIA Corporation\\CUDA Samples\\v5.0\\bin\\win32\\Release 目录运行deviceQuery.exe文件。\n如果安装正确，执行deviceQuery.exe文件会得到GPU设备的相应信息。如果没有安装支持CUDA的GPU也会得出GPU的信息，其中CUDA Capability Major/Minor version number信息为9999.9999。\nMicrosoft Windows上更详细的安装信息请查看：http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-microsoft-windows/index.html 。\nMac OS X的安装：http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-mac-os-x/index.html 。 Linux的安装：http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-linux/index.html 。\n4.第一个CUDA程序 在Microsoft Windows系统上，如果成功搭建了CUDA环境，则在Microsoft Visual Studio中已经集成了CUDA的开发组件。\n以下以Windows 7 + Microsoft Visual Studio 2008为例，创建第一个CUDA程序。\n打开Microsoft Visual Studio 2008，依次：File-\u0026gt;New-\u0026gt;Project-\u0026gt;NVIDIA-\u0026gt;CUDA-\u0026gt;CUDA 5.0 Runtime，输入相应的项目名称确定即可。\n默认会生成一个kernel.cu文件，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 #include \u0026#34;cuda_runtime.h\u0026#34; #include \u0026#34;device_launch_parameters.h\u0026#34; #include \u0026lt;stdio.h\u0026gt; void addWithCuda(int *c, const int *a, const int *b, size_t size); __global__ void addKernel(int *c, const int *a, const int *b) { int i = threadIdx.x; c[i] = a[i] + b[i]; } int main() { const int arraySize = 5; const int a[arraySize] = { 1, 2, 3, 4, 5 }; const int b[arraySize] = { 10, 20, 30, 40, 50 }; int c[arraySize] = { 0 }; // Add vectors in parallel. addWithCuda(c, a, b, arraySize); printf(\u0026#34;{1,2,3,4,5} + {10,20,30,40,50} = {%d,%d,%d,%d,%d}\\n\u0026#34;, c[0], c[1], c[2], c[3], c[4]); // cudaThreadExit must be called before exiting in order for profiling and // tracing tools such as Nsight and Visual Profiler to show complete traces. cudaThreadExit(); return 0; } // Helper function for using CUDA to add vectors in parallel. void addWithCuda(int *c, const int *a, const int *b, size_t size) { int *dev_a = 0; int *dev_b = 0; int *dev_c = 0; // Choose which GPU to run on, change this on a multi-GPU system. cudaSetDevice(0); // Allocate GPU buffers for three vectors (two input, one output) . cudaMalloc((void**)\u0026amp;dev_c, size * sizeof(int)); cudaMalloc((void**)\u0026amp;dev_a, size * sizeof(int)); cudaMalloc((void**)\u0026amp;dev_b, size * sizeof(int)); // Copy input vectors from host memory to GPU buffers. cudaMemcpy(dev_a, a, size * sizeof(int), cudaMemcpyHostToDevice); cudaMemcpy(dev_b, b, size * sizeof(int), cudaMemcpyHostToDevice); // Launch a kernel on the GPU with one thread for each element. addKernel\u0026lt;\u0026lt;\u0026lt;1, size\u0026gt;\u0026gt;\u0026gt;(dev_c, dev_a, dev_b); // cudaThreadSynchronize waits for the kernel to finish, and returns // any errors encountered during the launch. cudaThreadSynchronize(); // Copy output vector from GPU buffer to host memory. cudaMemcpy(c, dev_c, size * sizeof(int), cudaMemcpyDeviceToHost); cudaFree(dev_c); cudaFree(dev_a); cudaFree(dev_b); } 代码1\n这是一个将两个一维数组相加的例子。\n其中addKernel是内核函数，它的计算过程是在GPU上实现的，用函数类型限定符__global__限制，且函数类型为void型。\ncuda_runtime.h头文件包括了运行时API和其参数的定义。（如果使用驱动API则使用cuda.h头文件）。\ndevice_launch_parameters.h头文件包含了内核函数的5个变量threadIdx、blockDim、blockIdx、gridDim和wrapSize。\n对其中CUDA运行时API函数的解释：\ncudaSetDevice()：选择设备（GPU）。（可以不使用，不使用的情况下，默认选择设备0）\ncudaMalloc()：动态分配显存。\ncudaMemcpy()：设备与主机之内的数据拷贝。\ncudaThreadSynchronize()：同步所有设备上的线程，等待所有线程结束。\ncudaFree():释放由cudaMalloc分配的显存。\ncudaThreadExit():结束CUDA上下文环境，释放其中的资源。\n这些函数的具体介绍在 http://docs.nvidia.com/cuda/cuda-runtime-api/index.html 中。\n5. CUDA编程 5.1. 基本概念 CUDA编程中需要注意一些基本概念，分别为：主机(host)、设备(device)、运行时API、驱动API、warp、bank、函数类型限定符、变量类型限定符、thread、block、grid、计算能力、SIMT、内置变量、纹理、CUDA数组等。\n主机(host)：可理解为CPU与内存的组合。\n设备(device)：可理解为GPU与显存的组合。\n运行时API：是指CUDA运行时API是在驱动API的基础上封装而成的，简化了CUDA的开发。\n驱动API：是指CUDA驱动API，相比运行时API更接近于设备，可灵活运用设备的特性开发CUDA，可实现运行时API无法实现的功能。\nwarp：多处理器激活、管理、调度和执行并行任务的单位。计算能力2.x的设备warp为32个线程。未来的设备可能不同，可以通过内置变量warpSize查询。\nbank：为了获得较高的存储器带宽，共享存储器被划分为多个大小相等的存储器模块，称为存储体，这些存储体就叫bank，可同步访问。\n函数类型限定符：是CUDA C中特有的，用来修饰是主机函数，设备调用的设备函数，还是主机调用的设备函数。有__device__、global、host。\n变量类型限定符：是用来修饰设备变量的。有__device__、constant、shared。\nthread：设备中的线程，与主机中的线程是同一个概念。\nblock：线程块，由一组线程组成。一个线程块中的所以线程会在同一个多处理器上执行，一个多处理器上可同时执行多个线程块。\ngrid：有所有线程块组成的网格。\n计算能力：是NVidia GPU不同架构的计算能力。\nSIMT：单指令多线程，与单指令多数据（SIMD）类似。一条指令多个线程一同执行，实现程序的并行化。\n内置变量：有threadIdx、blockDim、blockIdx、gridDim、warpSize。其中threadIdx指此线程在线程块中的位置；blockDim指线程块维度；blockIdx指该线程块在网格中的位置；gridDim指线程块网格维度；warpSize指一个warp多少个线程。\n纹理：本文主要涉及到的是纹理参考、纹理绑定、纹理获取。\nCUDA数组：区别于线性存储器，对数据进行了对齐等的处理，包括一维、二维和三维。其中的数据为：一元、二元或四元组。\nCUDA编程模型基础\n在给出CUDA的编程实例之前，这里先对CUDA编程模型中的一些概念及基础知识做个简单介绍。CUDA编程模型是一个异构模型，需要CPU和GPU协同工作。在CUDA中，host和device是两个重要的概念，我们用host指代CPU及其内存，而用device指代GPU及其内存。CUDA程序中既包含host程序，又包含device程序，它们分别在CPU和GPU上运行。同时，host与device之间可以进行通信，这样它们之间可以进行数据拷贝。典型的CUDA程序的执行流程如下：\n分配host内存，并进行数据初始化；分配device内存，并从host将数据拷贝到device上；调用CUDA的核函数在device上完成指定的运算；将device上的运算结果拷贝到host上；释放device和host上分配的内存。 上面流程中最重要的一个过程是调用CUDA的核函数来执行并行计算，kernel是CUDA中一个重要的概念，kernel是在device上线程中并行执行的函数，核函数用__global__符号声明，在调用时需要用\u0026laquo;\u0026lt;grid, block\u0026raquo;\u0026gt;来指定kernel要执行的线程数量，在CUDA中，每一个线程都要执行核函数，并且每个线程会分配一个唯一的线程号thread ID，这个ID值可以通过核函数的内置变量threadIdx来获得。\n由于GPU实际上是异构模型，所以需要区分host和device上的代码，在CUDA中是通过函数类型限定词开区别host和device上的函数，主要的三个函数类型限定词如下：\n__global__：在device上执行，从host中调用（一些特定的GPU也可以从device上调用），返回类型必须是void，不支持可变参数参数，不能成为类成员函数。注意用__global__定义的kernel是异步的，这意味着host不会等待kernel执行完就执行下一步。__device__：在device上执行，单仅可以从device中调用，不可以和__global__同时用。__host__：在host上执行，仅可以从host上调用，一般省略不写，不可以和__global__同时用，但可和__device__，此时函数会在device和host都编译。 要深刻理解kernel，必须要对kernel的线程层次结构有一个清晰的认识。首先GPU上很多并行化的轻量级线程。kernel在device上执行时实际上是启动很多线程，一个kernel所启动的所有线程称为一个网格（grid），同一个网格上的线程共享相同的全局内存空间，grid是线程结构的第一层次，而网格又可以分为很多线程块（block），一个线程块里面包含很多线程，这是第二个层次。线程两层组织结构如下图所示，这是一个gird和block均为2-dim的线程组织。grid和block都是定义为dim3类型的变量，dim3可以看成是包含三个无符号整数（x，y，z）成员的结构体变量，在定义时，缺省值初始化为1。因此grid和block可以灵活地定义为1-dim，2-dim以及3-dim结构，对于图中结构（主要水平方向为x轴），定义的grid和block如下所示，kernel在调用时也必须通过执行配置\u0026laquo;\u0026lt;grid, block\u0026raquo;\u0026gt;来指定kernel所使用的线程数及结构。\n所以，一个线程需要两个内置的坐标变量（blockIdx，threadIdx）来唯一标识，它们都是dim3类型变量，其中blockIdx指明线程所在grid中的位置，而threaIdx指明线程所在block中的位置，如图中的Thread (1,1)满足：\n1 2 3 4 threadIdx.x = 1 threadIdx.y = 1 blockIdx.x = 1 blockIdx.y = 1 一个线程块上的线程是放在同一个流式多处理器（SM)上的，但是单个SM的资源有限，这导致线程块中的线程数是有限制的，现代GPUs的线程块可支持的线程数可达1024个。有时候，我们要知道一个线程在blcok中的全局ID，此时就必须还要知道block的组织结构，这是通过线程的内置变量blockDim来获得。它获取线程块各个维度的大小。对于一个2-dim的block ，线程 的ID值为 ，如果是3-dim的block ，线程 的ID值为\n。另外线程还有内置变量gridDim，用于获得网格块各个维度的大小。\nkernel的这种线程组织结构天然适合vector,matrix等运算，如我们将利用上图2-dim结构实现两个矩阵的加法，每个线程负责处理每个位置的两个元素相加，代码如下所示。线程块大小为(16, 16)，然后将N*N大小的矩阵均分为不同的线程块来执行加法运算。\n此外这里简单介绍一下CUDA的内存模型，如下图所示。可以看到，每个线程有自己的私有本地内存（Local Memory），而每个线程块有包含共享内存（Shared Memory）,可以被线程块中所有线程共享，其生命周期与线程块一致。此外，所有的线程都可以访问全局内存（Global Memory）。还可以访问一些只读内存块：常量内存（Constant Memory）和纹理内存（Texture Memory）。内存结构涉及到程序优化，这里不深入探讨它们。\n还有重要一点，你需要对GPU的硬件实现有一个基本的认识。上面说到了kernel的线程组织层次，那么一个kernel实际上会启动很多线程，这些线程是逻辑上并行的，但是在物理层却并不一定。这其实和CPU的多线程有类似之处，多线程如果没有多核支持，在物理层也是无法实现并行的。但是好在GPU存在很多CUDA核心，充分利用CUDA核心可以充分发挥GPU的并行计算能力。GPU硬件的一个核心组件是SM，前面已经说过，SM是英文名是 Streaming Multiprocessor，翻译过来就是流式多处理器。SM的核心组件包括CUDA核心，共享内存，寄存器等，SM可以并发地执行数百个线程，并发能力就取决于SM所拥有的资源数。当一个kernel被执行时，它的gird中的线程块被分配到SM上，一个线程块只能在一个SM上被调度。SM一般可以调度多个线程块，这要看SM本身的能力。那么有可能一个kernel的各个线程块被分配多个SM，所以grid只是逻辑层，而SM才是执行的物理层。SM采用的是SIMT (Single-Instruction, Multiple-Thread，单指令多线程)架构，基本的执行单元是线程束（warps)，线程束包含32个线程，这些线程同时执行相同的指令，但是每个线程都包含自己的指令地址计数器和寄存器状态，也有自己独立的执行路径。所以尽管线程束中的线程同时从同一程序地址执行，但是可能具有不同的行为，比如遇到了分支结构，一些线程可能进入这个分支，但是另外一些有可能不执行，它们只能死等，因为GPU规定线程束中所有线程在同一周期执行相同的指令，线程束分化会导致性能下降。当线程块被划分到某个SM上时，它将进一步划分为多个线程束，因为这才是SM的基本执行单元，但是一个SM同时并发的线程束数是有限的。这是因为资源限制，SM要为每个线程块分配共享内存，而也要为每个线程束中的线程分配独立的寄存器。所以SM的配置会影响其所支持的线程块和线程束并发数量。总之，就是网格和线程块只是逻辑划分，一个kernel的所有线程其实在物理层是不一定同时并发的。所以kernel的grid和block的配置不同，性能会出现差异，这点是要特别注意的。还有，由于SM的基本执行单元是包含32个线程的线程束，所以block大小一般要设置为32的倍数。\n5.2. 线程层次结构 CUDA线程的层次结构，由小到大依次为线程(thread)、线程块(block)、线程块网格(grid)。一维、二维或三维的线程组组成一个线程块，一维、二维或三维的线程块组组成一个线程块网格。\n下图是由二维的线程块组组成的线程块网络，其中线程块是由二维的线程组组成。\n图1 NVidia GPU的硬件结构是，一组流处理器组成一个多处理器，一个或多个多处理器组成一个GPU。其中流处理器，可以理解为处理计算的核心单元。多处理器类似于多核CPU。NVidia GPU从DX10（DirectX10）开始出现了Tesla、Fermi、Kepler架构，不同的架构多处理器中流处理器数量都有差别。\n在进行CUDA编程前，可以先检查一下自己的GPU的硬件配置，这样才可以有的放矢，可以通过下面的程序获得GPU的配置属性：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 int dev = 0; cudaDeviceProp devProp; CHECK(cudaGetDeviceProperties(\u0026amp;devProp, dev)); std::cout \u0026lt;\u0026lt; \u0026#34;使用GPU device \u0026#34; \u0026lt;\u0026lt; dev \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; devProp.name \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;SM的数量：\u0026#34; \u0026lt;\u0026lt; devProp.multiProcessorCount \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;每个线程块的共享内存大小：\u0026#34; \u0026lt;\u0026lt; devProp.sharedMemPerBlock / 1024.0 \u0026lt;\u0026lt; \u0026#34; KB\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;每个线程块的最大线程数：\u0026#34; \u0026lt;\u0026lt; devProp.maxThreadsPerBlock \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;每个EM的最大线程数：\u0026#34; \u0026lt;\u0026lt; devProp.maxThreadsPerMultiProcessor \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;每个SM的最大线程束数：\u0026#34; \u0026lt;\u0026lt; devProp.maxThreadsPerMultiProcessor / 32 \u0026lt;\u0026lt; std::endl; // 输出如下 使用GPU device 0: GeForce GT 730 SM的数量：2 每个线程块的共享内存大小：48 KB 每个线程块的最大线程数：1024 每个EM的最大线程数：2048 每个EM的最大线程束数：64 ref: https://zhuanlan.zhihu.com/p/34587739\n5.3. 存储器层次结构 CUDA存储器有：寄存器(register)、共享存储器(shared memory)、常量存储器(constant memory)、本地存储器(local memory)、全局存储器(global memory)、纹理存储器等。其中寄存器和本地存储器是线程(thread)私有的，共享存储器是对线程块(block)中的所有线程可见，常量存储器、全局存储器和纹理存储器是对网格(grid)中所有线程可见。\n下图解释了存储器的层次结构：\n5.4. 运行时API 运用运行时API开发CUDA程序需要了解：初始化、设备管理、存储器管理、流管理、事件管理、纹理参考管理、OpenGL互操作和Direct3D互操作。\n运行时API文档地址为：http://docs.nvidia.com/cuda/cuda-runtime-api/index.html 。\n5.4.1. 初始化 运行时API不存在显示初始化函数，初始化会在首次调用运行时函数时完成。虽然不需要调用初始化函数进行初始化，但是退出时需要调用退出函数cudaThreadExit()释放资源。\n5.4.2. 设备管理 有些电脑上可能有多块设备，因此对于不同的要求选择合适的设备。设备管理主要是获取设备信息和选择执行设备。\n主要有三个函数：\n·cudaGetDeviceCount()：得到电脑上设备的个数。\n·cudaGetDeviceProperties()：获得对应设备的信息。\n·cudaSetDevice()：设置CUDA上下文对应的设备。\n运行__global__函数前需要提前选择设备，如果不调用cudaSetDevice()函数，则默认使用0号设备。\n上面三个函数的具体用法请查看CUDA运行时API文档。\n5.4.3. 存储器管理 共享存储器、常量存储器、线性存储器和CUDA数组的使用是存储器管理的主要部分。\n5.4.3.1 共享存储器 共享存储器，使用__shared__变量限定符修饰，可静态或动态分配共享存储器。\n代码一：\n静态分配共享存储器，是在设备代码中直接分配共享存储器的大小，如下代码： 1 2 3 4 5 6 7 8 9 10 11 12 #define SHARED_MEM 16 __global__ void kernel(…) { __shared__ int shared[SHARED_MEM]; } void main() { kernel\u0026lt;\u0026lt;\u0026lt;nBlock, nThread\u0026gt;\u0026gt;\u0026gt;(…); } 代码2\n动态分配共享存储器，是在主机代码中使用内核函数的第三个特定参数传入分配共享存储器的大小，如下代码： 1 2 3 4 5 6 7 8 9 10 11 12 #define SHARED_MEM 16 __global__ void kernel(…) { extern __shared__ int shared[]; } void main() { int nSharedMem = (int)SHARED_MEM; kernel\u0026lt;\u0026lt;\u0026lt;nBlock, nThread, nSharedMem*sizeof(int)\u0026gt;\u0026gt;\u0026gt;(…); } 5.4.3.2. 常量存储器 常量存储器，使用__constant__变量限定符修饰。使用常量存储器，是由于其在设备上有片上缓存，比全局存储器读取效率高很多。\n使用常量存储器时会涉及的运行时API函数主要有：\n·cudaMemcpyToSymbol()\n·cudaMemcpyFromSymbol()\n·cudaGetSymbolAddress()\n·cudaGetSymbolSize()\n主机代码中使用cudaGetSymbolAddress()获取__constant__或__device__定义的变量地址。设备代码中可通过提取__device__、__shared__或__constant__变量的指针获取变量地址。\n5.4.3.3. 线性存储器 线性存储器是使用cudaMalloc()、cudaMallocPitch()或cudaMalloc3D()分配的，使用cudaFree()释放。二维的时候建议使用cudaMallocPitch()分配，cudaMallocPitch()函数对对齐进行了调整。这三个分配函数对应cudaMemset()、cudaMemset2D()、cudaMemset3D()三个memset函数和cudaMemcpy()、cudaMemcpy2D()、cudaMemcpy3D()三个memcpy函数。\n5.4.3.4. CUDA数组 CUDA数组是使用cudaMallocArray()、cudaMalloc3DArray()分配的，使用cudaFreeArray()释放。\n相关memcpy函数请查阅CUDA运行时API文档。\n具体使用可查阅CUDA编程指南：http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html 。\n5.4.4. 流管理 主机设备之间的内存拷贝与内核在设备上执行是异步的。在不使用流的情况下，是这样执行的：设备先从主机上拷贝内存，拷贝完成之后，再在设备上执行内核代码计算，最后当内核执行完毕，再把设备上的内存拷贝到主机上。当使用两个流的情况下，0号流执行内核代码的同时1号流拷贝主机内存到设备，1号流执行的同时0号流拷贝设备内存到主机（具体的实现并不一定如此，这里是为了说明流的作用简单做了假设）。两个流的情况下，部分内存拷贝和内置执行是同时进行的（异步的），比同步的内存拷贝和内核执行节省了时间。\n与流有关的函数有：\n·cudaStreamCreate()：流的创建； ·cudaStreamDestroy()：流的销毁； ·cudaStreamSynchronize()：流同步； ·*Async：与流相关的其他函数。 内核\u0026lt;\u0026lt;\u0026lt;…\u0026gt;\u0026gt;\u0026gt;的第四个参数为哪个流。 CUDA编程指南中有对流具体实现的讲解。 https://blog.csdn.net/a925907195/article/details/39500915 ","permalink":"https://jianye0428.github.io/en/posts/notes/gpu_compute/cuda_1/","summary":"[1] https://blog.csdn.net/Augusdi/article/details/12187291 CUDA编程 1.什么是CUDA CUDA(Compute Unified Device Architecture)，统一计算架构，是NVidia推出的并行计算平台。NVidia官方对其的解","title":"CUDA_1"},{"content":"一.常考C++基础概念 1.C++三大特性（封装、继承、多态） 封装：\n隐藏类的属性和实现细节，仅仅对外提供接口， 封装性实际上是由编译器去识别关键字public、private和protected来实现的， 体现在类的成员可以有公有成员(public)，私有成员(private)，保护成员(protected)。 私有成员是在封装体内被隐藏的部分，只有类体内声明的函数(类的成员函数)才可以访问私有成员， 而在类体外的函数是不能访问的，公有成员(public)是封装体与外界的一个接口， 类体外的函数可以访问公有成员，保护成员是只有该类的成员函数和该类的派生类才可以访问的。\n优点：隔离变化；便于使用；提高重用性；提高安全性 缺点：如果封装太多，影响效率；使用者不能知道代码具体实现。\n继承：\n被继承的是父类（基类），继承出来的是子类（派生类），子类拥有父类的所有的特性。 继承方式有公有继承、私有继承，保护继承。默认是私有继承\n*公有继承中父类的公有和保护成员在子类中不变，私有的在子类中不可访问。 *私有继承中父类的公有和保护成员在子类中变为私有，但私有的在子类中不可访问。 *保护继承中父类的公有和保护成员在子类中变为保护，但私有的在子类中不可访问。 c++语言允许单继承和多继承\n优点：继承减少了重复的代码、继承是多态的前提、继承增加了类的耦合性； 缺点：继承在编译时刻就定义了，无法在运行时刻改变父类继承的实现；\n父类通常至少定义了子类的部分行为，父类的改变都可能影响子类的行为； 如果继承下来的子类不适合解决新问题，父类必须重写或替换，那么这种依赖关系就限制了灵活性， 最终限制了复用性。\n虚继承：为了解决多重继承中的二义性问题，它维护了一张虚基类表。 (菱形继承问题)\n多态:\nref: 多态的四种表现形式\n运行时多态(虚函数) 编译时多态(模板) 重载 类型转换 运行时多态(Subtype Polymorphism/Runtime Polymorphism)\n运行时多态就是派生类重写基类的虚函数，在调用函数里，参数为基类的指针或引用，会构成多态。我之前写过一篇多态的原理，就是在讲多态(运行时多态)在底层是怎么实现的 多态的底层实现\n举个例子：比如买票这个行为，成人去买就是全价，学生买就是半价票。但是不管成人还是学生都是人这个体系。所以我们需要根据谁来买票才能决定价格，这个时候就需要多态。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #include \u0026lt;iostream\u0026gt; class ticket { public: virtual void price() = 0; }; class adult : public ticket { public: virtual void price() override { std::cout \u0026lt;\u0026lt; \u0026#34;成人全价！\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class student : public ticket { public: virtual void price() override { std::cout \u0026lt;\u0026lt; \u0026#34;学生半价！\u0026#34; \u0026lt;\u0026lt; std::endl; } }; void BuyTicket(ticket\u0026amp; t) { t.price(); } int main(void) { adult a; student s; BuyTicket(a); BuyTicket(s); return 0; } 编译时多态(Parametric Polymorphism/Compile-Time Polymorphism)\n编译时多态就是模板。在程序编译时，编译器根据参数的类型，就将生成某种类型的函数或类。我之前关于模板的(总结)[https://blog.csdn.net/weixin_42678507/article/details/88658291]\n举个简单的例子：Add() 函数是一个非常简单的函数，但是如果你写一个整型的 Add 函数，那么我想加 double 型的呢？你再写一个 double 型的 Add 函数，那么我想加 char 型的呢？\n这个时候就用到了模板，我们先定义一个逻辑，具体类型等编译时再生成该类型的函数或类。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #include \u0026lt;iostream\u0026gt; template\u0026lt;class T\u0026gt; T Add(T lhs, T rhs) { return lhs + rhs; } int main(void) { Add(1, 2); Add(2.0, 3.0); Add(\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;); return 0; } 重载(Ad-hoc Polymorphism/Overloading)\n函数名相同，参数不同就构成了重载。重载主要用于函数，当某个函数的功能无法处理某些参数的情况时，我们就可以重载一个函数来单独处理。\n举个例子：比如说上面的 Add 函数，当前内置类型都可以处理，但是如果我传两个字符串怎么办？就不可以像刚才那么加了。得重载一个函数单独处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; int Add(int lhs, int rhs) { return lhs + rhs; } std::string Add(const std::string\u0026amp; lhs, const std::string\u0026amp; rhs) { std::string ans(lhs); ans += rhs; return ans; } int main(void) { Add(1, 2); Add(\u0026#34;abc\u0026#34;, \u0026#34;def\u0026#34;); return 0; } 类型转换(Coercion Polymorphism/Casting)\n类型转换主要分为四种：\nstatic_cast: 相当于隐式类型转换。 const_cast: 这个可以去除一个 const 变量的 const 性质，使可以改变它的值。 reinterpret_cast: 相当于强制类型转换。 dynamic_cast: 这个可以使子类指针或引用赋值给父类指针或引用。 类型转换很简单，这里就不多赘述了。\n2.数组和链表的区别 数组和链表是两种不同的数据存储方式\n数组的定义\n数组是一组具有相同数据类型的变量的集合，这些变量称之为集合的元素。 每个元素都有一个编号，称之为下标，可以通过下标来区别并访问数组元素，数组元素的个数叫做数据的长度。\n链表的定义\n链表是一种物理存储单元上非连续、非顺序的存储结构,数据元素的逻辑顺序是通过链表中的指针链接次序实现的。 链表的特性是在中间任意位置插入和删除元素都非常快，不需要移动其它元素。 对于单向链表而言，链表中的每一个元素都要保存一个指向下一个元素的指针。 对于双向链表而言，链表中的每个元素既要保存指向下一个元素的指针，又要保存指向上一个元素的指针。 对于双向循环链表而言，链表中的最后一个元素保存一个指向第一个元素的指针。\n数组和链表的区别主要表现在以下几个方面\n比较 数组 链表 逻辑结构 (1) 数组在内存中连续； (2)使用数组之前，必须事先固定数组长度，不支持动态改变数组大小； (3) 数组元素增加时，有可能会数组越界； (4) 数组元素减少时，会造成内存浪费； （5）数组增删时需要移动其它元素 (1) 链表采用动态内存分配的方式，在内存中不连续 (2)支持动态增加或者删除元素 (3) 需要时可以使用malloc或者new来申请内存，不用时使用free或者delete来释放内存 内存结构 数组从栈上分配内存，使用方便，但是自由度小 链表从堆上分配内存，自由度大，但是要注意内存泄漏 访问效率 数组在内存中顺序存储，可通过下标访问，访问效率高 链表访问效率低，如果想要访问某个元素，需要从头遍历 越界问题 数组的大小是固定的，所以存在访问越界的风险 越界的风险\t只要可以申请得到链表空间，链表就无越界风险 数组和链表的使用场景\n比较 数组使用场景 链表使用场景 空间 数组的存储空间是栈上分配的，存储密度大，当要求存储的大小变化不大时，且可以事先确定大小，宜采用数组存储数据 链表的存储空间是堆上动态申请的，当要求存储的长度变化较大时，且事先无法估量数据规模，宜采用链表存储 时间 数组访问效率高。当线性表的操作主要是进行查找，很少插入和删除时，宜采用数组结构 链表插入、删除效率高，当线性表要求频繁插入和删除时，宜采用链表结构 3. 智能指针 我们知道除了静态内存和栈内存外，每个程序还有一个内存池，这部分内存被称为自由空间或者堆。程序用堆来存储动态分配的对象即那些在程序运行时分配的对象，当动态对象不再使用时，我们的代码必须显式的销毁它们。\n在C++中，动态内存的管理是用一对运算符完成的：new和delete，new:在动态内存中为对象分配一块空间并返回一个指向该对象的指针，delete：指向一个动态独享的指针，销毁对象，并释放与之关联的内存。\n动态内存管理经常会出现两种问题：一种是忘记释放内存，会造成内存泄漏；一种是尚有指针引用内存的情况下就释放了它，就会产生引用非法内存的指针。\n为了更加容易（更加安全）的使用动态内存，引入了智能指针的概念。智能指针的行为类似常规指针，重要的区别是它负责自动释放所指向的对象。标准库提供的两种智能指针的区别在于管理底层指针的方法不同，shared_ptr允许多个指针指向同一个对象，unique_ptr则“独占”所指向的对象。标准库还定义了一种名为weak_ptr的伴随类，它是一种弱引用，指向shared_ptr所管理的对象，这三种智能指针都定义在memory头文件中。\n1 智能指针的作用\n智能指针是一个类，用来存储指向动态分配对象的指针，负责自动释放动态分配的对象，防止堆内存泄漏。动态分配的资源，交给一个类对象去管理，当类对象生命周期结束时，自动调用析构函数释放资源 2 智能指针的种类: shared_ptr、unique_ptr、weak_ptr、auto_ptr\n四种指针详情 2.1 智能指针的实现原理\n智能指针的实现原理就是在一个类的内部封装了类对象的指针，然后在析构函数里对我们的类对象指针进行释放，因为类的析构是在类对象生命期结束时自动调用的，这样我们就省去了手动释放内存的操作，避免忘记手动释放导致的内存泄漏。\n2.2 C++11四种智能指针总结\n2.2.1 auto_ptr：\nauto_ptr以前是用在C98中，C++11被抛弃，头文件一般用来作为独占指针 auto_ptr被赋值或者拷贝后，失去对原指针的管理 auto_ptr不能管理数组指针，因为auto_ptr的内部实现中，析构函数中删除对象使用delete而不是delete[]，释放内存的时候仅释放了数组的第一个元素的空间，会造成内存泄漏。 auto_ptr不能作为容器对象，因为STL容器中的元素经常要支持拷贝，赋值等操作。 2.2.2 unique_ptr:\nC++11中用来替代auto_ptr 拷贝构造和赋值运算符被禁用，不能进行拷贝构造和赋值运算 虽然禁用了拷贝构造和赋值运算符，但unique_ptr可以作为返回值，用于从某个函数中返回动态申请内存的所有权，本质上是移动拷贝，就是使用std:move()函数，将所有权转移。 2.2.3 share_ptr:\n多个指针可以指向相同的对象，调用release()计数-1，计数0时资源释放 .use_count()查计数 .reset()放弃内部所有权 share_ptr多次引用同一数据会导致内存多次释放 循环引用会导致死锁， 引用计数不是原子操作。 shared_ptr 有两个数据成员，一个是指向 对象的指针 ptr，另一个是 ref_count 指针（包含vptr、use_count、weak_count、ptr等）； 在这里插入图片描述 1 2 shared_ptr\u0026lt;Foo\u0026gt; x(new Foo); shared_ptr\u0026lt;Foo\u0026gt; y = x; 步骤一：\n`y=x` 涉及两个成员的复制，这两步拷贝不会同时（原子）发生，中间步骤 1，复制 ptr 指针，中间步骤 2，复制 ref_count 指针，导致引用计数加 1 步骤二: 因为是两步，如果没有 mutex 保护，那么在多线程里就有数据竞争。\n多线程读写同一个 shared_ptr 必须加锁。\n2.2.4 weak_ptr:\n1.解决两个share_ptr互相引用产生死锁，计数永远降不到0，没办法进行资源释放，造成内存泄漏的问题。 2.使用时配合share_ptr使用，把其中一个share_ptr更换为weak_ptr。 4. 重载、重写、重定义 (1) 重载（overload）： 指函数名相同，但是它的参数表列个数或顺序，类型不同。但是不能靠返回类型来判断。 a 相同的范围（在同一个类中） b 函数名字相同、 参数不同 c virtual关键字可有可无 d 返回值可以不同；\n(2) 重写（覆盖override)是指派生类函数覆盖基类函数，特征是： a 不同的范围，分别位于基类和派生类中 b 函数的名字相同、 参数相同 c 基类函数必须有virtual关键字，不能有static d 返回值相同（或者协变），否则报错； e 重写函数的访问修饰符可以不同。尽管virtual是private的，派生类中重写改写为public, protected也是可以的\n(3) 重定义(隐藏redefine)是指派生类的函数屏蔽了与其同名的基类函数，特征是： a 不在同一个作用域（分别位于派生类与基类） b 函数名字相同 c 返回值可以不同 d 规则：\n如果派生类的函数和基类的函数同名，但是参数不同，此时，不管有无virtual，基类的函数被隐藏；\n如果派生类的函数与基类的函数同名，并且参数也相同，但是基类函数没有vitual关键字，此时，基类的函数被隐藏。\nps: 多态性可以分为静态多态性（方法的重载，一个类）和动态多态性（方法的覆盖，有继承关系的类之间的行为）。进而多态性可以由重载和覆盖来实现。\n5.static与const区别和作用 static:\n1.**static局部变量**将一个变量声明为函数的局部变量，那么这个局部变量在函数执行完不会释放，而是继续保留在内存中； 2.**static全局变量**表示一个变量在当前文件的全局可以访问； 3.**static函数**表示一个函数只能在当前文件中被访问； 4.**static类成员变量**表示这个成员为全类所共有； 5.**static类成员函数**表示这个函数为全类所有，且只能访问成员变量。 6.全局变量在整个工程文件内有效；静态全局变量只在定义它的文件中有效； 7.静态局部变量只在定义它的函数内有效，且程序只分配一次内存，函数返回时不会释放，下次调用时不会重新赋值，还保留上次结果值；局部变量在函数返回时就释放掉； 8.全局变量和静态变量编译器会默认初始化为0；局部变量的默认值未知； 9.局部静态变量与全局变量共享全局数据，但是静态局部变量值在定义该变量的函数内部可见。 10.静态成员（静态成员函数）与非静态成员（成员函数）的区别在于有无this指针；静态成员是静态存储，必须进行初始化； 11.静态成员函数访问非静态成员报错: 静态成员在类加载时就已经分配内存，而此时非静态成员尚未分配内存，访问不存在的内存自然会报错； const\n1.\u0026lt;font color=red\u0026gt;const常量\u0026lt;/font\u0026gt; 定义时必须初始化，以后不能修改； 2.\u0026lt;font color=red\u0026gt;const形参\u0026lt;/font\u0026gt; 该形参在函数里不能被修改； 3.\u0026lt;font color=red\u0026gt;const修饰类成员函数\u0026lt;/font\u0026gt; 该函数对成员变量只能进行读操作； static关键字作用\n1.函数体内static变量的作用范围为该函数体，该变量的内存只被分配一次，因此该值在下次调用时还维持上一次的值； 2.在模块内的static函数和变量可以被可以被模块内的函数访问，不能被模块外的函数访问； 3.在类内的static成员变量为整个类所有，类的所有对象只有一份拷贝； 4.在类内的static成员函数为整个类所有，这个函数不接收this指针，因此只能访问类的static成员变量； const关键字\n1.阻止一个变量被改变； 2.声明常量指针和指针常量； 3.const修饰形参，表示为输入参数，在函数体内不能修改该参数的值； 4.const修饰成员函数，表明为一个常函数，不能修改成员变量的值； 5.类的成员函数，有时必须返回const类型的值，使得返回值不能为左值。 const修饰指针有三种情况\nconst修饰指针 \u0026mdash; 常量指针 (const修饰的是指针,指针指向可以改,指针指向的值不可以更改) 1 2 3 const int * p1 = \u0026amp;a; p1 = \u0026amp;b; //正确 //*p1 = 100; 报错 const修饰常量 \u0026mdash; 指针常量 (const修饰的是常量,指针指向不可以改,指针指向的值可以更改) 1 2 3 int * const p2 = \u0026amp;a; //p2 = \u0026amp;b; //错误 *p2 = 100; //正确 const即修饰指针,又修饰常量 (const既修饰指针又修饰常量，都不可以改) 1 2 3 const int * const p3 = \u0026amp;a; //p3 = \u0026amp;b; //错误 //*p3 = 100; //错误 技巧:看const右侧紧跟着的是指针还是常量, 是指针就是常指针,是常量就是指针常量\n6. const与宏定义（#define）区别和作用 const 定义的是变量不是常量，只是这个变量的值不允许改变，是常变量，带有类型。编译运行的时候起作用，存在类型检查。\ndefine 定义的是不带类型的常数，只进行简单的字符替换。在预编译的时候起作用，不存在类型检查。\n1、两者的区别 (1) 编译器处理方式不同 #define 宏是在预处理阶段展开。 const 常量是编译运行阶段使用。\n(2) 类型和安全检查不同 #define 宏没有类型，不做任何类型检查，仅仅是展开。 const 常量有具体的类型，在编译阶段会执行类型检查。\n(3) 存储方式不同 #define宏仅仅是展开，有多少地方使用，就展开多少次，不会分配内存。（宏定义不分配内存，变量定义分配内存。） const常量会在内存中分配(可以是堆中也可以是栈中)。\n(4) const 可以节省空间，避免不必要的内存分配。 例如： const 定义常量从汇编的角度来看，只是给出了对应的内存地址，而不是象 #define 一样给出的是立即数，所以，const 定义的常量在程序运行过程中只有一份拷贝（因为是全局的只读变量，存在静态区），而 #define 定义的常量在内存中有若干个拷贝。\n(5) 提高了效率。 编译器通常不为普通const常量分配存储空间，而是将它们保存在符号表中，这使得它成为一个编译期间的常量，没有了存储与读内存的操作，使得它的效率也很高。\n(6) 宏替换只作替换，不做计算，不做表达式求解;宏预编译时就替换了，程序运行时，并不分配内存。计算时注意边缘效应\n7.虚函数和纯虚函数区别 1.虚函数和纯虚函数可以定义在同一个类中，含有纯虚函数的类被称为抽象类，而只含有虚函数的类不能被称为抽象类。 2.虚函数可以被直接使用，也可以被子类重载以后，以多态的形式调用，而纯虚函数必须在子类中实现该函数才可以使用，因为纯虚函数在基类有声明而没有定义。 3.虚函数和纯虚函数都可以在子类中被重载，以多态的形式被调用。 4.虚函数和纯虚函数通常存在于抽象基类之中，被继承的子类重载，目的是提供一个统一的接口。 5.虚函数的定义形式：virtual{};纯虚函数的定义形式：virtual { } = 0;在虚函数和纯虚函数的定义中不能有static标识符，原因很简单，被static修饰的函数在编译时要求前期绑定,然而虚函数却是动态绑定，而且被两者修饰的函数生命周期也不一样。 6.虚函数充分体现了面向对象思想中的继承和多态性这两大特性，在C++语言里应用极广。比如在微软的MFC类库中，你会发现很多函数都有virtual关键字，也就是说，它们都是虚函数。难怪有人甚至称虚函数是C++语言的精髓。 7.定义纯虚函数就是为了让基类不可实例化，因为实例化这样的抽象数据结构本身并没有意义或者给出实现也没有意义。 纯虚函数只是一个接口，是个函数的声明而已，它要留到子类里去实现。\n虚函数在子类里面也可以不重载的；但纯虚必须在子类去实现，这就像Java的接口一样。通常我们把很多函数加上virtual，是一个好的习惯，虽然牺牲了一些性能，但是增加了面向对象的多态性，因为你很难预料到父类里面的这个函数不在子类里面不去修改它的实现\n虚函数: https://www.cnblogs.com/zkfopen/p/11061414.html\n8. 指针和引用的区别 1.指针和引用的定义和性质区别：\n(1) 指针：指针是一个变量，只不过这个变量存储的是一个地址，指向内存的一个存储单元；而引用跟原来的变量实质上是同一个东西，只不过是原变量的一个别名而已。如：\n1 2 3 int a=1;int *p=\u0026amp;a; int a=1;int \u0026amp;b=a; 上面定义了一个整形变量和一个指针变量p，该指针变量指向a的存储单元，即p的值是a存储单元的地址。\n而下面2句定义了一个整形变量a和这个整形a的引用b，事实上a和b是同一个东西，在内存占有同一个存储单元。\n(2)引用不可以为空，当被创建的时候，必须初始化，而指针可以是空值，可以在任何时候被初始化。\n(3)可以有const指针，但是没有const引用；\n(4)指针可以有多级，但是引用只能是一级（int **p；合法 而 int \u0026amp;\u0026amp;a是不合法的）\n(5)指针的值可以为空，但是引用的值不能为NULL，并且引用在定义的时候必须初始化；\n(6)指针的值在初始化后可以改变，即指向其它的存储单元，而引用在进行初始化后就不会再改变了。\n(7)\u0026ldquo;sizeof引用\u0026quot;得到的是所指向的变量(对象)的大小，而\u0026quot;sizeof指针\u0026quot;得到的是指针本身的大小；\n(8)指针和引用的自增(++)运算意义不一样；\n(9)如果返回动态内存分配的对象或者内存，必须使用指针，引用可能引起内存泄漏；\n9. 结构体赋值 (结构体赋值)[https://blog.csdn.net/datase/article/details/78988320]\n10. C和C++区别 (C和C++区别)[https://blog.csdn.net/czc1997/article/details/81254971]\n11. C和C++传参方式区别 C语言不支持引用传参，如果想要改变传入参数的值，只能用传入指针的方式。\n12. 深拷贝和浅拷贝区别 (深拷贝和浅拷贝区别)[https://blog.csdn.net/Situo/article/details/110225143]\n13. 避免头文件重复包含以及宏定义重定义 1 2 3 #ifndef LWIP_TCP_KEEPALIVE #define LWIP_TCP_KEEPALIVE #endif 14. 你怎么理解虚拟类？虚拟类可以实例化一个对象吗？为什么？它的作用和其他类的区别 答案：虚拟类可以派生对象，纯虚类不可以实例化对象。因为纯虚类存在未定义的函数，只是个概念，不可真实存在。虚拟类用做多态，纯虚类做接口。\n15. 内联函数怎么实现的，什么时期处理的，优缺点 答案：在程序编译时，编译器将程序中出现的内联函数的调用表达式用内联函数的函数体来进行替换。 优点：不会产生函数调用的开销 缺点：增加目标程序的代码量，即增加空间开销\n16 .位运算（按位与、按位或、异或） 按位与运算符（\u0026amp;）\n参加运算的两个数，按二进制位进行“与”运算。\n运算规则：只有两个数的二进制同时为1，结果才为1，否则为0。（负数按补码形式参加按位与运算）\n即 0 \u0026amp; 0= 0 ，0 \u0026amp; 1= 0，1 \u0026amp; 0= 0， 1 \u0026amp; 1= 1。\n例：3 \u0026amp;5 即 00000011 \u0026amp; 00000101 = 00000001 ，所以 3 \u0026amp; 5的值为1。\n按位或运算符（|）\n参加运算的两个数，按二进制位进行“或”运算。\n运算规则：参加运算的两个数只要两个数中的一个为1，结果就为1。\n即 0 | 0= 0 , 1 | 0= 1 ， 0 | 1= 1 , 1 | 1= 1 。\n例：2 | 4 即 00000010 | 00000100 = 00000110 ，所以2 | 4的值为 6 。 异或运算符（^）\n参加运算的两个数，按二进制位进行“异或”运算。\n运算规则：参加运算的两个数，如果两个相应位为“异”（值不同），则该位结果为1，否则为0。\n即 0 ^ 0=0 ， 0 ^ 1= 1 ， 1 ^ 0= 1 ， 1 ^ 1= 0 。\n例： 2 ^ 4 即 00000010 ^ 00000100 =00000110 ，所以 2 ^ 4 的值为6 。\n17. 原码、反码、补码 原码：是最简单的机器数表示法。用最高位表示符号位，‘1’表示负号，‘0’表示正号。其他位存放该数的二进制的绝对值。\n反码：正数的反码还是等于原码 负数的反码就是他的原码除符号位外，按位取反。\n补码：正数的补码等于他的原码 负数的补码等于反码+1。\n18 . 堆和栈 (堆和栈)[https://blog.csdn.net/qq_45856289/article/details/106473750]\n19. 类和对象 面向对象(Object Oriented,OO)。\n起初，“面向对象”是指在程序设计中采用封装、继承、多态等设计方法。现在，面向对象的思想已经涉及到软件开发的各个方面。如，面向对象的分析（OOA，ObjectOriented Analysis），面向对象的设计（OOD，Object Oriented Design）、以及面向对象的编程实现（OOP，Object Oriented Programming）。 对象和类解释：\n1）对象：对象是人们要进行研究的任何事物，它不仅能表示具体的事物，还能表示抽象的规则、计划或事件。对象具有状态，一个对象用数据值来描述它的状态。对象还有操作，用于改变对象的状态，对象及其操作就是对象的行为。对象实现了数据和操作的结合，使数据和操作封装于对象的统一体中。\n2）类：具有相同特性（数据元素）和行为（功能）的对象的抽象就是类。因此，对象的抽象是类，类的具体化就是对象，也可以说类的实例是对象，类实际上就是一种数据类型。类具有属性，它是对象的状态的抽象，用数据结构来描述类的属性。类具有操作，它是对象的行为的抽象，用操作名和实现该操作的方法来描述。 对象和类的关系：\n类与对象的关系就如模具和铸件的关系，类的实力化的结果就是对象，而对对象的抽象就是类，类描述了一组有相同特性（属性）和相同行为的对象。\n20 . new和malloc区别 0.属性 new/delete是C++关键字，需要编译器支持。malloc/free是库函数，需要头文件支持。\n1.参数 使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算。而malloc则需要显式地指出所需内存的尺寸。\n2.返回类型 new操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故new是符合类型安全性的操作符。 而malloc内存分配成功则是返回void * ，需要通过强制类型转换将void*指针转换成我们需要的类型。\n3.分配失败 new内存分配失败时，会抛出bac_alloc异常。malloc分配内存失败时返回NULL。\n4.自定义类型 new会先调用operator new函数，申请足够的内存（通常底层使用malloc实现）。然后调用类型的构造函数，初始化成员变量，最后返回自定义类型指针。delete先调用析构函数，然后调用operator delete函数释放内存（通常底层使用free实现）。 malloc/free是库函数，只能动态的申请和释放内存，无法强制要求其做自定义类型对象构造和析构工作。\n5.重载 C++允许重载new/delete操作符，特别的，布局new的就不需要为对象分配内存，而是指定了一个地址作为内存起始区域，new在这段内存上为对象调用构造函数完成初始化工作，并返回此地址。而malloc不允许重载。\n6.内存区域 new操作符从自由存储区（free store）上为对象动态分配内存空间，而malloc函数从堆上动态分配内存。自由存储区是C++基于new操作符的一个抽象概念，凡是通过new操作符进行内存申请，该内存即为自由存储区。而堆是操作系统中的术语，是操作系统所维护的一块特殊内存，用于程序的内存动态分配，C语言使用malloc从堆上分配内存，使用free释放已分配的对应内存。自由存储区不等于堆，如上所述，布局new就可以不位于堆中\n21. 内核链表与双向循环链表 (内核链表与双向循环链表)[https://blog.csdn.net/liebao_han/article/details/53956609]\n22. 结构体和类的区别 1.结构体是一种值类型，而类是引用类型。值类型用于存储数据的值，引用类型用于存储对实际数据的引用。 那么结构体就是当成值来使用的，类则通过引用来对实际数据操作。\n结构体使用栈存储（Stack Allocation），而类使用堆存储（Heap Allocation) 栈的空间相对较小.但是存储在栈中的数据访问效率相对较高. 堆的空间相对较大.但是存储在堆中的数据的访问效率相对较低. 3.类是反映现实事物的一种抽象，而结构体的作用只是一种包含了具体不同类别数据的一种包装，结构体不具备类的继承多态特性\n4.结构体赋值是 直接赋值的值. 而对象的指针 赋值的是对象的地址\n5.Struct变量使用完之后就自动解除内存分配，Class实例有垃圾回收机制来保证内存的回收处理。\n6.结构体的构造函数中，必须为结构体所有字段赋值，类的构造函数无此限制\n首先,关于隐式构造函数.我们知道,在1个类中如果我们没有为类写任意的构造函数,那么C++编译器在编译的时候会自动的为这个类生成1个无参数的构造函数.我们将这个构造函数称之为隐式构造函数 但是一旦我们为这个类写了任意的1个构造函数的时候,这个隐式的构造函数就不会自动生成了.在结构体中,就不是这样了,在结构体中隐式的构造函数无论如何都存在。所以程序员不能手动的为结构添加1个无参数的构造函数。\n7.结构体中声明的字段无法赋予初值，类可以:\n如何选择结构体还是类\n1． 堆栈的空间有限，对于大量的逻辑的对象，创建类要比创建结构好一些 2． 结构表示如点、矩形和颜色这样的轻量对象，例如，如果声明一个含有 1000 个点对象的数组，则将为引用每个对象分配附加的内存。在此情况下，结构的成本较低。 3． 在表现抽象和多级别的对象层次时，类是最好的选择 4． 大多数情况下该类型只是一些数据时，结构时最佳的选择\n23. 结构体和联合体区别 两者最大的区别在于内存利用\n一、结构体struct\n各成员各自拥有自己的内存，各自使用互不干涉，同时存在的，遵循内存对齐原则。一个struct变量的总长度等于所有成员的长度之和。 二、联合体union\n各成员共用一块内存空间，并且同时只有一个成员可以得到这块内存的使用权(对该内存的读写)，各变量共用一个内存首地址。因而，联合体比结构体更节约内存。一个union变量的总长度至少能容纳最大的成员变量，而且要满足是所有成员变量类型大小的整数倍。\n24. 结构体和枚举 一、结构体\n结构体:很像面向对象中的对象，但是结构体没有方法只有属性，一个结构体由不同类型的元素组成，而相较于数组来说，数组只能存储相同类型的元素。结构体占用的空间等于内部各元素占用空间的和，并且元素在内存中的地址（按照元素定义的顺序）是连续的。\n注意：结构体不能像面向对象中那样递归调用，自己包含自己，但是可以包含其他类型的结构体。\n二、枚举\n枚举:和面向对象中一样，枚举都是用来定义一些固定取值的常量,但是C中的枚举中的值是整数，默认按照0递增,也可以在定义枚举的时候赋值，那么后面的元素的值就会以这个元素为第一个元素递增\n25 . 数组和指针的区别与联系 (数组和指针的区别与联系)[https://blog.csdn.net/cherrydreamsover/article/details/81741459]\n26 . 函数指针\u0026amp;指针函数 https://blog.csdn.net/baidu_37973494/article/details/83150266\n27 . const放在函数前后的区别 1、int GetY() const; 2、const int * GetPosition();\n对于1 该函数为只读函数，不允许修改其中的数据成员的值。\n对于2 修饰的是返回值，表示返回的是指针所指向值是常量\n28 . goto语句 goto语句也称为无条件转移语句，其一般格式如下： goto 语句标号； 其中语句标号是按标识符规定书写的符号， 放在某一语句行的前面，标号后加冒号(：)。语句标号起标识语句的作用，与goto 语句配合使用。举个例子：\n1 2 goto label; cout \u0026lt;\u0026lt; \u0026#34;This is the\u0026#34; 29 . extern关键字 1、extern用在变量或者函数的声明前，用来说明“此变量/函数是在别处定义的，要在此处引用”。extern声明不是定义，即不分配存储空间。也就是说，在一个文件中定义了变量和函数， 在其他文件中要使用它们， 可以有两种方式：使用头文件，然后声明它们，然后其他文件去包含头文件；在其他文件中直接extern。\n2、extern C作用\n链接指示符extern C 如果程序员希望调用其他程序设计语言尤其是C 写的函数，那么调用函数时必须告诉编译器使用不同的要求，例如当这样的函数被调用时函数名或参数排列的顺序可能不同，无论是C++函数调用它还是用其他语言写的函数调用它，程序员用链接指示符告诉编译器该函数是用其他的程序设计语言编写的，链接指示符有两种形式既可以是单一语句形式也可以是复合语句形式。 // 单一语句形式的链接指示符 extern \u0026ldquo;C\u0026rdquo; void exit(int); // 复合语句形式的链接指示符 extern \u0026ldquo;C\u0026rdquo; { int printf( const char* \u0026hellip; ); int scanf( const char* \u0026hellip; ); } // 复合语句形式的链接指示符 extern \u0026ldquo;C\u0026rdquo; { #include } 链接指示符的第一种形式由关键字extern 后跟一个字符串常量以及一个普通的函数，声明构成虽然函数是用另外一种语言编写的但调用它仍然需要类型检查例如编译器会检查传递给函数exit()的实参的类型是否是int 或者能够隐式地转换成int 型，多个函数声明可以用花括号包含在链接指示符复合语句中，这是链接指示符的第二种形式花扩号被用作分割符表示链接指示符应用在哪些声明上在其他意义上该花括号被忽略，所以在花括号中声明的函数名对外是可见的就好像函数是在复合语句外声明的一样，例如在前面的例子中复合语句extern \u0026ldquo;C\u0026quot;表示函数printf()和scanf()是在C 语言中写的，函数因此这个声明的意义就如同printf()和scanf()是在extern \u0026ldquo;C\u0026quot;复合语句外面声明的一样，当复合语句链接指示符的括号中含有#include 时，在头文件中的函数声明都被假定是用链接指示符的程序设计语言所写的，在前面的例子中在头文件中声明的函数都是C函数链接指示符不能出现在函数体中下列代码段将会导致编译错误。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 int main() { // 错误: 链接指示符不能出现在函数内 extern \u0026#34;C\u0026#34; double sqrt( double ); 305 第七章函数 double getValue(); //ok double result = sqrt ( getValue() ); //... return 0; } 如果把链接指示符移到函数体外程序编译将无错误 extern \u0026#34;C\u0026#34; double sqrt( double ); int main() { double getValue(); //ok double result = sqrt ( getValue() ); //... return 0; } 但是把链接指示符放在头文件中更合适，在那里函数声明描述了函数的接口所属，如果我们希望C++函数能够为C 程序所用又该怎么办呢我们也可以使用extern \u0026#34;C\u0026#34;链接指示符来使C++函数为C 程序可用例如。 // 函数calc() 可以被C 程序调用 extern \u0026#34;C\u0026#34; double calc( double dparm ) { /* ... */ } 如果一个函数在同一文件中不只被声明一次则链接指示符可以出现在每个声明中它，也可以只出现在函数的第一次声明中，在这种情况下第二个及以后的声明都接受第一个声明中链接指示符指定的链接规则例如 // ---- myMath.h ---- extern \u0026#34;C\u0026#34; double calc( double ); // ---- myMath.C ---- // 在Math.h 中的calc() 的声明 #include \u0026#34;myMath.h\u0026#34; // 定义了extern \u0026#34;C\u0026#34; calc() 函数 // calc() 可以从C 程序中被调用 double calc( double dparm ) { // ... 在本节中我们只看到为C 语言提供的链接指示extern \u0026#34;C\u0026#34;，extern \u0026#34;C\u0026#34;是惟一被保证由所有C++实现都支持的，每个编译器实现都可以为其环境下常用的语言提供其他链接指示例如extern \u0026#34;Ada\u0026#34;可以用来声明是用Ada 语言写的函数，extern \u0026#34;FORTRAN\u0026#34;用来声明是用FORTRAN 语言写的函数，等等因为其他的链接指示随着具体实现的不同而不同所以建议读者查看编译器的用户指南以获得其他链接指示符的进一步信息。 总结 extern “C” extern “C” 不但具有传统的声明外部变量的功能，还具有告知C++链接器使用C函数规范来链接的功能。 还具有告知C++编译器使用C规范来命名的功能。\n30 . 动态内存管理 (动态内存管理)[https://blog.csdn.net/zgege/article/details/82054076]\n31 .数组、链表、哈希、队列、栈数据结构特点，各自优点和缺点 数组(Array)： 优点：查询快，通过索引直接查找；有序添加，添加速度快，允许重复； 缺点：在中间部位添加、删除比较复杂，大小固定，只能存储一种类型的数据； 如果应用需要快速访问数据，很少插入和删除元素，就应该用数组。\n链表(LinkedList)： 优点：有序添加、增删改速度快，对于链表数据结构，增加和删除只要修改元素中的指针就可以了； 缺点：查询慢，如果要访问链表中一个元素，就需要从第一个元素开始查找； 如果应用需要经常插入和删除元素，就应该用链表。\n栈(Stack)： 优点：提供后进先出的存储方式，添加速度快，允许重复； 缺点：只能在一头操作数据，存取其他项很慢；\n队列(Queue)： 优点：提供先进先出的存储方式，添加速度快，允许重复； 缺点：只能在一头添加，另一头获取，存取其他项很慢；\n哈希(Hash)： 特点：散列表，不允许重复； 优点：如果关键字已知则存取速度极快； 缺点：如果不知道关键字则存取很慢，对存储空间使用不充分；\n32. 友元函数 引入友元函数的原因 类具有封装、继承、多态、信息隐藏的特性，只有类的成员函数才可以访问类的私有成员，非成员函数只能访问类的公有成员。为了使类的非成员函数访问类的成员，唯一的做法就是将成员定义为public，但这样做会破坏信息隐藏的特性。基于以上原因，引入友元函数解决。 (友元函数)[https://blog.csdn.net/qq_26337701/article/details/53996104]\n33. 设计模式之单例模式、工厂模式、发布订阅模式以及观察者模式 (设计模式)[https://blog.csdn.net/m0_37322399/article/details/108515158]\n34. 构造函数： 什么是构造函数？\n通俗的讲，在类中，函数名和类名相同的函数称为构造函数。它的作用是在建立一个对象时，做某些初始化的工作（例如对数据赋予初值）。C++允许同名函数，也就允许在一个类中有多个构造函数。如果一个都没有，编译器将为该类产生一个默认的构造函数。\n构造函数上惟一的语法限制是它不能指定返回类型，甚至void 也不行。\n不带参数的构造函数：一般形式为 类名 对象名(){函数体}\n带参数的构造函数：不带参数的构造函数，只能以固定不变的值初始化对象。带参数构造函数的初始化要灵活的多，通过传递给构造函数的参数，可以赋予对象不同的初始值。一般形式为：构造函数名（形参表）；\n创建对象使用时：类名 对象名（实参表）；\n构造函数参数的初始值：构造函数的参数可以有缺省值。当定义对象时，如果不给出参数，就自动把相应的缺省参数值赋给对象。一般形式为： 构造函数名（参数=缺省值，参数=缺省值，……）; 析构函数：\n当一个类的对象离开作用域时，析构函数将被调用(系统自动调用)。析构函数的名字和类名一样，不过要在前面加上 ~ 。对一个类来说，只能允许一个析构函数，析构函数不能有参数，并且也没有返回值。析构函数的作用是完成一个清理工作，如释放从堆中分配的内存。\n一个类中可以有多个构造函数，但析构函数只能有一个。对象被析构的顺序，与其建立时的顺序相反，即后构造的对象先析构。 1、概念不同：\n析构函数：对象所在的函数已调用完毕时，系统自动执行析构函数。\n构造函数：是一种特殊的方法。特别的一个类可以有多个构造函数 ，可根据其参数个数的不同或参数类型的不同来区分它们 即构造函数的重载。 2、作用不同：\n析构函数：析构函数被调用。\n构造函数：为对象成员变量赋初始值 3、目的不同：\n析构函数：”清理善后” 的工作\n构造函数：主要用来在创建对象时初始化对象， 即为对象成员变量赋初始值，总与new运算符一起使用在创建对象的语句中。\n35. C++模板 https://blog.csdn.net/zhaizhaizhaiaaa/article/details/104091658\n36. C++ STL https://www.cnblogs.com/shiyangxt/archive/2008/09/11/1289493.html\nref: https://blog.csdn.net/qq_52621551/article/details/122960158\nc++ 八股文 关键字与运算符 1. 指针与引⽤ 指针：存放某个对象的地址，其本⾝就是变量（命了名的对象），本⾝就有地址，所以可以有指向指针的指针；可变，包括其所指向的地址的改变和其指向的地址中所存放的数据的改变 (地址可变，地址存储的值也可变)\n引⽤：就是变量的别名，从⼀⽽终，不可变，必须初始化， 不存在指向空值的引⽤，但是存在指向空值的指针\n2. const 关键字 const的作⽤：被它修饰的值不能改变，是只读变量。必须在定义的时候就给它赋初值。\n顶层const: 表示指针本身是个常量 底层const: 表示指针所指的对象是一个常量\n2.1 常量指针（底层const）（指针指的对象不可改变）\n常量指针：是指定义了⼀个指针，这个指针指向⼀个只读的对象，不能通过常量指针来改变这个对象的值。常量指针强调的是指针对其所指对象的不可改变性。 特点：靠近变量名 形式:\nconst 数据类型 *指针变量 = 变量名 数据类型 const *指针变量 = 变量名 举例: 1 2 3 int temp = 10; const int* a = \u0026amp;temp; int const *a = \u0026amp;temp; 2.2 指针常量（顶层const）(指针不能改变) 指针常量：指针常量是指定义了⼀个指针，这个指针的值只能在定义时初始化，其他地⽅不能改变。指针常量强调的是指针的不可改变性。 特点: 靠近变量类型 形式: 数据类型 * const 指针变量=变量名\n实例: 1 int* const p = \u0026amp;temp 3. define 和 typedef的区别 ","permalink":"https://jianye0428.github.io/en/posts/notes/c++/2022-11-10_c++_basics/","summary":"一.常考C++基础概念 1.C++三大特性（封装、继承、多态） 封装： 隐藏类的属性和实现细节，仅仅对外提供接口， 封装性实际上是由编译器去识别关键","title":"C++_basics"},{"content":" 2.4 2.4.2 指针和const const指针\n常量指针(const pointer)：必须初始化，存放在指针中的地址的值不能改变\n1 2 int *const curRrr = \u0026amp;errNumb; const double *const pip = \u0026amp;pi; 2.4.3 顶层const 顶层const表示任意的对象是常量，这一点对任何数据类型都适用；底层const则是与指针和引用复合类型的基本类型部分有关； 顶层const(top-level const)：指针本身是个常量(指针不可改变，地址不可改变, 仅仅对指针有效) 1 2 int * const p = \u0026amp;errNumb; const int p = 42; 底层const(low-level const): 指针所指的对象是一个常量(对象的值不可改变) 1 2 const int *p = \u0026amp;errNumb; int const *p = \u0026amp;errNumb; 对于底层const，拷入和拷出的对象必须具有相同的底层const资格 2.4.4 constexpr 和 常量表达式 常量表达式(const expression) 是指值不会改变并且在编译过程就能得到计算结果的表达式。 constexpr变量 C++11新标准规定，允许将变量声名为constexpr类型以便由编译器来验证变量的值是否是一个常量表达式。 指针和constexpr 在constexpr声名中如果定义了一个指针，限定符constexpr仅对指针有效，与指针所指的对象无关。 2.5 处理类型 2.5.1 类型别名 typedef\nusing\n指针、常量和类型别名\n1 2 3 typedef char *pstring; const pstring cstr = 0; //声明指向char的常量指针，其基本数据类型是指针 const char *cstr = 0; // 声明指向常量字符的指针，其基本数据类型是char 2.5.2 auto 类型说明符 (c++11) auto: 让编译器通过初始值去分析表达式的所属类型。\n复合类型、常量和auto\n以引用对象的类型作为初始值; 或者将引用的类型设为auto, auto \u0026amp;g = ci auto一般会忽略顶层const， 底层const则会保留; 顶层const需要明确指出，例如auto const f = ci 符号\u0026amp;和*只是从属于某个声名符，而非基本数据类型的一部分\n2.5.3 decltype类型指示符 (C++11) 类型说明符decltype: 选择并返回操作数的类型。在此过程中，编译器分析表达式并得到它的类型，却不实际计算表达式的值。\n1 2 // sum的类型就是调用函数f() 返回的类型 delcltype(f()) sum = x; decltype处理顶层const和引用的方式和auto不同。如果decltype使用的表达式是一个变量，则decltype返回该变量类型(包括顶层const和引用)\n1 2 3 4 const int ci = 0, \u0026amp;cj = ci; decltype(ci) x = 0; //x的类型是const int decltype(cj) y = x; // y的类型是const int \u0026amp;, y绑定到变量x decltype(cj) z; //错误: z 是一个引用，必须初始化 decltype和引用\n如果decltype使用的表达式不是一个变量，则decltype返回表达式结果对应的类型。\n1 2 3 4 5 // decltype 可以是引用类型 int i = 42, *p = \u0026amp;i, \u0026amp;r = i; decltype(r) z; //错误: z的类型是int\u0026amp;, 必须初始化 decltype(r + 0) b; // 正确， int decltype(*p) c; //错误: c的类型是int\u0026amp;, 必须初始化 如果表达式的内容是解引用, 则decltype将得到引用类型。\n2.6 自定义数据结构 2.6.1 类数据成员\n(c++11)可以为数据成员提供类内初始值\n2.6.2 使用sales_data类 2.6.3 编写自己的头文件 预处理器概述\n#include:用指定文件代替#include #define:把一个名字设定为预处理变量 #ifdef:当且仅当变量已定义时为真 #ifndef:当且仅当变量未定义时为真 #endif:一旦检查结果为真，则执行后续操作直到#endif指令为止\nchapter 3 字符串、向量和数组 3.1 命名空间的using声明 作用域操作符:::编译器从操作符左侧名字所示的作用域中寻找右侧那个名字。\n使用using声明: using namespace::name;\n每个名字都需要独立的using声明。\n头文件不应包含using声明，因为头文件会拷贝到所有引用它的文件中去，容易引起名字冲突。\n3.2 标准库类型string 3.2.1 定义和初始化string对象 概念区分: 直接初始化和拷贝初始化\n拷贝初始化：使用=初始化一个变量，编译器直接把等号右侧的初始值拷贝到新创建的变量中去。 直接初始化： 不适用等号进行初始化 3.2.2 string对象上的一些操作 读写string对象\n可以使用iostream读写string对象 读取位置数量的string对象 1 2 3 4 5 6 7 int main() { string word; while (cin \u0026gt;\u0026gt; word) { cout \u0026lt;\u0026lt; word \u0026lt;\u0026lt; endl; } return 0; } 使用getline读取一整行: getline函数传入一个输入流和一个string对象，读取输入流直到遇到换行符，换行符也被读取进来，但是不存到string对象中 1 2 3 4 5 6 7 int main() { string line; while (getline(cin, line)) { cout \u0026lt;\u0026lt; line \u0026lt;\u0026lt; endl; } return 0; } string的empty()和size()操作 string::size_type类型： 一个无符号类型的值 比较string对象：==、!=、\u0026lt;、\u0026lt;=、\u0026gt;、\u0026gt;=(比较大小按字典顺序) 为string对象赋值 两个string对象相加 字面值和string对象相加：加法两面必须有一个是string对象 1 2 3 string s1 = \u0026#34;hello\u0026#34;; string s6 = s1 + \u0026#34;, \u0026#34; + \u0026#34;world\u0026#34;; // 正确: s1 + \u0026#34;, \u0026#34; 返回一个string对象 string s7 = \u0026#34;hello\u0026#34; + \u0026#34;world\u0026#34;; // 错误: 加号码两边都是字面值，没有string对象 3.2.3 处理string对象中的字符 处理每个字符? 使用基于for循环：for (char ch : string) 使用for循环改变字符串中的字符，必须把循环变量定义成引用类型：for (auto\u0026amp; ch : string) 只处理一部分字符： 使用下标或索引 使用下标执行迭代： 使用下标执行随机访问： 3.3 标准库类型vector 3.4 迭代器介绍 3.4.1 使用迭代器 begin() 和 end() (c++11) const_iterator: cbegin() 和 cend(); 迭代器运算符: == 和 !=：比较两个迭代器是否相等 *iter: iter-\u0026gt;mem ++iter --iter 迭代器类型: iterator：对象可读可写 const_iterator: 能读取但是不能修改它所指元素的值 结合解引用和成员访问操作 解引用: *iter 成员访问操作: (*it).empty() -\u0026gt;操作结合了解引用和成员访问操作: it-\u0026gt;mem == (*iter).mem 3.4.2 迭代器运算 迭代器的算术运算: 迭代器和一个整数值相加，返回向前或者向后移动若干个位置的迭代器 使用迭代器运算 3.5 数组 3.5.1 定义和初始化内置数组 声明数组: a[d] 声明时数组的维度必须是一个常量表达式 显示初始化数组元素 字符数组的特殊性: 声明时要加上空字符，如果没有则会被默认添加 数组之间不允许拷贝和赋值; 理解复杂的数组声明 可以定义存放指针的数组 int* p[10] 1 2 3 4 int *ptrs[10]; // 声明一个数组，存放十个指针 int (*parray)[10] = \u0026amp;arr; // 声明一个含有十个整数数组的指针 parray是指针的名字，指向一个数组 int (\u0026amp;arrRef)[10] = arr; // arrRef引用一个含有10个整数的数组 int *(\u0026amp;arry)[10] = ptrs; // arry 是数组的引用，该数组含有10个指针 3.5.2 访问数组元素 数组下标通常用size_t定义，size_t是一种机器相关的无符号数。\n3.5.3 指针和数组 在使用数组的时候，编译器会把它转化为指针； 在程序中用到数组名字的地方，编译器会把它替换为指向数组首元素的指针； 1 string *p2 = nums; // 等价于 p2 = \u0026amp;nums[0] 数组的操作实际上是指针的操作: 当使用数组作为一个auto变量的初始值时，推断得到的类型是指针而非数组； 当用decltype关键字是上述转换不会发生，decltype(ia)返回的类型是由10个整数构成的数组； 1 decltype(ia) ia3 = {0, 1, 2, 3,...} 指针也是迭代器: 可以将数组元素的指针当做迭代器使用 标准库函数begin 和 end 数组不是类类型，因此这两个函数不是成员函数 1 2 3 int ia[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}; int *beg = begin(ia); int *end = end(ia); 指向数组元素的指针可以执行以下运算: 解引用、递增、比较、与整数相加、两个指针相减等 解引用和指针运算的交互 下标和指针 3.5.4 C风格字符串 字符串存放在字符数组中并以空字符结尾 C标准string函数: 比较字符串 普通比较关系符用在c风格字符串上，其实比较的是两个指针的大小关系 方法: 调用strcmp(): 相等返回0， 前面较大返回正值， 反之返回负值 3.5.5 与旧代码的接口 混用string和c风格字符串 使用数组初始化vector对象 3.6 多维数组 多维数组的初始化 多维数组的下标引用 使用for循环处理多维数组 选用引用类型作为循环控制变量类型 指针的多维数组 多维数组的名字实际是指向第一维数组的指针 类型别名简化多维数组指针 chapter 4 表达式 4.1 基础 4.1.1 基础概念 一元运算符: 作用于一个运算对象\n例如: \u0026amp;取地址符、*解引用符 二元运算符: 作用于两个运算对象\n例如：==相等运算符、*乘法运算符 三元运算符\n函数调用也是一种运算符\n组合运算符和运算对象\n运算对象转换\n重载运算符: 当运算符作用于类类型时候，用户可以自定义其含义\n左值和右值: 当一个对象被用作右值的时候，用的是对象的值(内容)；当对象被用作左值的时候，用的是对象的身份(在内存中的地址)\n重要原则: 在需要右值的地方可以用左值来代替，但是不能把右值当成左值使用； 几个左值运算对象 decltype例子 假定p的类型是int*，解引用生成左值，所以decltype(*p)的结果是一个\u0026amp;int； 取地址符生成右值，所以decltype(\u0026amp;p)的结果是int**，指向指针的指针 4.1.2 优先律与结合律 4.1.3 求值顺序 明确规定求职顺序的运算符:\n逻辑与运算符(\u0026amp;\u0026amp;):先求左侧运算对象的值，只有当左侧为真时，再求右侧； 另外三种：逻辑或(||)、条件(?:)、逗号(,) 求值顺序、优先级和结合律\n4.2 算术运算符 4.3 逻辑和关系运算符 逻辑与和逻辑或 短路求值：逻辑与和逻辑或都是先确定左值，再求右值 逻辑非： 关系运算符：比较运算对象的大小关系，满足左结合律 相等性测试和布尔字面值 4.4 赋值运算符 赋值运算符的左侧必须是可修改的左值； 如果左右两个运算对象的类型不同， 则右侧的对象类型转换为左侧； 赋值运算符满足右结合律： 1 2 int ival, jval; ival = jval = 0; 赋值运算符优先级较低 切勿混淆相等运算符和赋值运算符 复合运算符: \u0026lt;=\u0026gt; a = a op b 1 2 += -= *= /= %= \u0026lt;\u0026lt;= \u0026gt;\u0026gt;= \u0026amp;= ^= |= 4.5 递增和递减运算符 递增和递减的前置版本和后置版本： 前置版本(++a)：先加1，再用运算对象；将对象本身作为左值对象返回(建议用前置版本) 后置版本(a++)：先用运算对象，再加1；讲对象的副本作为右值返回 在一条语句中混用解引用和递增运算符 1 2 auto pbeg = v.begin(); std::cout \u0026lt;\u0026lt; *pbeg++ \u0026lt;\u0026lt; std::endl; //因为++的优先级高于*，所以先将迭代器++，然后解引用迭代器未增加的对象，最终返回pbeg的初始值的副本 运算对象可按任意顺序求值， 容易造成行为未定义的错误 4.6 成员访问运算符 点运算符(.)和箭头运算符(-\u0026gt;)都可以用于访问成员； 点(.)：获取类对象的一个成员； 箭头运算符(-\u0026gt;)：ptr-\u0026gt;mem, 等价于(*ptr).mem 4.7 条件运算符 条件运算符： ?: =\u0026gt; cond ? expr1 : expr2 嵌套条件运算符：在条件运算符内部嵌套条件运算符 1 finalgrade = (grade \u0026gt; 90) ? \u0026#34;high grade\u0026#34; : (grade \u0026lt; 60) ? \u0026#34;fail\u0026#34; : \u0026#34;pass\u0026#34;; 满足右结合律 在输出表达式中使用条件运算符：条件运算符优先级底，需要在两端加上括号 1 2 cout \u0026lt;\u0026lt; ((grade \u0026lt; 60) ? \u0026#34;fail\u0026#34; : \u0026#34;pass\u0026#34;); // 输出pass 或者 fail cout \u0026lt;\u0026lt; (grade \u0026lt; 60) ? \u0026#34;fail\u0026#34; : \u0026#34;pass\u0026#34;; // 输出1或者0 4.8 位运算符 位运算符: 运算符 功能 ~ 求反 \u0026laquo; 左移 \u0026raquo; 右移 \u0026amp; 与 ^ 异或 移位运算符:\u0026lt;\u0026lt;、\u0026gt;\u0026gt;: 求反运算符:~:将0置1，将1置0 位与、位或、异或： 1 2 3 4 5 unsigned char b1 = 0145; 0 1 1 0 0 1 0 1 unsigned char b2 = 0257; 1 0 1 0 1 1 1 1 b1 \u0026amp; b2 ===============\u0026gt; 0 0 1 0 0 1 0 1 b1 | b2 ===============\u0026gt; 1 1 1 0 1 1 1 1 b1 ^ b2 ===============\u0026gt; 1 1 0 0 1 0 1 0 移位运算符（又叫IO运算符），满足左结合律 4.9 sizeof 运算符 sizeof()：返回表达式或类型的字节数，满足右结合律(不是求运算对象的值) sizeof(type)、sizeof expr 对数组使用sizeof，得到整个数组的大小，相当于对数组的每个元素执行一次sizeof 4.10 逗号运算符 逗号运算符: 含有两个运算对象，执行从左往右的运算顺序。 4.11 类型转换 类型转换: 隐式转换(implicit conversion): 自动执行的类型转换 举例: 1 int ival = 3.54 + 3; // 整型先被转换为double类型，然后在初始化过程中，根据初始化类型对象转换为声明类型 显式转换(explicit conversion): 4.11.1 算术转换 算术转换：在运算过程中，运算对象将转换成最宽的类型 整型提升： 把小整数类型转换成较大的整数类型 无符号类型的运算对象：(unsigned) 理解算术转换 4.11.2 其他隐式类型转换 数组转换成指针 指针的转换 转换成布尔类型 转换成常量 类类型定义的转换 4.11.3 显式类型转换 命名的强制类型的转换； static_cast、const_cast、reinterpret_cast、dynamic_cast（19.2节） static_cast: 任何具有明确定义的类型转换，只要不包含底层const，都可以用static_cast 1 double slope = static_cast\u0026lt;double\u0026gt;(j) / i; 当需要把一个较大的算术类型赋值给较小的类型时，可以用static_cast 可以使用static_cast找回存在于void*指针中的值 1 2 void *p = \u0026amp;d; double *dp = static_cast\u0026lt;double*\u0026gt;(p); const_cast:只能改变运算对象的底层const，只改变表达式的常量属性 1 2 const char* pc; char* p = const_cast\u0026lt;char*\u0026gt;(pc); // 正确，但是通过p写值是未定义的 reinterpret_cast: 为运算对象的位模式提供较底层次的重新解释 4.12 运算符优先级表 chapter 6 函数 6.1 函数基础 6.1.1 局部对象 名字有作用域，对象有生命周期 名字的作用域是程序文本的一部分，名字在其中可见； 对象的生命周期是程序执行过程中该对象存在的一段时间； 自动对象: 当函数的控制路径经过变量定义语句时创建该对象，在到达定义所在块末尾时销毁它 局部静态对象: 局部变量的生命周期贯穿在函数调用及之后的时间 可以将局部变量声明成: static size_t a = 0; 6.1.2 函数声明 函数只能定义一次，但可以声明多次； 在头文件中声明，在源文件中定义。 6.1.3 分离式编译 链接和编译多个源文件 6.2 参数传递 每次函数调用都会创建形参，然后用对应的实参初始化形参 引用传递(pass by reference): 绑定到对应的形参上 值传递(pass by value): 将实参的值拷贝后赋给形参 6.2.1 传值参数 使用传值参数，对变量的带动不会影响初始值； 指针形参: 执行指针拷贝时，拷贝的是指针的值，拷贝之后两个指针是不同的指针 指针形参的行为类似: 拷贝后，改变指针(实参)的值，不改变地址，因为指针拷贝只是创建了一个地址不同的指针，但是指向对象的值一样，可以通过指针改变 6.2.2 传引用参数 引用作用于引用所引用的对象本身； 使用引用避免拷贝 使用引用形参返回额外信息：将变量作为引用传入，然后再函数调用过程中对值进行修改，最后隐式返回 1 2 3 4 5 6 string::size_type find_char(const string \u0026amp;s, char c, string::size_type \u0026amp; occurs) { ... ++occurs; ... return ret; } 6.2.3 const形参和实参 要注意： 顶层const作用于对象本身； 1 2 3 4 const int ci = 42; // 不能改变ci，const 是顶层 int i = ci; // 当拷贝ci时，忽略顶层const int * const p = \u0026amp;i; // const是顶层，不能给p赋值 *p = 0; // 正确: 通过p改变对象的内容是允许的，现在i变成了0 指针或引用形参与const 尽量使用常量引用，不能在函数中改变它的值 6.2.4 数组形参 数组的两个性质: 1. 不允许拷贝数组 2. 使用数组时会将其转换成指针； 不能以值传递的方式使用数组参数； 管理指针形参有三种常用的技术 使用标记制定数组长度 使用标准库规范 显示传递一个表示数组的形参 void print(cosnt int ia[], size_t size) 数组形参和const 数组引用形参：允许将变量定义成数组的引用void print(int (\u0026amp;arr)[10]) 传递多维数组 6.2.5 main: 处理命令行选项 1 int main(int argc, char* argv[]) {} 第一个形参argc表示数组中字符串的数量，第二个形参是一个数组，元素是指向C风格字符串的指针。 6.2.6 含有可变形参的函数 无法预知向函数传递几个参数，可以进行输入可变形参 1.如果实参类型相同，可以传入initializer_list 如果类型不同，可以编写可变参数模板(16.4 - 618) initializer_list： 1 initilizer_list\u0026lt;string\u0026gt; ls; initializer_list对象中的元素永远是常量值，无法修改\n省略符形参: 只能出现在形参列表的最后一个位置 1 void foo(parm_list, ...) 6.3 返回类型和return语句 6.3.1 无返回值函数 没有返回值的return语句只能用在返回类型是void的函数中 6.3.2 有返回值函数 值是如何被返回的：返回的值用于初始化调用点的一个临时量，该临时量就是函数调用的结果。返回时，返回值被拷贝到调用点。\n不要返回局部对象的引用或者指针：函数结束以后，局部变量内存被释放，因此，引用或者指针无效。\n返回类类型的函数和调用运算符：\n引用返回左值：调用一个返回引用的函数得到左值，其他返回类型得到右值。\n1 2 3 4 5 6 7 8 9 10 char \u0026amp;get_val(string\u0026amp; str, string::size_type ix) { return str[ix]; } int main() { string s(\u0026#34;a value\u0026#34;); cout \u0026lt;\u0026lt; s \u0026lt;\u0026lt; endl; get_val(s, 0) = \u0026#39;A\u0026#39;; cout \u0026lt;\u0026lt; s \u0026lt;\u0026lt; endl; return 0; } 如果返回类型是常量引用，那么不能给调用结果赋值 列表初始化返回值：(C++11) 函数可以返回花括号包围的值的列表。\n主函数main的返回值\n允许main函数没有return语句，直接结束(如果控制到达了main函数的结尾处且没有return语句，编译器将隐式地插入一条返回0的return语句) 返回0表示执行成功，其他表示执行失败。 递归 (recursive function): 函数调用其自身\n递归函数必须含有终止条件，否则将不断调用直到程序栈空间耗尽为止 6.3.3 返回数组指针 因为数组不能被拷贝，因此函数不能返回数组，不过可以返回数组的指针或者引用； 声明一个返回数组指针的函数 返回数组指针的函数，后面必须跟着数组的维度 1 2 // Type (*function(parameter_list)) [dimension] int (*func(int i))[10] // 解引用func的调用将得到一个大小是10的数组，其元素类型为int 使用尾置返回类型 1 auto func(int i) -\u0026gt; int(*)[10]// 返回一个指针，指针指向含有10个整数的数组 使用decltype：如果我们知道函数返回的指针将指向哪个数组，就可以使用decltype关键字声明返回类型 1 2 3 4 5 6 int odd[] = {1,3,5,7,9}; int even[] = {0,2,4,6,8}; //返回一个指针，该指针指向含有5个整数的数组 decltype(odd) *arrPtr(int i) { // 用decltype表示返回的类型是一个指针 return (i % 2) ? \u0026amp;odd : \u0026amp;even; } 6.4 函数重载 同一作用域内，函数名字相同但是形式列表不同，称之为函数重载。 定义重载函数 判断两个形参的类型是否相异 重载和const重载 顶层const不影响传入函数的对象，一个拥有顶层const的形参无法和另一个没有顶层const的形参区分开来 如果形参是指针或者引用，可以通过区分其指向的是常量对象还是非常量对象实现函数重载，此时的const是底层const const_cast和重载: 通过const_cast实现常量引用和非常量引用之间的转换 1 2 const_cast\u0026lt;const string\u0026amp;\u0026gt; const_cast\u0026lt;string\u0026amp;\u0026gt; 调用重载函数 调用重载函数有可能的三只结果 编译器找到一个和实参最佳匹配的函数 找不到任何一个与调用实参匹配的函数，发出no match的错误信息 有多于一个函数可以匹配，但都不是最佳调用，此时发生错误，成为二义性调用(ambiguous call) 6.4.1 重载与作用域 在不同的作用域内无法重载函数名 6.5 特殊用途语言特性 6.5.1 默认实参 使用默认实参调用函数 默认实参声明 一个形参只能被赋予一次默认实参 形参右侧的所有形参必须都有默认值 默认实参初始值 局部变量不能作为默认实参，除此之外，只要表达式的类型能转换成形参所需的类型，该表达式就能作为默认实参 6.5.2 内联函数和constexpr函数 内联函数：将函数指定为内联，通常是将函数“内联地”展开，消除函数的运行时开销； constexpr函数：指能用于常量表达式的函数。 定义cosntexpr函数：函数的返回类型以及所有形参类型都是字面值类型，且函数体中只有一条return语句 举例： 1 2 constexpr int new_sz() {return 42;} constexpr int foo = new_sz(); 编译器把对constexpr函数的调用替换成其结果值，constexpr函数被隐式地指定为内联函数 把内联函数和constexpr函数放在头文件中 6.5.3 调试帮助 assert 和 NDEBUG assert预处理宏 assert (expr); 首先对expr求值，如果表达式为假（0），assert输出信息并终止程序的执行；如果为真，assert什么也不做 和预处理变量一样，宏名字在程序内必须唯一 NDEBUG预处理变量 assert依赖于NDEBUG，如果定义了NDEBUG，则assert什么也不做，如果没有定义，assert执行运行时检查。 如果NDEBUG未定义，将执行#ifndef和#endif之间的代码 1 2 3 4 5 6 7 // example void print(cosnt int ia[], size_t size) { #ifndef NDEBUG // __func__ cerr \u0026lt;\u0026lt; __func__ \u0026lt;\u0026lt; \u0026#34;: array size is \u0026#34; \u0026lt;\u0026lt; size \u0026lt;\u0026lt; endl; # endif } 对于程序调试有用的名字: __func__: 输出当前调试函数的名字 __file__: 存放文件名的字符串字面值 __line__: 存放当前行号的整型字面值 __time__: 存放文件编译时间的字符串字面值 __data__: 存放文件编译日期的字符串字面值 6.6 函数匹配 确定候选函数和可行函数 候选函数：1.与被调用函数同名 2. 函数声明在调用点可见； 可行函数：1.形参与实参数量相同 3. 类型相同或者可以相互转换； 寻找最佳匹配：形参与实参类型越接近越好 含有多个形参的函数匹配 6.6.1 实参类型转换 需要类型提升和算术类型转换的匹配 函数匹配和const实参 6.7 函数指针 chapter 7 类 7.1 定义抽象数据类型 7.1.1 设计Sales_data类 7.1.2 定义改进的Sales_data类 7.1.3 定义类相关的非成员函数 7.1.4 构造函数 7.1.5 拷贝、赋值和析构 chapter 12 动态内存 12.1 动态内存与智能指针 动态内存通过new和delete来管理 new: 在动态内存中为对象分配空间并返回一个指针 delete: 接受一个动态对象的指针，销毁该对象，并释放与之关联的内存 为什么引入智能指针? 为了防止内存泄露，智能指针能够自动释放所指对象 shared_ptr 和 unique_ptr区别 shared_ptr: 允许多个指针指向同一个对象 unique_ptr: “独占”所指对象 12.1.1 shared_ptr类 12.1.2 直接管理内存 12.1.3 shared_ptr 和 new 结合使用 12.1.4 智能指针和异常 12.1.5 unique_ptr 12.1.4 weak_ptr chapter 15 面向对象程序设计 15.1 OOP:概述 面向对象的核心思想数据抽象、继承和动态绑定\n2.2.2 ","permalink":"https://jianye0428.github.io/en/posts/notes/c++/2022-11-05_c++_primer/","summary":"2.4 2.4.2 指针和const const指针 常量指针(const pointer)：必须初始化，存放在指针中的地址的值不能改变 1 2 int *const curRrr = \u0026amp;errNumb; const double *const pip = \u0026amp;pi;","title":"C++_PRIMER Notes"},{"content":"ref: [1]. https://www.changping.me/2022/04/10/ai-distributed-training-coll-topo/\n1. 概述 在深度学习的分布式训练里，Ring AllReduce拓扑算法奠定了数据并行训练的集合通信基础，但集合通信拓扑不只是仅有Ring Allreduce，经典的集合通信拓扑算法还有2D-Ring/Hierarchical Ring AllReduce，halving and doubling AllReduce，Butterfly AllReduce，2D-Torus AllReduce，2D-Mesh AllReduce，double binary tree等。拓扑算法很多，但也不是所有的拓扑算法都能满足实际的生产需求的，这需要具体问题具体分析、具体场景具体设计。\n集合通信的难点在于需要在固定的网络互联结构的约束下进行高效的通信，集合通信拓扑算法与物理网络互联结构强相关，为了发挥网络通信的效率，也不是说就能随意发挥通信拓扑算法，更多的是在效率与成本、带宽与时延、客户要求与质量、创新与产品化等之间进行合理取舍。\n充分发挥训练加速卡与网络的效率是通信拓扑算法的初衷，但除了设计高效的集合通信拓扑算法外，分布式训练中需要解决的通信难题还有：网络是异构的，网络带宽是有限的，主机内PCIE SWITCH是有亲和性的，网络是会出故障的，节点是有落后者效应的，设备成本是需要考虑的，数据中心是有部署约束的，用户是有多租户要求的等，这些属于产品化的范畴不在本文阐述。\n2. 网络互联结构 分布式训练的集合通信拓扑算法与物理的网络互联结构强相关，而网络互联结构又多种多样，因此，本文需要先对网络互联结构进行约束，依据生产中常用的、既定的互联结构设计集合通信算法，网络互联结构描述如下：\n2.1 服务内网络互联结构 以一台集成了8张训练加速卡的服务器为例，如下图:\n这台服务器内的网络互联情况如下：\n1）在这台服务器内，8张训练加速卡通过私有协议连接组成多个主机内的物理ring环，且可双工；\n2）服务期内网络带宽 NVLINK\u0026gt;PCIE switch \u0026gt; QPI；\n3）加速卡1、2、3、4之间两两全互联，加速卡5,、6、7、8之间两两全互联，2、5、3、8之间非全互联；\n4）加速卡1、4与网卡NIC1 挂在同一个PCIE Switch上，具有亲和性，加速卡2、3与网卡NIC2挂在同一个PCIE Switch上，具有亲和性，而PCIE Switch之间也互联，因此 加速卡 1、2、3、4 与网卡NIC 1、NIC2具备亲和性，它们无需通过CPU的QPI线进行通信；\n5）加速卡5、8与网卡NIC3 挂在同一个PCIE Switch上，具有亲和性，加速卡6、7与网卡NIC4挂在同一个PCIE Switch上，具有亲和性，而PCIE Switch之间也互联的，因此 加速卡 5、6、7、8 与网卡NIC 3、NIC4具备亲和性，它们也无需通过CPU的QPI线进行通信；\n6）网卡可根据需要 选择 1张、2张、4张或8张，最多可以采用8张RDMA物理网卡；\n2.2 服务器间网络互联结构 以一个训练加速卡集群为例，如下图是一个常用的CLOS互联架构方案:\n在这个集群内，其网络互联情况如下：\n1）集群内每台服务器自带高速RDMA网卡，通过RDMA 交换机在主机间两两全互联；\n2）交换机组成CLOS架构，分为Spine与Leaf交换机，当然也可以是更为高端的Spine、Leaf合一的高端交换机；\n3）RDMA网卡与Leaf交换机互联，每台服务器的RDMA网卡数量根据成本与性能考虑，可以是1张、2张+每卡虚拟化4卡、4张+每卡虚拟化2卡或8张；\n2.3 高速网卡及其虚拟化使用 RDMA网卡是双工的且可虚拟化，在这里每台服务器可根据成本、性能的考虑选用1张、2张、4张或8张，且在服务器内左右对称，如下图：\n从成本与效率的角度考虑，每台服务器内的网卡可以是以下配置：\n1张物理RDMA网卡，不进行虚拟化，直接用双工通道，适合选用2D/Hierarchical Ring拓扑算法； 2张物理RDMA网卡，可以每张虚拟化出4个虚拟网卡，2X4共8卡，适合选用2D-MESH、2D-Torus拓扑算法； 4张物理RDMA网卡，可每张虚拟化出2个虚拟网卡，4X2共8卡，适合选用2D-MESH、2D-Torus拓扑算法； 8张物理RDMA网卡，不需要虚拟化，直接采用双工通道，适合选用2D-MESH、2D-Torus拓扑算法； 在实际的分布式训练生产集群中，集合通信算法也可以结合RDMA网卡端口（包括虚拟化的）的具体个数进行设计，而拓扑算法的选择也是需要根据成本与效率的进行合理取舍的。\n2.4 网络结构抽象 网络根据连接情况可分为ring结构、mesh结构、 torus 结构以及tree结构，基于以上的服务器内网络互联结构、服务器间网络互联结构以及网卡的具体情况，可以抽象出一个网络结构，即二维环面网络：Torus 网络，而Torus网络横向与纵向都可以看成ring结构，因此相应的拓扑算法基本上就是Ring-Based 集合通信拓扑算法。如下图：\nTORUS网络是常见的大规模并行计算机的互连网络，在上图这个Torus网络里：\n1）横向：主机内8卡通过私有连接协议，比如CXL/CCIX/NVLINK等组成一个或多个ring，如上图的黄色连接线，横向8卡组成二维Torus的横向维度；\n2）纵向：主机间通过RDMA（RoCE/IB）网卡、交换机互联组成1到8个ring，如上图的红色连接线，纵向采用RDMA网卡组成二维Torus的纵向维度；\n3）根据物理网卡数量、网卡虚拟化以及PCIe Switch亲和性的实际情况：\n每台服务器1张网卡可组成主机间一个ring，网卡与XPU0 挂载同一个PCIE switch上，依据最佳实践原则（比如性能、成本、客户要求等），适合选用2D/Hierarchical Ring拓扑算法； 两张网卡可组成主机间两个ring或者经过虚拟化组成8个ring，根据PCIE SWITCH亲和性原则，一张网卡与XPU0挂在同一个pcie switch，另一张网卡与XPU4挂在同一个pcie switch，依据最佳实践原则（比如性能、成本、客户要求等），适合选用2D-MESH、2D-Torus拓扑算法； 4张网卡、8张网卡以此类推，也是根据PCIE SWITCH亲和性原则进行连接，主机间RDMA物理网卡不够就虚拟化网口来凑，并且要服务器内的RDMA出口端口数左右平衡，依据最佳实践原则（比如性能、成本、客户要求等），也是适合选用2D-MESH、2D-Torus拓扑算法，这样才能发挥多张网卡以及XPU的算力优势。 4）更复杂的Torus网络组合关系还可以如下图，从横向只有 主机内的8卡纵向只有主机间的RDMA互联，扩展到 横向与纵向 主机内互联与主机间互联混合，但本文仅限于在横向8卡的二维Torus网络下进行拓扑算法选择与设计，因此不展开讲述。\n3. 常用的通信拓扑算法 Torus 网络结构可以解读本文中的物理网络互联结构的一切，而Torus网络的横向与纵向都可以看成ring结构，因此，相应的集合通信拓扑算法都可以看成是Ring-Based 集合通信拓扑算法。\n3.1 Ring AllReduce 在分布式训练中，Ring 是最基础的互联结构，在本文中Ring AllReduce的应用场景是在服务器内将8张加速卡组环通信进行分布式训练。每个XPU都是这个主机内互联环上的一个计算节点，每个节点都有一个前向和一个后向，它只会向它的前向接收数据，并向它的右向发送数据，如下图所示，8张XPU 通过主机内的私有互联网络组成一个环，当然因为这些通信网络是双工的，这8张XPU训练加速卡也可以看成是通过多个逻辑环互联起来的，同时缺点是，如果这个ring太大，Ring Allreduce的效率也会变得很低。\nRing Allreduce 有两种组合实现策略： 1）先Reduce后broadcast； 2）先ScatterReduce后AllGather，这两个策略执行后都会让每个XPU节点得到一样的平均梯度，如下图所示：\n3.1.1 Reduce +broadcast 在Reduce + broadcast里，reduce先将8张卡的梯度reduce sum到master节点 XPU0 上，再通过broadcast将这个总的平均梯度复制给其他XPU，如下图：\nReduce + broadcast这种策略有几个比较大的缺点： 1）8张卡的数据都reduce sum到一张卡，假设每张卡的梯度是100MB，8张卡就是800MB，这可能存在XPU 0计算很久，而其他7张卡空闲的情况存在，整体效率不高； 2）XPU0 的网络带宽可能会成为瓶颈，8张卡的数据都只能通过XPU0的互联网络进行reduce和broadcast，在数据量比较大的场景 XPU0的带宽成为瓶颈； 3）8张XPU不都是两两全互联的，因此，要把8张卡的数据一次Reduce或broadcast，这一点受限于网络互联条件做不到，那么就需要采用 ring或tree的策略进行reduce或broadcast，这样效率也不高。\n3.1.2 ScatterReduce + AllGather Ring AllReduce 的Ring ScatterReduce + Ring AllGather策略组合里，每个 XPU只会从前向接受数据，并发送数据给后向，其算法主要分为：\nScatterReduce：这一步会先scatter拆分数据块再进行reduce，并且在执行完毕后，每张XPU都会包括一个完整的经过融合的同维梯度； AllGather：这一步会进行全局Gather同步，最后所有 XPU都会得到完整的大的整个梯度； Ring ScatterReduce + Ring AllGather是效率比较高的 Ring AllReduce 组合策略，这个策略考虑到了XPU上的梯度可能很大的情况，比如一个梯度有400MB，在scatterreduce阶段就会先被拆分成 ring上XPU个数份，比如主机内XPU个数等于8，那么 这400MB 就会被 拆分成8份，每份50MB，从而减少了加速卡的计算量以及节约带宽。此外，scatterReduce通过将数据拆分成小块，同时并发进行scatterReduce，从而将通信时间隐藏在计算时间内进而提高Ring AllReduce的效率。\n3.1.2.1 ScatterReduce 首先， ScatterReduce先将梯度拆分为N个更小的块，N等于ring里XPU个数，8张卡就拆分成8份，然后进行N-1次scatterreduce迭代。在第一轮迭代中XPU 0上的A0传递给XPU1上A1并相加，XPU1上的B1传递给XPU2上的B2并相加，XPU 2上的C2传递给XPU3上C3并相加，XPU3上的D3传递给XPU4上的D4并相加，以此类推，过程如下图左侧：\n接下来，XPU还会进行N-2次 ScatterReduce 迭代，在每次迭代过程中，XPU都会从前向接收一个小梯度块并累加到自己的梯度块中，并且也会向其后向发送一个小梯度块，每个XPU接收和发送的小梯度块在每次迭代中都是不同的，这样经过迭代，到最后，每个XPU将有一个完整的同维梯度，该块梯度中包含所有XPU中该块对应的所有梯度的总和，如上图右侧的累加和部分。\n3.1.2.2 Allgather 在scatterReduce迭代完成之后，每个XPU都会得到一个同维度的完整的梯度累加值，将这些完整的累加值复制到其他的加速卡后，才算完成allReduce。Allgather的迭代次数与scatterReduce是相同的，也都需要进行N-1次（N是ring上的XPU卡数）迭代，但是不同于ScatterReduce的是allGather没有reduce的过程，只有数值的复制。这样迭代到最后，每个XPU都得到大的拆分前的梯度的完整累加值，如下图演示了这一过程，从第一次迭代开始，到最后AllGather拿到整体的结果。这里头的具体过程就不在这里描述了，可以查相关资料。\nRing AllReduce 实现简单，在ring较少时，效率也较高，但是在ring比较大时需要的网络节点跳数变得比较大，通信时延增加，因此效率也会降低。比如，一个1000张XPU的 ring，这里头网络的跳数 是N-1= 1000-1 =999， 同时传输的过程中，传输效率还受效率最低、带宽最低的XPU的限制，这时网络上的时延会变得巨高，这个时候ring allreduce拓扑算法就变得不大适用这个场景，同时如果在异构网络里涉及网络的不同连接方式，Ring AllReduce也不大适合使用，因此就需要采用另外的更适合网络结构的更高效的集合通信拓扑算法来进行优化。\n3.2 2D-Ring AllReduce 如果一台2.1里的服务器只配置了一张RDMA网卡，每台服务器通过RDMA交换机互联，这个集群的网络是异构的（如下图），那么Ring AllReduce拓扑算法就不适用了，这个时候，对于这个网络拓扑结构比较适合的是2D-Ring AllReduce也叫Hierarchical Ring AllReduce。\n经过抽象，可以将这个网络结构表达成如下的Torus结构：\n横向：每台服务器8个XPU节点，每个XPU节点通过私有协议网络互联；\n纵向：每台服务器通过一张RDMA网卡NIC 0 通过交换机互联，这个网卡NIC0 与XPU0 挂在同一个PCIE switch上，满足具备亲和性条件，XPU0上的梯度可以通过NIC 0 与其他服务器上的XPU进行全局规约。\n2D-Ring AllReduce的过程如下图所示：\n第1步，先进行主机内Ring AllReduce，也可以是 Ring Reduce或者根据主机内的互联情况选用的分层reduce方式，将8张卡上的梯度累加到Master节点 XPU0 上；\n第2步，进行主机间XPU 0的 Ring AllReduce，将每台服务器的XPU0上的数据进行全局规约；\n第3步，进行主机内Broadcast，将XPU0上的梯度复制到服务器内的其他XPU上\n2D-Ring AllReduce能充分发挥异构网络的优势，将主机内、主机间的网络带宽充分利用起来。但是XPU的利用率也不是很高，比如在做主机间的Ring AllReduce，每台服务器内的其他7张XPU是处于空闲状态的。\n再假设，如果每台服务器配置了 2张/4张/8张RDMA网卡，这个时候 2D-RING AllReduce又难以将网络的优势发挥出来，那么就需要选用 2D-Torus/2D-Mesh AllReduce拓扑算法。\n3.3 2D-Torus AllReduce 考虑到服务器内PCIE SWITCH 的亲和性问题，2D-Torus至少需要配备2张 左右对称的RDMA网卡才能发挥这个拓扑算法的优势。在这个集群里主机内每张卡都通过私有的通信协议组成Ring，而主机间，可以通过RDMA网卡（包括虚拟化出来的）与RDMA交换机将XPU两两互联，这个网络也是异构的，如下图所示：\n经过抽象，可以将这个网络结构表达成如下的Torus结构：\n横向：每台服务器8个XPU节点，每个XPU节点通过私有协议网络互联； 纵向：每台服务器通过至少2张RDMA网卡NIC 0 /NIC 1通过交换机互联，这个网卡NIC0 与XPU0、1、2、3 挂在同一个PCIE switch上，具备亲和性条件，XPU0、1、2、3上的梯度数据可以通过NIC 0 与其他服务器上的XPU进行交换。网卡NIC1 与XPU4、5、6、7 挂在同一个PCIE switch上，具备亲和性条件，XPU4、5、6、7上的梯度数据可以通过NIC 1 与其他服务器上的XPU进行交换； 当然如果网卡是4个或者8个，也可以根据PCIE SWITCH的亲和性情况合理安排XPU与NIC的对应关系。 2D-Torus AllReduce的过程如下图所示：\n第1步，横向，先进行主机内Ring ScatterReduce，将主机内8张卡上的梯度进行拆分与规约，这样经过迭代，到最后每个XPU将有一个完整的同维梯度，该块梯度包含所有XPU中该块所对应的所有梯度的总和（参考3.1.2.1 scatterReduce)\n第2步，纵向，进行主机间N个（N等于服务器内XPU个数，这里是8个）纵向的 Ring AllReduce，将每台服务器的XPU0-XPU7上的数据进行集群内纵向全局规约；\n第3步，横向，进行主机内AllGather，将XPUi(i=0-7)上的梯度复制到服务器内的其他XPU上；\n2D-Torus AllReduce能充分挖掘XPU的效率以及发挥异构网络里多网卡的优势，将XPU以及主机内、主机间的网络带宽优势充分利用起来。此外，除了 2D-Torus AllReduce外，2D-Mesh AllReduce也能发挥类似效率。\n3.4 2D-Mesh AllReduce 2D-Mesh AllReduce的主要思想也是分层，与2D-Torus AllReduce类似，都是水平和垂直两个方向，但是有点差异，如下图所示：\n不同于2D-Torus AllReduce的拓扑算法，2D-Mesh AllReduce 过程是：\n第1步，横向，先进行主机内Ring AllReduce 将主机内的8张XPU的梯度都进行规约；\n第2步，纵向，进行主机间N个（N等于主机内XPU个数，这里是8个）纵向的 Ring AllReduce；\n经过这两步，完成了整体的梯度累加，2D-Mesh AllReduce 也能充分发挥XPU与多网卡异构网络的优势，将XPU与主机内、主机间的网络带宽优势充分利用起来。这里的2D-Mesh与Google论文上的有点差异，主要是吸取了其分层的思想而不是复制其一样的设计。理论上2D-Mesh AllReduce对比 2D-Torus AllReduce，主机间AllReduce用的是 主机内8卡的全局梯度，数据量会比ScatterReduce部分来的大点，因此效率也会相应降低一点。\n4. 问题探讨 如下图所示，基于Torus网络的结构，组合Ring AllReduce，2D-Ring AllReduce, 2D-Mesh AllReduce，2D-Torus AllReduce还能构建 3D-Ring/Mesh/Torus AllReduce拓扑算法，但是这些拓扑算法的效率需要进行实践才能证实，也许在规模较大的集群里才能发挥出3D 拓扑算法的优势。\n关于 3D-Ring/Mesh/Torus AllReduce的拓扑算法，这里就不在阐述，可作为研究使用。\n5. 小结 本文讲述了分布式训练里最常用的几个网络结构以及通信拓扑算法：\nRing AllReduce 的最佳组合是 ScatterReduce + AllGather； 2D-Ring AllReduce = 主机内 ringAllReduce/Ring Reduce +主机间 RingAllReduce + 主机内Broadcast； 2D-Torus AllReduce = 主机内 Ring ReduceScatter + 主机间N个Ring AllReduce + 主机内Ring AllGather； 2D-Mesh AllReduce = 主机内Ring AllReduce + 主机间N个Ring AllReduce; Ring AllReduce适合主机内互联Ring的情况使用，2D-Ring AllReduce适合一台服务器配置了一张网卡的异构网络场景，2D-Torus AllReduce与2D-Mesh AllReduce适合一台服务器配置了2/4/8张网卡的异构网络场景。\n集合通信拓扑算法多种多样，但基于成本以及效率的取舍考虑，可生产适用的其实也不多，除了理论上的理解之外更重要的是自己编写代码去实践落地。除此之外，还需要解决网络带宽有限、网络容易出故障、落后者效应、部署约束、多租户等产品化的质量要求。\nREF: [1] https://www.changping.me\n[2] 《volta-architecture-whitepaper》\n[3] 2D-HRA: Two-Dimensional Hierarchical Ring-based All-reduce Algorithm in Large-Scale Distributed Machine Learning\n[4] Massively Distributed SGD: ImageNet/ResNet-50 Training in a Flash\n[5] https://zhuanlan.zhihu.com/p/79030485 , 腾讯机智团队分享–AllReduce算法的前世今生\n[6] https://zhuanlan.zhihu.com/p/370548366, ring allreduce和tree allreduce的具体区别是什么？\n[7] https://zhuanlan.zhihu.com/p/184942777 , 分布式深度学习初探\n[8] https://arxiv.org/abs/1811.06992 ， Image Classification at Supercomputer Scale\n","permalink":"https://jianye0428.github.io/en/posts/tech/distributedtraining/2022-11-01_distributedtraining_4/","summary":"ref: [1]. https://www.changping.me/2022/04/10/ai-distributed-training-coll-topo/ 1. 概述 在深度学习的分布式训练里，Ring AllReduce拓扑算法奠定了数据并行训练的集合通信基础，但集合通信拓扑不只是仅有Ring A","title":"分布式训练 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法"},{"content":"ref: [1]. https://zhuanlan.zhihu.com/p/493092647\n概述 集合通信（Collective Communications）是一个进程组的所有进程都参与的全局通信操作，其最为基础的操作有 发送send、接收receive、复制copy、组内进程栅障同步Barrier以及节点间进程同步(signal+wait)，这几个最基本的操作经过组合构成了一组通信模板也叫通信原语，比如：1对多的广播broadcast、多对1的收集gather、多对多的收集all-gather、1对多的发散scatter、多对1的规约reduce、多对多的规约all-reduce、组合的规约与发散reduce-scatter、多对多的all-to-all等，集合通信的难点在于通信效率以及网络硬件连接拓扑结构的最佳适用。\n通信原语 以一台集成了4张训练加速卡的服务器为例，如下图，服务器内四张训练加速卡是全连接的，物理连接方式可以是私有物理互联协议，比如CXL、NVLINK，也可以是PCIe、InfiniBand、Ethernet等，本文将以此物理拓扑结构描述集合通信中常用的几组通信原语。\nBroadcast Broadcast属于1对多的通信原语，一个数据发送者，多个数据接收者，可以在集群内把一个节点自身的数据广播到其他节点上。如下图所示，圈圈表示集群中的训练加速卡节点，相同的颜色的小方块则代表相同的数据。当主节点 0 执行Broadcast时，数据即从主节点0被广播至其他节点。\nBroadcast是数据的1对多的同步，它将一张XPU卡上的数据同步到其他所有的XPU卡上，其应用场景有：\n1）数据并行的参数初始化，确保每张卡上的初始参数是一致的；\n2）allReduce里的 broadcast + reduce组合里的broadcast操作；\n3）分布式训练parameter server 参数服务器结构里的 master节点 broadcast 数据到worker节点，再从worker节点reduce数据回master节点里的broadcast操作；\nScatter 同Broadcast一样，Scatter也是一个1对多的通信原语，也是一个数据发送者，多个数据接收者，可以在集群内把一个节点自身的数据发散到其他节点上。与Broadcast不同的是Broadcast把主节点0的数据发送给所有节点，而Scatter则是将数据的进行切片再分发给集群内所有的节点，如下图所示，不相同的颜色的小方块代表不相同的数据，主节点 0 将数据分为四份分发到了节点0-3。\nScatter是数据的1对多的分发，它将一张XPU卡上的数据进行分片再分发到其他所有的XPU卡上，他的反向操作对应Gather，其应用场景有: 1）ReduceScatter组合里的 Scatter操作； 2）模型并行里初始化时将模型scatter到不同的XPU上；\nGather Gather操作属于多对1的通信原语，具有多个数据发送者，一个数据接收者，可以在集群内把多个节点的数据收集到一个节点上，如下图所示，不相同的颜色的小方块代表不相同的数据。\nGather是数据的多对1的收集，它将多张XPU卡上的数据收集到1张XPU卡上，他的反向操作对应Scatter，其应用场景有：\n1）ReduceScatter组合里的 Scatter操作；\nAllGather AllGather属于多对多的通信原语，具有多个数据发送者，多个数据接收者，可以在集群内把多个节点的数据收集到一个主节点上（Gather），再把这个收集到的数据分发到其他节点上（broadcast），即收集集群内所有的数据到所有的节点上。\nAllGather是数据的多对多的同步全收集，它将多张XPU卡上的数据收集到多张XPU卡上，可以看做Gather + Broadcast的操作组合，它的反向操作对应ReduceScatter，其最应用场景有：\n1） AllGather可应用于模型并行；\n2）模型并行里前向计算里的参数全同步，需要用allgather把模型并行里将切分到不同的XPU上的参数全同步到一张XPU上才能进行前向计算。\nReduce Reduce属于多对1的通信原语，具有多个数据发送者，一个数据接收者，可以在集群内把多个节点的数据规约运算到一个主节点上，常用的规约操作符有：求累加和SUM、求累乘积PROD、求最大值MAX、求最小值MIN、逻辑与 LAND、按位与BAND、逻辑或LOR、按位或BOR、逻辑异或LXOR、按位异或BOXR、求最大值和最小大的位置MAXLOC、求最小值和最小值的位置MINLOC等，这些规约运算也需要加速卡支持对应的算子才能生效。\nReuduce操作从集群内每个节点上获取一个输入数据，通过规约运算操作后，得到精简数据，如下图的SUM求累加和：节点0数值 5、节点1数值6、节点2数值7、节点3数值8，经过SUM运算后 累积和为 26，即得到更为精简的数值，在reduce原语里回会去调用 reduce SUM算子来完成这个求和累加。\nReduce是数据的多对1的规约运算，它将所有张XPU卡上的数据规约（比如SUM求和）到1张XPU卡上，其应用场景有：\n1）AllReduce里的 broadcast + reduce组合里的reduce操作；\n2）ReduceScatter组合里的 reduce操作；\n3）分布式训练parameter server 参数服务器结构里的 master节点 broadcast 数据到worker节点，再从worker节点reduce数据回master节点里的reduce操作；\nReduceScatter ReduceScatter属于多对多的通信原语，具有多个数据发送者，多个数据接收者，其在集群内的所有节点上都按维度执行相同的Reduce规约运算，再将结果发散到集群内所有的节点上，Reduce-scatter等价于节点个数次的reduce规约运算操作，再后面执行节点个数的scatter次操作，其反向操作是AllGather。\n如下图所示，先reduce操作 XPU 0-3的数据reduce为 A(A0+A1+A2+A3) + B(B0 + B1 +B2 + B3) + C(C0 + C1 + C2 + C3) + D(D0 + D1 + D2 + D3 ) 到一张XPU上，再进行分片scatter到集群内所有的XPU卡上。\nReduceScatter是数据的多对多的reduce + scatter运算，它将所有的XPU卡上的数据先规约（比如SUM求和）到1张XPU卡上，再进行scatter，其应用场景有：\n1）ReduceScatter即可应用于数据并行也可应用于模型并行；\n2）数据并行allReduce里的 ReduceScatter+ Allgather组合里的ReduceScatter操作；\n3）模型并行里在前向allgather后的反向计算里的ReduceScatter；\nAllReduce AllReduce属于多对多的通信原语，具有多个数据发送者，多个数据接收者，其在集群内的所有节点上都执行相同的Reduce操作，可以将集群内所有节点的数据规约运算得到的结果发送到所有的节点上。AllReduce操作可通过在主节点上执行Reduce + Broadcast或ReduceScatter + AllGather实现，如下图所示：先在主节点上执行reduce得到规约累加和26，再把这个累加和26 broadcast到其他的节点，这样整个集群内，每个节点的数值就都保持一致。\nAllReduce是数据的多对多的规约运算，它将所有的XPU卡上的数据规约（比如SUM求和）到集群内每张XPU卡上，其应用场景有：\n1） AllReduce应用于数据并行；\n2）数据并行各种通信拓扑结构比如Ring allReduce、Tree allReduce里的 allReduce操作；\nAll-To-All All-To-All操作每一个节点的数据会scatter到集群内所有节点上，同时每一个节点也会Gather集群内所有节点的数据。ALLTOALL是对ALLGATHER的扩展，区别是ALLGATHER 操作中，不同节点向某一节点收集到的数据是相同的，而在ALLTOALL中，不同的节点向某一节点收集到的数据是不同的，如下图所示:\nAllToAll是数据的多对多的转置，它将所有张XPU卡上的数据转置到所有的XPU卡上，其主要应用场景有：\n1） AllToAll应用于模型并行；\n2）模型并行里的矩阵转置；\n3）数据并行到模型并行的矩阵转置；\nSend 与 Receive 数据或参数在不同XPU之间的发送与接收。\nBarrier BARRIER同步操作会阻塞所有的调用者直到所有的组内成员都调用了它， 用于一个集合通信子中所有进程的同步，调用函数时进程将处于等待状态，直到通信子中所有进程 都调用了该函数后才继续执行。\nSignal与Wait Signal与Wait属于记录型信号量机制： wait(s)，signal(s)可用于解决进程间的同步问题，在通信原语里从一个节点发送一个数据到另外一个节点时，会同时signal一个event值到对端，对端的wait操作接收到这个event时会返回一个确认给signal，这样保证在节点的进程间进行数据的同步操作。\n小结 在分布式训练过程中，深度学习训练框架不会去直接操作底层的通信网络，而是通过使用网络通信库来完成数据的集合通信，各家AI芯片加速卡厂家都会提供私有的网络通信库比如：xxx-AWARE OpenMPI或xCCL来完成这个底层通信硬件的屏蔽与抽象。在分布式训练集群里网络通信硬件连接样式多种多样，可以是Ethernet、InfiniBand 、RoCE v2/v1 等也可以是CXL、NVLINK等私有协议，这就要求在通信的后端层根据各个厂家的自己的SDK开发库接口，根据实际情况实现 各自的网络通信库，比如cuda-aware MPI、NCCL、NVSHMEM，以及根据实际的网络拓扑组合完成对应的最有效的网络拓扑算法。\n本文讲述了分布式训练里的集合通信原语，这些原语是集合通信拓扑算法的基本组成单元，后续的文章里会讲述如何组合这些通信原语以完成合适的通信拓扑算法。\n","permalink":"https://jianye0428.github.io/en/posts/tech/distributedtraining/2022-10-31_distributedtraining_3/","summary":"ref: [1]. https://zhuanlan.zhihu.com/p/493092647 概述 集合通信（Collective Communications）是一个进程组的所有进程都参与的全局通信操作，其最为基础的操作有 发送se","title":"分布式训练 – 第3篇 - 集合通信及其通信原语"},{"content":"ref: [1]. https://zhuanlan.zhihu.com/p/492667659\n前言 不同于教科书里讲的深度学习的评价指标，这里主要讲述生产训练中常用的评价指标。通常在分布式训练中对训练的过程与结果会进行评价，比如选择一个评价指标：准确率，即表明模型求解给定问题的准确度。而本文提到的评价指标主要分为两大类，即训练结果评价与训练系统评价。\n训练指标 教科书里经常提到的深度学习的评价指标有准确率、精确率、召回率、F1值等，如下：\n准确率（Accuracy），所有的预测正确（正类负类）的占总的比重； 精确率（Precision），查准率，即正确预测为正的占全部预测为正的比例； 召回率（Recall），查全率，即正确预测为正的占全部实际为正的比例； F1值（H-mean值），F1值为算数平均数除以几何平均数，且越大越好； 实际上这些指标在真正的生产过程中用的不多，在实际的分布式训练过程中，比较关心的训练评价指标有：\n加速比（speedup），即多卡训练下的单卡吞吐量平均指标除以单卡训练下的吞吐量平均指标，比如，大规模训练下的 ResNet-50 v1.5的单卡FPS指标是600，而单卡训练的FPS指标是800，那么加速比即 600/800 = 0.75，加速比体现的是训练集群的效率与可扩展性，越高的加速比表明训练集群的资源利用率越高，但是越高的加速比要求对训练集群的技术要求也越高。比如 一个 1000张卡的训练集群，要求 加速比 0.9以上，那么对于主机间的网络、主机内的网络、全栈软件、训练卡内部的硬件架构、集合通信拓扑算法、训练算法的优化等的要求都极高，这就涉及到整个分布式训练系统的问题，而不是单个点能彻底解决的； 吞吐量，sequence/sec 或 FPS, 即每秒能处理的图片数或数据量； 收敛时间（Time）与训练次数（epoch），生产过程中对训练所有的时间是有要求的，假设给定一个模型的训练次数(epoch)为100，如果要把这个100次都训练完需要 好几天，甚至好几个星期，那么可以认为生产不适用，基本上可以定义 训练一个模型到收敛需要 24小时以上，都可以看做是生产不适用，需要扩大训练集群的规模，使之训练时间控制在24小时之内； 平均准确率(eval Accuracy)，平均准确率是训练是否收敛的重要评判标准之一，比如定义一个 Resnet50 v1.5 的训练模型的准确率为 76%，如果训练结束的平均准确率能达到这个值就认为训练是收敛的； 可收敛，训练的最终结果可以达到 平均准确率的要求，即认为可收敛，否者即任务训练失败； 学习率(Learning rate)与损失率(Loss)，学习率大模型训练学习速度快，但是易导致损失率爆炸, 学习率小模型训练学习速度慢，而且容易过拟合，收敛速度慢； 曲线拟合(Curve Fitting)，这是一个非常重要的评价手段，在XPU训练的场景下，通常先用一个已有的之前训练好模型为基础或先用GPU训练出一个基础模型，然后把XPU训练的结果指标跟GPU训练模型的指标进行比较，曲线拟合即认为XPU的训练结果达标，这也是调试XPU训练结果的一个重要手段。这里埋一个问题，按照曲线拟合的说法，假设有一个2000张XPU卡的集群，怎样评价这个集群训练的结果是正确的？以GPU训练的结果做比较，那么找一个这么大规模的GPU集群进行训练然后得到想要的模型做基础匹配也是不大现实的，那么需要采用什么技术方案才能解决这个问题？ 以TensorBoard为例，说明模型的评价指标，在下面的命令行列输入一个baseline:/log_path_2：\n1 tensorboard --logdir=training_model:/log_path_1, baseline:/log_path_2 这个baseline 的模型已经确定是精度达标，生产可用的。然后 XPU训练的模型的 training_model:/log_path_1 与这个GPU训练处的baseline进行比，在tensorboard里可以表现如下图：\n在上图里，新的模型的eval_accuracy值与baseline的值最终是一样的，这说明训练结果是收敛且精度达标，eval_accuracy中间的线有点差异是由于按不同的训练次数进行tensorboard指标保存所造成。新模型的Loss线与Learning_rate 线也与基础线吻合，这说明XPU训练的模型质量可生产适用。eval_accuracy、Loss、Learning_rate是三个最重要的度量指标，只要这样三个指标达标，那么大概率即可判断这个在XPU下新训练的模型具备生产可用能力。\n系统指标 分布式训练系统其本身也是一个分布式系统，因此除了训练领域相关的度量指标，也有与分布式系统质量有关的一套度量指标，其中比较重要的几项内容如下：\n可用性(Availability)，可用性指的是分布式训练系统长时间可对外提供服务的能力，通常采用小数点后的9的个数作为度量指标，按照这种约定“五个九”等于0.99999（或99.999％）的可用性，默认企业级达标的可用性为6个9。但是当前从时间维度来度量可用性已经没有太大的意义，因为设计得好的系统可以在系统出现故障得情况下也能保证对外提供得服务不中断，因此，当前更合适得可用性度量指标 是请求失败率; 可靠性(Reliability)，可靠性一般指系统在一定时间内、在一定条件下可以无故障地执行指定功能的能力或可能性， 也是采用小数点后的9的个数作为度量指标，通常5个9的可靠性就可以满足企业级达标； 可伸缩性(Scalability)，是指通过向系统添加资源来处理越来越多的工作并且维持高质量服务的能力，其受可用性以及可靠性的制约，集群规模越大出故障的概率越高从而降低可用性、可靠性，为了保证可用性以及可靠性达标，需要适配合理的可伸缩性指标； 韧性(resilience)，通常也叫容错性（fault-tolerant），也就是健壮和强壮的意思，指的是系统的对故障与异常的处理能力，比如在软件故障、硬件故障、认为故障这样的场景下，系统还能保持正常工作的能力，分布式训练系统的容错能力是一个非常重要的指标。 小结 本文从实践的角度讲述了分布式训练的训练结果评价指标与系统评价指标，这些指标是度量一个分布式训练系统与训练的模型是否生产可用的重要参考。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。\n","permalink":"https://jianye0428.github.io/en/posts/tech/distributedtraining/2022-10-29_distributedtraining_2/","summary":"ref: [1]. https://zhuanlan.zhihu.com/p/492667659 前言 不同于教科书里讲的深度学习的评价指标，这里主要讲述生产训练中常用的评价指标。通常在分布式训练中对训练的过程与结果会进行评价，比如选","title":"分布式训练 – 第2章 - 训练与系统评价指标"},{"content":"ref: [1]. https://zhuanlan.zhihu.com/p/487945343\n前言 深度学习软件工程具有一体两面性：单卡的功能完备性、质量、用户体验以及多卡大规模。多卡大规模的出现是为了解决这样一个主要矛盾，即：“日益增长的数据、模型训练的需求与当前单卡计算能力无法满足这个需求之间的矛盾”，而分布式训练可以通过扩展卡子的规模解决这个矛盾，因此，这就是分布式训练的价值。\n然而，正如懂得很多道理，仍旧过不好这一生一样，懂得很多分布式训练的理论与知识，也不一定就能做好一个分布式训练系统。把这么多机器连接跑起来、跟跑好也是两回事，分布式训练是一门实践的软件工程，只有你PK过设计方案，调试过一个个Bug，手把手的敲过一行行的代码，为了性能指标能达标无所不用其极的去验证各种性能优化方案，才能知道细节在哪里，难点在哪里，痛点、挑战点在哪里。因此，宏观处着眼，微观处着手，才能完全理解分布式训练的道理。\n一个知识领域里的 “道 法 术 器” 这四个境界需要从 微观、中观以及宏观 三个角度来把握，微观是实践，中观讲方法论，宏观靠领悟。本系列文章我把它命名为《分布式训练》，从工程实战的角度拆解分布式训练里最重要的套路，也是从“微观实践、中观方法论、宏观领悟”这三个维度系统性的探讨分布式训练技术，本文讲述第一篇，也是最难讲清楚的一篇（后续保持迭代更新），即本质的一问：\u0026ldquo;什么是分布式训练\u0026quot;。\n什么是分布式训练 简单来说，分布式训练 = 分布式训练系统 = 分布式系统 + 训练系统，因此，要解答什么是分布式训练就需要解答什么是分布式系统以及什么是训练系统，而“系统 = 要素x连接 + 目的 + 边界”，因此进一步的就是需要分析分布式系统的要素、连接、目的与边界以及训练系统的要素、连接、目的与边界。\n分布式系统 在AI训练过程中采用单卡总会遇到一些问题，比如原始的数据样本太大无法加载进训练卡，或者模型太大无法训练，那么这就需要用到分布式技术把大量的数据分割成小块由多个训练卡分别进行计算，在更新运算结果后，再将结果统一合并得出最终的可用模型。百科上对分布式系统的定义有：\nA distributed system is a system whose components are located on different networked computers, which communicate and coordinate their actions by passing messages to one another. The components interact with one another in order to achieve a common goal.\n即：\n分布式系统是指其组件位于不同的网络计算机上的系统，这些组件通过相互传递消息来进行通信和协调其动作，且彼此相互交互以完成一个共同的任务目标。\n从这句话可以得出三个结论：\n分布式系统的组件是位于不同的网络计算机上的； 分布式系统的组件通过传递消息进行通信与协调的； 分布式系统的组件是通过相互交互以完成一个共同的任务目标，同时是有边界的； 因此基于此定义，拆解分布式系统的概念，从中可以看到分布式系统里的要素即为组件，连接即网络，目的是共同的任务目标。其中的位于不同的网络计算机上的“组件”是分布式系统的要素，即各种计算单元，比如Ai训练加速卡，“网络”是分布式系统的连接，即神经网与数据网，“共同的任务目标”是分布式系统的目的，即训练，至此，再进一步抽象，可以推导出分布式系统的公理化定义，也是分布式系统的本质理论定义：\n1 分布式系统 = 计算 x 网络 + 功能 + 边界 在这个公式里，计算即计算单元，是各种AI训练加速卡，比如GPU, TPU, DPU, DTU。网络即网络连接单元，在单个训练卡内为计算用的神经网，主机内的多个卡子之间是PCIE 以及PCIE Switch，以及各种高带宽通信网，比如GenZ,CXL,NVLINK,OpenCAPI,CCIX等，在主机之间是各种通信网络，比如RDMA网络、InfiniBand网络、普通的TCP网络以及对应的各种交换机，另外从磁盘 + 主机内存 + 训练卡的HBM这个IO路径我们认为属于IO网络，而这里的目的即训练，同时这个系统是有边界的，其专注于解决Ai训练过程中的难题，不是什么功能都能往里塞都能解决的。\n训练系统 以数据并行随机梯度下降( SGD )技术为例，神经网络训练的过程如下:\n1，首先需要通过在第一个step进行Broadcast操作将参数同步到集群内的所有的训练卡上;\n2，将数据样本切片分发到整个集群的每张训练卡上并且通过data Loader技术将数据样本加载进训练卡的高速内存空间内，作为输入X;\n3，每个训练卡在其数据样本上运行前向传播，计算出误差LOSSi；\n4，对计算出的LOSSi进行反向传播，得到梯度GRADi；\n5，所有的训练卡在主机内及主机之间进行集合通信并进行梯度归约(AllReduce)；\n6，最后再进行参数更新以获得新的梯度参数。\n本质上分布式训练是数据加载、前向传播、反向传播、集合通信以及参数更新这5个步骤的逻辑组合，因此，基于以上步骤，这里可以推导出训练系统的公式定义如下：\n1 训练系统 = 数据加载 + （前向传播 + 反向传播） + 集合通信 + 参数更新 从上面的步骤可知分布式训练是在固定的步骤迭代中进行的，并且需要系统内的所有的训练卡都完成它们的迭代步骤，才能进行最后的参数更新，这相当于在单个训练卡上执行梯度下降技术，但是通过在系统内所有的训练卡之间分发数据样本并同时执行计算来获得训练的加速。\n举例说明 以TensorFlow为例说明模型的训练过程，TensorFlow 是用数据流图做计算的，如下图所示:\n图中显示了 TensorFlow 的训练过程，其包含输入（input）、塑形（reshape）、Relu 层（Relu layer）、Logit 层（Logit layer）、Softmax、交叉熵（cross entropy）、梯度（gradient）、SGD 训练（SGD Trainer）等部分。\n它的训练过程是，首先从数据分片输入开始，经过Reshape数据清洗后，进行前向传播运算，通过Relu 层后得到LOSS值，然后进入 Logit 层，再进行反向传播并且用 Cross Entropy、softmax等 来计算梯度，接着进行梯度归约(Allreduce)，这一步在分布式场景就涉及集合通信的过程，最后进行参数更新SGD Trainer，如此迭代循环直到获得收敛指标达标的结果为止。\n小结 采用分布式训练的目的往往也是因为数据量或模型太大，一个加速卡的高速内存放不下，因此对数据或者模型进行切分，分发到多卡上进行计算与归约。本文很概况性的讲述了什么是分布式训练，简单来说分布式训练就是分布式计算的一种，通过对数据样本的计算，得出最后可用的模型再用于数据推理。本系列文章的后续内将展开讲述分布式训练的基础理论、训练过程、质量保证、集合通信、系统工程、产品化等，同样分布式训练系统除了解决训练所带来的各种故障也还需要解决分布式所带来的各种故障。\n","permalink":"https://jianye0428.github.io/en/posts/tech/distributedtraining/2022-10-29_distributedtraining_1/","summary":"ref: [1]. https://zhuanlan.zhihu.com/p/487945343 前言 深度学习软件工程具有一体两面性：单卡的功能完备性、质量、用户体验以及多卡大规模。多卡大规模的出现是为了解决这样一个主要矛盾，即：“","title":"分布式训练 – 第1章 - 什么是分布式训练"},{"content":"reference: [1]. The Transformer Family [2]. Attention [3]. 细节考究\nTransformer Family Notations Symbol Meaning $d$ The model size / hidden state dimension / positional encoding size. $h$ The number of heads in multi-head attention layer. $L$ The segment length of input sequence. $X \\in \\mathbb R ^ {L \\times d}$ The input sequence where each element has been mapped into an embedding vector of shape , same as the model size. $W^k \\in \\mathbb R ^ {d \\times d^k}$ The key weight matrix. $W^q \\in \\mathbb R ^ {d \\times d^k}$ The query weight matrix. $W^v \\in \\mathbb R ^ {d \\times d^k}$ The value weight matrix.Often we have $d_k = d_v = d$. $W^K_i, W^q_i \\in \\mathbb R ^ {d \\times d^k / h}; W^v_i \\in \\mathbb R^{d x d_v / h}$ The weight matrices per head. $W^o \\in \\mathbb d_v \\times d$ The output weight matrix. $Q = XW^q \\in \\mathbb R^{L \\times d_q}$ The query embedding inputs. $K = XW^k \\in \\mathbb R^{L \\times d_k}$ The key embedding inputs. $V = XW^v \\in \\mathbb R^{L \\times d_v}$ The value embedding inputs. $S_i$ A collection of key positions for the -th query to attend to. $A \\in \\mathbb R ^ {L \\times L}$ The self-attention matrix between a input sequence of lenght $L$ and itself. $A = softmax (Q K^T/\\sqrt{(d_k)} )$ $a_ij \\ in A $ The scalar attention score between query $q_i$ and key $k_j$. $P \\in \\mathbb R ^ {L \\times d}$ position encoding matrix, where the $i-th$ row is the positional encoding for input $x_i$. Attention and Self-Attention Attention is a mechanism in the neural network that a model can learn to make predictions by selectively attending to a given set of data. The amount of attention is quantified by learned weights and thus the output is usually formed as a weighted average.\nSelf-attention is a type of attention mechanism where the model makes prediction for one part of a data sample using other parts of the observation about the same sample. Conceptually, it feels quite similar to non-local means. Also note that self-attention is permutation-invariant; in other words, it is an operation on sets.\nThere are various forms of attention / self-attention, Transformer (Vaswani et al., 2017) relies on the scaled dot-product attention: given a query matrix $Q$, a key matrix $K$ and a value matrix $V$, the output is a weighted sum of the value vectors, where the weight assigned to each value slot is determined by the dot-product of the query with the corresponding key:\n$$\\text{Attention}(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$$\nAnd for a query and a key vector $q_i, k_j \\in \\mathbb R ^ d$ (row vectors in query and key matrices), we have a scalar score:\n$$a_{ij} = softmax(\\frac{q_i k_j^T}{\\sqrt{d_k}}) = \\frac{\\exp(q_i k_j^T)}{\\sqrt{d_k}\\sum_{r \\in S_i}(q_i k_j^T)}$$\nwhere $S_i$ is a collection of key positions for the $i$-th query to attend to.\nSee my old post for other types of attention if interested.\nMulti-Head Self-Attention The multi-head self-attention module is a key component in Transformer. Rather than only computing the attention once, the multi-head mechanism splits the inputs into smaller chunks and then computes the scaled dot-product attention over each subspace in parallel. The independent attention outputs are simply concatenated and linearly transformed into expected dimensions.\n$$\\text{MulitHeadAttention}(X_q, X_k, X_v) = [\\text{head}_1,;\u0026hellip;; \\text{head}_h] W^o, where \\text{head}_i = \\text{Attention}(X_qW_i^q, X_kW_i^k, X_vW_i^v)$$\nwhere $[.;.]$ is a concatenation operation. $W_i^q, W_i^k \\in \\mathbb R^{d \\times d_{k} / h}$, $W_i^v \\in \\mathbb R^{d \\times d_{v} / h}$ are weight matrices to map input embeddings of size $L \\times d$ into query, key and value matrices. And $W^o \\in \\mathbb R ^ {d_v \\times d}$ is the output linear transformation. All the weights should be learned during training.\nTransformer The Transformer (which will be referred to as “vanilla Transformer” to distinguish it from other enhanced versions; Vaswani, et al., 2017) model has an encoder-decoder architecture, as commonly used in many NMT models. Later decoder-only Transformer was shown to achieve great performance in language modeling tasks, like in GPT and BERT.\nEncoder-Decoder Architecture\nThe encoder generates an attention-based representation with capability to locate a specific piece of information from a large context. It consists of a stack of 6 identity modules, each containing two submodules, a multi-head self-attention layer and a point-wise fully connected feed-forward network. By point-wise, it means that it applies the same linear transformation (with same weights) to each element in the sequence. This can also be viewed as a convolutional layer with filter size 1. Each submodule has a residual connection and layer normalization. All the submodules output data of the same dimension $d$.\nThe function of Transformer decoder is to retrieve information from the encoded representation. The architecture is quite similar to the encoder, except that the decoder contains two multi-head attention submodules instead of one in each identical repeating module. The first multi-head attention submodule is masked to prevent positions from attending to the future.\nPositional Encoding\nBecause self-attention operation is permutation invariant, it is important to use proper positional encoding to provide order information to the model. The positional encoding $P \\in \\mathbb R ^ {L \\times d}$ has the same dimension as the input embedding, so it can be added on the input directly. The vanilla Transformer considered two types of encodings:\n(1). Sinusoidal positional encoding is defined as follows, given the token $i = 1, \u0026hellip;, L$ position and the dimension $\\delta = 1, \u0026hellip;, d$:\n$$ \\text{PE}(i, \\delta) = \\left{ \\begin{aligned} \\sin\\big(\\frac{i}{10000^{2\\delta\u0026rsquo;/d}}\\big) , if \\delta\u0026amp;=2\\delta\u0026rsquo;\\ \\cos\\big(\\frac{i}{10000^{2\\delta\u0026rsquo;/d}}\\big) , if \\delta\u0026amp;=2\\delta\u0026rsquo;+1 \\ \\end{aligned} \\right.$$\nIn this way each dimension of the positional encoding corresponds to a sinusoid of different wavelengths in different dimensions, from $2\\pi$ to 10000 * $2\\pi$.\n(2). Learned positional encoding, as its name suggested, assigns each element with a learned column vector which encodes its absolute position (Gehring, et al. 2017).\n视觉Transformer入门 0 摘要 transformer结构是google在17年的Attention Is All You Need论文中提出，在NLP的多个任务上取得了非常好的效果，可以说目前NLP发展都离不开transformer。最大特点是抛弃了传统的CNN和RNN，整个网络结构完全是由Attention机制组成。由于其出色性能以及对下游任务的友好性或者说下游任务仅仅微调即可得到不错效果，在计算机视觉领域不断有人尝试将transformer引入，近期也出现了一些效果不错的尝试，典型的如目标检测领域的detr和可变形detr，分类领域的vision transformer等等。本文从transformer结构出发，结合视觉中的transformer成果(具体是vision transformer和detr)进行分析，希望能够帮助cv领域想了解transformer的初学者快速入门。由于本人接触transformer时间也不长，也算初学者，故如果有描述或者理解错误的地方欢迎指正。\n1 transformer介绍 一般讲解transformer都会以机器翻译任务为例子讲解，机器翻译任务是指将一种语言转换得到另一种语言，例如英语翻译为中文任务。从最上层来看，如下所示：\n1.1 早期seq2seq 机器翻译是一个历史悠久的问题，本质可以理解为序列转序列问题，也就是我们常说的seq2seq结构，也可以称为encoder-decoder结构，如下所示：\nencoder和decoder在早期一般是RNN模块(因为其可以==捕获时序信息==)，后来引入了LSTM或者GRU模块，不管内部组件是啥，其核心思想都是通过Encoder编码成一个表示向量，即上下文编码向量，然后交给Decoder来进行解码，翻译成目标语言。一个采用典型RNN进行编码翻译的可视化图如下：\n可以看出，其解码过程是顺序进行，每次仅解码出一个单词。对于CV领域初学者来说，RNN模块构建的seq2seq算法，理解到这个程度就可以了，不需要深入探讨如何进行训练。但是上述结构其实有缺陷，具体来说是：(缺陷)\n不论输入和输出的语句长度是什么，中间的上下文向量长度都是固定的，一旦长度过长，仅仅靠一个固定长度的上下文向量明显不合理 仅仅利用上下文向量解码，会有信息瓶颈，长度过长时候信息可能会丢失 通俗理解是编码器与解码器的连接点仅仅是编码单元输出的隐含向量，其包含的信息有限，对于一些复杂任务可能信息不够，如要翻译的句子较长时，一个上下文向量可能存不下那么多信息，就会造成翻译精度的下降。\n1.2 基于attention的seq2seq 基于上述缺陷进而提出带有注意力机制Attention的seq2seq，同样可以应用于RNN、LSTM或者GRU模块中。注意力机制Attention对人类来说非常好理解，假设给定一张图片，我们会自动聚焦到一些关键信息位置，而不需要逐行扫描全图。此处的attention也是同一个意思，其本质是对输入的自适应加权，结合cv领域的senet中的se模块就能够理解了。\nse模块最终是学习出一个$1 \\times 1 \\times c$的向量，然后逐通道乘以原始输入，从而对特征图的每个通道进行加权即通道注意力，对attention进行抽象，不管啥领域其机制都可以归纳为下图：\n将Query(通常是向量)和4个Key(和Q长度相同的向量)分别计算相似性，然后经过softmax得到q和4个key相似性的概率权重分布，然后对应权重乘以Value(和Q长度相同的向量)，最后相加即可得到包含注意力的attention值输出，理解上应该不难。举个简单例子说明：\n假设世界上所有小吃都可以被标签化，例如微辣、特辣、变态辣、微甜、有嚼劲\u0026hellip;.，总共有1000个标签，现在我想要吃的小吃是[微辣、微甜、有嚼劲]，这三个单词就是我的Query 来到东门老街一共100家小吃店，每个店铺卖的东西不一样，但是肯定可以被标签化，例如第一家小吃被标签化后是[微辣、微咸],第二家小吃被标签化后是[特辣、微臭、特咸]，第三家小吃被标签化后是[特辣、微甜、特咸、有嚼劲]，其余店铺都可以被标签化，每个店铺的标签就是Keys,但是每家店铺由于卖的东西不一样，单品种类也不一样，所以被标签化后每一家的标签List不一样长 Values就是每家店铺对应的单品，例如第一家小吃的Values是[烤羊肉串、炒花生] 将Query和所有的Keys进行一一比对，相当于计算相似性，此时就可以知道我想买的小吃和每一家店铺的匹配情况，最后有了匹配列表，就可以去店铺里面买东西了(Values和相似性加权求和)。最终的情况可能是，我在第一家店铺买了烤羊肉串，然后在第10家店铺买了个玉米，最后在第15家店铺买了个烤面筋 以上就是完整的注意力机制，采用我心中的标准Query去和被标签化的所有店铺Keys一一比对，此时就可以得到我的Query在每个店铺中的匹配情况，最终去不同店铺买不同东西的过程就是权重和Values加权求和过程。简要代码如下：\n1 2 3 4 5 6 7 # 假设q是(1,N,512),N就是最大标签化后的list长度，k是(1,M,512),M可以等于N，也可以不相等 # (1,N,512) x (1,512,M)--\u0026gt;(1,N,M) attn = torch.matmul(q, k.transpose(2, 3)) # query compare with keys # softmax转化为概率，输出(1,N,M)，表示q中每个n和每个m的相关性 attn=F.softmax(attn, dim=-1) # (1,N,M) x (1,M,512)--\u0026gt;(1,N,512)，V和k的shape相同 output = torch.matmul(attn, v) 带有attention的RNN模块组成的ser2seq,解码时候可视化如下： 在没有attention时候，不同解码阶段都仅仅利用了同一个编码层的最后一个隐含输出，加入attention后可以通过在每个解码时间步输入的都是不同的上下文向量，以上图为例，解码阶段会将第一个开启解码标志(也就是Q)与编码器的每一个时间步的隐含状态(一系列Key和Value)进行点乘计算相似性得到每一时间步的相似性分数，然后通过softmax转化为概率分布，然后将概率分布和对应位置向量进行加权求和得到新的上下文向量，最后输入解码器中进行解码输出，其详细解码可视化如下：\n通过上述简单的attention引入，可以将机器翻译性能大幅提升，引入attention有以下几个好处：\n注意力显著提高了机器翻译性能 注意力允许解码器以不同程度的权重利用到编码器的所有信息，可以绕过瓶颈 通过检查注意力分布，可以看到解码器在关注什么，可解释性强 1.3 基于transformer的seq2seq 基于attention的seq2seq的结构虽然说解决了很多问题，但是其依然存在不足：\n不管是采用RNN、LSTM还是GRU都不利于并行训练和推理，因为相关算法只能从左向右依次计算或者从右向左依次计算 长依赖信息丢失问题，顺序计算过程中信息会丢失，虽然LSTM号称有缓解，但是无法彻底解决 最大问题应该是无法并行训练，不利于大规模快速训练和部署，也不利于整个算法领域发展，故在Attention Is All You Need论文中抛弃了传统的CNN和RNN，将attention机制发挥到底，整个网络结构完全是由Attention机制组成，这是一个比较大的进步.\ngoogle所提基于transformer的seq2seq整体结构如下所示：\n其包括6个结构完全相同的编码器，和6个结构完全相同的解码器，其中每个编码器和解码器设计思想完全相同，只不过由于任务不同而有些许区别，整体详细结构如下所示：\n第一眼看有点复杂，其中N=6，由于基于transformer的翻译任务已经转化为分类任务(目标翻译句子有多长，那么就有多少个分类样本)，故在解码器最后会引入fc+softmax层进行概率输出，训练也比较简单，直接采用ce loss即可，对于采用大量数据训练好的预训练模型，下游任务仅仅需要训练fc层即可。上述结构看起来有点复杂，一个稍微抽象点的图示如下：\n看起来比基于RNN或者其余结构构建的seq2seq简单很多。下面结合代码和原理进行深入分析。\n1.4 transformer深入分析 前面写了一大堆，没有理解没有关系，对于cv初学者来说其实只需要理解QKV的含义和注意力机制的三个计算步骤:\nQ和所有K计算相似性； 对相似性采用softmax转化为概率分布； 将概率分布和V进行一一对应相乘，最后相加得到新的和Q一样长的向量输出即可. 重点是下面要讲的transformer结构。\n下面按照 编码器输入数据处理-\u0026gt;编码器运行-\u0026gt;解码器输入数据处理-\u0026gt;解码器运行-\u0026gt;分类head 的实际运行流程进行讲解。\n1.4.1 编码器输入数据处理 (1). 源单词嵌入\n以上面翻译任务为例，原始待翻译输入是三个单词:\n输入是三个单词，为了能够将文本内容输入到网络中肯定需要进行向量化(不然单词如何计算？)，具体是采用nlp领域的embedding算法进行词嵌入，也就是常说的Word2Vec。对于cv来说知道是干嘛的就行，不必了解细节。假设每个单词都可以嵌入成512个长度的向量，故此时输入即为3x512，注意Word2Vec操作只会输入到第一个编码器中，后面的编码器接受的输入是前一个编码器输出。\n为了便于组成batch(不同训练句子单词个数肯定不一样)进行训练，可以简单统计所有训练句子的单词个数，取最大即可，假设统计后发现待翻译句子最长是10个单词，那么编码器输入是10x512，额外填充的512维向量可以采用固定的标志编码得到.\n(2) 位置编码 positional encoding\n采用经过单词嵌入后的向量输入到编码器中还不够，因为transformer内部没有类似RNN的循环结构，没有捕捉顺序序列的能力，或者说无论句子结构怎么打乱，transformer都会得到类似的结果。为了解决这个问题，在编码词向量时会额外引入了位置编码position encoding向量表示两个单词i和j之间的距离，简单来说就是在词向量中加入了单词的位置信息。\n加入位置信息的方式非常多，最简单的可以是直接将绝对坐标0,1,2编码成512个长度向量即可。作者实际上提出了两种方式：\n网络自动学习 自己定义规则 提前假设单词嵌入并且组成batch后，shape为(b,N,512)，N是序列最大长度，512是每个单词的嵌入向量长度,b是batch\n(a) 网络自动学习\n1 self.pos_embedding = nn.Parameter(torch.randn(1, N, 512)) 比较简单，因为位置编码向量需要和输入嵌入(b,N,512)相加，所以其shape为(1,N,512)表示N个位置，每个位置采用512长度向量进行编码\n(b) 自己定义规则\n自定义规则做法非常多，论文中采用的是sin-cos规则，具体做法是：\n将向量(N,512)采用如下函数进行处理 $$PE_{pos, 2i} = sin(pos/1000^{2i/d_{model}})$$ $$PE_{pos, 2i+1} = cos(pos/1000^{2i/d_{model}})$$ pos即0~N,i是0-511 将向量的512维度切分为奇数行和偶数行 偶数行采用sin函数编码，奇数行采用cos函数编码 然后按照原始行号拼接 1 2 3 4 5 6 7 8 9 10 def get_position_angle_vec(position): # d_hid是0-511,position表示单词位置0～N-1 return [position / np.power(10000, 2 * (hid_j // 2) / d_hid) for hid_j in range(d_hid)] # 每个单词位置0～N-1都可以编码得到512长度的向量 sinusoid_table = np.array([get_position_angle_vec(pos_i) for pos_i in range(n_position)]) # 偶数列进行sin sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2]) # dim 2i # 奇数列进行cos sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2]) # dim 2i+1 上面例子的可视化如下：\n如此编码的优点是能够扩展到未知的序列长度，例如前向时候有特别长的句子，其可视化如下：\n作者为啥要设计如此复杂的编码规则？原因是sin和cos的如下特性：\n$\\left{\\begin{aligned} sin(\\alpha + \\beta) = sin\\alpha cos\\beta + cos \\alpha sin \\beta \\ cos(\\alpha + \\beta) = cos\\alpha cos\\beta - sin \\alpha sin \\beta \\end{aligned}\\right.$\n可以将$PE_{pos + k}$用$PE(pos)$进行线性表出：\n$\\left{\\begin{aligned} PE(pos+k, 2i) = PE(pos, 2i) \\times PE(k, 2i+1) + PE(pos, 2i+1) \\times PE(k,2i) \\ PE(pos+k, 2i + 1) = PE(pos, 2i + 1) \\times PE(k, 2i+1) - PE(pos, 2i) \\times PE(k,2i) \\end{aligned}\\right.$\n假设k=1，那么下一个位置的编码向量可以由前面的编码向量线性表示，等价于以一种非常容易学会的方式告诉了网络单词之间的绝对位置，让模型能够轻松学习到相对位置信息。注意编码方式不是唯一的，将单词嵌入向量和位置编码向量相加就可以得到编码器的真正输入了，其输出shape是(b,N,512)。\n1.4.2 编码器前向过程 编码器由两部分组成：自注意力层和前馈神经网络层。\n其前向可视化如下：\n注意上图没有绘制出单词嵌入向量和位置编码向量相加过程，但是是存在的。\n(1) 自注意力层\n通过前面分析我们知道自注意力层其实就是attention操作，并且由于其QKV来自同一个输入，故称为自注意力层。我想大家应该能想到这里attention层作用，在参考资料1博客里面举了个简单例子来说明attention的作用：假设我们想要翻译的输入句子为The animal didn\u0026rsquo;t cross the street because it was too tired，这个“it”在这个句子是指什么呢？它指的是street还是这个animal呢？这对于人类来说是一个简单的问题，但是对于算法则不是。当模型处理这个单词“it”的时候，自注意力机制会允许“it”与“animal”建立联系，即随着模型处理输入序列的每个单词，自注意力会关注整个输入序列的所有单词，帮助模型对本单词更好地进行编码。实际上训练完成后确实如此，google提供了可视化工具，如下所示：\n上述是从宏观角度思考，如果从输入输出流角度思考，也比较容易：\n假设我们现在要翻译上述两个单词，首先将单词进行编码，和位置编码向量相加，得到自注意力层输入X,其shape为(b,N,512)；然后定义三个可学习矩阵 Image (通过nn.Linear实现)，其shape为(512,M)，一般M等于前面维度512，从而计算后维度不变；将X和矩阵Image 相乘，得到QKV输出，shape为(b,N,M)；然后将Q和K进行点乘计算向量相似性；采用softmax转换为概率分布；将概率分布和V进行加权求和即可。其可视化如下：\n上述绘制的不是矩阵形式，更好理解而已。对于第一个单词的编码过程是：将q1和所有的k进行相似性计算，然后除以维度的平方根(论文中是64，本文可以认为是512)使得梯度更加稳定，然后通过softmax传递结果，这个softmax分数决定了每个单词对编码当下位置(“Thinking”)的贡献，最后对加权值向量求和得到z1。\n这个计算很明显就是前面说的注意力机制计算过程，每个输入单词的编码输出都会通过注意力机制引入其余单词的编码信息。\n上述为了方便理解才拆分这么细致，实际上代码层面采用矩阵实现非常简单：\n上面的操作很不错，但是还有改进空间，论文中又增加一种叫做“多头”注意力(“multi-headed” attention)的机制进一步完善了自注意力层，并在两方面提高了注意力层的性能：\n它扩展了模型专注于不同位置的能力。在上面的例子中，虽然每个编码都在z1中有或多或少的体现，但是它可能被实际的单词本身所支配。如果我们翻译一个句子，比如“The animal didn’t cross the street because it was too tired”，我们会想知道“it”指的是哪个词，这时模型的“多头”注意机制会起到作用。 它**给出了注意力层的多个\u0026quot;表示子空间\u0026quot;**,对于“多头”注意机制，有多个查询/键/值权重矩阵集(Transformer使用8个注意力头，因此我们对于每个编码器/解码器有8个矩阵集合)。 简单来说就是类似于分组操作，将输入X分别输入到8个attention层中，得到8个Z矩阵输出，最后对结果concat即可。论文图示如下：\n先忽略Mask的作用，左边是单头attention操作，右边是n个单头attention构成的多头自注意力层。\n代码层面非常简单，单头attention操作如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class ScaledDotProductAttention(nn.Module): \u0026#39;\u0026#39;\u0026#39; Scaled Dot-Product Attention \u0026#39;\u0026#39;\u0026#39; def __init__(self, temperature, attn_dropout=0.1): super().__init__() self.temperature = temperature self.dropout = nn.Dropout(attn_dropout) def forward(self, q, k, v, mask=None): # self.temperature是论文中的d_k ** 0.5，防止梯度过大 # QxK/sqrt(dk) attn = torch.matmul(q / self.temperature, k.transpose(2, 3)) if mask is not None: # 屏蔽不想要的输出 attn = attn.masked_fill(mask == 0, -1e9) # softmax+dropout attn = self.dropout(F.softmax(attn, dim=-1)) # 概率分布xV output = torch.matmul(attn, v) return output, attn 再次复习下Multi-Head Attention层的图示，可以发现在前面讲的内容基础上还加入了残差设计和层归一化操作，目的是为了防止梯度消失，加快收敛。\nMulti-Head Attention实现在ScaledDotProductAttention基础上构建：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 class MultiHeadAttention(nn.Module): \u0026#39;\u0026#39;\u0026#39; Multi-Head Attention module \u0026#39;\u0026#39;\u0026#39; # n_head头的个数，默认是8 # d_model编码向量长度，例如本文说的512 # d_k, d_v的值一般会设置为 n_head * d_k=d_model， # 此时concat后正好和原始输入一样，当然不相同也可以，因为后面有fc层 # 相当于将可学习矩阵分成独立的n_head份 def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1): super().__init__() # 假设n_head=8，d_k=64 self.n_head = n_head self.d_k = d_k self.d_v = d_v # d_model输入向量，n_head * d_k输出向量 # 可学习W^Q，W^K,W^V矩阵参数初始化 self.w_qs = nn.Linear(d_model, n_head * d_k, bias=False) self.w_ks = nn.Linear(d_model, n_head * d_k, bias=False) self.w_vs = nn.Linear(d_model, n_head * d_v, bias=False) # 最后的输出维度变换操作 self.fc = nn.Linear(n_head * d_v, d_model, bias=False) # 单头自注意力 self.attention = ScaledDotProductAttention(temperature=d_k ** 0.5) self.dropout = nn.Dropout(dropout) # 层归一化 self.layer_norm = nn.LayerNorm(d_model, eps=1e-6) def forward(self, q, k, v, mask=None): # 假设qkv输入是(b,100,512),100是训练每个样本最大单词个数 # 一般qkv相等，即自注意力 residual = q # 将输入x和可学习矩阵相乘，得到(b,100,512)输出 # 其中512的含义其实是8x64，8个head，每个head的可学习矩阵为64维度 # q的输出是(b,100,8,64),kv也是一样 q = self.w_qs(q).view(sz_b, len_q, n_head, d_k) k = self.w_ks(k).view(sz_b, len_k, n_head, d_k) v = self.w_vs(v).view(sz_b, len_v, n_head, d_v) # 变成(b,8,100,64)，方便后面计算，也就是8个头单独计算 q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2) if mask is not None: mask = mask.unsqueeze(1) # For head axis broadcasting. # 输出q是(b,8,100,64),维持不变,内部计算流程是： # q*k转置，除以d_k ** 0.5，输出维度是b,8,100,100即单词和单词直接的相似性 # 对最后一个维度进行softmax操作得到b,8,100,100 # 最后乘上V，得到b,8,100,64输出 q, attn = self.attention(q, k, v, mask=mask) # b,100,8,64--\u0026gt;b,100,512 q = q.transpose(1, 2).contiguous().view(sz_b, len_q, -1) q = self.dropout(self.fc(q)) # 残差计算 q += residual # 层归一化，在512维度计算均值和方差，进行层归一化 q = self.layer_norm(q) return q, attn 现在pytorch新版本已经把MultiHeadAttention当做nn中的一个类了，可以直接调用。\n(2) 前馈神经网络层\n这个层就没啥说的了，非常简单：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class PositionwiseFeedForward(nn.Module): \u0026#39;\u0026#39;\u0026#39; A two-feed-forward-layer module \u0026#39;\u0026#39;\u0026#39; def __init__(self, d_in, d_hid, dropout=0.1): super().__init__() # 两个fc层，对最后的512维度进行变换 self.w_1 = nn.Linear(d_in, d_hid) # position-wise self.w_2 = nn.Linear(d_hid, d_in) # position-wise self.layer_norm = nn.LayerNorm(d_in, eps=1e-6) self.dropout = nn.Dropout(dropout) def forward(self, x): residual = x x = self.w_2(F.relu(self.w_1(x))) x = self.dropout(x) x += residual x = self.layer_norm(x) return x (3) 编码层操作整体流程\n可视化如下所示：\n单个编码层代码如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 class EncoderLayer(nn.Module): def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1): super(EncoderLayer, self).__init__() self.slf_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout) self.pos_ffn = PositionwiseFeedForward(d_model, d_inner, dropout=dropout) def forward(self, enc_input, slf_attn_mask=None): # Q K V是同一个，自注意力 # enc_input来自源单词嵌入向量或者前一个编码器输出 enc_output, enc_slf_attn = self.slf_attn( enc_input, enc_input, enc_input, mask=slf_attn_mask) enc_output = self.pos_ffn(enc_output) return enc_output, enc_slf_attn 将上述编码过程重复n遍即可，除了第一个模块输入是单词嵌入向量与位置编码的和外，其余编码层输入是上一个编码器输出，即后面的编码器输入不需要位置编码向量。如果考虑n个编码器的运行过程，如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class Encoder(nn.Module): def __init__( self, n_src_vocab, d_word_vec, n_layers, n_head, d_k, d_v, d_model, d_inner, pad_idx, dropout=0.1, n_position=200): # nlp领域的词嵌入向量生成过程(单词在词表里面的索引idx--\u0026gt;d_word_vec长度的向量) self.src_word_emb = nn.Embedding(n_src_vocab, d_word_vec, padding_idx=pad_idx) # 位置编码 self.position_enc = PositionalEncoding(d_word_vec, n_position=n_position) self.dropout = nn.Dropout(p=dropout) # n个编码器层 self.layer_stack = nn.ModuleList([ EncoderLayer(d_model, d_inner, n_head, d_k, d_v, dropout=dropout) for _ in range(n_layers)]) # 层归一化 self.layer_norm = nn.LayerNorm(d_model, eps=1e-6) def forward(self, src_seq, src_mask, return_attns=False): # 对输入序列进行词嵌入，加上位置编码 enc_output = self.dropout(self.position_enc(self.src_word_emb(src_seq))) enc_output = self.layer_norm(enc_output) # 作为编码器层输入 for enc_layer in self.layer_stack: enc_output, _ = enc_layer(enc_output, slf_attn_mask=src_mask) return enc_output 到目前为止我们就讲完了编码部分的全部流程和代码细节。现在再来看整个transformer算法就会感觉亲切很多了：\n1.4.3 解码器输入数据处理 在分析解码器结构前先看下解码器整体结构，方便理解：\n其输入数据处理也要区分第一个解码器和后续解码器，和编码器类似，第一个解码器输入不仅包括最后一个编码器输出，还需要额外的输出嵌入向量，而后续解码器输入是来自最后一个编码器输出和前面解码器输出。\n(1) 目标单词嵌入\n这个操作和源单词嵌入过程完全相同，维度也是512，假设输出是i am a student，那么需要对这4个单词也利用word2vec算法转化为4x512的矩阵，作为第一个解码器的单词嵌入输入。\n(2) 位置编码\n同样的也需要对解码器输入引入位置编码，做法和编码器部分完全相同，且将目标单词嵌入向量和位置编码向量相加，即可作为第一个解码器输入。\n和编码器单词嵌入不同的地方是在进行目标单词嵌入前，还需要将目标单词即是i am a student右移动一位，新增加的一个位置采用提前定义好的标志位BOS_WORD代替，现在就变成[BOS_WORD,i,am,a,student]，为啥要右移？因为解码过程和seq2seq一样是顺序解码的，需要提供一个开始解码标志。不然第一个时间步的解码单词i是如何输出的呢？具体解码过程其实是：输入BOS_WORD，解码器输出i；输入前面已经解码的BOS_WORD和i，解码器输出am\u0026hellip;，输入已经解码的BOS_WORD、i、am、a和student，解码器输出解码结束标志位EOS_WORD,每次解码都会利用前面已经解码输出的所有单词嵌入信息\n下面有个非常清晰的gif图，一目了然：\n上图没有绘制BOS_WORD嵌入向量输入，然后解码出i单词的过程。\n1.4.4 解码器前向过程 仔细观察解码器结构，其包括：带有mask的MultiHeadAttention、MultiHeadAttention和前馈神经网络层三个组件，带有mask的MultiHeadAttention和MultiHeadAttention结构和代码写法是完全相同，唯一区别是是否输入了mask。\n为啥要mask？原因依然是顺序解码导致的。试想模型训练好了，开始进行翻译(测试)，其流程就是上面写的：输入BOS_WORD，解码器输出i；输入前面已经解码的BOS_WORD和i，解码器输出am\u0026hellip;，输入已经解码的BOS_WORD、i、am、a和student，解码器输出解码结束标志位EOS_WORD,每次解码都会利用前面已经解码输出的所有单词嵌入信息，这个测试过程是没有问题，但是训练时候我肯定不想采用上述顺序解码类似rnn, 即一个一个目标单词嵌入向量顺序输入训练，肯定想采用类似编码器中的矩阵并行算法，一步就把所有目标单词预测出来。要实现这个功能就可以参考编码器的操作，把目标单词嵌入向量组成矩阵一次输入即可，但是在解码am时候，不能利用到后面单词a和student的目标单词嵌入向量信息，否则这就是作弊(测试时候不可能能未卜先知)。为此引入mask，目的是构成下三角矩阵，右上角全部设置为负无穷(相当于忽略)，从而实现当解码第一个字的时候，第一个字只能与第一个字计算相关性，当解出第二个字的时候，只能计算出第二个字与第一个字和第二个字的相关性。具体是：在解码器中，自注意力层只被允许处理输出序列中更靠前的那些位置，在softmax步骤前，它会把后面的位置给隐去（把它们设为-inf）。\n还有个非常重要点需要知道(看图示可以发现)：解码器内部的带有mask的MultiHeadAttention的qkv向量输入来自目标单词嵌入或者前一个解码器输出，三者是相同的，但是后面的MultiHeadAttention的qkv向量中的kv来自最后一层编码器的输入，而q来自带有mask的MultiHeadAttention模块的输出。\n关于带mask的注意力层写法其实就是前面提到的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class ScaledDotProductAttention(nn.Module): \u0026#39;\u0026#39;\u0026#39; Scaled Dot-Product Attention \u0026#39;\u0026#39;\u0026#39; def __init__(self, temperature, attn_dropout=0.1): super().__init__() self.temperature = temperature self.dropout = nn.Dropout(attn_dropout) def forward(self, q, k, v, mask=None): # 假设q是b,8,10,64(b是batch，8是head个数，10是样本最大单词长度， # 64是每个单词的编码向量) # attn输出维度是b,8,10,10 attn = torch.matmul(q / self.temperature, k.transpose(2, 3)) # 故mask维度也是b,8,10,10 # 忽略b,8，只关注10x10的矩阵，其是下三角矩阵，下三角位置全1，其余位置全0 if mask is not None: # 提前算出mask，将为0的地方变成极小值-1e9，把这些位置的值设置为忽略 # 目的是避免解码过程中利用到未来信息 attn = attn.masked_fill(mask == 0, -1e9) # softmax+dropout attn = self.dropout(F.softmax(attn, dim=-1)) output = torch.matmul(attn, v) return output, attn 可视化如下：图片来源https://zhuanlan.zhihu.com/p/44731789\n整个解码器代码和编码器非常类似：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class DecoderLayer(nn.Module): \u0026#39;\u0026#39;\u0026#39; Compose with three layers \u0026#39;\u0026#39;\u0026#39; def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1): super(DecoderLayer, self).__init__() self.slf_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout) self.enc_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout) self.pos_ffn = PositionwiseFeedForward(d_model, d_inner, dropout=dropout) def forward( self, dec_input, enc_output, slf_attn_mask=None, dec_enc_attn_mask=None): # 标准的自注意力，QKV=dec_input来自目标单词嵌入或者前一个解码器输出 dec_output, dec_slf_attn = self.slf_attn( dec_input, dec_input, dec_input, mask=slf_attn_mask) # KV来自最后一个编码层输出enc_output，Q来自带有mask的self.slf_attn输出 dec_output, dec_enc_attn = self.enc_attn( dec_output, enc_output, enc_output, mask=dec_enc_attn_mask) dec_output = self.pos_ffn(dec_output) return dec_output, dec_slf_attn, dec_enc_attn 考虑n个解码器模块，其整体流程为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class Decoder(nn.Module): def __init__( self, n_trg_vocab, d_word_vec, n_layers, n_head, d_k, d_v, d_model, d_inner, pad_idx, n_position=200, dropout=0.1): # 目标单词嵌入 self.trg_word_emb = nn.Embedding(n_trg_vocab, d_word_vec, padding_idx=pad_idx) # 位置嵌入向量 self.position_enc = PositionalEncoding(d_word_vec, n_position=n_position) self.dropout = nn.Dropout(p=dropout) # n个解码器 self.layer_stack = nn.ModuleList([ DecoderLayer(d_model, d_inner, n_head, d_k, d_v, dropout=dropout) for _ in range(n_layers)]) # 层归一化 self.layer_norm = nn.LayerNorm(d_model, eps=1e-6) def forward(self, trg_seq, trg_mask, enc_output, src_mask, return_attns=False): # 目标单词嵌入+位置编码 dec_output = self.dropout(self.position_enc(self.trg_word_emb(trg_seq))) dec_output = self.layer_norm(dec_output) # 遍历每个解码器 for dec_layer in self.layer_stack: # 需要输入3个信息：目标单词嵌入+位置编码、最后一个编码器输出enc_output # 和dec_enc_attn_mask，解码时候不能看到未来单词信息 dec_output, dec_slf_attn, dec_enc_attn = dec_layer( dec_output, enc_output, slf_attn_mask=trg_mask, dec_enc_attn_mask=src_mask) return dec_output 1.4.5 分类层 在进行编码器-解码器后输出依然是向量，需要在后面接fc+softmax层进行分类训练。假设当前训练过程是翻译任务需要输出i am a student EOS_WORD这5个单词。假设我们的模型是从训练集中学习一万个不同的英语单词（我们模型的“输出词表”）。因此softmax后输出为一万个单元格长度的向量，每个单元格对应某一个单词的分数，这其实就是普通多分类问题，只不过维度比较大而已。\n依然以前面例子为例，假设编码器输出shape是(b,100,512)，经过fc后变成(b,100,10000)，然后对最后一个维度进行softmax操作，得到bx100个单词的概率分布，在训练过程中bx100个单词是知道label的，故可以直接采用ce loss进行训练。\n1 2 3 self.trg_word_prj = nn.Linear(d_model, n_trg_vocab, bias=False) dec_output, *_ = self.model.decoder(trg_seq, trg_mask, enc_output, src_mask) return F.softmax(self.model.trg_word_prj(dec_output), dim=-1) 1.4.6 前向流程 以翻译任务为例：\n将源单词进行嵌入，组成矩阵(加上位置编码矩阵)输入到n个编码器中，输出编码向量KV 第一个解码器先输入一个BOS_WORD单词嵌入向量，后续解码器接受该解码器输出，结合KV进行第一次解码 将第一次解码单词进行嵌入，联合BOS_WORD单词嵌入向量构成矩阵再次输入到解码器中进行第二次解码，得到解码单词 不断循环，每次的第一个解码器输入都不同，其包含了前面时间步长解码出的所有单词 直到输出EOS_WORD表示解码结束或者强制设置最大时间步长即可 这个解码过程其实就是标准的seq2seq流程。到目前为止就描述完了整个标准transformer训练和测试流程。\n2 视觉领域的transformer 在理解了标准的transformer后，再来看视觉领域transformer就会非常简单，因为在cv领域应用transformer时候大家都有一个共识：尽量不改动transformer结构，这样才能和NLP领域发展对齐，所以大家理解cv里面的transformer操作是非常简单的。\n2.1 分类vision transformer 论文题目：An Image is Worth 16x16 Words:Transformers for Image Recognition at Scale 论文地址：https://arxiv.org/abs/2010.11929 github: https://github.com/lucidrains/vit-pytorch\n其做法超级简单，只含有编码器模块：\n本文出发点是彻底抛弃CNN，以前的cv领域虽然引入transformer，但是或多或少都用到了cnn或者rnn，本文就比较纯粹了，整个算法几句话就说清楚了，下面直接分析。\n2.1.1 图片分块和降维 因为transformer的输入需要序列，所以最简单做法就是把图片切分为patch，然后拉成序列即可。假设输入图片大小是256x256，打算分成64个patch，每个patch是32x32像素\n1 x = rearrange(img, \u0026#39;b c (h p1) (w p2) -\u0026gt; b (h w) (p1 p2 c)\u0026#39;, p1=p, p2=p) 这个写法是采用了爱因斯坦表达式，具体是采用了einops库实现，内部集成了各种算子，rearrange就是其中一个，非常高效。不懂这种语法的请自行百度。p就是patch大小，假设输入是b,3,256,256，则rearrange操作是先变成(b,3,8x32,8x32)，最后变成(b,8x8,32x32x3)即(b,64,3072)，将每张图片切分成64个小块，每个小块长度是32x32x3=3072，也就是说输入长度为64的图像序列，每个元素采用3072长度进行编码。\n考虑到3072有点大，故作者先进行降维：\n1 2 3 # 将3072变成dim，假设是1024 self.patch_to_embedding = nn.Linear(patch_dim, dim) x = self.patch_to_embedding(x) 仔细看论文上图，可以发现假设切成9个块，但是最终到transfomer输入是10个向量，额外追加了一个0和_。为啥要追加？原因是**我们现在没有解码器了，而是编码后直接就进行分类预测，那么该解码器就要负责一点点解码器功能，那就是：需要一个类似开启解码标志，非常类似于标准transformer解码器中输入的目标嵌入向量右移一位操作。**试下如果没有额外输入，9个块输入9个编码向量输出，那么对于分类任务而言，我应该取哪个输出向量进行后续分类呢？选择任何一个都说不通，所以作者追加了一个可学习嵌入向量输入。那么额外的可学习嵌入向量为啥要设计为可学习，而不是类似nlp中采用固定的token代替？个人不负责任的猜测这应该就是图片领域和nlp领域的差别，nlp里面每个词其实都有具体含义，是离散的，但是图像领域没有这种真正意义上的离散token，有的只是一堆连续特征或者图像像素，如果不设置为可学习，那还真不知道应该设置为啥内容比较合适，全0和全1也说不通。自此现在就是变成10个向量输出，输出也是10个编码向量，然后取第0个编码输出进行分类预测即可。从这个角度看可以认为编码器多了一点点解码器功能。具体做法超级简单，0就是位置编码向量，_是可学习的patch嵌入向量。\n1 2 3 4 5 6 # dim=1024 self.cls_token = nn.Parameter(torch.randn(1, 1, dim)) # 变成(b,64,1024) cls_tokens = repeat(self.cls_token, \u0026#39;() n d -\u0026gt; b n d\u0026#39;, b=b) # 额外追加token，变成b,65,1024 x = torch.cat((cls_tokens, x), dim=1) 2.1.2 位置编码 位置编码也是必不可少的，长度应该是1024，这里做的比较简单，没有采用sincos编码，而是直接设置为可学习，效果差不多\n1 2 # num_patches=64，dim=1024,+1是因为多了一个cls开启解码标志 self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim)) 对训练好的pos_embedding进行可视化，如下所示：\n相邻位置有相近的位置编码向量，整体呈现2d空间位置排布一样。 将patch嵌入向量和位置编码向量相加即可作为编码器输入\n1 2 x += self.pos_embedding[:, :(n + 1)] x = self.dropout(x) 2.1.3 编码器前向过程 作者采用的是没有任何改动的transformer，故没有啥说的。\n1 self.transformer = Transformer(dim, depth, heads, mlp_dim, dropout) 2.1.4 分类head 在编码器后接fc分类器head即可\n1 2 3 4 5 6 7 8 9 10 self.mlp_head = nn.Sequential( nn.LayerNorm(dim), nn.Linear(dim, mlp_dim), nn.GELU(), nn.Dropout(dropout), nn.Linear(mlp_dim, num_classes) ) # 65个输出里面只需要第0个输出进行后续分类即可 self.mlp_head(x[:, 0]) 到目前为止就全部写完了，是不是非常简单，外层整体流程为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 class ViT(nn.Module): def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, channels=3, dropout=0.,emb_dropout=0.): super().__init__() # image_size输入图片大小 256 # patch_size 每个patch的大小 32 num_patches = (image_size // patch_size) ** 2 # 一共有多少个patch 8x8=64 patch_dim = channels * patch_size ** 2 # 3x32x32=3072 self.patch_size = patch_size # 32 # 1,64+1,1024,+1是因为token，可学习变量，不是固定编码 self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim)) # 图片维度太大了，需要先降维 self.patch_to_embedding = nn.Linear(patch_dim, dim) # 分类输出位置标志，否则分类输出不知道应该取哪个位置 self.cls_token = nn.Parameter(torch.randn(1, 1, dim)) self.dropout = nn.Dropout(emb_dropout) # 编码器 self.transformer = Transformer(dim, depth, heads, mlp_dim, dropout) # 输出头 self.mlp_head = nn.Sequential( nn.LayerNorm(dim), nn.Linear(dim, mlp_dim), nn.GELU(), nn.Dropout(dropout), nn.Linear(mlp_dim, num_classes) ) def forward(self, img, mask=None): p = self.patch_size # 先把图片变成64个patch,输出shape=b,64,3072 x = rearrange(img, \u0026#39;b c (h p1) (w p2) -\u0026gt; b (h w) (p1 p2 c)\u0026#39;, p1=p, p2=p) # 输出 b,64,1024 x = self.patch_to_embedding(x) b, n, _ = x.shape # 输出 b,1,1024 cls_tokens = repeat(self.cls_token, \u0026#39;() n d -\u0026gt; b n d\u0026#39;, b=b) # 额外追加token，变成b,65,1024 x = torch.cat((cls_tokens, x), dim=1) # 加上位置编码1,64+1,1024 x += self.pos_embedding[:, :(n + 1)] x = self.dropout(x) x = self.transformer(x, mask) # 分类head,只需要x[0]即可 # x = self.to_cls_token(x[:, 0]) x = x[:, 0] return self.mlp_head(x) 2.1.5 实验分析 作者得出的结论是：cv领域应用transformer需要大量数据进行预训练，在同等数据量的情况下性能不如cnn。一旦数据量上来了，对应的训练时间也会加长很多，那么就可以轻松超越cnn。\n同时应用transformer，一个突出优点是可解释性比较强：\n2.2 目标检测detr 论文名称：End-to-End Object Detection with Transformers 论文地址：https://arxiv.org/abs/2005.12872 github：https://github.com/facebookresearch/detr detr是facebook提出的引入transformer到目标检测领域的算法，效果很好，做法也很简单，符合其一贯的简洁优雅设计做法。\n对于目标检测任务，其要求输出给定图片中所有前景物体的类别和bbox坐标，该任务实际上是无序集合预测问题。针对该问题，detr做法非常简单：**给定一张图片，经过CNN进行特征提取，然后变成特征序列输入到transformer的编解码器中，直接输出指定长度为N的无序集合，集合中每个元素包含物体类别和坐标。**其中N表示整个数据集中图片上最多物体的数目，因为整个训练和测试都Batch进行，如果不设置最大输出集合数，无法进行batch训练，如果图片中物体不够N个，那么就采用no object填充，表示该元素是背景。\n整个思想看起来非常简单，相比faster rcnn或者yolo算法那就简单太多了，因为其不需要设置先验anchor，超参几乎没有，也不需要nms(因为输出的无序集合没有重复情况)，并且在代码程度相比faster rcnn那就不知道简单多少倍了，通过简单修改就可以应用于全景分割任务。可以推测，如果transformer真正大规模应用于CV领域，那么对初学者来说就是福音了，理解transformer就几乎等于理解了整个cv领域了(当然也可能是坏事)。\n2.2.1 detr核心思想分析 相比faster rcnn等做法，detr最大特点是将目标检测问题转化为无序集合预测问题。论文中特意指出faster rcnn这种设置一大堆anchor，然后基于anchor进行分类和回归其实属于代理做法即不是最直接做法，目标检测任务就是输出无序集合，而faster rcnn等算法通过各种操作，并结合复杂后处理最终才得到无序集合属于绕路了，而detr就比较纯粹了。\n尽管将transformer引入目标检测领域可以避免上述各种问题，但是其依然存在两个核心操作：\n无序集合输出的loss计算 针对目标检测的transformer改进 2.2.2 detr算法实现细节 下面结合代码和原理对其核心环节进行深入分析.\n2.2.2.1 无序集合输出的loss计算 在分析loss计算前，需要先明确N个无序集合的target构建方式。作者在coco数据集上统计，一张图片最多标注了63个物体，所以N应该要不小于63，作者设置的是100。为啥要设置为100？有人猜测是和coco评估指标只取前100个预测结果算法指标有关系。\ndetr输出是包括batchx100个无序集合，每个集合包括类别和坐标信息。对于coco数据而言，作者设置类别为91(coco类别标注索引是1-91,但是实际就标注了80个类别)，加上背景一共92个类别，对于坐标分支采用4个归一化值表征即cxcywh中心点、wh坐标，然后除以图片宽高进行归一化(没有采用复杂变换策略)，故每个集合是 Image ，c是长度为92的分类向量，b是长度为4的bbox坐标向量。总之detr输出集合包括两个分支：分类分支shape=(b,100,92)，bbox坐标分支shape=(b,100,4)，对应的target也是包括分类target和bbox坐标target，如果不够100，则采用背景填充，计算loss时候bbox分支仅仅计算有物体位置，背景集合忽略。\n现在核心问题来了：输出的bx100个检测结果是无序的，如何和gt bbox计算loss？这就需要用到经典的双边匹配算法了，也就是常说的匈牙利算法，该算法广泛应用于最优分配问题，在bottom-up人体姿态估计算法中进行分组操作时候也经常使用。detr中利用匈牙利算法先进行最优一对一匹配得到匹配索引，然后对bx100个结果进行重排就和gt bbox对应上了(对gt bbox进行重排也可以，没啥区别)，就可以算loss了。\n匈牙利算法是一个标准优化算法，具体是组合优化算法，在scipy.optimize.linear_sum_assignmen函数中有实现，一行代码就可以得到最优匹配，网上解读也非常多，这里就不写细节了，该函数核心是需要输入A集合和B集合两两元素之间的连接权重，基于该重要性进行内部最优匹配，连接权重大的优先匹配。\n上述描述优化过程可以采用如下公式表达：\n$$\\hat{\\sigma} = \\mathop{\\arg\\min}\\limits_{\\sigma \\in \\partial_{N}} {\\sum^{N}{i}} L{match} (y_i, \\hat{y}_{\\sigma(i)})$$\n优化对象是$\\sigma$ ，其是长度为N的list， $\\sigma(i) = i$ ， $\\sigma(i)$ 表示无序gt bbox集合的哪个元素和输出预测集合中的第i个匹配。其实简单来说就是找到最优匹配，因为在最佳匹配情况下l_match和最小即loss最小。\n前面说过匈牙利算法核心是需要提供输入A集合和B集合两两元素之间的连接权重，这里就是要输入N个输出集合和M个gt bbox之间的关联程度，如下所示\n$$L_{Hungarian} (y, \\hat{y}) = \\sum^{N}{i=1}[-\\log\\hat{p}{\\hat{\\sigma}(i)} + \\mathbb{1} L_{box}(b_i, \\hat{b}_{\\hat{\\sigma}(i)})]$$\n而Lbox具体是：\n$$\\lambda_{iou}L_{iou}(b_i, \\hat{b}{\\sigma(i)}) + \\lambda{L_1}||b_i - \\hat{b}_{\\sigma(i)}||_1$$\nHungarian意思就是匈牙利，也就是前面的L_match，上述意思是需要计算M个gt bbox和N个输出集合两两之间的广义距离，距离越近表示越可能是最优匹配关系，也就是两者最密切。广义距离的计算考虑了分类分支和bbox分支，下面结合代码直接说明，比较简单。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # detr分类输出，num_queries=100，shape是(b,100,92) bs, num_queries = outputs[\u0026#34;pred_logits\u0026#34;].shape[:2] # 得到概率输出(bx100,92) out_prob = outputs[\u0026#34;pred_logits\u0026#34;].flatten(0, 1).softmax(-1) # 得到bbox分支输出(bx100,4) out_bbox = outputs[\u0026#34;pred_boxes\u0026#34;].flatten(0, 1) # 准备分类target shape=(m,)里面存储的是类别索引，m包括了整个batch内部的所有gt bbox tgt_ids = torch.cat([v[\u0026#34;labels\u0026#34;] for v in targets]) # 准备bbox target shape=(m,4)，已经归一化了 tgt_bbox = torch.cat([v[\u0026#34;boxes\u0026#34;] for v in targets]) #核心 #bx100,92-\u0026gt;bx100,m，对于每个预测结果，把目前gt里面有的所有类别值提取出来，其余值不需要参与匹配 #对应上述公式，类似于nll loss，但是更加简单 cost_class = -out_prob[:, tgt_ids]　#计算out_bbox和tgt_bbox两两之间的l1距离 bx100,m cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1) #额外多计算一个giou loss bx100,m cost_giou = -generalized_box_iou(box_cxcywh_to_xyxy(out_bbox), box_cxcywh_to_xyxy(tgt_bbox)) #得到最终的广义距离bx100,m，距离越小越可能是最优匹配 C = self.cost_bbox * cost_bbox + self.cost_class * cost_class + self.cost_giou * cost_giou # bx100,m--\u0026gt; batch,100,m C = C.view(bs, num_queries, -1).cpu() #计算每个batch内部有多少物体，后续计算时候按照单张图片进行匹配，没必要batch级别匹配,徒增计算 sizes = [len(v[\u0026#34;boxes\u0026#34;]) for v in targets] #匈牙利最优匹配，返回匹配索引 indices = [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(sizes, -1))] return [(torch.as_tensor(i, dtype=torch.int64), torch.as_tensor(j, dtype=torch.int64)) for i, j in indices] 在得到匹配关系后算loss就水到渠成了。分类分支计算ce loss，bbox分支计算l1 loss+giou loss\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def loss_labels(self, outputs, targets, indices, num_boxes, log=True): #shape是(b,100,92) src_logits = outputs[\u0026#39;pred_logits\u0026#39;] #得到匹配后索引，作用在label上 idx = self._get_src_permutation_idx(indices) #得到匹配后的分类target target_classes_o = torch.cat([t[\u0026#34;labels\u0026#34;][J] for t, (_, J) in zip(targets, indices)]) #加入背景(self.num_classes)，补齐bx100个 target_classes = torch.full(src_logits.shape[:2], self.num_classes, dtype=torch.int64, device=src_logits.device) #shape是(b,100,),存储的是索引，不是one-hot target_classes[idx] = target_classes_o #计算ce loss,self.empty_weight前景和背景权重是1和0.1,克服类别不平衡 loss_ce = F.cross_entropy(src_logits.transpose(1, 2), target_classes, self.empty_weight) losses = {\u0026#39;loss_ce\u0026#39;: loss_ce} return losses def loss_boxes(self, outputs, targets, indices, num_boxes): idx = self._get_src_permutation_idx(indices) src_boxes = outputs[\u0026#39;pred_boxes\u0026#39;][idx] target_boxes = torch.cat([t[\u0026#39;boxes\u0026#39;][i] for t, (_, i) in zip(targets, indices)], dim=0) #l1 loss loss_bbox = F.l1_loss(src_boxes, target_boxes, reduction=\u0026#39;none\u0026#39;) losses = {} losses[\u0026#39;loss_bbox\u0026#39;] = loss_bbox.sum() / num_boxes #giou loss loss_giou = 1 - torch.diag(box_ops.generalized_box_iou( box_ops.box_cxcywh_to_xyxy(src_boxes), box_ops.box_cxcywh_to_xyxy(target_boxes))) losses[\u0026#39;loss_giou\u0026#39;] = loss_giou.sum() / num_boxes return losses 2.2.2.2 针对目标检测的transformer改进 分析完训练最关键的：双边匹配+loss计算部分，现在需要考虑在目标检测算法中transformer如何设计？下面按照算法的4个步骤讲解。\ntransformer细节如下： (1) cnn骨架特征提取\n骨架网络可以是任何一种，作者选择resnet50，将最后一个stage即stride=32的特征图作为编码器输入。由于resnet仅仅作为一个小部分且已经经过了imagenet预训练，故和常规操作一样，会进行如下操作：\nresnet中所有BN都固定，即采用全局均值和方差 resnet的stem和第一个stage不进行参数更新，即parameter.requires_grad_(False) backbone的学习率小于transformer,lr_backbone=1e-05,其余为0.0001 假设输入是(b,c,h,w)，则resnet50输出是(b,1024,h//32,w//32)，1024比较大，为了节省计算量，先采用1x1卷积降维为256,最后转化为序列格式输入到transformer中，输入shape=(h\u0026rsquo;xw\u0026rsquo;,b,256)，h\u0026rsquo;=h//32\n1 2 3 4 5 self.input_proj = nn.Conv2d(backbone.num_channels, hidden_dim, kernel_size=1) # 输出是(b,256,h//32,w//32) src=self.input_proj(src) # 变成序列模式，(h\u0026#39;xw\u0026#39;,b,256),256是每个词的编码长度 src = src.flatten(2).permute(2, 0, 1) (2) 编码器设计和输入\n编码器结构设计没有任何改变，但是输入改变了。\n(a) 位置编码需要考虑2d空间\n由于图像特征是2d特征，故位置嵌入向量也需要考虑xy方向。前面说过编码方式可以采用sincos，也可以设置为可学习，本文采用的依然是sincos模式，和前面说的一样，但是需要考虑xy两个方向(前面说的序列只有x方向)。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #输入是b,c,h,w #tensor_list的类型是NestedTensor，内部自动附加了mask， #用于表示动态shape，是pytorch中tensor新特性https://github.com/pytorch/nestedtensor x = tensor_list.tensors # 原始tensor数据 # 附加的mask，shape是b,h,w 全是false mask = tensor_list.mask not_mask = ~mask # 因为图像是2d的，所以位置编码也分为x,y方向 # 1 1 1 1 .. 2 2 2 2... 3 3 3... y_embed = not_mask.cumsum(1, dtype=torch.float32) # 1 2 3 4 ... 1 2 3 4... x_embed = not_mask.cumsum(2, dtype=torch.float32) if self.normalize: eps = 1e-6 y_embed = y_embed / (y_embed[:, -1:, :] + eps) * self.scale x_embed = x_embed / (x_embed[:, :, -1:] + eps) * self.scale # 0~127 self.num_pos_feats=128,因为前面输入向量是256，编码是一半sin，一半cos dim_t = torch.arange(self.num_pos_feats, dtype=torch.float32, device=x.device) # 归一化 dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats) pos_x = x_embed[:, :, :, None] / dim_t pos_y = y_embed[:, :, :, None] / dim_t # 输出shape=b,h,w,128 pos_x = torch.stack((pos_x[:, :, :, 0::2].sin(), pos_x[:, :, :, 1::2].cos()), dim=4).flatten(3) pos_y = torch.stack((pos_y[:, :, :, 0::2].sin(), pos_y[:, :, :, 1::2].cos()), dim=4).flatten(3) pos = torch.cat((pos_y, pos_x), dim=3).permute(0, 3, 1, 2) # 每个特征图的xy位置都编码成256的向量，其中前128是y方向编码，而128是x方向编码 return pos # b,n=256,h,w 可以看出对于h//32,w//32的2d图像特征，不是类似vision transoformer做法简单的将其拉伸为h//32 x w//32，然后从0-n进行长度为256的位置编码，而是考虑了xy方向同时编码，每个方向各编码128维向量，这种编码方式更符合图像特定。\n还有一个细节需要注意：原始transformer的n个编码器输入中，只有第一个编码器需要输入位置编码向量，但是detr里面对每个编码器都输入了同一个位置编码向量，论文中没有写为啥要如此修改。\n(b) QKV处理逻辑不同\n作者设置编码器一共6个，并且位置编码向量仅仅加到QK中，V中没有加入位置信息，这个和原始做法不一样，原始做法是QKV都加上了位置编码，论文中也没有写为啥要如此修改。\n其余地方就完全相同了，故代码就没必要贴了。总结下和原始transformer编码器不同的地方：\n输入编码器的位置编码需要考虑2d空间位置 位置编码向量需要加入到每个编码器中 在编码器内部位置编码仅仅和QK相加，V不做任何处理 经过6个编码器forward后，输出shape为(h//32xw//32,b,256)。\n(c) 编码器部分整体运行流程\n6个编码器整体forward流程如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class TransformerEncoder(nn.Module): def __init__(self, encoder_layer, num_layers, norm=None): super().__init__() # 编码器copy6份 self.layers = _get_clones(encoder_layer, num_layers) self.num_layers = num_layers self.norm = norm def forward(self, src, mask: Optional[Tensor] = None, src_key_padding_mask: Optional[Tensor] = None, pos: Optional[Tensor] = None): # 内部包括6个编码器，顺序运行 # src是图像特征输入，shape=hxw,b,256 output = src for layer in self.layers: # 每个编码器都需要加入pos位置编码 # 第一个编码器输入来自图像特征，后面的编码器输入来自前一个编码器输出 output = layer(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask, pos=pos) return output 每个编码器内部运行流程如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def forward_post(self, src, src_mask: Optional[Tensor] = None, src_key_padding_mask: Optional[Tensor] = None, pos: Optional[Tensor] = None): # 和标准做法有点不一样，src加上位置编码得到q和k，但是v依然还是src， # 也就是v和qk不一样 q = k = src+pos src2 = self.self_attn(q, k, value=src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)[0] src = src + self.dropout1(src2) src = self.norm1(src) src2 = self.linear2(self.dropout(self.activation(self.linear1(src)))) src = src + self.dropout2(src2) src = self.norm2(src) return src (3) 解码器设计和输入\n解码器结构设计没有任何改变，但是输入也改变了。\n(a) 新引入Object queries\nobject queries(shape是(100,256))可以简单认为是输出位置编码,其作用主要是在学习过程中提供目标对象和全局图像之间的关系,相当于全局注意力，必不可少, 非常关键。代码形式上是可学习位置编码矩阵。和编码器一样，该可学习位置编码向量也会输入到每一个解码器中。我们可以尝试通俗理解：object queries矩阵内部通过学习建模了100个物体之间的全局关系，例如房间里面的桌子旁边(A类)一般是放椅子(B类)，而不会是放一头大象(C类)，那么在推理时候就可以利用该全局注意力更好的进行解码预测输出。\n1 2 # num_queries=100,hidden_dim=256 self.query_embed = nn.Embedding(num_queries, hidden_dim) 论文中指出object queries作用非常类似faster rcnn中的anchor，只不过这里是可学习的，不是提前设置好的。\n(b) 位置编码也需要\n编码器环节采用的sincos位置编码向量也可以考虑引入，且该位置编码向量输入到每个解码器的第二个Multi-Head Attention中，后面有是否需要该位置编码的对比实验。\n(c) QKV处理逻辑不同\n解码器一共包括6个，和编码器中QKV一样，V不会加入位置编码。上述说的三个操作，只要看下网络结构图就一目了然了。\n(d) 一次解码输出全部无序集合\n和原始transformer顺序解码操作不同的是，detr一次就把N个无序框并行输出了(因为任务是无序集合，做成顺序推理有序输出没有很大必要)。为了说明如何实现该功能，我们需要先回忆下原始transformer的顺序解码过程：输入BOS_WORD，解码器输出i；输入前面已经解码的BOS_WORD和i，解码器输出am\u0026hellip;，输入已经解码的BOS_WORD、i、am、a和student，解码器输出解码结束标志位EOS_WORD,每次解码都会利用前面已经解码输出的所有单词嵌入信息。现在就是一次解码，故只需要初始化时候输入一个全0的查询向量A，类似于BOS_WORD作用，然后第一个解码器接受该输入A，解码输出向量作为下一个解码器输入，不断推理即可，最后一层解码输出即为我们需要的输出，不需要在第二个解码器输入时候考虑BOS_WORD和第一个解码器输出。\n总结下和原始transformer解码器不同的地方：\n额外引入可学习的Object queries，相当于可学习anchor，提供全局注意力 编码器采用的sincos位置编码向量也需要输入解码器中，并且每个解码器都输入 QKV处理逻辑不同 不需要顺序解码，一次即可输出N个无序集合 e) 解码器整体运行流程\nn个解码器整体流程如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class TransformerDecoder(nn.Module): def forward(self, tgt, memory, tgt_mask: Optional[Tensor] = None, memory_mask: Optional[Tensor] = None, tgt_key_padding_mask: Optional[Tensor] = None, memory_key_padding_mask: Optional[Tensor] = None, pos: Optional[Tensor] = None, query_pos: Optional[Tensor] = None): # 首先query_pos是query_embed，可学习输出位置向量shape=100,b,256 # tgt = torch.zeros_like(query_embed),用于进行一次性解码输出 output = tgt # 存储每个解码器输出，后面中继监督需要 intermediate = [] # 编码每个解码器 for layer in self.layers: # 每个解码器都需要输入query_pos和pos # memory是最后一个编码器输出 # 每个解码器都接受output作为输入，然后输出新的output output = layer(output, memory, tgt_mask=tgt_mask, memory_mask=memory_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask, pos=pos, query_pos=query_pos) if self.return_intermediate: intermediate.append(self.norm(output)) if self.return_intermediate: return torch.stack(intermediate) # 6个输出都返回 return output.unsqueeze(0) 内部每个解码器运行流程为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def forward_post(self, tgt, memory, tgt_mask: Optional[Tensor] = None, memory_mask: Optional[Tensor] = None, tgt_key_padding_mask: Optional[Tensor] = None, memory_key_padding_mask: Optional[Tensor] = None, pos: Optional[Tensor] = None, query_pos: Optional[Tensor] = None): # query_pos首先是可学习的，其作用主要是在学习过程中提供目标对象和全局图像之间的关系 # 这个相当于全局注意力输入，是非常关键的 # query_pos是解码器特有 q = k = tgt+query_pos # 第一个自注意力模块 tgt2 = self.self_attn(q, k, value=tgt, attn_mask=tgt_mask, key_padding_mask=tgt_key_padding_mask)[0] tgt = tgt + self.dropout1(tgt2) tgt = self.norm1(tgt) # memory是最后一个编码器输出，pos是和编码器输入中完全相同的sincos位置嵌入向量 # 输入参数是最核心细节，query是tgt+query_pos，而key是memory+pos # v直接用memory tgt2 = self.multihead_attn(query=tgt+query_pos, key=memory+pos, value=memory, attn_mask=memory_mask, key_padding_mask=memory_key_padding_mask)[0] tgt = tgt + self.dropout2(tgt2) tgt = self.norm2(tgt) tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt)))) tgt = tgt + self.dropout3(tgt2) tgt = self.norm3(tgt) return tgt 解码器最终输出shape是(6,b,100,256)，6是指6个解码器的输出。\n(4) 分类和回归head\n在解码器输出基础上构建分类和bbox回归head即可输出检测结果，比较简单：\n1 2 3 4 5 6 7 8 9 10 11 12 13 self.class_embed = nn.Linear(256, 92) self.bbox_embed = MLP(256, 256, 4, 3) # hs是(6,b,100,256)，outputs_class输出(6,b,100,92)，表示6个分类分支 outputs_class = self.class_embed(hs) # 输出(6,b,100,4)，表示6个bbox坐标回归分支 outputs_coord = self.bbox_embed(hs).sigmoid() # 取最后一个解码器输出即可，分类输出(b,100,92)，bbox回归输出(b,100,4) out = {\u0026#39;pred_logits\u0026#39;: outputs_class[-1], \u0026#39;pred_boxes\u0026#39;: outputs_coord[-1]} if self.aux_loss: # 除了最后一个输出外，其余编码器输出都算辅助loss out[\u0026#39;aux_outputs\u0026#39;] = self._set_aux_loss(outputs_class, outputs_coord) 作者实验发现，如果对解码器的每个输出都加入辅助的分类和回归loss，可以提升性能，故作者除了对最后一个编码层的输出进行Loss监督外，还对其余5个编码器采用了同样的loss监督，只不过权重设置低一点而已。\n(5) 整体推理流程\n基于transformer的detr算法，作者特意强调其突出优点是部署代码不超过50行，简单至极。\n当然上面是简化代码，和实际代码不一样。具体流程是：\n将(b,3,800,1200)图片输入到resnet50中进行特征提取,输出shape=(b,1024,25,38) 通过1x1卷积降维，变成(b,256,25,38) 利用sincos函数计算位置编码 将图像特征和位置编码向量相加，作为编码器输入，输出编码后的向量，shape不变 初始化全0的(100,b,256)的输出嵌入向量，结合位置编码向量和query_embed，进行解码输出，解码器输出shape为(6,b,100,256) 将最后一个解码器输出输入到分类和回归head中，得到100个无序集合 对100个无序集合进行后处理，主要是提取前景类别和对应的bbox坐标，乘上(800,1200)即可得到最终坐标,后处理代码如下： 1 2 3 4 5 6 7 8 9 prob = F.softmax(out_logits, -1) scores, labels = prob[..., :-1].max(-1) # convert to [x0, y0, x1, y1] format boxes = box_ops.box_cxcywh_to_xyxy(out_bbox) # and from relative [0, 1] to absolute [0, height] coordinates img_h, img_w = target_sizes.unbind(1) scale_fct = torch.stack([img_w, img_h, img_w, img_h], dim=1) boxes = boxes * scale_fct[:, None, :] results = [{\u0026#39;scores\u0026#39;: s, \u0026#39;labels\u0026#39;: l, \u0026#39;boxes\u0026#39;: b} for s, l, b in zip(scores, labels, boxes)] 既然训练时候对6个解码器输出都进行了loss监督，那么在测试时候也可以考虑将6个解码器的分类和回归分支输出结果进行nms合并，稍微有点性能提升。\n2.2.3 实验分析 (1) 性能对比\nFaster RCNN-DC5是指的resnet的最后一个stage采用空洞率=stride设置代替stride，目的是在不进行下采样基础上扩大感受野，输出特征图分辨率保持不变。+号代表采用了额外的技巧提升性能例如giou、多尺度训练和9xepoch训练策略。可以发现detr效果稍微好于faster rcnn各种版本，证明了视觉transformer的潜力。但是可以发现其小物体检测能力远远低于faster rcnn，这是一个比较大的弊端。\n(2) 各个模块分析\n编码器数目越多效果越好，但是计算量也会增加很多，作者最终选择的是6。\n可以发现解码器也是越多越好，还可以观察到第一个解码器输出预测效果比较差，增加第二个解码器后性能提升非常多。上图中的NMS操作是指既然我们每个解码层都可以输入无序集合，那么将所有解码器无序集合全部保留，然后进行nms得到最终输出，可以发现性能稍微有提升，特别是AP50。\n作者对比了不同类型的位置编码效果，因为query_embed(output pos)是必不可少的，所以该列没有进行对比实验，始终都有，最后一行效果最好，所以作者采用的就是该方案，sine at attn表示每个注意力层都加入了sine位置编码，相比仅仅在input增加位置编码效果更好。\n(3) 注意力可视化\n前面说过transformer具有很好的可解释性，故在训练完成后最终提出了几种可视化形式\n(a) bbox输出可视化\n这个就比较简单了，直接对预测进行后处理即可\n1 2 3 4 5 6 probas = outputs[\u0026#39;pred_logits\u0026#39;].softmax(-1)[0, :, :-1] # 只保留概率大于0.9的bbox keep = probas.max(-1).values \u0026gt; 0.9 # 还原到原图，然后绘制即可 bboxes_scaled = rescale_bboxes(outputs[\u0026#39;pred_boxes\u0026#39;][0, keep], im.size) plot_results(im, probas[keep], bboxes_scaled) (b) 解码器自注意力层权重可视化\n这里指的是最后一个解码器内部的第一个MultiheadAttention的自注意力权重，其实就是QK相似性计算后然后softmax后的输出可视化，具体是：\n1 2 3 4 5 6 7 8 9 10 11 12 # multihead_attn注册前向hook，output[1]指的就是softmax后输出 model.transformer.decoder.layers[-1].multihead_attn.register_forward_hook( lambda self, input, output: dec_attn_weights.append(output[1]) ) # 假设输入是(1,3,800,1066) outputs = model(img) # 那么dec_attn_weights是(1,100,850=800//32x1066//32) # 这个就是QK相似性计算后然后softmax后的输出，即自注意力权重 dec_attn_weights = dec_attn_weights[0] # 如果想看哪个bbox的权重，则输入idx即可 dec_attn_weights[0, idx].view(800//32, 1066//32) c) 编码器自注意力层权重可视化\n这个和解码器操作完全相同。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 model.transformer.encoder.layers[-1].self_attn.register_forward_hook( lambda self, input, output: enc_attn_weights.append(output[1]) ) outputs = model(img) # 最后一个编码器中的自注意力模块权重输出(b,h//32xw//32,h//32xw//32)，其实就是qk计算然后softmax后的值即(1,25x34=850,850) enc_attn_weights = enc_attn_weights[0] # 变成(25, 34, 25, 34) sattn = enc_attn_weights[0].reshape(shape + shape) # 想看哪个特征点位置的注意力 idxs = [(200, 200), (280, 400), (200, 600), (440, 800), ] for idx_o, ax in zip(idxs, axs): # 转化到特征图尺度 idx = (idx_o[0] // fact, idx_o[1] // fact) # 直接sattn[..., idx[0], idx[1]]即可 ax.imshow(sattn[..., idx[0], idx[1]], cmap=\u0026#39;cividis\u0026#39;, interpolation=\u0026#39;nearest\u0026#39;) 2.2.4 小结 detr整体做法非常简单，基本上没有改动原始transformer结构，其显著优点是：不需要设置啥先验，超参也比较少，训练和部署代码相比faster rcnn算法简单很多，理解上也比较简单。但是其缺点是：改了编解码器的输入，在论文中也没有解释为啥要如此设计，而且很多操作都是实验对比才确定的，比较迷。算法层面训练epoch次数远远大于faster rcnn(300epoch)，在同等epoch下明显性能不如faster rcnn，而且训练占用内存也大于faster rcnn。\n整体而言，虽然效果不错，但是整个做法还是显得比较原始，很多地方感觉是尝试后得到的做法，没有很好的解释性，而且最大问题是训练epoch非常大和内存占用比较多，对应的就是收敛慢，期待后续作品。\n3 总结 本文从transformer发展历程入手，并且深入介绍了transformer思想和实现细节；最后结合计算机视觉领域的几篇有典型代表文章进行深入分析，希望能够给cv领域想快速理解transformer的初学者一点点帮助。\n4 参考资料 [1] http://jalammar.github.io/illustrated-transformer/ [2] https://zhuanlan.zhihu.com/p/54356280 [3] https://zhuanlan.zhihu.com/p/44731789 [4] https://looperxx.github.io/CS224n-2019-08-Machine%20Translation,%20Sequence-to-sequence%20and%20Attention/ [5] https://github.com/lucidrains/vit-pytorch [6] https://github.com/jadore801120/ attention-is-all-you-need-pytorch [7] https://github.com/facebookresearch/detr\nref: [1]. https://mp.weixin.qq.com/s/Tb0Zh5n_3dEYwInU6sJUhA\n基于Transformer的多模态轨迹预测 0 引言 轨迹预测是自动驾驶领域关注的热点。对周围车辆轨迹的精确预测可以辅助自动驾驶车辆做出合理的决策规划，进而实现车辆在异构高动态复杂多变环境中安全驾驶。在车辆交互场景中，由于驾驶员意图与环境的不确定性，车辆轨迹将呈现多模态属性，即在相同历史轨迹条件下，车辆的未来轨迹具有多种可能性。对车辆的多模态轨迹预测并保证预测的准确性与多样性是当前自动驾驶领域研究的重点与难点。\n近年来，Transformer在多模态预测领域取得突破性进展，其特有的完全基于注意力机制模块能够充分挖掘高动态场景下车辆之间的交互关系并有效建模轨迹的多模态分布。在近年来的一些研究中，基于Transformer的多模态轨迹预测显示出比CNN，RNN等多模态预测模型更优的准确性与多样性。本文以基于Transformer的多模态车辆轨迹预测为主线，回顾近年来代表性的基于Transformer的多模态轨迹预测的算法，最后对基于Transformer的多模态轨迹预测做出总结与展望。\n1 Transformer框架 2017年，Waswani等人提出Transformer[1]，这是一种完全基于注意力机制的模型。注意力机制是一种捕捉向量之间相关性的方法，既可以考虑全局又可以聚焦重点，其在捕获车辆之间交互信息有非常好的性能。\n基于注意力机制的Transformer比经典的深度学习模型CNN[12]和RNN[2]具备如下优势。注意力机制可以解决基于CNN方法中可解释性差以及无法建模智能体间交互关系的问题。注意力机制可以解决基于RNN[2]方法中长距离依赖问题，可以有更好的记忆力，可以获取更长距离的信息。相较于基于 RNN的方法在第t时间步的隐藏状态Ht需要前一个时间步t-1的隐藏状态输出后才能处理，难以并行，Transformer模型可以实现并行计算, Transformer可以同时提取上下文信息，并且在信息传递过程中规避梯度爆炸或梯度遗忘问题。\nTransformer框架主要包含编码器、解码器、注意力机制三个重要部分，以下具体介绍。\n1.1 编码器-解码器 编码器用于将历史轨迹和环境信息嵌入到上下文信息中并输入到Transformer中，其输入为车道信息，历史轨迹，车辆交互信息等，输出为具有这些信息的特征。编码器由N=6个独立层组成，每层有两个子层，分别是多头注意力和全连接前馈网络，子层通过残差结构连接后进行归一化输出，每层维度d_model=512确保输入输出维度不变。\n解码器用于生成预测轨迹，其输入为编码器的输出，输出为预测轨迹。解码器由N=6个独立层组成，每层有三个子层，除了多头注意力和全连接前馈网络，还插入第三个子层，掩码多头注意力(Masked Multi-head attention)，用于对编码器堆栈的输出执行多头注意，掩码用于未来时刻进行掩码处理，确保当前位置的预测不会依赖于未来位置。\n1.2 注意力机制 注意力机制用于建模车辆间交互关系。注意力机制将查询向量Q和一组键值对向量K-V映射到输出，输出值的加权和，权重则是通过Q和K相似度计算。Transformer框架主要由缩放点积注意力机制和多头注意力机制组成，缩放点积注意力机制中输入由向量query(dk)，key(dk)以及value(dv)组成，如图2，QK向量通过点积处理计算相似度，通过比例因子$\\sqrt{d_k}$(用来求dk的平方根)处理避免QK内积方差太大导致难以学习的情况，应用softmax函数获取权重来获得value的权重。掩码(Mask)处理避免解码器在训练是获取未来的信息影响预测。\n$$Attention(Q, K, V) = softmax(\\frac{QK^{T}}{\\sqrt{d_k}}) V$$\n多头注意机制通过将Q,K,V分别线性投影到缩放点积注意机制中，投影h次后做h次注意力函数运算，通过并行计算，生成dv维输出value，将每一个输出值链接后再做一次投影得到最终value。通过多头注意机制，Transformer模型可以联合注意来自不同位置的不同子空间信息。\n1.3 小结 在这一节中主要介绍了Transformer框架中三个主要部分，编码器，解码器，注意力机制的输入输出及其在轨迹预测中的用途。下一节中将对基于Transformer的多模态轨迹方法介绍。\n2 基于Transformer的多模态轨迹预测方法 上一部分介绍了Transformer中编码器解码器结构，缩放点积注意机制，多头注意机制。这一部分中，将介绍近年来基于Transformer框架的可随场景变化的自适应调整的多模态方法。多模态轨迹预测旨在为处于异构复杂高动态环境中的目标车辆生成多条可能的且具有安全性的轨迹，由于不确定性的存在，目标车辆即使在相同场景下也有可能表现不同，因此这也是多模态轨迹预测面临的挑战。实现多模态预测的另一个挑战在于如何用有限的训练样本覆盖给定场景中所有可能的结果。多智能体轨迹预测需要在两个关键维度建模：(1)时间维度：将历史信息对智能体未来状态的影响建模 (2)社会维度：对每个智能体之间的交互关系建模。在时间维度层面，现有基于经典深度学习的模型CNN，RNN无法建模长时间序列，会导致时间信息丢失问题，基于Transformer可以通过将位置编码通过时间编码的形式保存长历史轨迹的信息。在社会维度层面，Transformer模型可以通过注意力机制建模人-车，车-车，车-环境之间的交互关系，可以通过分配权重的方式选择影响力最大的交互，以此为基础，Transformer可扩展到多智能体交互环境中。\n现有基于概率的方法[3]和基于建议的启发式[4]的方法虽然可以通过添加规则的方式输出概率分布或通过添加具有强约束的锚点实现多模态轨迹预测，但是基于概率的方法过度依赖于先验分布和损失函数，容易出现优化不稳定或模式崩溃现象，基于建议的启发式方法过度依赖于锚点质量，不能保证生成多模态情况。基于Transformer的方法可以避免在设计先验分布和损失函数过程中大量的人工工作，同时可以更好的捕捉到轨迹预测的多模态性质，实现多模态轨迹预测。\nLiu[5]等针对如何实现多模态轨迹预测，提出mmTransformer框架，该方法在Argoverse基准排行榜排名第一名，框架由三个独立的堆叠式的Transformer模型组成，分别聚合历史轨迹，道路信息以及交互信息。如图2所示，mmTransformer整体框架可由两部分组成，第一部分仅由运动提取器和地图聚合器分别对车辆的信息及环境信息进行编码，不考虑交互信息，第二部分通过社会构造函数对临近信息进行聚合，并对车辆之间的依赖关系进行建模，整个过程是依照逻辑顺序，即社会关系是基于每个车辆特征构建的。该方法还提出基于区域的训练策略(RTS)，在初始化建议后，将建议路径分为空间群组，通过路径分配计算路径回归损失和分类损失，以确保生成预测轨迹的多样性。\nYuan等针对时间和社会维度上独立特征编码信息丢失问题，提出AgentFormer[6]允许一个智能体在某个时间的状态直接影响另一个智能体未来的状态，而不是通过在一个维度上编码的中间特征，AgentFormer(图3)可以同时学习时序信息和交互关系，智能体当前时刻的关系可以通过不同时刻关系体现，解决了传统Transformer注意力中各个输入元素权重平等造成的时间和智能体信息损失，该模型采用时间编码减少时间信息损失，通过独特的Agent-aware注意力机制编码智能体和时间的关系，采用CVAE形式，以概率形式描述，确保了生成轨迹的多模态性。\nHuang[10]等针对如何编码多智能体交互问题，使用TF编码器(图4)建模智能体与周围车辆的交互关系，多头注意机制可以帮助提取智能体交互的不同信息。通过矢量地图表示和基于地车道集的地图结构提取地图和目标智能体之间的关系。\nZhao等针对传统注意力机制无法捕获多智能体之间交互的问题，提出Spatial-Channel Transformer[9]在基于Transformer框架的基础上，插入了一个通道注意力(Channel-wise attention)模块(图5)，即挤压激励网络（SE）[8]，并将SE网络用于轨迹前途，以捕获相邻通道之间的相互作用。Zhang等针对多智能体轨迹预测问题，提出的Gatformer[11]相较于GNN，采用灵活的图结构，相比基于图神经网络的方法，降低了全连通图造成的计算复杂性。基于稀疏图，Gatformer可以预测多智能体未来的轨迹，同时考虑智能体之间相互作用。目前基于GAN和CVAE方法导致模型存在可解释性差的问题，Gatformer注意机制通过对交互权重分配可以提高性能并提高模型的可解释性，该模型对模型在多环境下验证了模型的鲁棒性。\n复杂的驾驶环境通常是静态动态混合形式作为输入信息，针对如何表示融合有关道路几何形状，车道连通性，时变交通信号灯状态，其他交通参与者状态以及交互的历史信息，并将其编码，现有方法为了对多样特征建模而设计的具有不同特定模块集的复杂TF模型，由于注意对输入序列长度是二次方，且位置前馈网络是昂贵的自网络因此导致TF难以规模化，质量和效率无法同时保证。针对此问题，Waymo提出WayFormer7 在Transformer框架的基础上，研究了三种输入模式：前融合，后融合和分层融合的利弊，对于每种融合类型，探索通过分解注意或潜在query注意来权衡效率和质量的策略。后融合中每种特征都有与之相对应的编码器，前融合不是将注意编码器专用于每个模态，而是减少特定模态的参数到投影层，分层融合是前融合，后融合折中的模型，将场景信息分别通过注意编码器编码后聚合，将聚合特征输入到最终的注意机制交叉模型中，有效的将场景编码器的深度在模态特定编码器和跨模态编码器之间平均。本文还对如何将Transformer扩展到大型多维序列中提供了解决方案，减少了每个块的注意分量和位置前馈网络的计算成本。\n3 总结与展望 综上所述，现阶段在多模态轨迹预测领域的整体框架已经成型，都是由编码器+交互+解码器组成，针对多模态轨迹预测目前具有的挑战性问题，基于Transformer轨迹预测在Argoverse数据集的平均位移误差(ADE)和最终位移误差(FDE)性能指标上取得了最优水平。Transformer框架在交互部分，特别是对障碍物周围信息交互效果相比CNN与RNN方法有明显的提升，Transformer可以解决长历史轨迹信息丢失问题，同时依靠注意力机制捕获车辆之间交互信息。\n然而Transformer模型虽然在自然语言处理及视觉领域均取得了非常显著的成果，但是在自动驾驶轨迹预测方向的研究还是较少。目前还无法确Transformer算法可以应用到更为复杂多变的环境中，因为在现实环境中，由于传感器限制，如果有其他交通参与者遮挡，或者出现缺失/过时/不准确的道路基础设施信息，以及感知范围有限，无法获得实验阶段的理想数据，会导致预测轨迹出现偏差。同时可解释性低也是基于Transformer模型面临的主要问题之一，现有方法中对于预测轨迹的置信度难以解释，因此导致模型解释性低。这些问题也将是未来使用Transformer做多模态轨迹预测的可继续深入的方向。其次现有方法对于多模态的研究还不充分，相信在未来的发展中，基于Transformer的多模态轨迹预测方法会更加完善，轨迹预测技术走进现实生活一定可以实现。\n参考文献：\n[1]A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin, “Attention is all you need,” CoRR, vol. abs/1706.03762, 2017.arXiv: 1706.03762. [Online]. Available: http://arxiv.org/abs/1706.03762.\n[2]A. Graves, “Generating sequences with recurrent neural networks,” CoRR, vol. abs/1308.0850, 2013. arXiv: 1308 . 0850. [Online]. Available: http : / /arxiv.org/abs/1308.0850.\n[3]N. Lee, W. Choi, P. Vernaza, C. B. Choy, P. H. S. Torr, and M. K. Chandraker, “DESIRE: distant future prediction in dynamic scenes with interacting agents,” CoRR, vol. abs/1704.04394, 2017. arXiv: 1704 . 04394. [Online]. Available: http://arxiv.org/abs/1704.04394.\n[4]H. Zhao, J. Gao, T. Lan, C. Sun, B. Sapp, B. Varadarajan, Y. Shen, Y. Shen, Y. Chai, C. Schmid, C. Li, and D. Anguelov, “TNT: target-driven trajectory prediction,”CoRR, vol. abs/2008.08294, 2020. arXiv: 2008 . 08294. [Online]. Available:https://arxiv.org/abs/2008.08294.\n[5]Y. Liu, J. Zhang, L. Fang, Q. Jiang, and B. Zhou, “Multimodal motion prediction with stacked transformers,” in 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021, pp. 7573–7582. DOI: 10.1109/CVPR46437.2021.00749.\n[6]Y. Yuan, X. Weng, Y. Ou, and K. Kitani, “Agentformer: Agent-aware transformers for socio-temporal multi-agent forecasting,” in 2021 IEEE/CVF International Conference on Computer Vision (ICCV), 2021, pp. 9793–9803. DOI: 10.1109/ICCV48922.2021.00967.\n[7]Nayakanti, N., Al-Rfou, R., Zhou, A., Goel, K., Refaat, K. S., and Sapp, B., “Wayformer: Motion Forecasting via Simple \u0026amp; Efficient Attention Networks”, arXiv e-prints, 2022.\n[8]J. Hu, L. Shen, S. Albanie, G. Sun, and E. Wu, “Squeeze-and-excitation networks,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 42,no. 8, pp. 2011–2023, 2020. DOI: 10.1109/TPAMI.2019.2913372.\n[9]J. Zhao, X. Li, Q. Xue, and W. Zhang, “Spatial-channel transformer network for trajectory prediction on the traffic scenes,” CoRR, vol. abs/2101.11472,2021. arXiv: 2101.11472. [Online]. Available: https://arxiv.org/abs/2101.11472.\n[10]Z. Huang, X. Mo and C. Lv, \u0026ldquo;Multi-modal Motion Prediction with Transformer-based Neural Network for Autonomous Driving,\u0026rdquo; 2022 International Conference on Robotics and Automation (ICRA), 2022, pp. 2605-2611, doi: 10.1109/ICRA46639.2022.9812060.\n[11]K. Zhang, X. Feng, L. Wu, and Z. He, “Trajectory prediction for autonomous driving using spatial-temporal graph attention transformer,” IEEE Transac tions on Intelligent Transportation Systems, pp. 1–11, 2022. DOI: 10.1109/TITS.2022.3164450.\n[12]G. Xie, A. Shangguan, F. Rong, W. Ji, M. Weigang, and X. Hei, “Motion trajectory prediction based on a cnn-lstm sequential model,” Science China Information Sciences, 2020.\nref: [1]. https://mp.weixin.qq.com/s/yCcsHNXeIBdCVuUwpUVy3w\nTransformer 详解 B站讲解视频 参考连接: https://wmathor.com/index.php/archives/1438/\nTransformer 是谷歌大脑在 2017 年底发表的论文 attention is all you need 中所提出的 seq2seq 模型。现在已经取得了大范围的应用和扩展，而 BERT 就是从 Transformer 中衍生出来的预训练语言模型\n这篇文章分为以下几个部分 - Transformer 直观认识 - Positional Encoding - Self Attention Mechanism - 残差连接和 Layer Normalization - Transformer Encoder 整体结构 - Transformer Decoder 整体结构 - 总结 - 参考文章\n0. Transformer 直观认识 Transformer 和 LSTM 的最大区别，就是 LSTM 的训练是迭代的、串行的，必须要等当前字处理完，才可以处理下一个字。而 Transformer 的训练时并行的，即所有字是同时训练的，这样就大大增加了计算效率。Transformer 使用了位置嵌入 (Positional Encoding) 来理解语言的顺序，使用自注意力机制（Self Attention Mechanism）和全连接层进行计算，这些后面会讲到\nTransformer 模型主要分为两大部分，分别是 Encoder 和 Decoder。Encoder 负责把输入（语言序列）隐射成隐藏层（下图中第 2 步用九宫格代表的部分），然后解码器再把隐藏层映射为自然语言序列。例如下图机器翻译的例子（Decoder 输出的时候，是通过 N 层 Decoder Layer 才输出一个 token，并不是通过一层 Decoder Layer 就输出一个 token）\n本篇文章大部分内容在于解释 Encoder 部分，即把自然语言序列映射为隐藏层的数学表达的过程。理解了 Encoder 的结构，再理解 Decoder 就很简单了\n上图为 Transformer Encoder Block 结构图，注意：下面的内容标题编号分别对应着图中 1,2,3,4 个方框的序号\n1. Positional Encoding 由于 Transformer 模型没有循环神经网络的迭代操作，所以我们必须提供每个字的位置信息给 Transformer，这样它才能识别出语言中的顺序关系\n现在定义一个位置嵌入的概念，也就是 Positional Encoding，位置嵌入的维度为 [max_sequence_length, embedding_dimension], 位置嵌入的维度与词向量的维度是相同的，都是 embedding_dimension。max_sequence_length 属于超参数，指的是限定每个句子最长由多少个词构成\n注意，我们一般以字为单位训练 Transformer 模型。首先初始化字编码的大小为 [vocab_size, embedding_dimension]，vocab_size 为字库中所有字的数量，embedding_dimension 为字向量的维度，对应到 PyTorch 中，其实就是 nn.Embedding(vocab_size, embedding_dimension)\n论文中使用了 sin 和 cos 函数的线性变换来提供给模型位置信息:\n$$\\left{\\begin{aligned} PE(pos, 2i) = \\sin (pos/10000^{2i/d_{model}}) \\ PE(pos, 2i + 1) = \\cos (pos/10000^{2i/d_{model}}) \\ \\end{aligned}\\right.$$\n上式中 $pos$ 指的是一句话中某个字的位置，取值范围是$ [0, max_sequence_length] $ ， $ i $ 指的是字向量的维度序号，取值范围是 [0, embedding_dimension / 2] ， $d_{model}$指的是 embedding_dimension​的值\n上面有 sin 和 cos 一组公式，也就是对应着 embedding_dimension 维度的一组奇数和偶数的序号的维度，例如 0,1 一组，2,3 一组，分别用上面的 sin 和 cos 函数做处理，从而产生不同的周期性变化，而位置嵌入在 embedding_dimension​维度上随着维度序号增大，周期变化会越来越慢，最终产生一种包含位置信息的纹理，就像论文原文中第六页讲的，位置嵌入函数的周期从 $ 2\\pi $ 到 $10000 * 2 \\pi$ 变化，而每一个位置在 embedding_dimension ​维度上都会得到不同周期的 $ \\sin $ 和 $ \\cos $ 函数的取值组合，从而产生独一的纹理位置信息，最终使得模型学到位置之间的依赖关系和自然语言的时序特性。\n如果不理解这里为何这么设计，可以看这篇文章 Transformer 中的 Positional Encoding\n下面画一下位置嵌入，纵向观察，可见随着 embedding_dimension​序号增大，位置嵌入函数的周期变化越来越平缓\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import numpy as np import matplotlib.pyplot as plt import seaborn as sns import math def get_positional_encoding(max_seq_len, embed_dim): # 初始化一个positional encoding # embed_dim: 字嵌入的维度 # max_seq_len: 最大的序列长度 positional_encoding = np.array([ [pos / np.power(10000, 2 * i / embed_dim) for i in range(embed_dim)] if pos != 0 else np.zeros(embed_dim) for pos in range(max_seq_len)]) positional_encoding[1:, 0::2] = np.sin(positional_encoding[1:, 0::2]) # dim 2i 偶数 positional_encoding[1:, 1::2] = np.cos(positional_encoding[1:, 1::2]) # dim 2i+1 奇数 return positional_encoding positional_encoding = get_positional_encoding(max_seq_len=100, embed_dim=16) plt.figure(figsize=(10,10)) sns.heatmap(positional_encoding) plt.title(\u0026#34;Sinusoidal Function\u0026#34;) plt.xlabel(\u0026#34;hidden dimension\u0026#34;) plt.ylabel(\u0026#34;sequence length\u0026#34;) 1 2 3 4 5 6 7 plt.figure(figsize=(8, 5)) plt.plot(positional_encoding[1:, 1], label=\u0026#34;dimension 1\u0026#34;) plt.plot(positional_encoding[1:, 2], label=\u0026#34;dimension 2\u0026#34;) plt.plot(positional_encoding[1:, 3], label=\u0026#34;dimension 3\u0026#34;) plt.legend() plt.xlabel(\u0026#34;Sequence length\u0026#34;) plt.ylabel(\u0026#34;Period of Positional Encoding\u0026#34;) 2. Self Attention Mechanism 对于输入的句子 $ X $，通过 WordEmbedding 得到该句子中每个字的字向量，同时通过 Positional Encoding 得到所有字的位置向量，将其相加（维度相同，可以直接相加），得到该字真正的向量表示。第 $ t $ 个字的向量记作 $ x_t $。\n接着我们定义三个矩阵 $ W_Q $, $ W_K $, $ W_V $，使用这三个矩阵分别对所有的字向量进行三次线性变换，于是所有的字向量又衍生出三个新的向量 $ q_t $, $ k_t $, $ v_t $。我们将所有的 $ q_t $ 向量拼成一个大矩阵，记作查询矩阵 $ Q $ ，将所有的 $ k_t $ 向量拼成一个大矩阵，记作键矩阵 $ K $ ，将所有的 $ v_t $ 向量拼成一个大矩阵，记作值矩阵 $ V $ （见下图）\n为了获得第一个字的注意力权重，我们需要用第一个字的查询向量 $ q_1 $ 乘以键矩阵 $ K $（见下图）\n1 2 3 [0, 4, 2] [1, 0, 2] x [1, 4, 3] = [2, 4, 4] [1, 0, 1] 之后还需要将得到的值经过 softmax，使得它们的和为 1（见下图）\n1 softmax([2, 4, 4]) = [0.0, 0.5, 0.5] 有了权重之后，将权重其分别乘以对应字的值向量 $ v_t $（见下图）\n1 2 3 0.0 * [1, 2, 3] = [0.0, 0.0, 0.0] 0.5 * [2, 8, 0] = [1.0, 4.0, 0.0] 0.5 * [2, 6, 3] = [1.0, 3.0, 1.5] 最后将这些权重化后的值向量求和，得到第一个字的输出（见下图）\n1 2 3 4 5 [0.0, 0.0, 0.0] + [1.0, 4.0, 0.0] + [1.0, 3.0, 1.5] ----------------- = [2.0, 7.0, 1.5] 对其它的输入向量也执行相同的操作，即可得到通过 self-attention 后的所有输出\n矩阵计算\n上面介绍的方法需要一个循环遍历所有的字$ x_t $，我们可以把上面的向量计算变成矩阵的形式，从而一次计算出所有时刻的输出\n第一步就不是计算某个时刻的$ q_t $, $ k_t $, $ v_t $了，而是一次计算所有时刻的 $ Q $, $ K $, $ V $。计算过程如下图所示，这里的输入是一个矩阵 $ X $，矩阵第 $ t $ 行为第 $ t $ 个词的向量表示 $x_t$\n接下来将 $ Q $ 和 $K_T$ 相乘，然后除以 $ \\sqrt{d_k} $（这是论文中提到的一个 trick），经过 softmax 以后再乘以 $ V $ 得到输出\nMulti-Head Attention\n这篇论文还提出了 Multi-Head Attention 的概念。其实很简单，前面定义的一组 $Q $, $ K $, $ V $, 可以让一个词 attend to 相关的词，我们可以定义多组 $Q $, $ K $, $ V $，让它们分别关注不同的上下文。计算 $Q $, $ K $, $ V $ 的过程还是一样，只不过线性变换的矩阵从一组 $ W^Q $, $ W^K $, $ W^V $ 变成了多组$ W^Q_0 $, $ W^K_0 $, $ W^V_0 $ ，$ W^Q_1 $, $ W^K_1 $, $ W^V_1 $ ，… 如下图所示:\n对于输入矩阵 $ X $ ，每一组 $ Q $ 、$ K $ 和 $ V $ 都可以得到一个输出矩阵 $ Z $ 。如下图所示\nPadding Mask 上面 Self Attention 的计算过程中，我们通常使用 mini-batch 来计算，也就是一次计算多句话，即 $ X $ 的维度是 [batch_size, sequence_length]，sequence_length​是句长，而一个 mini-batch 是由多个不等长的句子组成的，我们需要按照这个 mini-batch 中最大的句长对剩余的句子进行补齐，一般用 0 进行填充，这个过程叫做 padding\n但这时在进行 softmax 就会产生问题。回顾 softmax 函数 $\\sigma(z_i) = \\frac{e^{z_i}}{\\sum_K^{j=i} e^{z_j}}$，$e^0$ 是 1，是有值的，这样的话 softmax 中被 padding 的部分就参与了运算，相当于让无效的部分参与了运算，这可能会产生很大的隐患。因此需要做一个 mask 操作，让这些无效的区域不参与运算，一般是给无效区域加一个很大的负数偏置，即\n$$\\left{\\begin{aligned} Z_{illegal} = Z_{illegal} + bias_{illegal} \\ bias_{illegal}-\u0026gt; -\\infin \\ \\end{aligned}\\right.$$\n3. 残差连接和 Layer Normalization 残差连接\n4. Transformer Encoder 整体结构 5. Transformer Decoder 整体结构 6. 总结 7. 参考文章 ","permalink":"https://jianye0428.github.io/en/posts/notes/2022-10-09_transformer/","summary":"reference: [1]. The Transformer Family [2]. Attention [3]. 细节考究 Transformer Family Notations Symbol Meaning $d$ The model size / hidden state dimension / positional encoding size. $h$ The number of heads in multi-head attention layer. $L$ The segment length of input sequence. $X \\in \\mathbb R ^ {L \\times d}$ The input sequence where each element has been mapped into an embedding vector of shape , same","title":"Transformer Overview"},{"content":"references: [1]. https://www.cnblogs.com/rossiXYZ/p/14881812.html\n0 摘要 Horovod 是Uber于2017年发布的一个易于使用的高性能的分布式训练框架，在业界得到了广泛应用。\n本系列将通过源码分析来带领大家了解 Horovod。本文是系列第三篇，从 python 开始进入 Horovod 世界，看看 Horovodrun 做了什么。\n前两篇链接如下：\n深度学习分布式训练框架 Horovod (1) \u0026mdash; 基础知识\n深度学习分布式训练框架 horovod (2) \u0026mdash; 从使用者角度切入\n1 背景知识 首先介绍一些相关背景知识。\n1.1 分布式体系 在设计并行计算机时，最直接的方式就是多个计算单元共享一个内存。共享内存的编程在数据交换和访问上有较大的优势，程序编写起来更加简单。但在扩展性上有较大的瓶颈。\n另一种方式为分布式内存。即每个计算单元有单独的内存，计算单元之间的数据访问通过互联网络去传输。这一架构在可移植性和扩展上会强很多，但消息的传递会成为程序设计中的难点。\n将这两点结合，即是分布式共享内存并行计算机的架构，也是当今最常用的体系结构。\n1.2 并行任务通信 并行任务通信一般分为P2P(Point-to-point communication)和 Collective communication。\nP2P通信这种模式只有一个sender和一个receiver，即点到点通信. Collective communication含多个sender多个receive Collective communication包含一些常见的原语\nbroadcast reduce，allreduce scatter，scatter reduce gather，allgather ring-base collectives ring-allreduce 传统Collective communication假设通信节点组成的topology是一颗fat tree，这样通信效率最高。但实际的通信topology可能比较复杂，并不是一个fat tree。因此一般用ring-based Collective communication。\n1.3 MPI MPI(Message Passing Interface) 是一种可以支持点对点和广播的通信协议，具体实现的库有很多，使用比较流行的包括 Open Mpi， Intel MPI 等等。\nMPI 是一种消息传递编程模型。消息传递指用户必须通过显式地发送和接收消息来实现处理器间的数据交换。在这种并行编程中，每个控制流均有自己独立的地址空间，不同的控制流之间不能直接访问彼此的地址空间，必须通过显式的消息传递来实现。这种编程方式是大规模并行处理机(MPP)和机群(Cluster)采用的主要编程方式。由于消息传递程序设计要求用户很好地分解问题，组织不同控制流间的数据交换，并行计算粒度大，特别适合于大规模可扩展并行算法。\nMPI 是基于进程的并行环境。进程拥有独立的虚拟地址空间和处理器调度，并且执行相互独立。MPI 设计为支持通过网络连接的机群系统，且通过消息传递来实现通信，消息传递是 MPI 的最基本特色。\n1.4 Open-MPI OpenMPI 是一种高性能消息传递库，最初是作为融合的技术和资源从其他几个项目（FT-MPI， LA-MPI， LAM/MPI， 以及 PACX-MPI），它是 MPI-2 标准的一个开源实现，由一些科研机构和企业一起开发和维护。因此，OpenMPI 能够从高性能社区中获得专业技术、工业技术和资源支持，来创建最好的 MPI 库。OpenMPI 提供给系统和软件供应商、程序开发者和研究人员很多便利。易于使用，并运行本身在各种各样的操作系统，网络互连，以及一批/调度系统。\n1.5 MPI 使用问题 因为MPI是分布式内存编程，在后面的开发中涉及节点间信息的传递。往往数据和程序是在多个节点上，所以需要保证执行命令时各节点之间信息的交换。\n具体使用之中，就有两个问题:\n这个多台机器Open-MPI是如何发现并建立连接的呢？ 多机多卡在训练过程中，传输环如何建立，这个也是决定了训练效率，那么Open-MPI如何去做呢？ 关于第一个问题：\n设置SSH免密登录可以免去操作中密码的输入。各节点生成私钥和公钥后需要认证，此时可以保证本机免密登录。将各个子节点的公钥文件发送给主节点，然后分别加入到主节点的认证文件中，此时可以保证主节点对各个子节点的免密登录。最后将认证文件传回到每个子节点，从而保证各个子节点对其他节点之间的免密登录。\n在 Open-MPI 启动的时候，可以指定--hostfile或者--host去指定要运行任务的 IP 或 Hostname，这样 Open-MPI 就会试图通过 ssh 免秘钥的方式试图去链接对方机器，并执行一系列命令，主要是为了同步环境变量、当前路径以及下发启动命令。\n当然用户也可以通过其他方式给远程机器下发命令，这个可以通过环境变量OMPI_MCA_plm_rsh_agent指定。\n关于第二个问题：\n当所有的机器建立好连接，准备开始计算，为了能够最高效的去通信，Open-MPI中集成了组件——hwloc。该组件主要是为了单机硬件资源拓扑构建，进而构建最短路径通信。\n2 入口点 很多机器学习框架都会采用如下套路：shell脚本（可选），python端 和 C++端。\nShell脚本是启动运行的入口，负责解析参数，确认并且调用训练程序； Python是用户的接口，引入了C++库，封装了API，负责运行时和底层C++交互； C++实现底层训练逻辑； 以我们先看看 hordovodrun 脚本。\n2.1 如何运行 官方给出的 Hovorod 运行范例之一如下：\n1 horovodrun -np 2 -H localhost:4 --gloo python /horovod/examples/tensorflow2/tensorflow2_mnist.py 这里 -np 指的是进程的数量，localhost:4表示localhost节点上4个GPU。\n注意，如果虚拟机只有一个核。想要强行地达到并行的效果，可以使用 -np参数，它会自动帮你把一个核心切成多份处理器，每一个分布式处理就是一个slot。\n因此，我们可以从 horovodrun 这个命令入手看看。\n2.2 horovodrun 入口文件可以从 setup.py 看到，其就被映射成 horovod.runner.launch:run_commandline。\n1 2 3 4 5 6 entry_points={ \u0026#39;console_scripts\u0026#39;: [ \u0026#39;horovodrun = horovod.runner.launch:run_commandline\u0026#39; ] } 所以我们看看 run_commandline\n2.3 run_commandline 该命令位于：horovod-master/horovod/runner/launch.py，我们摘录重要部分。\n1 2 3 def run_commandline(): args = parse_args() _run(args) 于是进入到 _run 函数。可以看到，Horovod 会依据是否是弹性训练来选择不同的路径。我们在此系列中，会首先分析 非弹性训练 _run_static。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def _run(args): # if hosts are not specified, either parse from hostfile, or default as # localhost if not args.hosts and not args.host_discovery_script: if args.hostfile: args.hosts = hosts.parse_host_files(args.hostfile) else: # Set hosts to localhost if not specified args.hosts = \u0026#39;localhost:{np}\u0026#39;.format(np=args.np) # Convert nics into set args.nics = set(args.nics.split(\u0026#39;,\u0026#39;)) if args.nics else None if _is_elastic(args): return _run_elastic(args) else: return _run_static(args) # 我们先看这里 2.4 非弹性训练 _run_static() 在 _run_static 之中做了如下操作：\n首先解析各种参数，得到 settings； 会调用 driver_service.get_common_interfaces 获取网卡以及其他host的信息，依据这些信息会进行slot分配，这部分很复杂，具体我们会有专文讲解（下一篇）。 这里有一个问题：为什么要得到 host, slot, rank 之间的关系信息？由于工程上的考虑，底层 C++ 世界中对于 rank 的角色做了区分：rank 0 是 master，rank n 是 worker，所以这些信息需要决定并且传递给 C++世界； 会根据是否在参数中传递运行函数来决定采取何种路径，一般默认没有运行参数，所以会执行_launch_job 来启动训练 job； 具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def _run_static(args): settings = hvd_settings.Settings(verbose=2 if args.verbose else 0, ssh_port=args.ssh_port, ssh_identity_file=args.ssh_identity_file, extra_mpi_args=args.mpi_args, tcp_flag=args.tcp_flag, binding_args=args.binding_args, key=secret.make_secret_key(), start_timeout=tmout, num_proc=args.np, hosts=args.hosts, output_filename=args.output_filename, run_func_mode=args.run_func is not None, nics=args.nics,...) # 首先解析各种参数，得到 settings fn_cache = None if not args.disable_cache: params = \u0026#39;\u0026#39; if args.np: params += str(args.np) + \u0026#39; \u0026#39; if args.hosts: params += str(args.hosts) + \u0026#39; \u0026#39; if args.ssh_port: params += str(args.ssh_port) if args.ssh_identity_file: params += args.ssh_identity_file parameters_hash = hashlib.md5(params.encode(\u0026#39;utf-8\u0026#39;)).hexdigest() fn_cache = cache.Cache(CACHE_FOLDER, CACHE_STALENESS_THRESHOLD_MINUTES, parameters_hash) # 获取网卡以及其他host的信息，依据这些信息会进行slot分配 all_host_names, _ = hosts.parse_hosts_and_slots(args.hosts) remote_host_names = network.filter_local_addresses(all_host_names) nics = driver_service.get_common_interfaces(settings, all_host_names, remote_host_names, fn_cache) if args.run_func: # get the driver IPv4 address driver_ip = network.get_driver_ip(nics) run_func_server = KVStoreServer(verbose=settings.verbose) # 启动内部KV服务器 run_func_server_port = run_func_server.start_server() put_data_into_kvstore(driver_ip, run_func_server_port, \u0026#39;runfunc\u0026#39;, \u0026#39;func\u0026#39;, args.run_func) # 把\u0026#39;func\u0026#39;, args.run_func存储成KV command = [sys.executable, \u0026#39;-m\u0026#39;, \u0026#39;horovod.runner.run_task\u0026#39;, str(driver_ip), str(run_func_server_port)] try: _launch_job(args, settings, nics, command) results = [None] * args.np for i in range(args.np): results[i] = read_data_from_kvstore(driver_ip, run_func_server_port,\u0026#39;runfunc_result\u0026#39;, str(i)) return results finally: run_func_server.shutdown_server() else: command = args.command _launch_job(args, settings, nics, command) # 我们重点讲解这里 return None 目前逻辑如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 +-----------+ |horovodrun | +-----+-----+ | | v +--------+--------+ | run_commandline | +----+------+-----+ | | +---------+ +--------+ | | | | v v +-----+--------+ +----+--------+ | _run_elastic | | _run_static | | | | | +--------------+ +-------------+ 至此，我们已经分析完成 horovod 的入口，下面会分析具体如何启动 Job。\n3 运行训练 Job 3.1 _launch_job _launch_job 会根据配置或者安装情况来进行具体调用。我们看到有三种可能：gloo, mpi, js。\njsrun的资料很难找，所以我们重点看看 gloo, mpi 这两种。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def _launch_job(args, settings, nics, command): env = os.environ.copy() config_parser.set_env_from_args(env, args) def gloo_run_fn(): driver_ip = network.get_driver_ip(nics) gloo_run(settings, nics, env, driver_ip, command) def mpi_run_fn(): mpi_run(settings, nics, env, command) def js_run_fn(): js_run(settings, nics, env, command) run_controller(args.use_gloo, gloo_run_fn, args.use_mpi, mpi_run_fn, args.use_jsrun, js_run_fn, args.verbose) 3.2 run_controller run_controller 依然是一个中介函数，具体导入 gloo 或者 mpi。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def run_controller(use_gloo, gloo_run, use_mpi, mpi_run, use_jsrun, js_run, verbosity): if use_gloo: gloo_run() elif use_mpi: mpi_run() elif use_jsrun: js_run() else: if mpi_built(verbose=verbose): if lsf.LSFUtils.using_lsf() and is_jsrun_installed(): js_run() else: mpi_run() elif gloo_built(verbose=verbose): gloo_run() 目前逻辑如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 +-----------+ |horovodrun | +-----+-----+ | | v +--------+--------+ | run_commandline | +----+------+-----+ | | +---------+ +--------+ | | | | v v +-----+--------+ +----+--------+ | _run_elastic | | _run_static | | | | | +--------------+ +------+------+ | | v +------+------+ | _launch_job | | | +------+------+ | | v +---------+--------+ | run_controller | | | +----+----+-----+--+ | | | +-------------+ | +--------+ | | | | | | v v v +------+---+ +------+----+ +---+-----+ | gloo_run | | mpi_run | | js_run | | | | | | | +----------+ +-----------+ +---------+ 于是我们下面就分为两个分支介绍：gloo \u0026amp; mpi。\n4 Gloo 实现 4.1 Gloo 简介 Gloo 是 facebook出品的一个类似MPI的集合通信库（https://github.com/facebookincubator/gloo）。\n集合通信库的主要特征是：大体上会遵照 MPI 提供的接口规定，实现了包括点对点通信（SEND,RECV等），集合通信（ REDUCE，BROADCAST，ALLREDUCE等）等相关接口，然后根据自己硬件或者是系统的需要，在底层实现上进行相应改动，保证接口的稳定和性能。\nGloo 为CPU和GPU提供了集合通信程序的优化实现。 它特别适用于GPU，因为它可以执行通信而无需使用GPUDirect 将数据传输到CPU的内存。 它还能够使用 NCCL 执行快速的节点内通信，并实现其自己的节点间例程计算。你不需要考虑内存数据的拷贝，只需要实现逻辑就可以。\nGloo 支持集合通信（collective Communication），并对其进行了优化。由于 GPU 之间可以直接进行数据交换，而无需经过 CPU 和内存，因此，在 GPU 上使用 gloo后端速度更快。\nHorovod 为什么会选择 Gloo？个人认为除了其功能的全面性和性能之外，基于它可以二次开发是一个亮点，比如下面我们所说的 Rendezvous 功能就被 Horovod 用来实现弹性训练（我们后文有专门讲解）。\nGloo 和 MPI 都起到了同样类似作用：\n一方面Horovod内集成了基于 Gloo 的AllReduce，类似于NCCL，都是用作梯度规约； 另一方面，Gloo 可以用来启动多个进程（Hovorod里用Rank表示），实现并行计算； 具体如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 +-----------------------+ +-----------------------+ +------------------------+ | gloo_run slot 1 | | gloo_run slot 2 | | gloo_run slot 3 | | | | | | | | +-------------------+ | | +------------------+ | | +------------------+ | | | python train.py | | | | python train.py | | | | python train.py | | +----+ +\u0026lt;------+ +\u0026lt;------+ +\u0026lt;------+ | | | | | | | | | | | | | | | | +-------------------+ | | +------------------+ | | +------------------+ | | | | | | | | | | | +-----------------------+ +-----------------------+ +------------------------+ | | | | | | | v--------------------------------------------------------------------------------------\u0026gt; Ring Allreduce on Gloo 4.2 Rendezvous 功能 4.2.1 Rendezvous 概念 在 Gloo 的文档中，如此说:\n1 2 3 4 5 6 The rendezvous process needs to happen exactly once per Gloo context. It makes participating Gloo processes exchange details for setting up their communication channels. For example, when the TCP transport is used, processes exchange IP address and port number details of listening sockets. Rendezvous can be executed by accessing a key/value store that is accessible by all participating processes. Every process is responsible for setting a number of keys and will wait until their peers have set their keys. The values stored against these keys hold the information that is passed to the transport layer. 大致意思是：\nGloo 在每一个 Gloo context 之中有一个 rendezvous process，Gloo 利用它来交换通讯需要的细节。\nRendezvous 具体实现是可以依靠访问一个 KVstore 来完成。具体细节就是通过 KVstore 来进行交互。\n以 Horovod 为例：\nHorovod 在进行容错 AllReduce 训练时，除了启动 worker 进程外，还会启动一个driver 进程。这个 driver 进程用于帮助 worker 调用 gloo 构造 AllReduce 通信环。 driver 进程中会创建一个带有 KVStore 的 RendezvousServer，driver 会将参与通信的 worker 的 ip 等信息存入 KVstore 中。 然后 worker 就可以调用 gloo 来访问 RendezvousServer 构造通信环了。 4.2.2 RendezvousServer 具体代码如下，可以看到是启动了RendezvousHTTPServer(就是继承拓展了 HTTPServer):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class RendezvousServer: def __init__(self, verbose=0): self._httpd = None self._listen_thread = None self._verbose = verbose # Rendezvous function finds a available port, create http socket, # and start listening loop to handle request # self.httpd.init needs to be called after server start def start(self, handler_cls=RendezvousHandler): # 下面马上介绍 self._httpd, port = find_port( lambda addr: RendezvousHTTPServer( addr, handler_cls, self._verbose)) # start the listening loop self._listen_thread = in_thread(target=self._httpd.serve_forever) return port def init(self, host_alloc_plan): self._httpd.init(host_alloc_plan) def stop(self): self._httpd.shutdown() self._listen_thread.join() 4.2.3 KVStore KVStore 是由 KVStoreHandler 来体现，RendezvousHandler 继承了 KVStoreHandler，进而被 RendezvousServer 作为 handler 使用。\nKVStoreHandler 精简版代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class KVStoreHandler(SimpleHTTPRequestHandler): # Override PUT handler def do_PUT(self): paths = self.path.split(\u0026#39;/\u0026#39;) _, scope, key = paths # Get body length content_length = int(self.headers[\u0026#39;Content-Length\u0026#39;]) value = self.rfile.read(content_length) self._put_value(scope, key, value) self.send_status_code(OK) def _put_value(self, scope, key, value): with self.server.cache_lock: scope_dict = self.server.cache.setdefault(scope, {}) scope_dict[key] = value 4.2.4 底层使用 Rendezvous 具体如何使用？简要的说：\nPython世界构建了一个 RendezvousServer，其地址配置在环境变量（或者其他方式）中。 在 C++ 世界中，比如 horovod/common/gloo/gloo_context.h，horovod/common/gloo/gloo_context.cc 之中有使用。即得到 Python 配置的 RendezvousServer 的地址端口等，然后构建 gloo 所需的 context。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #define HOROVOD_HOSTNAME \u0026#34;HOROVOD_HOSTNAME\u0026#34; #define HOROVOD_RANK \u0026#34;HOROVOD_RANK\u0026#34; #define HOROVOD_SIZE \u0026#34;HOROVOD_SIZE\u0026#34; #define HOROVOD_LOCAL_RANK \u0026#34;HOROVOD_LOCAL_RANK\u0026#34; #define HOROVOD_LOCAL_SIZE \u0026#34;HOROVOD_LOCAL_SIZE\u0026#34; #define HOROVOD_CROSS_RANK \u0026#34;HOROVOD_CROSS_RANK\u0026#34; #define HOROVOD_CROSS_SIZE \u0026#34;HOROVOD_CROSS_SIZE\u0026#34; #define HOROVOD_ELASTIC \u0026#34;HOROVOD_ELASTIC\u0026#34; ctx = Rendezvous(HOROVOD_GLOO_GLOBAL_PREFIX, rendezvous_addr_env, rendezvous_port, rank, size, dev, timeout); local_ctx = Rendezvous(HOROVOD_GLOO_LOCAL_PREFIX + hostname, rendezvous_addr_env, rendezvous_port, local_rank, local_size, dev, timeout); cross_ctx = Rendezvous(HOROVOD_GLOO_CROSS_PREFIX + std::to_string(local_rank), rendezvous_addr_env, rendezvous_port, cross_rank, cross_size, dev, timeout); 逻辑如下，C++世界会从python世界的获取到RendezvousServer的 IP，port：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 +---------------------\u0026gt; System Env +------------------+ | addr, port, ... addr, port, ... | | + | | | | | | | | | | | | | | | | | Python | C++ | | | | | | | | | | | | v +---------+---------------+ | +------------+--------+ | RendezvousServer | | |GlooContext | | | | | | | | | | | | | | | | | RendezvousHandler | | | Rendezvous | | | | | | +-------------------------+ | +---------------------+ | + 4.3 Horovd 的 gloo 入口 gloo_run 是 horovod 之中，gloo 模块的 相关入口。\n注释说的很清楚：每一个 thread 将使用 ssh 命令在远程host之上启动训练job。\n1 2 3 4 5 6 def gloo_run(settings, nics, env, server_ip, command): # Each thread will use ssh command to launch the job on each remote host. If an # error occurs in one thread, entire process will be terminated. Otherwise, # threads will keep running and ssh session. exec_command = _exec_command_fn(settings) launch_gloo(command, exec_command, settings, nics, env, server_ip) 就是用 launch_gloo 来运行 exec_command。\n此时 command 参数类似 \u0026quot;['python', 'train.py']\u0026quot;。\n4.4 构建可执行环境 gloo_run 的第一部分是 exec_command = _exec_command_fn(settings)，就是基于各种配置来生成可以执行命令环境。如果是远程，就得生成相关远程可运行命令环境（包括切换目录，远程执行等等）。\n4.4.1 _exec_command_fn 具体又可以分为两部分：\n利用 get_remote_command 来生成相关远程可运行环境，比如在训练脚本前面加上 'ssh -o PasswordAuthentication=no -o StrictHostKeyChecking=no'； 调整输入输出，利用 safe_shell_exec.execute 来实现安全执行能力； 具体如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def _exec_command_fn(settings): \u0026#34;\u0026#34;\u0026#34; executes the jobs defined by run command on hosts. :param hosts_alloc: list of dict indicating the allocating info. For example, [{\u0026#39;Hostname\u0026#39;:\u0026#39;worker-0\u0026#39;, \u0026#39;Rank\u0026#39;: 0, \u0026#39;Local_rank\u0026#39;: 0, \u0026#39;Cross_rank\u0026#39;:0, \u0026#39;Size\u0026#39;:2, \u0026#39;Local_size\u0026#39;:1, \u0026#39;Cross_size\u0026#39;:2}, {\u0026#39;Hostname\u0026#39;:\u0026#39;worker-1\u0026#39;, \u0026#39;Rank\u0026#39;: 1, \u0026#39;Local_rank\u0026#39;: 0, \u0026#39;Cross_rank\u0026#39;:1, \u0026#39;Size\u0026#39;:2, \u0026#39;Local_size\u0026#39;:1, \u0026#39;Cross_size\u0026#39;:2} ] :type hosts_alloc: list(dict) :param remote_host_names: names that are resolved to one of the addresses of remote hosts interfaces. :param _run_command: command to execute \u0026#34;\u0026#34;\u0026#34; def _exec_command(command, slot_info, events): index = slot_info.rank host_name = slot_info.hostname host_address = network.resolve_host_address(host_name) local_addresses = network.get_local_host_addresses() # 需要构建远程命令 if host_address not in local_addresses: local_command = quote(\u0026#39;cd {pwd} \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 ; {command}\u0026#39; .format(pwd=os.getcwd(), command=command)) command = get_remote_command(local_command, host=host_name, port=settings.ssh_port, identity_file=settings.ssh_identity_file) # Redirect output if requested # 调整输入输出，利用 safe_shell_exec.execute 来实现安全执行能力 stdout = stderr = None stdout_file = stderr_file = None if settings.output_filename: padded_rank = _pad_rank(index, settings.num_proc) output_dir_rank = os.path.join(settings.output_filename, \u0026#39;rank.{rank}\u0026#39;.format(rank=padded_rank)) if not os.path.exists(output_dir_rank): os.mkdir(output_dir_rank) stdout_file = open(os.path.join(output_dir_rank, \u0026#39;stdout\u0026#39;), \u0026#39;w\u0026#39;) stderr_file = open(os.path.join(output_dir_rank, \u0026#39;stderr\u0026#39;), \u0026#39;w\u0026#39;) stdout = MultiFile([sys.stdout, stdout_file]) stderr = MultiFile([sys.stderr, stderr_file]) # 实现安全执行能力 exit_code = safe_shell_exec.execute(command, index=index, stdout=stdout, stderr=stderr, events=events,...) return exit_code, time.time() return _exec_command 4.4.2 get_remote_command 本函数是针对远程 host，获取如何在其上运行的方式。这个函数是比较新加入的，具体和 kubeflow mpi operator 也相关，以后有机会再分析。\n1 2 3 4 5 6 7 8 9 10 11 12 SSH_COMMAND_PREFIX = \u0026#39;ssh -o PasswordAuthentication=no -o StrictHostKeyChecking=no\u0026#39; def get_ssh_command(local_command, host, port=None, identity_file=None, timeout_s=None): port_arg = f\u0026#39;-p {port}\u0026#39; if port is not None else \u0026#39;\u0026#39; identity_file_arg = f\u0026#39;-i {identity_file}\u0026#39; if identity_file is not None else \u0026#39;\u0026#39; timeout_arg = f\u0026#39;-o ConnectTimeout={timeout_s}\u0026#39; if timeout_s is not None else \u0026#39;\u0026#39; return f\u0026#39;{SSH_COMMAND_PREFIX} {host} {port_arg} {identity_file_arg} {timeout_arg} {local_command}\u0026#39; def get_remote_command(local_command, host, port=None, identity_file=None, timeout_s=None): return f\u0026#39;{env_util.KUBEFLOW_MPI_EXEC} {host} {local_command}\u0026#39; if env_util.is_kubeflow_mpi() \\ else get_ssh_command(local_command, host, port, identity_file, timeout_s) 大致逻辑如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 command : python train.py + | | v +---------+-------------+ | | | get_remote_command | | | +---------+-------------+ | | v ssh -o ... python train.py + | | | v +---------+--------------+ |safe_shell_exec.execute | | | +------------------------+ 4.5 使用 gloo 执行命令 获取到了可执行环境 exec_command 与 执行命令 command 之后，就可以使用 gloo 来执行命令了。\n每个 command 都是被 exec_command 来执行。\nlaunch_gloo 来获取命令，各种配置信息，网卡信息（nics，比如 {\u0026rsquo;lo\u0026rsquo;}），host信息等，然后开始运行，就是开始运行我们的训练代码了，具体是：\n建立 RendezvousServer，这个会被底层 Gloo C++ 环境使用到; host_alloc_plan = get_host_assignments 来根据host进行分配slot，就是horovod的哪个rank应该在哪个host上的哪个slot之上运行； get_run_command 获取到可执行命令； slot_info_to_command_fn 来得到在slot之上可执行的 slot command； 依据 slot_info_to_command_fn 构建 args_list，这个 list 之中，每一个arg就是一个 slot command； 多线程执行，在每一个 exec_command 之上执行每一个 arg（slot command）； 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def launch_gloo(command, exec_command, settings, nics, env, server_ip): \u0026#34;\u0026#34;\u0026#34; Launches the given command multiple times using gloo. Each command is launched via exec_command. :param command: command to launch :param exec_command: means to execute a single command :param settings: settings for the distribution :param nics: common interfaces :param env: environment to use :param server_ip: ip to use for rendezvous server \u0026#34;\u0026#34;\u0026#34; # Make the output directory if it does not exist if settings.output_filename: _mkdir_p(settings.output_filename) # start global rendezvous server and get port that it is listening on # 建立 RendezvousServer，这个会被底层 Gloo C++ 环境使用到 rendezvous = RendezvousServer(settings.verbose) # allocate processes into slots # 来根据host进行分配slot，就是horovod的哪个rank应该在哪个host上的哪个slot之上运行 hosts = parse_hosts(settings.hosts) host_alloc_plan = get_host_assignments(hosts, settings.num_proc) # start global rendezvous server and get port that it is listening on global_rendezv_port = rendezvous.start() rendezvous.init(host_alloc_plan) # 获取到可执行命令 run_command = get_run_command(command, server_ip, nics, global_rendezv_port) # 得到在slot之上可执行的 slot command slot_info_to_command = _slot_info_to_command_fn(run_command, env) event = register_shutdown_event() # 依据 slot_info_to_command_fn 构建 args_list，这个 list 之中，每一个arg就是一个 slot command args_list = [[slot_info_to_command(slot_info), slot_info, [event]] for slot_info in host_alloc_plan] # If an error occurs in one thread, entire process will be terminated. # Otherwise, threads will keep running. # 多线程执行，在每一个 exec_command 之上执行每一个 arg（slot command） res = threads.execute_function_multithreaded(exec_command, args_list, block_until_all_done=True) for name, value in sorted(res.items(), key=lambda item: item[1][1]): exit_code, timestamp = value 具体 HostInfo.from_string 信息如下：\n1 2 3 4 5 6 7 8 9 10 class HostInfo: def __init__(self, hostname, slots): self.hostname = hostname self.slots = slots @staticmethod def from_string(host_string): hostname, slots = host_string.strip().split(\u0026#39;:\u0026#39;) return HostInfo(hostname, int(slots)) 4.5.1.2 分配方案 get_host_assignments 会依据 host 和 process capacities (slots) 来给 Horovod 之中的进程分配，即给出一个 horovod rank 和 slot 的对应关系。设置了几个 np，就有几个 slot。\n给出的分配方案类似如下，这样就知道了哪个rank对应于哪个host上的哪个slot：\n1 2 3 4 [ SlotInfo(hostname=\u0026#39;h1\u0026#39;, rank=0, local_rank=0, cross_rank=0, size=2, local_size=2, coress_size=1), SlotInfo(hostname=\u0026#39;h2\u0026#39;, rank=1, local_rank=0, cross_rank=0, size=2, local_size=2, coress_size=1), ] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def get_host_assignments(hosts, min_np, max_np=None): \u0026#34;\u0026#34;\u0026#34;Assign hosts with process capacities (slots) to ranks in the Horovod process. This function will try to allocate as many as possible processes on the same host to leverage local network. :param hosts: list of HostInfo objects describing host and slot capacity :type hosts: list[HostInfo] :param min_np: minimum number of processes to be allocated :param max_np: (optional) maximum number of processes to be allocated :return: a list of the allocation of process on hosts in a `SlotInfo` object. :rtype: list[SlotInfo] \u0026#34;\u0026#34;\u0026#34; host_ranks = [] cross_ranks = collections.defaultdict(dict) rank = 0 # 依据 hosts 信息构建 rank, local rank, cross rank(hierarchical allreduce所需要) for host_info in hosts: ranks = [] for local_rank in range(host_info.slots): if rank == max_np: break ranks.append(rank) rank += 1 cross_ranks_at_local = cross_ranks[local_rank] cross_ranks_at_local[host_info.hostname] = len(cross_ranks_at_local) host_ranks.append((host_info, ranks)) world_size = rank # 给出一个 horovod rank 和 slot 的对应关系。返回一个alloc_list，每个SlotInfo包括各种rank信息 alloc_list = [] for host_info, ranks in host_ranks: local_size = len(ranks) for local_rank, rank in enumerate(ranks): cross_ranks_at_local = cross_ranks[local_rank] cross_rank = cross_ranks_at_local[host_info.hostname] cross_size = len(cross_ranks_at_local) alloc_list.append( SlotInfo( hostname=host_info.hostname, rank=rank, local_rank=local_rank, cross_rank=cross_rank, size=world_size, local_size=local_size, cross_size=cross_size)) return alloc_list 4.5.2 得到运行命令 get_run_command 是从环境变量中得到 Gloo 的变量，然后加到 command 之上。此步完成之后，得到类似如下命令：\n1 HOROVOD_GLOO_RENDEZVOUS_ADDR=1.1.1.1 HOROVOD_GLOO_RENDEZVOUS_PORT=2222 HOROVOD_CPU_OPERATIONS=gloo HOROVOD_GLOO_IFACE=lo HOROVOD_CONTROLLER=gloo python train.py 可以把这个格式缩写为：{horovod_gloo_env} command。\n代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def create_run_env_vars(server_ip, nics, port, elastic=False): # 从环境变量中得到 Gloo 的变量 run_envs = { \u0026#39;HOROVOD_GLOO_RENDEZVOUS_ADDR\u0026#39;: server_ip, \u0026#39;HOROVOD_GLOO_RENDEZVOUS_PORT\u0026#39;: port, \u0026#39;HOROVOD_CONTROLLER\u0026#39;: \u0026#34;gloo\u0026#34;, \u0026#39;HOROVOD_CPU_OPERATIONS\u0026#39;: \u0026#34;gloo\u0026#34;, \u0026#39;HOROVOD_GLOO_IFACE\u0026#39;: list(nics)[0], # TODO: add multiple ifaces in future \u0026#39;NCCL_SOCKET_IFNAME\u0026#39;: \u0026#39;,\u0026#39;.join(nics), } if elastic: run_envs[\u0026#34;HOROVOD_ELASTIC\u0026#34;] = \u0026#34;1\u0026#34; return run_envs def get_run_command(command, server_ip, nics, port, elastic=False): env_vars = create_run_env_vars(server_ip, nics, port, elastic) env_string = \u0026#34; \u0026#34;.join( [f\u0026#34;{k}={str(v)}\u0026#34; for k, v in env_vars.items()]) run_command = ( \u0026#39;{env_string} \u0026#39; \u0026#39;{command}\u0026#39; # expect a lot of environment variables .format(env_string=env_string, command=\u0026#39; \u0026#39;.join(quote(par) for par in command))) return run_command 4.5.3 得到slot运行命令 得到运行命令之后，这里会结合 horovod env 和 env，以及slot 分配情况 进一步修改为适合 gloo 运行的方式。就是可以在具体每一个slot上运行的命令。\n可以把这个格式缩写为：{horovod_gloo_env} {horovod_rendez_env} {env} run_command。\n此步完成之后，得到类似如下：\n1 2 3 4 HOROVOD_HOSTNAME=1.1.1.1 HOROVOD_RANK=1 HOROVOD_SIZE=2 HOROVOD_LOCAL_RANK=1 SHELL=/bin/bash PATH=XXXX USER=xxx PWD=xxx SSH_CONNECTION=\u0026#34;1.1.1.1 11 2.2.2.2 22\u0026#34; HOME=xxx SSH_CLIENZT=xxxx HOROVOD_GLOO_IFACE=lo NCCL_SOCKET_IFNAME=lo HOROVOD_GLOO_RENDEZVOUS_ADDR=1.1.1.1 HOROVOD_GLOO_RENDEZVOUS_PORT=2222 HOROVOD_CPU_OPERATIONS=gloo HOROVOD_GLOO_IFACE=lo HOROVOD_CONTROLLER=gloo python train.py 具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def _slot_info_to_command_fn(run_command, env): # TODO: Workaround for over-buffered outputs. Investigate how mpirun avoids this problem. env = copy.copy(env) # copy env so we do not leak env modifications env[\u0026#39;PYTHONUNBUFFERED\u0026#39;] = \u0026#39;1\u0026#39; def slot_info_to_command(slot_info): \u0026#34;\u0026#34;\u0026#34; Given a slot_info, creates a command used by gloo to launch a single job. :param slot_info: host and slot to execute the run command on :return: \u0026#34;\u0026#34;\u0026#34; env_vars = create_slot_env_vars(slot_info) horovod_rendez_env = \u0026#34; \u0026#34;.join( [f\u0026#34;{k}={str(v)}\u0026#34; for k, v in env_vars.items()]) return \u0026#39;{horovod_env} {env} {run_command}\u0026#39; .format( horovod_env=horovod_rendez_env, env=\u0026#39; \u0026#39;.join([\u0026#39;%s=%s\u0026#39; % (key, quote(value)) for key, value in env.items() if env_util.is_exportable(key)]), run_command=run_command) return slot_info_to_command 4.5.4 多线程调用命令 这就是启动了多线程进行调用。gloo_run 的注释说的很清楚：在调用 execute_function_multithreaded 时，每一个thread将使用 ssh 命令在远程host之上启动训练job。\n回忆下之前我们在“构建可执行环境” 中提到：利用 get_remote_command 来生成相关远程可运行环境，比如在训练脚本前面加上 \u0026lsquo;ssh -o PasswordAuthentication=no -o StrictHostKeyChecking=no\u0026rsquo;。大家就理解了如何在远端执行。\n在本地运行，则命令大致为：\n1 2 3 4 5 cd /code directory \u0026gt; /dev/null 2 \u0026gt;\u0026amp;1 HOROVOD_HOSTNAME=1.1.1.1 HOROVOD_RANK=1 HOROVOD_SIZE=2 HOROVOD_LOCAL_RANK=1 SHELL=/bin/bash PATH=XXXX USER=xxx PWD=xxx SSH_CONNECTION=\u0026#34;1.1.1.1 11 2.2.2.2 22\u0026#34; HOME=xxx SSH_CLIENZT=xxxx HOROVOD_GLOO_IFACE=lo NCCL_SOCKET_IFNAME=lo HOROVOD_GLOO_RENDEZVOUS_ADDR=1.1.1.1 HOROVOD_GLOO_RENDEZVOUS_PORT=2222 HOROVOD_CPU_OPERATIONS=gloo HOROVOD_GLOO_IFACE=lo HOROVOD_CONTROLLER=gloo python train.py 在远端运行，命令就需要加上 ssh 信息，大致为：\n1 2 3 4 5 6 ssh -o PasswordAuthentication=no -o StrictHostKeyChecking=no 1.1.1.1 cd /code directory \u0026gt; /dev/null 2 \u0026gt;\u0026amp;1 HOROVOD_HOSTNAME=1.1.1.1 HOROVOD_RANK=1 HOROVOD_SIZE=2 HOROVOD_LOCAL_RANK=1 SHELL=/bin/bash PATH=XXXX USER=xxx PWD=xxx SSH_CONNECTION=\u0026#34;1.1.1.1 11 2.2.2.2 22\u0026#34; HOME=xxx SSH_CLIENZT=xxxx HOROVOD_GLOO_IFACE=lo NCCL_SOCKET_IFNAME=lo HOROVOD_GLOO_RENDEZVOUS_ADDR=1.1.1.1 HOROVOD_GLOO_RENDEZVOUS_PORT=2222 HOROVOD_CPU_OPERATIONS=gloo HOROVOD_GLOO_IFACE=lo HOROVOD_CONTROLLER=gloo python train.py execute_function_multithreaded 具体代码如下，其中：\nfn 就是前面提到的程序运行环境（能力）exec_command。 fn(*arg[:-1]) 就是在 exec_command 之中运行slot_info_to_command。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 def execute_function_multithreaded(fn, args_list, block_until_all_done=True, max_concurrent_executions=1000): \u0026#34;\u0026#34;\u0026#34; Executes fn in multiple threads each with one set of the args in the args_list. :param fn: function to be executed :type fn: :param args_list: :type args_list: list(list) :param block_until_all_done: if is True, function will block until all the threads are done and will return the results of each thread\u0026#39;s execution. :type block_until_all_done: bool :param max_concurrent_executions: :type max_concurrent_executions: int :return: If block_until_all_done is False, returns None. If block_until_all_done is True, function returns the dict of results. { index: execution result of fn with args_list[index] } :rtype: dict \u0026#34;\u0026#34;\u0026#34; result_queue = queue.Queue() worker_queue = queue.Queue() for i, arg in enumerate(args_list): arg.append(i) worker_queue.put(arg) def fn_execute(): while True: try: arg = worker_queue.get(block=False) except queue.Empty: return exec_index = arg[-1] # fn 就是前面提到的程序运行环境（能力）exec_command # fn(*arg[:-1])是在 exec_command 之中运行 slot_info_to_command res = fn(*arg[:-1]) result_queue.put((exec_index, res)) threads = [] number_of_threads = min(max_concurrent_executions, len(args_list)) # 在多线程中执行 fn_execute for _ in range(number_of_threads): thread = in_thread(target=fn_execute, daemon=not block_until_all_done) threads.append(thread) # Returns the results only if block_until_all_done is set. # 如果有设置，则 block 等待 results = None if block_until_all_done: # Because join() cannot be interrupted by signal, a single join() # needs to be separated into join()s with timeout in a while loop. have_alive_child = True while have_alive_child: have_alive_child = False for t in threads: t.join(0.1) if t.is_alive(): have_alive_child = True results = {} while not result_queue.empty(): item = result_queue.get() results[item[0]] = item[1] return results python train.py 就会进入到我们的训练代码。\n大致逻辑如下图，可以看到，结合了各种信息之后，构建了一个可以执行的结果，然后多host执行：\n图左面，是从 参数中获取 host 等信息，然后解析出 slot 信息； 图右边，是从 python train.py 这个待运行的命令，基于各种配置来生成可以执行命令环境。如果是远程，就得生成 相关远程可运行命令环境（包括切换目录，远程执行等等）； 图中间，是从 python train.py 这个待运行的命令，经过添加 env 信息，gloo 信息。然后结合 左面的 slot 信息 和 右面 的可以执行命令环境 之后，得到了可以在多线程上运行，从而在 多slot 运行的命令。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 args : \u0026#39;10.11.11.11:4,10.11.11.12:4\u0026#39; python train.py command : python train.py + + + | | | | | | v v v +----------+--------+ +----------+----------+ +---------+-------------+ | parse_hosts | | get_run_command | | | +----------+--------+ | | | get_remote_command | | +----------+----------+ | | | | +---------+-------------+ v | | +------------+-----------+ v | | get_host_assignments | v | | gloo python train.py +------------+-----------+ + ssh -o ... python train.py | | + | | | v | | | | SlotInfo(hostname=\u0026#39;h2\u0026#39;, rank=1) v v + +-----------+---------------+ +---------+--------------+ | | _slot_info_to_command_fn | |safe_shell_exec.execute | +-----------------------\u0026gt; | | | | +-----------+---------------+ +---------+--------------+ | | | | v | | HOROVOD_CONTROLLER=gloo python train.py | + | | | | | v | +-------------+-------------------+ | | | | | execute_function_multithreaded | \u0026lt;---------------+ | | +---------------------------------+ 图示如下：\n4.6 C++举例 我们给出一个底层代码，大家就进一步了解 Gloo 可以起到什么作用。\n这个就是 Horovod 之中，rank 0 最终给其他 rank 发送构建好的 Tensor。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 void GlooController::SendFinalTensors(ResponseList\u0026amp; response_list) { // Notify all nodes which tensors we\u0026#39;d like to reduce at this step. std::string encoded_response; ResponseList::SerializeToString(response_list, encoded_response); // Boardcast the response length int encoded_response_length = (int)encoded_response.length() + 1; { gloo::BroadcastOptions opts(gloo_context_.ctx); opts.setOutput(\u0026amp;encoded_response_length, 1); opts.setRoot(RANK_ZERO); gloo::broadcast(opts); // 广播给其他rank } // Boardcast the response { gloo::BroadcastOptions opts(gloo_context_.ctx); opts.setOutput((uint8_t*)(encoded_response.c_str()), encoded_response_length); opts.setRoot(RANK_ZERO); gloo::broadcast(opts); // 广播给其他rank } } 5 Mpi 实现 5.1 openmpi 库 horovod 这里主要依赖 openmpi。\nMPI：英文全称是Message Passing Interface，MPI是一个跨语言的通讯协议，用于编写并行计算机。支持点对点和广播。MPI是一个信息传递应用程序接口，包括协议和和语义说明，他们指明其如何在各种实现中发挥其特性。MPI的目标是高性能，大规模性，和可移植性。 openMPI：英文全称是open Message Passing Interface。openMPI是MPI的一种实现，一种库项目。 MPI在Hovorod的角色比较特殊：\n一方面Horovod内集成了基于MPI的AllReduce，类似于NCCL，都是用作梯度规约；\n另一方面，MPI可以用来在所有机器上启动多个进程(Hovorod里用Rank表示)，实现并行计算；\n5.2 mpi_run 函数 此部分代码位于：horovod/runner/mpi_run.py。\n首先摘录其关键代码如下，可以看出来其核心是运行 mpirun 命令。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 我是下面大段代码中的关键代码！ mpirun_command = ( \u0026#39;mpirun {basic_args} \u0026#39; \u0026#39;-np {num_proc}{ppn_arg}{hosts_arg} \u0026#39; \u0026#39;{binding_args} \u0026#39; \u0026#39;{mpi_args} \u0026#39; \u0026#39;{mpi_ssh_args} \u0026#39; \u0026#39;{tcp_intf_arg} \u0026#39; \u0026#39;{nccl_socket_intf_arg} \u0026#39; \u0026#39;{output_filename_arg} \u0026#39; \u0026#39;{env} {extra_mpi_args} {command}\u0026#39; .format(basic_args=basic_args, num_proc=settings.num_proc, ppn_arg=ppn_arg, hosts_arg=hosts_arg, binding_args=binding_args, mpi_args=\u0026#39; \u0026#39;.join(mpi_impl_flags), tcp_intf_arg=tcp_intf_arg, nccl_socket_intf_arg=nccl_socket_intf_arg, mpi_ssh_args=mpi_ssh_args, output_filename_arg=\u0026#39; \u0026#39;.join(output), env=env_list, extra_mpi_args=settings.extra_mpi_args if settings.extra_mpi_args else \u0026#39;\u0026#39;, command=\u0026#39; \u0026#39;.join(quote(par) for par in command)) ) # Execute the mpirun command. if settings.run_func_mode: exit_code = safe_shell_exec.execute(mpirun_command, env=env, stdout=stdout, stderr=stderr) else: os.execve(\u0026#39;/bin/sh\u0026#39;, [\u0026#39;/bin/sh\u0026#39;, \u0026#39;-c\u0026#39;, mpirun_command], env) 就是依据各种配置以及参数来构建 mpirun 命令的所有参数，比如 ssh 的参数，mpi 参数，nccl 参数等等。\n最后得到的 mpirun 命令举例如下：\n1 2 3 4 mpirun --allow-run-as-root --np 2 -bind-to none -map-by slot \\ -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH \\ -mca pml ob1 -mca btl ^openib \\ python train.py 具体代码如下，具体是：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 # 上面代码是我之中的片段 def mpi_run(settings, nics, env, command, stdout=None, stderr=None): \u0026#34;\u0026#34;\u0026#34; Runs mpi_run. Args: settings: Settings for running MPI. Note: settings.num_proc and settings.hosts must not be None. nics: Interfaces to include by MPI. env: Environment dictionary to use for running command. command: Command and arguments to run as a list of string. stdout: Stdout of the mpi process. Only used when settings.run_func_mode is True. stderr: Stderr of the mpi process. Only used when settings.run_func_mode is True. \u0026#34;\u0026#34;\u0026#34; # 得到各种配置 mpi_impl_flags, impl_binding_args, mpi = _get_mpi_implementation_flags(settings.tcp_flag, env=env) impi = _IMPI_IMPL == mpi # 处理ssh参数 ssh_args = [] if settings.ssh_port: ssh_args += [f\u0026#39;-p {settings.ssh_port}\u0026#39;] if settings.ssh_identity_file: ssh_args += [f\u0026#39;-i {settings.ssh_identity_file}\u0026#39;] mpi_ssh_args = \u0026#39;\u0026#39; if ssh_args: joined_ssh_args = \u0026#39; \u0026#39;.join(ssh_args) mpi_ssh_args = f\u0026#39;-bootstrap=ssh -bootstrap-exec-args \\\u0026#34;{joined_ssh_args}\\\u0026#34;\u0026#39; if impi else f\u0026#39;-mca plm_rsh_args \\\u0026#34;{joined_ssh_args}\\\u0026#34;\u0026#39; # 处理网络配置，网卡信息等 tcp_intf_arg = \u0026#39;-mca btl_tcp_if_include {nics}\u0026#39;.format( nics=\u0026#39;,\u0026#39;.join(nics)) if nics and not impi else \u0026#39;\u0026#39; nccl_socket_intf_arg = \u0026#39;-{opt} NCCL_SOCKET_IFNAME={nics}\u0026#39;.format( opt=\u0026#39;genv\u0026#39; if impi else \u0026#39;x\u0026#39;, nics=\u0026#39;,\u0026#39;.join(nics)) if nics else \u0026#39;\u0026#39; # 处理host信息 # On large cluster runs (e.g. Summit), we need extra settings to work around OpenMPI issues host_names, host_to_slots = hosts.parse_hosts_and_slots(settings.hosts) if not impi and host_names and len(host_names) \u0026gt;= _LARGE_CLUSTER_THRESHOLD: mpi_impl_flags.append(\u0026#39;-mca plm_rsh_no_tree_spawn true\u0026#39;) mpi_impl_flags.append(\u0026#39;-mca plm_rsh_num_concurrent {}\u0026#39;.format(len(host_names))) # if user does not specify any hosts, mpirun by default uses local host. # There is no need to specify localhost. hosts_arg = \u0026#39;-{opt} {hosts}\u0026#39;.format(opt=\u0026#39;hosts\u0026#39; if impi else \u0026#39;H\u0026#39;, hosts=\u0026#39;,\u0026#39;.join(host_names) if host_names and impi else settings.hosts) # 处理ppn配置 ppn_arg = \u0026#39; \u0026#39; if host_to_slots and impi: ppn = host_to_slots[host_names[0]] for h_name in host_names[1:]: ppn_arg = \u0026#39; -ppn {} \u0026#39;.format(ppn) # 处理超时配置 if settings.prefix_output_with_timestamp and not impi: mpi_impl_flags.append(\u0026#39;--timestamp-output\u0026#39;) binding_args = settings.binding_args if settings.binding_args and not impi else \u0026#39; \u0026#39;.join(impl_binding_args) # 配置需要root身份运行 basic_args = \u0026#39;-l\u0026#39; if impi else \u0026#39;--allow-run-as-root --tag-output\u0026#39; output = [] if settings.output_filename: output.append(\u0026#39;-outfile-pattern\u0026#39; if impi else \u0026#39;--output-filename\u0026#39;) output.append(settings.output_filename) # 构建环境信息列表 env_list = \u0026#39;\u0026#39; if impi else \u0026#39; \u0026#39;.join( \u0026#39;-x %s\u0026#39; % key for key in sorted(env.keys()) if env_util.is_exportable(key)) # 构建最终的 MPI 命令 # Pass all the env variables to the mpirun command. mpirun_command = ( \u0026#39;mpirun {basic_args} \u0026#39; \u0026#39;-np {num_proc}{ppn_arg}{hosts_arg} \u0026#39; \u0026#39;{binding_args} \u0026#39; \u0026#39;{mpi_args} \u0026#39; \u0026#39;{mpi_ssh_args} \u0026#39; \u0026#39;{tcp_intf_arg} \u0026#39; \u0026#39;{nccl_socket_intf_arg} \u0026#39; \u0026#39;{output_filename_arg} \u0026#39; \u0026#39;{env} {extra_mpi_args} {command}\u0026#39; # expect a lot of environment variables .format(basic_args=basic_args, num_proc=settings.num_proc, ppn_arg=ppn_arg, hosts_arg=hosts_arg, binding_args=binding_args, mpi_args=\u0026#39; \u0026#39;.join(mpi_impl_flags), tcp_intf_arg=tcp_intf_arg, nccl_socket_intf_arg=nccl_socket_intf_arg, mpi_ssh_args=mpi_ssh_args, output_filename_arg=\u0026#39; \u0026#39;.join(output), env=env_list, extra_mpi_args=settings.extra_mpi_args if settings.extra_mpi_args else \u0026#39;\u0026#39;, command=\u0026#39; \u0026#39;.join(quote(par) for par in command)) ) # we need the driver\u0026#39;s PATH and PYTHONPATH in env to run mpirun, # env for mpirun is different to env encoded in mpirun_command for var in [\u0026#39;PATH\u0026#39;, \u0026#39;PYTHONPATH\u0026#39;]: if var not in env and var in os.environ: # copy env so we do not leak env modifications env = copy.copy(env) # copy var over from os.environ env[var] = os.environ[var] # Execute the mpirun command. if settings.run_func_mode: exit_code = safe_shell_exec.execute(mpirun_command, env=env, stdout=stdout, stderr=stderr) else: os.execve(\u0026#39;/bin/sh\u0026#39;, [\u0026#39;/bin/sh\u0026#39;, \u0026#39;-c\u0026#39;, mpirun_command], env) 5.3 mpirun命令 因为 mpi_run 使用的是 mpirun 命令来运行，所以我们介绍一下。\nmpirun是MPI程序的启动脚本，它简化了并行进程的启动过程，尽可能屏蔽了底层的实现细节，从而为用户提供了一个通用的MPI并行机制。\n在用mpirun命令执行并行程序时，参数-np指明了需要并行运行的进程个数。mpirun首先在本地结点上启动一个进程，然后根据/usr/local/share/machines.LINUX文件中所列出的主机，为每个主机启动一个进程。若进程数比可用的并行节点数多，则多余的进程将重新按照上述规则进行。按这个机制分配好进程后，一般会给每个节点分一个固定的标号，类似于身份证了，后续在消息传递中会用到。\n这里需要说明的是，实际运行的\norterun(Open MPI SPMD / MPMD启动器; mpirun / mpiexec只是它的符号链接)\n命令举例如下：\n1 2 3 4 5 mpirun -np 4 \\ -bind-to none -map-by slot \\ -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH \\ -mca pml ob1 -mca btl ^openib \\ python train.py 6 总结 对比 gloo 和 mpi 的实现，我们还是能看出来区别。\n6.1 gloo gloo 只是一个库，需要 horovod 来完成命令分发功能。\ngloo 需要 horovod 自己实现本地运行和远端运行方式，即 get_remote_command 函数 实现 'ssh -o PasswordAuthentication=no -o StrictHostKeyChecking=no'。\ngloo 需要实现 RendezvousServer，底层会利用 RendezvousServer 进行通讯。\n6.2 mpi mpi 则功能强大很多，只要把命令配置成被 mpirun 包装，openmpi 就可以自行完成命令分发执行。说到底，horovod 是一个 mpirun 程序，即使运行了 tensor flow，也是一个mpi程序，可以互相交互。\n","permalink":"https://jianye0428.github.io/en/posts/notes/2022-10-09_horovod_3/","summary":"references: [1]. https://www.cnblogs.com/rossiXYZ/p/14881812.html 0 摘要 Horovod 是Uber于2017年发布的一个易于使用的高性能的分布式训练框架，在业界得到了广泛应用。 本系列将通过源码分析来带领大家了解 Ho","title":"深度学习分布式训练框架 horovod(3) --- Horovodrun背后做了什么"},{"content":"reference: [1].https://www.cnblogs.com/rossiXYZ/p/14856543.html\n0 摘要 Horovod 是Uber于2017年发布的一个易于使用的高性能的分布式训练框架，在业界得到了广泛应用。\n本系列将通过源码分析来带领大家了解 Horovod。系列大约有15 ～ 18 篇，本文是系列第二篇，从用户角度切入 Horovod。\n前一篇参见如下：\n深度学习分布式训练框架 Horovod[1] \u0026ndash; 基础知识\n1 Horovod 简介 Horovod 是Uber于2017年发布的一个易于使用的高性能的分布式训练框架，支持TensorFlow，Keras，PyTorch和MXNet。Horovod 的名字来自于俄国传统民间舞蹈，舞者手牵手围成一个圈跳舞，与分布式 TensorFlow 流程使用 Horovod 互相通信的场景很像。\n因为各个机器学习框架对于底层集合通信库（ nccl，openmpi，gloo 等等）的利用水平可能各不相同，使得他们无法充分利用这些底层集合通信库的威力。因而，hovorod 就整合这些框架，提供一个易用高效的解决方案。\nUber的工程师就是根据FaceBook的一篇paper：“Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour”和百度的一篇“Bringing HPC Techniques to Deep Learning” 改进并发布了开源框架Horovod。\nHorovod 相比于百度的工作，并无学术上的贡献。但是 Horovod 扎实的工程实现，使得它受到了更多的关注。它最大的优势在于对 RingAllReduce 进行了更高层次的抽象，使其支持多种不同的框架。同时引入了 Nvidia NCCL，对 GPU 更加友好。\nHorovod依赖于Nvidia的 NCCL2 做 All Reduce，依赖于MPI做进程间通信，简化了同步多 GPU 或多节点分布式训练的开发流程。由于使用了NCCL2，Horovod也可以利用以下功能：NVLINK，RDMA，GPUDirectRDMA，自动检测通信拓扑，能够回退到 PCIe 和 TCP/IP 通信。\n我们需要几个问题来引导分析：\nHovorod 怎么进行数据分割？ Hovorod 怎么进行训练代码分发？ Hovorod 启动时候，python 和 C++ 都做了什么？ 如何确保 Hovorod 启动时候步骤一致； 2 Hovorod 机制概述 2.1 Horovod 机制 Horovod使用数据并行化策略在GPU上分配训练。\n在数据并行化中，作业中的每个GPU都会接收其自己的数据批处理的独立切片，即它的“批处理切片”。 每个GPU都使用自己分配到的数据来独立计算，进行梯度更新。\n假如使用两个GPU，批处理大小为32，则第一个GPU将处理前16条记录的正向传播和向后传播，以及第二个GPU处理后16条记录的正向传播和向后传播。然后，这些梯度更新将在GPU之间平均在一起，最后应用于模型。\n每一个迭代的操作方法如下：\n每个 worker 将维护自己的模型权重副本和自己的数据集副本。\n收到执行信号后，每个工作进程都会从数据集中提取一个不相交的批次，并计算该批次的梯度。\nWorkers 使用ring all-reduce算法来同步彼此的梯度，从而在本地所有节点上计算同样的平均梯度。\n将每个设备上的梯度 tensor 切分成长度大致相等的 num_devices 个分片，后续每一次通信都将给下一个邻居发送一个自己的分片（同时从上一个邻居接受一个新分片）。\nScatterReduce 阶段：通过 num_devices - 1 轮通信和相加，在每个 device 上都计算出一个 tensor 分片的和，即每个 device 将有一个块，其中包含所有device 中该块中所有值的总和；具体如下：\nAllGather 阶段：通过 num_devices - 1 轮通信和覆盖，将上个阶段计算出的每个 tensor 分片的和 广播到其他 device；最终所有节点都拥有所有tensor分片和。具体如下： 在每个设备上合并分片，得到梯度和，然后除以 num_devices，得到平均梯度； 每个 worker 将 梯度更新 应用于其模型的本地副本。\n执行下一个batch。\n3 示例代码 3.1 摘要代码 我们此处给出官网示例代码部分摘要，具体分析参见下面代码中的注释。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 import tensorflow as tf import horovod.tensorflow.keras as hvd # Horovod: initialize Horovod. hvd.init() # 初始化 Horovod，启动相关线程和MPI线程 # Horovod: pin GPU to be used to process local rank (one GPU per process) # 依据 local rank 为不同的进程分配不同的GPU gpus = tf.config.experimental.list_physical_devices(\u0026#39;GPU\u0026#39;) for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True) if gpus: tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], \u0026#39;GPU\u0026#39;) (mnist_images, mnist_labels), _ = \\ tf.keras.datasets.mnist.load_data(path=\u0026#39;mnist-%d.npz\u0026#39; % hvd.rank()) # 切分数据 dataset = tf.data.Dataset.from_tensor_slices( (tf.cast(mnist_images[..., tf.newaxis] / 255.0, tf.float32), tf.cast(mnist_labels, tf.int64)) ) dataset = dataset.repeat().shuffle(10000).batch(128) mnist_model = tf.keras.Sequential([ tf.keras.layers.Conv2D(32, [3, 3], activation=\u0026#39;relu\u0026#39;), ...... tf.keras.layers.Dense(10, activation=\u0026#39;softmax\u0026#39;) ]) # Horovod: adjust learning rate based on number of GPUs. scaled_lr = 0.001 * hvd.size() # 根据Worker的数量增加学习率的大小 opt = tf.optimizers.Adam(scaled_lr) # Horovod: add Horovod DistributedOptimizer. # 把常规TensorFlow Optimizer通过Horovod包装起来，进而使用 ring-allreduce 来得到平均梯度 opt = hvd.DistributedOptimizer( opt, backward_passes_per_step=1, average_aggregated_gradients=True) # Horovod: Specify `experimental_run_tf_function=False` to ensure TensorFlow # uses hvd.DistributedOptimizer() to compute gradients. mnist_model.compile(loss=tf.losses.SparseCategoricalCrossentropy(), optimizer=opt, metrics=[\u0026#39;accuracy\u0026#39;], experimental_run_tf_function=False) callbacks = [ hvd.callbacks.BroadcastGlobalVariablesCallback(0), # 广播初始化，将模型的参数从第一个设备传向其他设备，以保证初始化模型参数的一致性 hvd.callbacks.MetricAverageCallback(), hvd.callbacks.LearningRateWarmupCallback(initial_lr=scaled_lr, warmup_epochs=3, verbose=1), ] # Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them. # 只有设备0需要保存模型参数作为checkpoint if hvd.rank() == 0: callbacks.append(tf.keras.callbacks.ModelCheckpoint(\u0026#39;./checkpoint-{epoch}.h5\u0026#39;)) # Horovod: write logs on worker 0. verbose = 1 if hvd.rank() == 0 else 0 # Train the model. # Horovod: adjust number of steps based on number of GPUs. mnist_model.fit(dataset, steps_per_epoch=500 // hvd.size(), callbacks=callbacks, epochs=24, verbose=verbose) 3.2 horovodrun Horovod训练脚本未作为Python脚本启动。 例如，您不能使用python train.py运行此脚本。 需要采用特殊的CLI命令 horovodrun 来启动（训练代码 train.py 需要手动拷贝到各个节点上，且目录相同）：\n1 $ horovodrun -np 4 -H localhost:4 python train.py 4 运行逻辑 我们按照顺序梳理，看看在程序初始化过程背后都做了什么。\n4.1 引入python文件 如下代码会引入各种相关python文件。\n1 2 import tensorflow as tf import horovod.tensorflow.keras as hvd 4.2 初始化 in python python 世界的初始化位于 horovod-master/horovod/mxnet/mpi_ops.py\n4.2.1 引入SO库 4.2.1.1 SO库 horovod/tensorflow/mpi_ops.py 之中会引入SO库。 比如 dist-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so。\nSO库 就是 horovod 中 C++ 代码编译出来的结果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def _load_library(name): \u0026#34;\u0026#34;\u0026#34;Loads a .so file containing the specified operators. \u0026#34;\u0026#34;\u0026#34; filename = resource_loader.get_path_to_datafile(name) library = load_library.load_op_library(filename) return library # Check possible symbol not found error from tensorflow version mismatch try: MPI_LIB = _load_library(\u0026#39;mpi_lib\u0026#39; + get_ext_suffix()) except Exception as e: check_installed_version(\u0026#39;tensorflow\u0026#39;, tf.__version__, e) raise e else: check_installed_version(\u0026#39;tensorflow\u0026#39;, tf.__version__) 4.2.2.2 SO作用 引入库的作用是获取到 C++ 的函数，并且用 python 封装一下，这样就可以在 python 世界使用 C++代码了。\n由下文可以看出来，python 的 _allreduce 函数就会把功能转发给 C++，由 MPI_LIB.horovod_allreduce 完成。\n1 2 3 4 5 6 7 8 def _allreduce(tensor, name=None, op=Sum, prescale_factor=1.0, postscale_factor=1.0, ignore_name_scope=False): if name is None and not _executing_eagerly(): name = \u0026#39;HorovodAllreduce_%s\u0026#39; % _normalize_name(tensor.name) return MPI_LIB.horovod_allreduce(tensor, name=name, reduce_op=op, prescale_factor=prescale_factor, postscale_factor=postscale_factor, ignore_name_scope=ignore_name_scope) 4.2.2 初始化配置 我们摘录了主要部分，就是初始化 _HorovodBasics，然后从 _HorovodBasics 内获取各种函数，变量和配置，比如是否编译了mpi，gloo等等.\n1 2 3 4 5 6 7 8 9 10 11 12 13 from horovod.common.basics import HorovodBasics as _HorovodBasics _basics = _HorovodBasics(__file__, \u0026#39;mpi_lib\u0026#39;) # import basic methods init = _basics.init size = _basics.size local_size = _basics.local_size rank = _basics.rank local_rank = _basics.local_rank mpi_built = _basics.mpi_built gloo_enabled = _basics.gloo_enabled ...... 4.2.3 hvd.init() 初始化 首先需要用 hvd.init() 来初始化，horovod 管理的所有状态都会传到 hvd 对象中。\n1 2 # Horovod: initialize Horovod. hvd.init() 此处调用的是 HorovodBasics 中的函数，我们看看做了什么。\n可以看到，这部分会一直深入到 C++世界，调用了大量的 MPI_LIB_CTYPES 函数，所以我们接下来就要进入到 C++的世界看看。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def init(self, comm=None): \u0026#34;\u0026#34;\u0026#34;A function that initializes Horovod. \u0026#34;\u0026#34;\u0026#34; atexit.register(self.shutdown) if not isinstance(comm, list): mpi_built = self.MPI_LIB_CTYPES.horovod_mpi_built() from mpi4py import MPI if MPI._sizeof(MPI.Comm) == ctypes.sizeof(ctypes.c_int): MPI_Comm = ctypes.c_int else: MPI_Comm = ctypes.c_void_p self.MPI_LIB_CTYPES.horovod_init_comm.argtypes = [MPI_Comm] comm_obj = MPI_Comm.from_address(MPI._addressof(comm)) self.MPI_LIB_CTYPES.horovod_init_comm(comm_obj) else: comm_size = len(comm) self.MPI_LIB_CTYPES.horovod_init( (ctypes.c_int * comm_size)(*comm), ctypes.c_int(comm_size)) 目前逻辑如下图：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 Import python files + | | v Import C++ SO files | | | v Create _HorovodBasics + | | v hvd.init() + Python | +------------------------------------------+ C++ | | v 4.3 初始化 in C++ 4.3.1 horovod_init_comm 在初始化的时候，Horovod 会：\n调用 MPI_Comm_dup 获取一个 Communicator，这样就有了和 MPI 协调的基础。 然后调用 InitializeHorovodOnce。 1 2 3 4 void horovod_init_comm(MPI_Comm comm) { MPI_Comm_dup(comm, \u0026amp;mpi_context.mpi_comm); InitializeHorovodOnce(nullptr, 0); } 4.3.2 InitializeHorovodOnce InitializeHorovodOnce 是初始化的主要工作，主要是：\n依据是否编译了 mpi 或者 gloo，对各自的 context 进行处理，为 globalstate 创建对应的 controller； 启动了后台线程 BackgroundThreadLoop 用来在各个worker之间协调； 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 void horovod_init(const int* ranks, int nranks) { InitializeHorovodOnce(ranks, nranks); } void InitializeHorovodOnce(const int* ranks, int nranks) { // Ensure background thread is only started once. if (!horovod_global.initialize_flag.test_and_set()) { horovod_global.control_operation = ParseControllerOpsFromEnv(); horovod_global.cpu_operation = ParseCPUOpsFromEnv(); #if HAVE_MPI // 依据是否编译了MPI进行处理 // Enable mpi is it\u0026#39;s used either in cpu data transfer or controller if (horovod_global.cpu_operation == LibType::MPI || horovod_global.control_operation == LibType::MPI) { mpi_context.Enable(); } if (horovod_global.control_operation == LibType::MPI){ // 创建一个 MPIController 对象 horovod_global.controller.reset(new MPIController( horovod_global.response_cache, horovod_global.tensor_queue, horovod_global.timeline, horovod_global.parameter_manager, horovod_global.group_table, mpi_context)); horovod_global.controller-\u0026gt;SetRanks(ranks, nranks); } #endif #if HAVE_GLOO // 依据是否编译了 GLOO 进行处理 // Enable gloo is it\u0026#39;s used either in cpu data transfer or controller if (horovod_global.cpu_operation == LibType::GLOO || horovod_global.control_operation == LibType::GLOO) { gloo_context.Enable(); } if (horovod_global.control_operation == LibType::GLOO) { horovod_global.controller.reset(new GlooController( horovod_global.response_cache, horovod_global.tensor_queue, horovod_global.timeline, horovod_global.parameter_manager, horovod_global.group_table, gloo_context)); } #endif // Reset initialization flag // 启动后台线程 horovod_global.initialization_done = false; horovod_global.background_thread = std::thread( BackgroundThreadLoop, std::ref(horovod_global)); } // Wait to ensure that the background thread has finished initializing MPI. while (!horovod_global.initialization_done) { std::this_thread::sleep_for(std::chrono::milliseconds(1)); } } 4.3.3 HorovodGlobalState 在 C++ 世界，HorovodGlobalState 起到了集中管理各种全局变量的作用。\nHorovodGlobalState 在 horovod 中是一个全局变量，其中的元素可以供不同的线程访问。HorovodGlobalState 在加载 C++ 的代码时候就已经创建了，同时创建的还有各种 context（mpi_context, nccl_context, gpu_context）。\nHorovod 主要会在backgroundThreadLoop 中完成 HorovodGlobalState 不同元素初始化，比较重要的有：\ncontroller 管理总体通信控制流； tensor_queue 会处理从前端过来的通信需求（allreduce，broadcast 等)； 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // All the Horovod state that must be stored globally per-process. HorovodGlobalState horovod_global; #if HAVE_MPI MPIContext mpi_context; #endif #if HAVE_GLOO GlooContext gloo_context; #endif .... std::unique_ptr\u0026lt;OperationManager\u0026gt; op_manager; HorovodGlobalState 摘要如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 struct HorovodGlobalState { // Background thread running MPI communication. std::thread background_thread; // 后台线程，用来在各个worker之间协调 ParameterManager parameter_manager; // 维护后台总体参数配置 // Encapsulates the fusion buffers, handles resizing and auto-tuning of buffer // size. FusionBufferManager fusion_buffer; // 融合tensor，以便缩减通信开销 std::shared_ptr\u0026lt;Controller\u0026gt; controller; //管理总体通信控制流 TensorQueue tensor_queue; //处理从前端过来的通信需求（allreduce，broadcast 等） // Pointer to shared buffer for allgather void* shared_buffer = nullptr; // LRU cache of Responses ResponseCache response_cache; // Information on registered groups. GroupTable group_table; ~HorovodGlobalState() { // Make sure that the destructor of the background thread is safe to // call. If a thread is still joinable (not detached or complete) its // destructor cannot be called. if (background_thread.joinable()) { shut_down = true; background_thread.join(); } } }; 目前具体逻辑如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 Import python files + | | v Import C++ SO files | | | v Create _HorovodBasics + | | v hvd.init() + Python | +-------------------------------------------------------------------------------------------------------------+ | c++ | v +-----------------------------+ | HorovodGlobalState | horovod_init_comm | | + +------------------+ | | | | horovod_global +---------\u0026gt; | TensorQueue | | | | | | v | | | background_thread | | mpi_context | | | InitializeHorovodOnce +------------\u0026gt; | | | ParameterManager | + | | | | | | gloo_context | | FusionBufferManager | | | | | | | | | | Controller | v | op_manager | | | background_threa | | | ResponseCache | +------------------+ | | | shared_buffer | +-----------------------------+ 如图：\n至此，horovod 已经初始化完成，用户代码可以使用了。\n4.3 hvd 概念 在用户代码中，接下来是rank概念。\n1 2 3 hvd.local_rank() hvd.rank() 我们介绍下几个相关概念：\nHorovod为设备上的每个GPU启动了该训练脚本的一个副本。local rank就是分配给某一台计算机上每个执行训练的唯一编号（也可以认为是进程号或者GPU设备的ID号），范围是 0 到 n-1，其中 n 是该计算机上GPU设备的数量。 rank 可以认为是代表分布式任务里的一个执行训练的唯一全局编号（用于进程间通讯）。Rank 0 在Horovod中通常具有特殊的意义：它是负责此同步的设备。 在百度的实现中，不同 Rank 的角色是不一样的，Rank 0 会充当 coordinator 的角色。它会协调来自其他 Rank 的 MPI 请求，是一个工程上的考量。这一设计也被后来的 Horovod 采用。 Rank 0 也用来把参数广播到其他进程 \u0026amp; 存储 checkpoint。 world_size：进程总数量，会等到所有world_size个进程就绪之后才会开始训练。 hvd.init 这部分的目的就是让并行进程们可以知道自己被分配的 rank / local rank 等信息，于是后续可以根据 local rank（所在节点上的第几张 GPU 卡） 来设置所需的显存分配。\n4.5 数据处理 接下来是数据处理。\n1 2 3 4 5 dataset = tf.data.Dataset.from_tensor_slices( (tf.cast(mnist_images[..., tf.newaxis] / 255.0, tf.float32), tf.cast(mnist_labels, tf.int64)) ) dataset = dataset.repeat().shuffle(10000).batch(128) 这里有几点需要说明：\n首先，训练的数据需要放置在任何节点都能访问的地方。\n其次，Horovod 需要对数据进行分片处理，需要在不同机器上按Rank进行切分，以保证每个GPU进程训练的数据集是不一样的。\n数据集本体需要出于数据并行性的需求而被拆分为多个分片，Horovod的不同工作节点都将分别读取自己的数据集分片。\n从 PyTorch 示例脚本看得更加清楚。\n1 2 3 4 5 # Horovod: use DistributedSampler to partition the training data. train_sampler = torch.utils.data.distributed.DistributedSampler( train_dataset, num_replicas=hvd.size(), rank=hvd.rank()) train_loader = torch.utils.data.DataLoader( train_dataset, batch_size=args.batch_size, sampler=train_sampler, **kwargs) DataLoader的采样器组件从要绘制的数据集中返回可迭代的索引。 PyTorch中的默认采样器是顺序的，返回序列0, 1, 2, …, n 。 Horovod使用其DistributedSampler覆盖了此行为，该DistributedSampler处理跨计算机的数据集分区。 DistributedSampler本身接受两个参数作为输入： hvd.size() (GPU的总数，例如16)和hvd.rank() (从总体列表中分配给该设备的ID，例如0…15)。\nPytorch使用的是数据分布式训练，每个进程实际上是独立加载数据的，所以需要加载相同数据集后用一定的规则根据rank来顺序切割获取不同的数据子集，DistributedSampler就是用来确保dataloader只会load到整个数据集的一个特定子集的做法(实际上不用Pytorch提供的DistributedSampler工具，自己做加载数据后切分word_size个子集按rank顺序拿到子集效果也是一样)。\n同时为了能够按顺序划分数据子集，拿到不同部分数据，所以数据集不能够进行随机打散，所以用了参数 'shuffle': False。\n4.6 广播初始化变量 以下代码完成广播初始化的功能。\n1 hvd.callbacks.BroadcastGlobalVariablesCallback(0) 这句代码保证的是 rank 0 上的所有参数只在 rank 0 初始化，然后广播给其他节点，即变量从第一个流程向其他流程传播，以实现参数一致性初始化。\n下面就介绍下 Horvod 之中广播的使用。\n4.6.1 广播定义 广播的具体实现是：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class BroadcastGlobalVariablesCallbackImpl(object): def __init__(self, backend, root_rank, device=\u0026#39;\u0026#39;, *args): super(BroadcastGlobalVariablesCallbackImpl, self).__init__(*args) self.backend = backend self.root_rank = root_rank self.device = device self.broadcast_done = False def on_batch_end(self, batch, logs=None): if self.broadcast_done: return with tf.device(self.device): if hvd._executing_eagerly() and hasattr(self.model, \u0026#39;variables\u0026#39;): # TensorFlow 2.0 or TensorFlow eager hvd.broadcast_variables(self.model.variables, root_rank=self.root_rank) hvd.broadcast_variables(self.model.optimizer.variables(), root_rank=self.root_rank) else: bcast_op = hvd.broadcast_global_variables(self.root_rank) self.backend.get_session().run(bcast_op) self.broadcast_done = True 4.6.2 broadcast_variables broadcast_variables 调用了 _make_broadcast_group_fn 完成功能，可以看到对于 执行图 的每个变量，调用了 broadcast。\n1 2 3 4 5 6 7 8 9 10 def broadcast_variables(variables, root_rank): \u0026#34;\u0026#34;\u0026#34;Broadcasts variables from root rank to all other processes. Arguments: variables: variables for broadcast root_rank: rank of the process from which global variables will be broadcasted to all other processes. \u0026#34;\u0026#34;\u0026#34; broadcast_group = _make_broadcast_group_fn() return broadcast_group(variables, root_rank) 以及\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @_cache def _make_broadcast_group_fn(): if _executing_eagerly(): # Eager mode will parallelize independent control flow def broadcast_group(variables, root_rank): for var in variables: var.assign(broadcast(var, root_rank)) return _make_subgraph(broadcast_group) else: # Graph mode requires an Op def broadcast_group(variables, root_rank): return tf.group(*[var.assign(broadcast(var, root_rank)) for var in variables]) return broadcast_group 4.6.3 调用 MPI broadcast 就是调用了 MPI 函数真正完成了功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def broadcast(tensor, root_rank, name=None, ignore_name_scope=False): \u0026#34;\u0026#34;\u0026#34;An op which broadcasts the input tensor on root rank to the same input tensor on all other Horovod processes. The broadcast operation is keyed by the name of the op. The tensor type and shape must be the same on all Horovod processes for a given name. The broadcast will not start until all processes are ready to send and receive the tensor. Returns: A tensor of the same shape and type as `tensor`, with the value broadcasted from root rank. \u0026#34;\u0026#34;\u0026#34; if name is None and not _executing_eagerly(): name = \u0026#39;HorovodBroadcast_%s\u0026#39; % _normalize_name(tensor.name) return MPI_LIB.horovod_broadcast(tensor, name=name, root_rank=root_rank, ignore_name_scope=ignore_name_scope) 4.6.4 同步参数 在后台进程中，会根据情况定期同步参数。\n1 2 3 4 5 6 7 8 9 10 11 12 bool RunLoopOnce(HorovodGlobalState\u0026amp; state) { // 业务逻辑功能 if (state.parameter_manager.IsAutoTuning()) { bool should_sync = state.parameter_manager.Update(tensor_names, total_tensor_size); // 看看是否需要同步，如果需要，就同步。 if (should_sync) { state.controller-\u0026gt;SynchronizeParameters(); } } ...... } 同步参数代码也是调用了 Bcast 功能完成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 void Controller::SynchronizeParameters() { ParameterManager::Params param; if (is_coordinator_) { // rank 0 执行操作 param = parameter_manager_.GetParams(); } void* buffer = (void*)(\u0026amp;param); size_t param_size = sizeof(param); Bcast(buffer, param_size, 0, Communicator::GLOBAL); if (!is_coordinator_) { // worker 执行操作 parameter_manager_.SetParams(param); } } 4.7 DistributedOptimizer 最后需要配置DistributedOptimizer，这就是关键点之一。\n1 2 3 # Horovod: add Horovod DistributedOptimizer. opt = hvd.DistributedOptimizer( opt, backward_passes_per_step=1, average_aggregated_gradients=True) TF Optimizer 是模型训练的关键API，可以获取到每个OP的梯度并用来更新权重。HVD 在原始 TF Optimizer的基础上包装了hvd.DistributedOptimizer。\nDistributedOptimizer包装器将原始优化器作为输入，将梯度计算委托给它。 即DistributedOptimizer会调用原始优化器进行梯度计算。这样，在集群中每台机器都会用原始优化器得到自己的梯度（Local Gradient）。\nHorovod DistributedOptimizer接下来会使用all-reduce或all-gather来完成全局梯度归并，然后将这些平均梯度应用于所有设备。\n我们梳理下其中的调用关系：\nhvd.DistributedOptimizer继承 keras Optimizer，在计算时候，依然由传入的原始优化器做计算。 在得到计算的梯度之后，调用 hvd.allreduce 或者 hvd.allgather 来计算。 最后实施这些平均之后的梯度。从而实现整个集群的梯度归并操作。 具体后文会详细介绍。\n4.8 未来可能 Horovod 目前架构的基础是：机器学习的模型参数在一张 GPU 上可以存下。\n未来是否可以把模型分片结合进来，是一个很大的看点。\n另外，如果模型的全连接层较多，则全连接层的强耦合性结合 allreduce 类似 bsp 的同步机制，还是会让网络通信时间成为瓶颈。因此，在 ring-allreduce 环境下，同步协议的改造，比如利用 SSP 来替换 BSP，或者利用梯度压缩来加快 allreduce 进程也是值得探索的方向。\n5 总结 针对文初提出的几个问题，我们现在回答如下：\nHovorod 怎么进行数据分割？ 答案：有的框架可以自动做数据分割。如果框架不提供，则需要用户自己进行数据分割，以保证每个GPU进程训练的数据集是不一样的。 Hovorod 怎么进行模型分发？ 用户需要手动拷贝训练代码到各个节点上。 Hovorod 启动时候，python 和 C++ 都做了什么？ 答案：python 会引入 C++库，初始化各种变量和配置。C++部分会对 MPI，GLOO上下文进行初始化，启动后台进程处理内部通信。 如何确保 Hovorod 启动时候步骤一致； 答案： rank 0 上的所有参数只在 rank 0 初始化，然后广播给其他节点，即变量从第一个流程向其他流程传播，以实现参数一致性初始化。 下一篇文章将深入到python世界看看。\nreference: [1].https://www.cnblogs.com/rossiXYZ/p/14856543.html\n","permalink":"https://jianye0428.github.io/en/posts/notes/2022-10-08_horovod_2/","summary":"reference: [1].https://www.cnblogs.com/rossiXYZ/p/14856543.html 0 摘要 Horovod 是Uber于2017年发布的一个易于使用的高性能的分布式训练框架，在业界得到了广泛应用。 本系列将通过源码分析来带领大家了解 Hor","title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入"},{"content":"0 摘要 Horovod 是Uber于2017年发布的一个易于使用的高性能的分布式训练框架，在业界得到了广泛应用。\n本系列将通过源码分析来带领大家了解 Horovod。系列大约有15 ～ 18 篇，本文是系列第一篇，介绍相关背景知识。\n1 分布式并行训练 我们首先要介绍下分布式并行训练。\n1.1 分布式并行训练的必要 传统的模型训练中，迭代计算只能利用当前进程所在主机上的所有硬件资源，可是单机扩展性始终有限。而目前的机器学习有如下特点：\n样本数量大 目前训练数据越来越多，在大型互联网场景下，每天的样本量可以达到百亿级别。 特征维度多 因为巨大样本量导致机器学习模型参数越来越多，特征维度可以达到千亿或者万亿级别。 训练性能要求高 虽然样本量和模型参数巨大，但是业务需要我们在短期内训练出一个优秀的模型来验证。 模型实时上线 对于推荐资讯类应用，往往要求根据用户最新行为及时调整模型进行预测。 因此，单机面对海量数据和巨大模型时是无能为力的，有必要把数据或者模型分割成为多份，在多个机器上借助不同主机上的硬件资源进行训练加速。\n1.2 分布式训练 本文所说的训练，指的是利用训练数据通过计算梯度下降的方式迭代地去优化神经网络参数，并最终输出网络模型的过程。在单次模型训练迭代中，会有如下操作：\n首先利用数据对模型进行前向的计算。所谓的前向计算，就是将模型上一层的输出作为下一层的输入，并计算下一层的输出，从输入层一直算到输出层为止。 其次会根据目标函数，我们将反向计算模型中每个参数的导数，并且结合学习率来更新模型的参数。 而并行梯度下降的基本思想便是：多个处理器分别利用自己的数据来计算梯度，最后通过聚合或其他方式来实现并行计算梯度下降以加速模型训练过程。 比如两个处理器分别处理一半数据计算梯度 g_1, g_2，然后把两个梯度结果进行聚合更新，这样就实现了并行梯度下降。\n1.3 训练并行机制 1.3.1 三种机制 由于使用小批量算法，可以把宽度$(∝W)$和深度$(∝D)$的前向传播和反向传播分发到并行的处理器上，这样深度训练的并行机制主要有三种：\n第一个是模型并行机制（按照网络结构分区）。 通常是针对一个节点无法存下整个模型的情况下，去对图进行拆分。 将模型参数进行分布式存储。计算机上每个计算可以建模为一个有向无环图（DAG），顶点是计算指令，边是数据依赖（数据流）。\u0026ldquo;基于图去拆分\u0026rdquo; 会根据每一层中的神经元（即四维张量中的C、H或W维）来把一张大的图拆分成很多部分，每个部分都会在很多设备上去计算。 或者可以这么理解：深度学习的计算主要是矩阵运算，有时候矩阵非常大无法放到显存中，就只能把超大矩阵拆分了放到不同卡上计算。 模型较后部分的计算必须等前面计算完成，因此不同节点间的计算实际是串行的。但每个部分计算互不妨碍，更像是流水线结构。 第二个是数据并行机制（按照输入样本分区）。 更多场景下我们模型规模不大，在一张 GPU 可以容纳，但是训练数据量会比较大，这时候就采用数据并行机制。 具体就是在多节点上并行分割数据和训练。 第三种不常用的并行机制是 流水线机制（按层分区）。 在深度学习中，流水线可以是指重叠的计算，即在一层和下一层之间（当数据准备就绪时）连续计算；或者根据深度划分DNN，将层分配给特定处理器。 流水线可以看作是数据并行的一种形式，因为元素（样本）是通过网络并行处理的，但也可以看作是模型并行，因为流水线的长度是由DNN结构决定的。 具体可见下图: 1.3.2 如何使用 数据的并行往往意味着计算性能的可扩展，而模型的并行往往意味着内存使用的可扩展。\n需要注意的是：数据并行和模型并行也并不冲突，两者可以同时存在，而流水线机制也可以和模型并行一起混用。比如，DistBelief分布式深度学习系统结合了三种并行策略。训练在同时复制的多个模型上训练，每个模型副本在不同的样本上训练（数据并行），每个副本上，依据同一层的神经元（模型并行性）和不同层（流水线）上划分任务，进行分布训练。\n另外也需要根据具体问题具体分析，比如现代卷积神经网络主要由两种层构成，他们具有不一样的属性和性能。\n卷积层，占据了90% ~ 95% 的计算量，5% 的参数，但是对结果具有很大的表达能力。 全连接层，占据了 5% ~ 10% 的计算量， 95% 的参数，但是对于结果具有相对较小的表达的能力。 综上：卷积层计算量大，所需参数系数 W 少，全连接层计算量小，所需参数系数 W 多。因此对于卷积层适合使用数据并行，对于全连接层适合使用模型并行。\n1.4 数据并行训练 我们本系列主要讨论数据并行训练（其中的一种架构）.\n数据并行训练只是一种逻辑架构。我们从沐神的书里面摘录：\n假设机器上有k个GPU。给定要训练的模型，每个GPU将独立地维护一组完整的模型参数，尽管GPU上的参数值是相同且同步的。例如，下图演示了在k=2时使用数据并行的训练。\n一般来说，训练过程如下：\n在训练的任何迭代中，给定一个随机的小批量，我们将该小批量中的样本分成k个部分，并将它们均匀地分在多个GPU上。 每个GPU根据分配给它的小批量子集计算模型参数的损失和梯度。 将k个GPU中每个GPU的局部梯度聚合以获得当前的小批量随机梯度。 聚合梯度被重新分配到每个GPU。 每个GPU使用这个小批量随机梯度来更新它维护的完整的模型参数集。 2 通信和架构 前面提到并行梯度下降的例子：两个处理器分别处理一般数据计算梯度 $g_1$, $g_2$，然后把两个梯度结果进行聚合，最后再把最新参数发给各个分布计算单元，这种训练算法叫模型一致性方法（consistent model methods）。这就涉及到了通信问题，即如何做聚合。\n2.1 方法和架构 一般有两种通信方法：Share memory 和 Message passing。\nShare memory 就是所有处理器共享同一块内存，这样通信很容易，但是同一个节点内的处理器之间才可以共享内存，不同节点处理器之间无法共享内存。 Message passing 就是不同节点之间用消息（比如基于 TCP/IP 或者 RDMA）进行传递/通信，这样容易扩展，可以进行大规模训练。 因此我们知道，Message passing 才是解决方案，于是带来了问题：如何协调这些节点之间的通讯。\n有两种架构：\nClient-Server架构: 一个 server 节点协调其他节点工作，其他节点是用来执行计算任务的 worker。 Peer-to-Peer架构：每个节点都有邻居，邻居之间可以互相通信。 2.2 异步 vs 同步 异步 vs 同步 是通信的另外一个侧面。\n在数据并行训练之中，各个计算设备分别根据各自获得的batch，前向计算获得损失，进而反向传播计算梯度。计算好梯度后，就涉及到一个梯度同步的问题：每个计算设备 都有根据自己的数据计算的梯度，如何在不同GPU之间维护模型的不同副本之间的一致性？ 如果不同的模型以某种方式最终获得不同的权重，则权重更新将变得不一致，并且模型训练将有所不同。\n怎么做这个同步就是设计分布式机器学习系统的一个核心问题。\n分布式训练的梯度同步策略可分为异步（asynchronous）梯度更新 和 同步（synchronous）梯度更新机制。\n同步指的是所有的设备都是采用相同的模型参数来训练，等待所有设备的mini-batch训练完成后，收集它们的梯度然后取均值，然后执行模型的一次参数更新。\n同步训练相当于通过聚合很多设备上的mini-batch形成一个很大的batch来训练模型，Facebook就是这样做的，但是他们发现当batch大小增加时，同时线性增加学习速率会取得不错的效果。 同步训练看起来很不错，但是实际上需要各个设备的计算能力要均衡，而且要求集群的通信也要均衡。 因为每一轮结束时算得快的节点都需等待算得慢的节点算完，再进行下一轮迭代。类似于木桶效应，一个拖油瓶会严重拖慢训练进度，所以同步训练方式相对来说训练速度会慢一些。这个拖油瓶一般就叫做 straggler。(缺点) 异步训练中，各个设备完成一个mini-batch训练之后，不需要等待其它节点，直接去更新模型的参数，这样总体会训练速度会快很多\n异步训练的一个很严重的问题是梯度失效问题（stale gradients），刚开始所有设备采用相同的参数来训练，但是异步情况下，某个设备完成一步训练后，可能发现模型参数其实已经被其它设备更新过了，此时这个梯度就过期了，因为现在的模型参数和训练前采用的参数是不一样的。由于梯度失效问题，异步训练虽然速度快，但是可能陷入次优解（sub-optimal training performance）。 具体如图所示:\n这两种更新方式各有优缺点：\n异步更新可能会更快速地完成整个梯度计算。 同步更新 可以更快地进行一个收敛。 选择哪种方式取决于实际的应用场景。\n3 具体架构 接下来，我们看看几种具体架构实现，先给出一个总体说明：\n名称 通信 架构 并行性 MapReduce 消息传递 client-server 批同步 Parameter Server 消息传递 client-server 异步 Decentralized Network 消息传递 P2P(Peer to Peer) 同步或异步 3.1 MapReduce MapReduce是Client-Server架构。以 Spark 为例看看是如何进行并行化：\nSpark Driver 就是 Server，Spark Executor 就是 Worker 节点，每一个梯度下降过程包含一个广播、map和一个 reduce 操作。 Server 定义了 map操作（就是具体的训练），也可以把信息广播到worker节点。 Worker 会执行 map 操作进行训练，在此过程中，数据被分给 worker 进行计算。 计算结束后，worker把计算结果传回 driver 处理，这个叫做reduce。 在 reduce 过程中，Server 节点对 worker 传来的计算结果进行聚合之后，把聚合结果广播到各个worker节点，进行下一次迭代。 3.2 Parameter Server 参数服务器 Parameter server 也是一种client-server架构。和MapReduce不同在于 Parameter server 可以是异步的，MapReduce只有等所有map都完成了才能做reduce操作。\n参数服务器架构中，计算设备被划分为参数服务器（PS）和worker。\n参数服务器（server）。是中心化的组件，主要是负责模型参数的存储，平均梯度和交换更新。参数服务器可以按照不同比例的参数服务器和工作线程进行配置，每个参数服务器都有着不同的配置数据。 工作节点（worker）。每个工作节点会负责它领域内的数据分片所对应模型参数的更新计算（比如前向和反向传播这类计算密集的运算），同时它们又会向参数服务器去传递它所计算的梯度，由参数服务器来汇总所有的梯度，再进一步反馈到所有节点。 具体步骤如下：\n所有的参数都存储在参数服务器中，而 工作节点（worker） 是万年打工仔。 工作节点 们只负责计算梯度，待所有计算设备完成梯度计算之后，把计算好的梯度发送给参数服务器，这样参数服务器收到梯度之后，执行一定的计算（梯度平均等）之后，就更新其维护的参数，做到了在节点之间对梯度进行平均，利用平均梯度对模型进行更新。 然后参数服务器再把更新好的新参数返回给所有的工作节点，以对每个节点中的模型副本应用一致化更新。 打工仔们会再进行下一轮的前后向计算。 逻辑如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 +----------------------------------------------+ | Parameter Server | | | | | | Compute : New P = P + Sum(Delta P ...) | | | | | | Parameter 1, Parameter 2, Parameter 3 ... | | | | | +--+----+----------+--+----------------+--+----+ ^ | ^ | ^ | | | | | | | Delta P | | Delta P| | Delta P| | +-----+ | | | | +------+ | +-----+ | | | | | | New P | | New P +------+ | | | | | | | New P | v | | | | | | v | v +-+-----------+ +-----+--+---+ +-----+--+---+ | Worker | | Worker | | Worker | | | | | | | | | | | ...... | | | Model | | Model | | Model | +------+------+ +------+-----+ +----+-------+ ^ ^ ^ | | | | | | +----+----+ +----+-----+ +--+-----+ | Data 1 | | Data 2 | | Data 3 | +---------+ +----------+ +--------+ 如图: 参数服务器既可以用在数据并行上，也可以被用到模型并行训练上。比如可以将模型切分为多个部分，存储在不同的PS Server节点上，并提供方便的访问服务，这是参数服务器的本质。\n3.3 Decentralized Network Decentralized Network 就是去中心化网络，其特点如下：\n去中心化网络没有一个中心节点，属于 Peer-to-Peer 架构。 采用 message passing 进行通信，且节点只和邻居通信。 并行方式可以采用异步或者同步。 去中心化网络的收敛情况取决于网络连接情况： 连接越紧密，收敛性越快，当强连接时候，模型可以很快收敛； 如果不是强连接，它可能不收敛； 4 AllReduce 因为本系列是 Horovod，所以我们要先说说参数服务器的劣势，下一个系列我们再说参数服务器优势。\n4.1 参数服务器劣势 尽管参数服务器可以提升表现，但仍然面临几个问题：\n确定工作者与参数服务器的正确比例：如果使用一个参数服务器，它可能会成为网络或计算瓶颈。 如果使用多个参数服务器，则通信模式变为“All-to-All”，这可能使网络饱和。 处理程序复杂性：参数服务器的概念较多，这通常导致陡峭的学习曲线和大量的代码重构，压缩了实际建模的时间。 硬件成本 : 参数服务器的引入也增加了系统的硬件成本。 人们发现，MPI_AllReduce 语义也可以很好地满足数据并行训练这一需要。\n需要注意的是：AllReduce 既可以是去中心化，也可以是主从式的。\n4.2 并行任务通信分类 并行任务的通信一般可以分为 Point-to-point communication和 Collective communication。\nP2P 这种模式只有一个sender和一个receiver，实现起来比较简单，比如NV GPU Direct P2P技术服务于单机多卡的单机卡间数据通信 。 Collective communication包含多个sender和多个receiver，一般的通信原理包括 broadcast，gather,all-gather，scatter，reduce，all-reduce，reduce-scatter，all-to-all等。 4.3 MPI_AllReduce AllReduce(对m个独立参数进行规约，并将规约结果返回给所有进程), 其实是最显然和直接的分布式机器学习抽象，因为大部分算法的结构都是分布数据。在每个子集上面算出一些局部统计量，然后整合出全局统计量，并且再分配给各个节点去进行下一轮的迭代，这样一个过程就是AllReduce。\n可以把每个 Worker 看作是 MPI 概念中的一个进程，比如可以用 4 个 Worker 组成了一个组，该组由 4 个进程组成。我们在这四个进程中对梯度进行一次 MPI_AllReduce。\n根据 MPI_AllReduce 的语义，所有参与计算的进程都有结果，所以梯度就完成了分发。只要在初始化的时候，我们可以保证每个 Worker 的参数是一致的，那在后续的迭代计算中，参数会一直保持一致，因为梯度信息是一致的。\nAllReduce 跟 MapReduce 有类似，但后者采用的是面向通用任务处理的多阶段执行任务的方式，而AllReduce则让一个程序在必要的时候占领一台机器，并且在所有迭代的时候一直跑到底，来防止重新分配资源的开销，这更加适合于机器学习的任务处理。\n所以，MPI_AllReduce 的语义可以很好地解决深度学习中梯度同步的问题。但是到底能不能使用它，还是要看下层的实现对这一场景是否足够友好。\n5 ring-allreduce 百度提出使用新算法来平均梯度，取消 Reducer，并让这些梯度在所有节点之间交流，这被称为 ring-allreduce，他们使用 TensorFlow 也实现了这种算法（https://github.com/baidu-research/tensorflow-allreduce）。\n5.1 特点 Ring-Allreduce特点如下：\nRing Allreduce 算法使用定义良好的成对消息传递步骤序列在一组进程之间同步状态（在这种情况下为张量）。 Ring-Allreduce 的命名中 Ring 意味着设备之间的拓扑结构为一个逻辑环形，每个设备都应该有一个左邻和一个右邻居，且本设备只会向它右邻居发送数据，并且从它的左邻居接受数据。 Ring-Allreduce 的命名中的 Allreduce 则代表着没有中心节点，架构中的每个节点都是梯度的汇总计算节点。 此种算法各个节点之间只与相邻的两个节点通信，并不需要参数服务器。因此，所有节点都参与计算也参与存储，也避免产生中心化的通信瓶颈。 相比PS架构，Ring-Allreduce 架构是带宽优化的，因为集群中每个节点的带宽都被充分利用。 在 ring-allreduce 算法中，每个 N 节点与其他两个节点进行 2 * (N-1) 次通信。在这个通信过程中，一个节点发送并接收数据缓冲区传来的块。在第一个N-1迭代中，接收的值被添加到节点缓冲区中的值。在第二个N-1迭代中，接收的值代替节点缓冲区中保存的值。百度的文章证明了这种算法是带宽上最优的，这意味着如果缓冲区足够大，它将最大化地利用可用的网络。 在深度学习训练过程中，计算梯度采用BP算法，其特点是后面层的梯度先被计算，而前面层的梯度慢于后面层，Ring-allreduce架构可以充分利用这个特点，在前面层梯度计算的同时进行后面层梯度的传递，从而进一步减少训练时间。 Ring架构下的同步算法将参数在通信环中依次传递，往往需要多步才能完成一次参数同步。在大规模训练时会引入很大的通信开销，并且对小尺寸张量（tensor）不够友好。对于小尺寸张量，可以采用批量操作（batch）的方法来减小通信开销。 综上所述，Ring-based AllReduce 架构的网络通讯量如果处理适当，不会随着机器增加而增加，而仅仅和模型 \u0026amp; 网络带宽有关，这针对参数服务器是个巨大的提升。\n5.2 策略 Ring-based AllReduce 策略包括 Scatter-Reduce 和 AllGather 两个阶段。\n首先是scatter-reduce，scatter-reduce 会逐步交换彼此的梯度并融合，最后每个 GPU 都会包含完整融合梯度的一部分，是最终结果的一个块。\n假设环中有 N 个 worker，每个 worker 有长度相同的数组，需要将 worker 的数组进行求和。在 Scatter-Reduce 阶段，每个 worker 会将数组分成 N 份数据块，然后 worker 之间进行 N 次数据交换。在第 k 次数据交换时，第 i 个 worker 会将自己的 (i - k) % N 份数据块发送给下一个 worker。接收到上一个 worker 的数据块后，worker 会将其与自己对应的数据块求和。 然后是allgather。GPU 会逐步交换彼此不完整的融合梯度，最后所有 GPU 都会得到完整的最终融合梯度。\n在执行完 Scatter-Reduce 后，每个 worker 的数组里都有某个数据块是最终求和的结果，现在需要将各数据块的最后求和结果发送到每个 worker 上。和 Scatter-Reduce 一样，也需要 N 次循环。在第 k 次循环时，第 i 个 worker 会将其第 (i+1-k)%N 个数据块发送给下一个 worker 。接收到前一个 worker 的数据块后，worker 会用接收的数据快覆盖自己对应的数据块。进行 N 次循环后，每个 worker 就拥有了数组各数据块的最终求和结果了。 以下部分来自 https://andrew.gibiansky.com/blog/machine-learning/baidu-allreduce/，这是我能找到最优秀的解读。\n5.2.1 结构 环形结构如下，每个 GPU 应该有一个左邻居和一个右邻居；它只会向其右侧邻居发送数据，并从其左侧邻居接收数据。\n5.2.2 scatter reduce scatter-reduce：会逐步交换彼此的梯度并融合，最后每个 GPU 都会包含完整融合梯度的一部分。\n为简单起见，我们假设目标是按元素对单个大型浮点数数组的所有元素求和；系统中有 N 个 GPU，每个 GPU 都有一个相同大小的数组，在 allreduce 的最后环节，每个 GPU 都应该有一个相同大小的数组，其中包含原始数组中数字的总和。\n5.2.2.1 分块 首先，GPU 将阵列划分为 N 个较小的块（其中 N 是环中的 GPU 数量）。\n接下来，GPU 将进行 N-1 次 scatter-reduce 迭代。\n在每次迭代中，GPU 会将其一个块发送到其右邻居，并将从其左邻居接收一个块并累积到该块中。每个 GPU 发送和接收的数据块每次迭代都不同。第 n 个 GPU 通过发送块 n 和接收块 n – 1 开始，然后逐步向后进行，每次迭代发送它在前一次迭代中接收到的块。\n5.2.2.2 第一次迭代 在第一次迭代中，上图中的五个 GPU 将发送和接收以下块：\nGPU 发送 接收 0 块0 块4 1 块1 块0 2 块2 块1 3 块3 块2 4 块4 块3 scatter-reduce 的第一次迭代中的数据传输如下：\n第一次发送和接收完成后，每个 GPU 都会有一个块，该块由两个不同 GPU 上相同块的总和组成。例如，第二个 GPU 上的第一个块将是该块中来自第二个 GPU 和第一个 GPU 的值的总和。\n5.2.2.2 全部迭代 在后续迭代中，该过程继续直到最后。最终每个 GPU 将有一个块，这个块包含所有 GPU 中该块中所有值的总和。\n下面系列图展示了所有数据传输和中间结果，从第一次迭代开始，一直持续到scatter-reduce完成。\niter 1：\niter2：\niter3：\niter4：\n所有 scatter-reduce 传输后的最终状态\n5.2.3 Allgather 在 scatter-reduce 步骤完成后，在每个 GPU 的数组中都有某一些值（每个 GPU 有一个块）是最终值，其中包括来自所有 GPU 的贡献。为了完成 allreduce，GPU 必须接下来交换这些块，以便所有 GPU 都具有最终所需的值。\nring allgather 与 scatter-reduce 进行相同的处理（发送和接收的 N-1 次迭代），但是他们这次不是累积 GPU 接收的值，而只是简单地覆盖块。第 n 个 GPU 开始发送第 n+1 个块并接收第 n 个块，然后在以后的迭代中始终发送它刚刚接收到的块。\n5.2.3.1 第一次迭代 例如，在我们的 5-GPU 设置的第一次迭代中，GPU 将发送和接收以下块：\nGPU 发送 接收 0 块1 块0 1 块2 块1 2 块3 块2 3 块4 块3 4 块0 块4 allgather 的第一次迭代中的数据传输如下。\n第一次迭代完成后，每个 GPU 都会有最终数组的两个块。在接下来的迭代中，该过程继续一直到最后，最终每个 GPU 将拥有整个数组的完全累加值。\n5.2.3.2 全部迭代 下面系列图展示了所有数据传输和中间结果，从第一次迭代开始，一直持续到全部收集完成。\nAllgather 数据传输（迭代 1） Allgather 数据传输（迭代 2）如下： Allgather 数据传输（迭代 3）：\nAllgather 数据传输（迭代 4）：\n所有全部转移后的最终状态。\n5.2.4 Horovod 架构图 工作原理也可以借助Horovod的发布帖子 来看看。\n5.2.5 百度思路 或者我们从百度的源码中也可以直接看到思路，现在摘录给大家。\n具体代码参见 https://github.com/baidu-research/tensorflow-allreduce/commit/66d5b855e90b0949e9fa5cca5599fd729a70e874#diff-3d530d590e551619acd776cfe7eaff06R517\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 /* Perform a ring allreduce on the data. Allocate the necessary output tensor and * store it in the output parameter. * * Assumes that all MPI processes are doing an allreduce of the same tensor, * with the same dimensions. * * A ring allreduce is a bandwidth-optimal way to do an allreduce. To do the allreduce, * the nodes involved are arranged in a ring: * * .--0--. * / \\ * 3 1 * \\ / * *--2--* * * Each node always sends to the next clockwise node in the ring, and receives * from the previous one. * * The allreduce is done in two parts: a scatter-reduce and an allgather. In * the scatter reduce, a reduction is done, so that each node ends up with a * chunk of the final output tensor which has contributions from all other * nodes. In the allgather, those chunks are distributed among all the nodes, * so that all nodes have the entire output tensor. * * Both of these operations are done by dividing the input tensor into N * evenly sized chunks (where N is the number of nodes in the ring). * * The scatter-reduce is done in N-1 steps. In the ith step, node j will send * the (j - i)th chunk and receive the (j - i - 1)th chunk, adding it in to * its existing data for that chunk. For example, in the first iteration with * the ring depicted above, you will have the following transfers: * * Segment 0: Node 0 --\u0026gt; Node 1 * Segment 1: Node 1 --\u0026gt; Node 2 * Segment 2: Node 2 --\u0026gt; Node 3 * Segment 3: Node 3 --\u0026gt; Node 0 * * In the second iteration, you\u0026#39;ll have the following transfers: * * Segment 0: Node 1 --\u0026gt; Node 2 * Segment 1: Node 2 --\u0026gt; Node 3 * Segment 2: Node 3 --\u0026gt; Node 0 * Segment 3: Node 0 --\u0026gt; Node 1 * * After this iteration, Node 2 has 3 of the four contributions to Segment 0. * The last iteration has the following transfers: * * Segment 0: Node 2 --\u0026gt; Node 3 * Segment 1: Node 3 --\u0026gt; Node 0 * Segment 2: Node 0 --\u0026gt; Node 1 * Segment 3: Node 1 --\u0026gt; Node 2 * * After this iteration, Node 3 has the fully accumulated Segment 0; Node 0 * has the fully accumulated Segment 1; and so on. The scatter-reduce is complete. * * Next, the allgather distributes these fully accumululated chunks across all nodes. * Communication proceeds in the same ring, once again in N-1 steps. At the ith step, * node j will send chunk (j - i + 1) and receive chunk (j - i). For example, at the * first iteration, the following transfers will occur: * * Segment 0: Node 3 --\u0026gt; Node 0 * Segment 1: Node 0 --\u0026gt; Node 1 * Segment 2: Node 1 --\u0026gt; Node 2 * Segment 3: Node 2 --\u0026gt; Node 3 * * After the first iteration, Node 0 will have a fully accumulated Segment 0 * (from Node 3) and Segment 1. In the next iteration, Node 0 will send its * just-received Segment 0 onward to Node 1, and receive Segment 3 from Node 3. * After this has continued for N - 1 iterations, all nodes will have a the fully * accumulated tensor. * * Each node will do (N-1) sends for the scatter-reduce and (N-1) sends for the allgather. * Each send will contain K / N bytes, if there are K bytes in the original tensor on every node. * Thus, each node sends and receives 2K(N - 1)/N bytes of data, and the performance of the allreduce * (assuming no latency in connections) is constrained by the slowest interconnect between the nodes. * */ 5.3 区别 在中等规模模型情况下，all-reduce 更适合。当规模巨大时候则应该使用参数服务器。\n参数服务器 适合的是高维稀疏模型训练，它利用的是维度稀疏的特点，每次 pull or push 只更新有效的值。但是深度学习模型是典型的dense场景，embedding做的就是把稀疏变成稠密。所以这种 pull or push 的不太适合。而 网络通信上更优化的 all-reduce 适合中等规模的深度学习。\n又比如由于推荐搜索领域模型的 Embedding 层规模庞大以及训练数据样本长度不固定等原因，导致容易出现显存不足和卡间同步时间耗费等问题，所以 all-reduce 架构很少被用于搜索推荐领域。\n至此，背景知识已经介绍完毕，下一篇我们开始介绍 Horovod 的使用。\nreference: [1] https://www.cnblogs.com/rossiXYZ/p/14856464.html\n","permalink":"https://jianye0428.github.io/en/posts/notes/2022-10-08_horovod_1/","summary":"0 摘要 Horovod 是Uber于2017年发布的一个易于使用的高性能的分布式训练框架，在业界得到了广泛应用。 本系列将通过源码分析来带领大家了解 Horov","title":"深度学习分布式训练框架 Horovod[1] -- 基础知识"},{"content":"ref: [1] https://www.cnblogs.com/rushup0930/p/13359513.html\n[2] https://blog.csdn.net/u013250861/article/details/123029585#t12\n[3] https://blog.csdn.net/wf592523813/article/details/95202448\n[4] https://zhuanlan.zhihu.com/p/69101372\nclassification 分类 主要涉及的知识点：\n混淆矩阵、Precision(精准率)、Recall(召回率)、Accuracy(准确率)、F1-score （包括二分类和多分类问题） ROC、AUC 最常见的指标Accuracy到底有哪些不足？ 解: Accuracy是分类问题中最常用的指标，它计算了分类正确的预测数与总预测数的比值。但是，对于不平衡数据集而言，Accuracy并不是一个好指标。 假设我们有100张图片，其中91张图片是「狗」，5张是「猫」，4张是「猪」，我们希望训练一个三分类器，能正确识别图片里动物的类别。其中，狗这个类别就是大多数类 (majority class)。当大多数类中样本（狗）的数量远超过其他类别（猫、猪）时，如果采用Accuracy来评估分类器的好坏，那么即便模型性能很差 (如无论输入什么图片，都预测为「狗」)，也可以得到较高的Accuracy Score (如91%)。此时，虽然Accuracy Score很高，但是意义不大。当数据异常不平衡时，Accuracy评估方法的缺陷尤为显著。\n二分类模型的常见指标 在二分类问题中，假设该样本一共有两种类别：Positive和Negative。当分类器预测结束，我们可以绘制出混淆矩阵（confusion matrix）。其中分类结果分为如下几种：\nTrue Positive (TP): 把正样本成功预测为正。 True Negative (TN)：把负样本成功预测为负。 False Positive (FP)：把负样本错误地预测为正。 False Negative (FN)：把正样本错误的预测为负。 一个小技巧， 第一个字母表示划分正确与否， T 表示判定正确（判定正确）， F表示判定错误(False)； 第二个字母表示分类器判定结果， P表示判定为正例， N表示判定为负例。\n在二分类模型中，Accuracy，Precision，Recall和F1 score的定义如下：\n$$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\nAccuracy 能够清晰的判断我们模型的表现，但有一个严重的缺陷： 在正负样本不均衡的情况下，占比大的类别往往会成为影响 Accuracy 的最主要因素，此时的 Accuracy 并不能很好的反映模型的整体情况。\n$$\\text{Precision} = \\frac{TP}{TP + FP}$$\nPrecision着重评估在预测为Positive的所有数据中，真实Positve的数据到底占多少？\n精确率高，意味着分类器要尽量在 “更有把握” 的情况下才将样本预测为正样本， 这意味着精确率能够很好的体现模型对于负样本的区分能力，精确率越高，则模型对负样本区分能力越强。\n$$\\text{Recall} = \\frac{TP}{TP + FN}$$\nRecall着重评估：在所有的Positive数据中，到底有多少数据被成功预测为Positive\n召回率高，意味着分类器尽可能将有可能为正样本的样本预测为正样本，这意味着召回率能够很好的体现模型对于正样本的区分能力，召回率越高，则模型对正样本的区分能力越强。\n举例:\n一个医院新开发了一套癌症AI诊断系统，想评估其性能好坏。我们把病人得了癌症定义为Positive，没得癌症定义为Negative。那么， 到底该用什么指标进行评估呢？\n如用Precision对系统进行评估，那么其回答的问题就是： 在诊断为癌症的一堆人中，到底有多少人真得了癌症？\n如用Recall对系统进行评估，那么其回答的问题就是： 在一堆得了癌症的病人中，到底有多少人能被成功检测出癌症？\n如用Accuracy对系统进行评估，那么其回答的问题就是： 在一堆癌症病人和正常人中，有多少人被系统给出了正确诊断结果（患癌或没患癌）？\n那啥时候应该更注重Recall而不是Precision呢？\n当False Negative (FN)的成本代价很高 (后果很严重)，希望尽量避免产生FN时，应该着重考虑提高Recall指标。\n那啥时候应该更注重Precision而不是Recall呢？\n当False Positive (FP)的成本代价很高 (后果很严重)时，即期望尽量避免产生FP时，应该着重考虑提高Precision指标。\n$$\\text{F1-score} = \\frac{2 \\times Precision \\times Recall}{Precision + Recall}$$\n而F1-score是Precision和Recall两者的综合。\n举个更有意思的例子（我拍脑袋想出来的，绝对原创哈），假设检察机关想将罪犯捉拿归案，需要对所有人群进行分析，以判断某人犯了罪（Positive），还是没犯罪（Negative）。显然，检察机关希望不漏掉一个罪人（提高recall），也不错怪一个好人（提高precision），所以就需要同时权衡recall和precision两个指标。\n尤其在上个世纪，中国司法体制会更偏向Recall，即「天网恢恢，疏而不漏，任何罪犯都插翅难飞」。而西方司法系统会更偏向Precision，即「绝不冤枉一个好人，但是难免有罪犯成为漏网之鱼，逍遥法外」。到底是哪种更好呢？显然，极端并不可取。Precision和Recall都应该越高越好，也就是F1应该越高越好。\n如何通俗的解释召回率与精确率？\n例：公园里有50只皮卡丘和10只臭臭泥。有正常审美的人都会想要用精灵球把尽可能多的皮卡丘抓回来，同时尽可能少地抓住臭臭泥。 最终我们的精灵球成功抓回来了45只皮卡丘和10只臭臭泥。 我们就可以说50只皮卡丘中有45只被召唤 (call) 回来 (re) 了，所以 recall = 45 / 50。 但同时，这台机器还误把5只臭臭泥识别为皮卡丘，在它抓回来的所有55只神奇宝贝中，精灵球对皮卡丘判断的精准性 (precision) = 45 / 55。 在上面的例子中，精灵球=预测模型，皮卡丘=正样本，臭臭泥=负样本。 总结这两个概念的用处：描述模型对正样本的预测性能 1、recall描述模型“把正样本叫 (call) 回来(re)”的能力。 2、precision描述模型“叫回来的正样本”有多少是精确的。\nAOC / AUC 混淆矩阵中有着Positive、Negative、True、False的概念，其意义如下：\n称预测类别为1的为Positive（阳性），预测类别为0的为Negative（阴性）。 预测正确的为True（真），预测错误的为False（伪）。 对上述概念进行组合，就产生了如下的混淆矩阵:\n然后，由此引出True Positive Rate（真阳率）、False Positive（伪阳率）两个概念：\n$$TP Rate = \\frac{TP}{TP + FN}$$ $$FP Rate = \\frac{FP}{FP + TN}$$\n仔细看这两个公式，发现其实TPRate就是TP除以TP所在的列，FPRate就是FP除以FP所在的列，二者意义如下：\nTPRate的意义是所有真实类别为1的样本中，预测类别为1的比例。 FPRate的意义是所有真实类别为0的样本中，预测类别为1的比例。 如果上述概念都弄懂了，那么ROC曲线和AUC就so easy了：\n按照定义，AUC即ROC曲线下的面积，而ROC曲线的横轴是FPRate，纵轴是TPRate，当二者相等时，即y=x，如下图:\n表示的意义是：对于不论真实类别是1还是0的样本，分类器预测为1的概率是相等的。\n换句话说，分类器对于正例和负例毫无区分能力，和抛硬币没什么区别，一个抛硬币的分类器是我们能想象的最差的情况，因此一般来说我们认为AUC的最小值为0.5（当然也存在预测相反这种极端的情况，AUC小于0.5，这种情况相当于分类器总是把对的说成错的，错的认为是对的，那么只要把预测类别取反，便得到了一个AUC大于0.5的分类器）。\n而我们希望分类器达到的效果是：对于真实类别为1的样本，分类器预测为1的概率（即TPRate），要大于真实类别为0而预测类别为1的概率（即FPRate），即y＞x，因此大部分的ROC曲线长成下面这个样子：\n说了这么多还是不够直观，不妨举个简单的例子。\n首先对于硬分类器（例如SVM，NB），预测类别为离散标签，对于8个样本的预测情况如下：\n得到混淆矩阵如下：\n进而算得TPRate=3/4，FPRate=2/4，得到ROC曲线：\n最终得到AUC为0.625。\n对于LR等预测类别为概率的分类器，依然用上述例子，假设预测结果如下：\n这时，需要设置阈值来得到混淆矩阵，不同的阈值会影响得到的TPRate，FPRate，如果阈值取0.5，小于0.5的为0，否则为1，那么我们就得到了与之前一样的混淆矩阵。其他的阈值就不再啰嗦了。依次使用所有预测值作为阈值，得到一系列TPRate，FPRate，描点，求面积，即可得到AUC。\n最后说说AUC的优势，AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价。\n例如在反欺诈场景，设欺诈类样本为正例，正例占比很少（假设0.1%），如果使用准确率评估，把所有的样本预测为负例，便可以获得99.9%的准确率。\n但是如果使用AUC，把所有样本预测为负例，TPRate和FPRate同时为0（没有Positive），与(0,0) (1,1)连接，得出AUC仅为0.5，成功规避了样本不均匀带来的问题。\n多分类模型的常见指标详细解析 在多分类（大于两个类）问题中，假设我们要开发一个动物识别系统，来区分输入图片是猫，狗还是猪。给定分类器一堆动物图片，产生了如下结果混淆矩阵。\n在混淆矩阵中，正确的分类样本（Actual label = Predicted label）分布在左上到右下的对角线上。其中，Accuracy的定义为分类正确（对角线上）的样本数与总样本数的比值。Accuracy度量的是全局样本预测情况。而对于Precision和Recall而言，每个类都需要单独计算其Precision和Recall。 classify_multiclass_prediction 比如，对类别「猪」而言，其Precision和Recall分别为:\n$$\\text{Precision} = \\frac{TP}{TP + FP} = \\frac{20}{20 + 50} = \\frac{2}{7}$$\n$$\\text{Recall} = \\frac{TP}{TP + FN} = \\frac{20}{10} = \\frac{2}{3}$$\n也就是: $$P_{cat} = \\frac{8}{15}, P_{dog} = \\frac{17}{23}, P_{pig} = \\frac{2}{7}, (P代表Precision) $$ $$R_{cat} = \\frac{4}{7}, R_{dog} = \\frac{17}{32}, R_{pig} = \\frac{2}{3}, (R代表Recall) $$\n如果想评估该识别系统的总体功能，必须考虑猫、狗、猪三个类别的综合预测性能。那么，到底要怎么综合这三个类别的Precision呢？是简单加起来做平均吗？通常来说， 我们有如下几种解决方案（也可参考scikit-learn官网）：\n1. Macro-average方法 该方法最简单，直接将不同类别的评估指标（Precision/ Recall/ F1-score）加起来求平均，给所有类别相同的权重。该方法能够平等看待每个类别，但是它的值会受稀有类别影响。\n$$\\text{Macro-Precision} = \\frac{P_{cat} + P_{dog} + P_{pig}}{3} = 0.5194$$ $$\\text{Macro-Recall} = \\frac{R_{cat} + R_{dog} + R_{pig}}{3} = 0.5898$$\n2. Weighted-average方法\n该方法给不同类别不同权重（权重根据该类别的真实分布比例确定），每个类别乘权重后再进行相加。该方法考虑了类别不平衡情况，它的值更容易受到常见类（majority class）的影响。\n$$W_{cat} : W_{dog} : W_{pig} = N_{cat} : N_{dog} : N_{pig} = \\frac{7}{26} : \\frac{16}{26} : \\frac{3}{26} (W代表权重，N代表样本在该类别下的真实数目)$$ $$\\text{Weighted-Precision} = P_{cat} \\times W_{cat} + P_{dog} \\times W_{dog} + P_{pig} \\times W_{pig} = 0.6314$$ $$\\text{Weighted-Recall} = {R_{cat} \\times W_{cat} + R_{dog} \\times W_{dog} + R_{pig} \\times W_{pig}}= 0.5577$$\n3. Micro-average方法\n该方法把每个类别的TP, FP, FN先相加之后，在根据二分类的公式进行计算。\n$$\\text{Micro-Precision} = \\frac{TP_{cat} + TP_{dog} + TP_{pig}}{TP_{cat} + TP_{dog} + TP_{pig} + FP_{cat} + FP_{dog} + FP_{pig}} = 0.5577$$ $$\\text{Micro-Recall} = \\frac{TP_{cat} + TP_{dog} + TP_{pig}}{TP_{cat} + TP_{dog} + TP_{pig} + FN_{cat} + FN_{dog} + FN_{pig}} = 0.5577$$\n其中，特别有意思的是，Micro-precision 和 Micro-recall竟然始终相同！这是为啥呢？\n这是因为在某一类中的False Positive样本，一定是其他某类别的False Negative样本。听起来有点抽象？举个例子，比如说系统错把「狗」预测成「猫」，那么对于狗而言，其错误类型就是False Negative，对于猫而言，其错误类型就是False Positive。于此同时，Micro-precision和Micro-recall的数值都等于Accuracy，因为它们计算了对角线样本数和总样本数的比值，总结就是\n$$\\text{Micro-Precision} = \\text{Micro-Recall} = \\text{Micro-F1 score} = \\text{Accuracy}$$\ndemo示例:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import numpy as np import seaborn as sns from sklearn.metrics import confusion_matrix import pandas as pd import matplotlib.pyplot as plt from sklearn.metrics import accuracy_score, average_precision_score,precision_score,f1_score,recall_score # create confusion matrix y_true = np.array([-1]*70 + [0]*160 + [1]*30) y_pred = np.array([-1]*40 + [0]*20 + [1]*20 + [-1]*30 + [0]*80 + [1]*30 + [-1]*5 + [0]*15 + [1]*20) cm = confusion_matrix(y_true, y_pred) conf_matrix = pd.DataFrame(cm, index=[\u0026#39;Cat\u0026#39;,\u0026#39;Dog\u0026#39;,\u0026#39;Pig\u0026#39;], columns=[\u0026#39;Cat\u0026#39;,\u0026#39;Dog\u0026#39;,\u0026#39;Pig\u0026#39;]) # plot size setting fig, ax = plt.subplots(figsize = (4.5,3.5)) sns.heatmap(conf_matrix, annot=True, annot_kws={\u0026#34;size\u0026#34;: 19}, cmap=\u0026#34;Blues\u0026#34;) plt.ylabel(\u0026#39;True label\u0026#39;, fontsize=18) plt.xlabel(\u0026#39;Predicted label\u0026#39;, fontsize=18) plt.xticks(fontsize=18) plt.yticks(fontsize=18) plt.savefig(\u0026#39;confusion.pdf\u0026#39;, bbox_inches=\u0026#39;tight\u0026#39;) plt.show() print(\u0026#39;------Weighted------\u0026#39;) print(\u0026#39;Weighted precision\u0026#39;, precision_score(y_true, y_pred, average=\u0026#39;weighted\u0026#39;)) print(\u0026#39;Weighted recall\u0026#39;, recall_score(y_true, y_pred, average=\u0026#39;weighted\u0026#39;)) print(\u0026#39;Weighted f1-score\u0026#39;, f1_score(y_true, y_pred, average=\u0026#39;weighted\u0026#39;)) print(\u0026#39;------Macro------\u0026#39;) print(\u0026#39;Macro precision\u0026#39;, precision_score(y_true, y_pred, average=\u0026#39;macro\u0026#39;)) print(\u0026#39;Macro recall\u0026#39;, recall_score(y_true, y_pred, average=\u0026#39;macro\u0026#39;)) print(\u0026#39;Macro f1-score\u0026#39;, f1_score(y_true, y_pred, average=\u0026#39;macro\u0026#39;)) print(\u0026#39;------Micro------\u0026#39;) print(\u0026#39;Micro precision\u0026#39;, precision_score(y_true, y_pred, average=\u0026#39;micro\u0026#39;)) print(\u0026#39;Micro recall\u0026#39;, recall_score(y_true, y_pred, average=\u0026#39;micro\u0026#39;)) print(\u0026#39;Micro f1-score\u0026#39;, f1_score(y_true, y_pred, average=\u0026#39;micro\u0026#39;)) Regression 回归 回归算法的评价指标就是MSE，RMSE，MAE、R-Squared。\nMSE和MAE适用于误差相对明显的时候，大的误差也有比较高的权重，RMSE则是针对误差不是很明显的时候；MAE是一个线性的指标，所有个体差异在平均值上均等加权，所以它更加凸显出异常值，相比MSE；\nRMSLE: 主要针对数据集中有一个特别大的异常值，这种情况下，data会被skew，RMSE会被明显拉大，这时候就需要先对数据log下，再求RMSE，这个过程就是RMSLE。对低估值（under-predicted）的判罚明显多于估值过高(over-predicted)的情况（RMSE则相反）\n","permalink":"https://jianye0428.github.io/en/posts/notes/2022-08-16_classification_and_regression_metrics/","summary":"ref: [1] https://www.cnblogs.com/rushup0930/p/13359513.html [2] https://blog.csdn.net/u013250861/article/details/123029585#t12 [3] https://blog.csdn.net/wf592523813/article/details/95202448 [4] https://zhuanlan.zhihu.com/p/69101372 classification 分类 主要涉及的知识点： 混淆矩阵、Precision(精准率)、Recall(召回率)、Accuracy(准确率)、F1-","title":"分类问题与回归问题指标综述"},{"content":"C++ STL (Standard Template Library) 总结 C++ STL 容器是使用频率超高的基础设施，只有了解各个容器的底层原理，才能得心应手地用好不同的容器，做到用最合适的容器干最合适的事情。\n本文旨在对 C++ 标准模板库的 array, vector, deque, list, forward_list, queue, priority_queue, stack, map, multimap, set, multi_set, unordered_map, unordered_multimap, unordered_set, unordered_multiset 共十六类容器进行系统的对比分析，重点关注各个容器的底层原理与性能特点。本文唯一参考资料为C++官方文档，若有其它参考则会指明出处。\n1. array Container properties: Sequence | Contiguous storage | Fixed-size aggregate\n容器属性：顺序容器（支持随机访问），连续内存空间，固定大小；//连续内存\n类模板头：template \u0026lt; class T, size_t N \u0026gt; class array;\narray 即数组，其大小固定，所有的元素严格按照内存地址线性排列，array 并不维护元素之外的任何多余数据，甚至也不会维护一个size这样的变量，这保证了它在存储性能上和C++语法中的数组符号[]无异。尽管其它大部分标准容器都可以通过 std::allocator 来动态的分配和回收内存空间，但 Array 并不支持这样做。\nArray 和其它标准容器一个很重要的不同是：对两个 array 执行 swap 操作意味着真的会对相应 range 内的元素一一置换，因此其时间花销正比于置换规模；但同时，对两个 array 执行 swap 操作不会改变两个容器各自的迭代器的依附属性，这是由 array 的 swap 操作不交换内存地址决定的。\nArray 的另一个特性是：不同于其它容器，array 可以被当作 std::tuple 使用，因为 array 的头文件重载了get()以及tuple_size()和tuple_element()函数（注意这些函数非 array 的成员函数，而是外部函数）。\n最后需要注意，虽然 array 和 C++语法中的[]符号无限接近，但两者是两个存在，array 毕竟是标准模板库的一员，是一个class，因此支持 begin(), end(), front(), back(), at(), empty(), data(), fill(), swap(), ... 等等标准接口，而[]是真正的最朴素的数组。\n2. vector Container properties: Sequence | Dynamic array | Allocator-aware\n容器属性：顺序容器（支持随机访问），动态调整大小，使用内存分配器动态管理内存；//连续内存\n类模板头：template \u0026lt; class T, class Alloc = allocator \u0026gt; class vector;\n一句话来说，vector 就是能够动态调整大小的 array。和 array 一样，vector 使用连续内存空间来保存元素，这意味着其元素可以用普通指针的++和--操作来访问；不同于 array 的是，其存储空间可以自动调整。\n在底层上，vector 使用动态分配的 array，当现有空间无法满足增长需求时，会重新分配（reallocate）一个更大的 array 并把所有元素移动过去，因此，vector 的 reallocate 是一个很耗时的处理。所以，每次 reallocate 时都会预留多余的空间，以满足潜在的增长需求，也就是说，vector的capacity()通常会大于size()。vector 什么时候做 reallocate，reallocate 多少多余空间，是有具体策略的，按下不表。总体来说，vector 比 array 多了一些内存消耗，以换取更灵活的内存管理。\n和其它的动态顺序容器（deque, list, forward_list）相比，vector 在元素访问上效率最高，在尾部增删元素的效率也相对最高。如果调用者有在尾部以外的地方增删元素的需求，vector 则不如其它容器，并且迭代器的一致性也较差（have less consistent iterators and references than lists and forward_lists）。\n3. queue 容器属性：容器适配器(adapter)，先进先出型容器（FIFO）；//C++设计模式之适配器模式\ntemplate \u0026lt;class T, class Container = deque \u0026gt; class queue;\nqueue（普通队列）是一个专为 FIFO 设计的容器适配器，也即只能从一端插入、从另一端删除；所谓容器适配器，是指它本身只是一个封装层，必须依赖指定的底层容器（通过模板参数中的class Container指定）才能实现具体功能。\n**容器适配器(Adapter)**实际上是C++设计模式的一种 \u0026ndash; 称为 Adapter 模式（适配器模式），Adapter 模式的目的是将第三方库提供的接口做一个封装和转化，使其适配自己工程中预留的接口，或者适应自己工程的调用风格。换句话说，Adapter 模式的目的是将被调用类（如第三方库）的接口转化为希望的接口。\n回到正题，queue 可以接纳任何一个至少支持下列接口的容器作为底层容器：\nempty(); size(); front(); back(); push_back(); pop_front().\n在标准模板库容器中，deque 和 list 满足上述要求，当然用户也可以自定义一个满足上述要求的容器。通过模板参数可以看出，默认情况下，queue 使用 deque 作为底层容器。\n4. deque Container properties: Sequence | Dynamic array | Allocator-aware\n容器属性：顺序容器（支持随机访问），动态调整大小，使用内存分配器动态管理内存；//分段连续内存\n类模板头：template \u0026lt; class T, class Alloc = allocator \u0026gt; class deque;\ndeque（读作\u0026quot;deck\u0026quot;）是 double-ended queue 的缩写，是一个可以在首尾两端进行动态增删的顺序容器。\n不同的库对 deque 的实现可能不同，但大体上都是某种形式的动态 array，且都支持随机访问。deque 的功能和 vector 比较接近，但 deque 额外支持在头部动态增删元素。和 vector 不一样的是，deque 不保证存储区域一定是连续的! 因此用指向元素的普通指针做++和--操作是非常危险的行为。\n从底层机理上能更透彻地理解 deque 的特点：vector 使用的是单一的 array，deque 则会使用很多个离散的 array 来组织数据「the elements of a deque can be scattered in different chunks of storage」！如果说 vector 是连续的，deque 则是分段连续。deque 会维护不同 array 之间的关联信息，使用户无需关心分段这个事实。这样做的好处是很明显的：deque 在 reallocate 时，只需新增/释放两端的 storage chunk 即可，无需移动已有数据（vector 的弊端），极大提升了效率，尤其在数据规模很大时，优势明显。\n相比于 vector 和 list，deque 并不适合遍历！因为每次访问元素时，deque 底层都要检查是否触达了内存片段的边界，造成了额外的开销！deque 的核心优势是在双端都支持高效的增删操作，程序员选择使用 deque 时需要有双端操作的明确理由。\n5. priority_queue 容器属性：容器适配器，严格弱序（Strict Weak Ordering），优先级队列；\ntemplate \u0026lt;class T, class Container = vector,\nclass Compare = less \u0026gt; class priority_queue;\n和 queue 类似，priority_queue（术语叫作优先级队列）也只是一个容器适配器，需要指定底层容器才能实例化，参见模板参数中的class Container形参。priority_queue 的核心特点在于其严格弱序特性（strict weak ordering）：也即 priority_queue 保证容器中的第一个元素始终是所有元素中最大的！为此，用户在实例化一个 priority_queue 时，必须为元素类型（class T）重载\u0026lt;运算符，以用于元素排序！\npriority_queue 的原理可以用一个大顶堆来解释：priority_queue 在内部维护一个基于二叉树的大顶堆数据结构，在这个数据结构中，最大的元素始终位于堆顶部，且只有堆顶部的元素（max heap element）才能被访问和获取，大顶堆的具体原理可参见任何一本数据结构书籍。\n为了支持这种工作原理，priority_queue 对底层容器也是有要求的，priority_queue 的底层容器必须支持随机访问和至少以下接口：\nempty(); size(); front(); push_back(); pop_back().\n标准模板库中的 vector 和 deque 能够满足上述需求，默认情况下，priority_queue 使用 vector 作为底层容器。\n某种程度上来说，priority_queue 默认在 vector 上使用堆算法将 vector 中元素构造成大顶堆的结构，因此 priority_queue 就是堆 ，所有需要用到堆的位置，都可以考虑使用 priority_queue。priority_queue 默认是大顶堆，用户也可以通过自定义模板参数中的 class Compare 来实现一个小顶堆。\n相比于 queue（普通队列）的先进先出FIFO，priority_queue 实现了最高优先级先出。\n6. list Container properties: Sequence | Doubly-linked list | Allocator-aware\n容器属性：顺序容器（可顺序访问，但不支持随机访问），双链表，使用内存分配器动态管理内存；//离散内存\n类模板头：template \u0026lt; class T, class Alloc = allocator \u0026gt; class list;\nlist 是一种支持在任意位置都可以快速地插入和删除元素的容器，且支持双向遍历。list 容器能够做到这些的原因在于其底层结构是双链表，双链表允许把各个元素都保存在彼此不相干的内存地址上，但每个元素都会与前后相邻元素关联。\n和其它的顺序容器（array, vector, deque）相比，list 的最大优势在于支持在任意位置插入、删除和移动元素，对 list 来说，在哪个位置进行操作并没有区别。list 在部分算法（如 sorting）中的效率可能优于其它顺序容器。\nlist 的主要缺点是不支持元素的随机访问！如果我们想要访问某个元素，则必须从一个已知元素（如 begin 或 end）开始朝一个方向遍历，直至到达要访问的元素。此外，list 还要消耗更多的内存空间，用于保存各个元素的关联信息。\n[另说] list 对内存空间的使用效率并不高，一方面元素内存地址是离散的而非连续，另一方面，list 需要保存额外的关联信息。\n7. forward_list Container properties: Sequence | Linked list | Allocator-aware\n容器属性：顺序容器（可顺序访问，但不支持随机访问），单链表，使用内存分配器动态管理内存；\n类模板头：template \u0026lt; class T, class Alloc = allocator \u0026gt; class list;\nforward_list 也是一种支持在任意位置快速插入和删除元素的容器，forward_list 相比于 list 的核心区别是它是一个单链表，因此, 每个元素只会与相邻的下一个元素关联！由于关联信息少了一半，因此 forward_list 占用的内存空间更小，且插入和删除的效率稍稍高于 list。作为代价，forward_list 只能单向遍历。\n相比于其它顺序容器（array, vector, deque），forward_list 的优缺点和 list 基本相同。\n既然已经有了 list，为什么 C++ STL 又设计了 forward_list 这一容器呢？设计 forward_list 的目的是为了达到不输于任何一个C风格手写链表的极值效率！为此，forward_list 是一个最小链表设计，它甚至没有size()接口，因为内部维护一个size变量会降低增删元素的效率。如果想要获取 forward_list 的 size，一个通常的做法是，用 std::distance 计算 begin 到 end 的距离得出 size。一句话总结：list 兼顾了接口丰富性牺牲了效率，而 forward_list 舍弃了不必要的接口只为追求极致效率。\n8. stack 容器属性：容器适配器，后进先出型容器（LIFO）；\ntemplate \u0026lt;class T, class Container = deque \u0026gt; class stack;\nstack（栈）是一个专为 LIFO 设计的容器适配器，也即只能从一端插入和删除；作为适配器，需要指定底层容器才能实例化，参见模板参数中的class Container形参。\nstack 的特点是后进先出（一端进出），不允许遍历；任何时候外界只能访问 stack 顶部的元素；只有在移除 stack 顶部的元素后，才能访问下方的元素。stack 需要底层容器能够在一端增删元素，这一端也即 stack 的“栈顶”；stack 可以接纳任何一个至少支持下列接口的容器作为底层容器：\nempty(); size(); back(); push_back(); pop_back()\n在标准模板库容器中，vector、deque 和 list 满足上述要求，当然用户也可以自定义一个满足上述要求的容器。通过模板参数可以看出，默认情况下，stack 使用 deque 作为底层容器。\nstack 容器应用广泛，例如，编辑器中的 undo （撤销操作）机制就是用栈来记录连续的操作。stack 的设计场景和自助餐馆中堆叠的盘子、摞起来的一堆书类似。\n9. map Container properties: Associative | Ordered | Map | Unique keys | Allocator-aware\n容器属性：关联容器，有序，元素类型\u0026lt;key, value\u0026gt;，key是唯一的，使用内存分配器动态管理内存 ；\ntemplate \u0026lt; class Key, // map::key_type\nclass T, // map::mapped_type\nclass Compare = less, // map::key_compare\nclass Alloc = allocator\u0026lt;pair\u0026lt;const Key,T\u0026gt; \u0026gt; // map::allocator_type\nclass map;\nmap 是一个关联型容器，其元素类型是由 key 和 value 组成的 std::pair，实际上 map 中元素的数据类型正是 typedef pair\u0026lt;const Key, T\u0026gt; value_type;，这就看的很清楚了。\n所谓关联容器，是指对所有元素的检索都是通过元素的 key 进行的（而非元素的内存地址），map 通过底层的「红黑树」数据结构来将所有的元素按照 key 的相对大小进行排序，所实现的排序效果也是严格弱序特性（strict weak ordering），为此，开发者需要重载 key 的\u0026lt;运算符或者模板参数中的 class Compare。所提到的红黑树是一种自平衡二叉搜索树，它衍生自B树，这里推荐两篇文章（记一次腾讯面试：有了二叉查找树、平衡树（AVL）为啥还需要红黑树？，图解：什么是红黑树？）作为更深入的参考。\n大体来说，map 访问元素的速度要稍慢于下文的 unordered_map，这是因为虽然都叫“map”，但两者的底层机制完全不一样。但是，相比于后者，map 支持在一个子集合上进行直接迭代器访问，原因在于 map 中的元素是被有序组织的。\n最后，map 也支持通过operator[]的方式来直接访问 value。\n10. multimap Container properties: Associative | Ordered | Map | Multiple equivalent keys | Allocator-aware\n容器属性: 关联容器，有序，元素类型\u0026lt;key, value\u0026gt;，允许不同元素key相同，使用内存分配器管理内存；\ntemplate \u0026lt; class Key, // map::key_type\nclass T, // map::mapped_type\nclass Compare = less, // map::key_compare\nclass Alloc = allocator\u0026lt;pair\u0026lt;const Key,T\u0026gt; \u0026gt; // map::allocator_type\nclass map;\nmap 中不允许出现 key 相同的两个元素，但 multimap 则可以这样做！\nmultimap 与 map 底层原理完全一样，都是使用「红黑树」对元素数据按 key 的比较关系，进行快速的插入、删除和检索操作；所不同的是 multimap 允许将具有相同 key 的不同元素插入容器（这个不同体现了 multimap 对红黑树的使用方式的差异）。在 multimap 容器中，元素的 key 与元素 value 的映射关系，是一对多的，因此，multimap 是多重映射容器。\n注意，在向 multimap 中新增元素时，multimap 只会判断 key 是否相同，而完全不会判断 value 是否相同！这意味着如果相同的 \u0026lt;key, value\u0026gt; 插入了多次，multimap 会对它们悉数保存！\n在使用中，我们可以通过迭代器配合 lower_bound() 和 upper_bound() 来访问一个 key 对应的所有 value，也可以使用equal_range()来访问一个 key 对应的所有 value，也可以通过find()配合count()来访问一个 key 对应的所有 value，个人认为前两种方法使用起来更方便一点。\n下文中将要提到的 multiset 之于 set 类似于这里的 multimap 之于 map。\n11. set Container properties: Associative | Ordered | Set | Unique keys | Allocator-aware\n容器属性：关联容器，有序，元素自身即key，元素有唯一性，使用内存分配器动态管理内存；\ntemplate \u0026lt; class T, // set::key_type/value_type\nclass Compare = less, // set::key_compare/value_compare\nclass Alloc = allocator // set::allocator_type\nclass set;\nset 是一个关联型容器，和 map 一样，它的底层结构是「红黑树」，但和 map 不一样的是，set 是直接保存 value 的，或者说，set 中的 value 就是 key。\nset 中的元素必须是唯一的，不允许出现重复的元素，且元素不可更改，但可以自由插入或者删除。\n由于底层是红黑树，所以 set 中的元素也是严格弱序（strict weak ordering）排序的，因此支持用迭代器做范围访问（迭代器自加自减）。\n实际使用中，set 和 map 是近亲，性能相似，他们的差别是元素的 value 本身是否也作为 key 来标识自己。\n12. multi_set Container properties: Associative | Ordered | Set | Multiple equivalent keys | Allocator-aware\n容器属性：关联容器，有序，元素自身即key，允许不同元素值相同，使用内存分配器动态管理内存 ；\ntemplate \u0026lt; class T, // multiset::key_type/value_type\nclass Compare = less, // multiset::key_compare/value_compare\nclass Alloc = allocator \u0026gt; // multiset::allocator_type\nclass multiset;\nmultiset 之于 set 就如同 multimap 之于 map：\nmultiset 和 set 底层都是红黑树，multiset 相比于 set 支持保存多个相同的元素；\nmultimap 和 map 底层都是红黑树，multimap 相比于 map 支持保存多个key相同的元素。\n鉴于以上近亲关系，multiset 的性能特点与其它三者相似，不再赘述。\n13. unordered_map Container properties: Associative | Unordered | Map | Unique keys | Allocator-aware\n容器属性：关联容器，无序，元素类型\u0026lt;key, value\u0026gt;，key是唯一的，使用内存分配器动态管理内存 ； template \u0026lt; class Key, // unordered_map::key_type\nclass T, // unordered_map::mapped_type class Hash = hash, // unordered_map::hasher\nclass Pred = equal_to, // unordered_map::key_equal\nclass Alloc = allocator\u0026lt; pair\u0026lt;const Key,T\u0026gt; \u0026gt; // unordered_map::allocator_type\nclass unordered_map;\nunordered_map 和 map 一样，都是关联容器，以键值对儿 \u0026lt;key, value\u0026gt; 作为元素进行存储；但是，除此之外，两者可以说是完全不一样！\n这是由底层的数据结构决定的，map 以红黑树作为底层结构组织数据，而 unordered_map 以哈希表(hash table)作为底层数据结构来组织数据，这造成了两点重要影响：\n1. unordered_map 不支持排序，在使用迭代器做范围访问时（迭代器自加自减）效率更低；\n2. 但 unordered_map 直接访问元素的速度更快（尤其在规模很大时），因为它通过直接计算 key 的哈希值来访问元素，是O(1)复杂度！\n网络上有对 map VS unordered_map 效率对比的测试，通常 map 增删元素的效率更高，unordered_map 访问元素的效率更高，可以参见这篇文章。另外，unordered_map 内存占用更高，因为底层的哈希表需要预分配足量的空间。\n综上，unordered_map 更适用于增删操作不多，但需要频繁访问，且内存资源充足的场合。\n比如在机器人领域的SLAM技术中，可以选择 unordered_map 来维护体素形式的 local map？ 当然 deque 应该也是不错的选择。\n14. unordered_multimap Container properties: Associative | Unordered | Map | Multiple equivalent keys | Allocator-aware\n容器属性：关联容器，无序，元素类型\u0026lt;key, value\u0026gt;，允许不同元素key相同，使用内存分配器管理内存 ；\ntemplate \u0026lt; class Key, // unordered_multimap::key_type\nclass T, // unordered_multimap::mapped_type\nclass Hash = hash, // unordered_multimap::hasher\nclass Pred = equal_to, // unordered_multimap::key_equal\nclass Alloc = allocator\u0026lt; pair\u0026lt;const Key,T\u0026gt; \u0026gt; // unordered_multimap::allocator_type\nclass unordered_multimap;\nunordered_multimap 是对 unordered_map 的拓展，唯一区别在于 unordered_multimap 允许不同元素的 key 相同，但两者无论是在底层结构还是在容器特性上都是相通的，仅仅是对底层哈希表的使用方式稍有不同。\n在 unordered_multimap 中想要访问同一个 key 下对应的所有元素的话，可以使用equal_range()轻松做到；当然，也可以使用find()和count()配合的方式来访问。\nunordered_multimap 的容器特性参见 unordered_map，不再赘述。\n15. unordered_set Container properties: Associative | Unordered | Set | Unique keys | Allocator-aware\n容器属性：关联容器，无序，元素自身即key，元素有唯一性，使用内存分配器动态管理内存 ；\ntemplate \u0026lt; class Key, // unordered_set::key_type/value_type\nclass Hash = hash, // unordered_set::hasher\nclass Pred = equal_to, // unordered_set::key_equal\nclass Alloc = allocator // unordered_set::allocator_type\nclass unordered_set;\n所有unordered_XXX类容器的特点都是以哈希表作为底层结构；所有 XXX_set 类容器的特点都是「元素自身也作为key」来标识自己。我们在把两类特性叠加到一起，就得到了 unordered_set。\n在 unordered_set 中，元素自身同时也作为 key 使用；既然是作为 key 使用，那么元素就不能被更改，也即 unordered_set 中的元素都是 constant 的，但我们可以自由的插入和删除元素，这也是所有XXX_set类容器的性质。既然底层结构是哈希表，意味着 unordered_set 中的元素是无序的，不能按照大小排序，这也是所有unordered_XXX类容器的性质。\n和所有的unordered_XXX类容器一样： 1. unordered_set 直接用迭代器做范围访问时（迭代器自加自减）效率更低，低于 set； 2. 但 unordered_set 直接访问元素的速度更快（尤其在规模很大时），因为它通过直接计算 key 的哈希值来访问元素，是O(1)复杂度！\n16. unordered_multiset Container properties: Associative | Unordered | Set | Multiple equivalent keys | Allocator-aware 容器属性：关联容器，无序，元素自身即key，允许不同元素值相同，使用内存分配器动态管理内存 ； template \u0026lt; class Key, // unordered_multiset::key_type/value_type class Hash = hash, // unordered_multiset::hasher class Pred = equal_to, // unordered_multiset::key_equal class Alloc = allocator // unordered_multiset::allocator_type class unordered_multiset;\nunordered_multiset，顾名思义，就是集齐了“哈希表为底层结构”，“元素自身即key”，“允许不同元素值相同”这三个特性的容器，是对 unordered_set 的简单拓展。\nunordered_multiset 的效率特性与所有基于哈希表的容器相似，参见 unordered_set，不再赘述。\n17. pair \u0026amp;\u0026amp; tuple template \u0026lt;class\u0026hellip; Types\u0026gt; class tuple;\ntemplate \u0026lt;class T1, class T2\u0026gt; struct pair;\nstd::pair 和 std::tuple 并不是stl容器库中的容器，不过鉴于经常用到，就顺便整理一下。先从 tuple 说起，pair 相当于 tuple 的特例。\ntuple 叫作元组，它可以把一组类型相同或不同的元素组合到一起，且元素的数量不限。tuple 的底层原理与 stl 中的容器完全不同，但在功能上，tuple 是对容器的有效补充，因为所有的容器都只能组合相同类型的元素，但tuple 可以组合任意不同类型的元素。在使用上，可以用std::make_tuple()来构造 tuple 对象，可以用std::get()来获取 tuple 对象的某个元素，注意std::get()返回的是 tuple 对象中某个元素的索引，因此是可以用作左值的！此外，也可以用std::tie()打包一组变量来作为左值接受 tuple 对象的赋值。\ntuple 的底层原理大概是一个层层继承的类，详情可以参考这篇文章，写的非常透彻。\npair 可以看作是把 tuple 的 size 限制为 2 的一个特例，pair 只能把一对儿元素组合到一起。在使用上，可以用std::make_pair()来直接构建 pair 对象，可以用std::get\u0026lt;0\u0026gt;()和std::get\u0026lt;1\u0026gt;()来分别获取 pair 对象的两个元素，但更方便的做法是直接访问 pair 类型的两个数据成员pair对象.first和pair对象.second来访问元素\nreference:\n[1]. https://zhuanlan.zhihu.com/p/542115773\n","permalink":"https://jianye0428.github.io/en/posts/tech/2022-08-01_c++_data_structure/","summary":"C++ STL (Standard Template Library) 总结 C++ STL 容器是使用频率超高的基础设施，只有了解各个容器的底层原理，才能得心应手地用好不同的容器，做到用最合适的容器干最合适的事情。","title":"C++ STL (Standard Template Library) Containers"},{"content":"Horovod 介绍 Horovod 是 Uber 开源的深度学习工具，它的发展吸取了Facebook \u0026ldquo;Training ImageNet In 1 Hour\u0026rdquo; 与百度 \u0026ldquo;Ring Allreduce\u0026rdquo; 的优点，在保证分布式训练性能的同时，兼顾了前端的简洁和对不同深度学习框架的支持，使用起来对开发人员比较的友好，算是分布式训练方向的标杆项目了。\n集合通信库 集合通信库，这个词可能听起来会比较的陌生，不过如果我再提几个关键字，可能大家多少都会有所耳闻。资历比较老的是 MPI (Message Passing Interface 及其实现 OpenMPI 和 MPICH，年轻一点的会是 Nvidia 针对其显卡开源的 NCCL，或者是 facebook 开源的 gloo，或者是像华为针对其高性能硬件提供的HCCL，大体上都可以归入到集合通信库的类别。他们相同的地方是大体上会遵照 MPI 提供的接口规定，实现了包括点对点通信（SEND,RECV等），集合通信（ REDUCE，BROADCAST，ALLREDUCE等）等相关接口，然后根据自己硬件或者是系统的需要，在底层实现上进行了相应的改动，保证接口的稳定和性能。\n点对点通信: Point-to-Point Communication Send/Recv:\n集合通信 Scatter/Gather\nreduce/allreduce\nboradcast/all-gather\n这里在机器学习训练中使用比较多的是 all-reduce，场景类似在不同的 node 上跑不同 batch 的数据，然后更新梯度需要从各个汇总之后平均再回传到各自的 node 中。而这部分，有很多种实现的方式，比较直观和简单的是把所有的梯度都汇总到的某一个 node 上（如下图 node d 所示），然后再把汇总的信息重新分发到不同的 node 上 ，这样可以计算通信量，如下：对于 P 个节点，每个节点消息大小为 M，node d 节点的通信量为 2*(P-1)M，这里假设节点之间互联互通，带宽为B。\n不过这种情况下，很容易导致 node d 会成为性能瓶颈，因为 node d 需要跟其他所有 node 通信所以它的通信量是其他节点的 P 倍。假设节点间的带宽还是一样，node d 完成所有通信所需要的时间是 2(P-1)M/B*。所以现在很多的集合通信框架不会使用这种方式，更多的是通过树状或者是环状(ring) 去实现 all-reduce。\n如果只是做成树状的可以做成如下图所示，虽然传递的步数增多了，不过消除了node d 的通信瓶颈，完成所有的通信的时间大概是 2log_2N(M/B)*，随着节点数目 P 的增加，树形结构的效果会越来越明显。\n业界用得最多一种优化的方式是，每次只传一部分，这部分是百度提出的 ring-allreduce 的方案，具体的介绍可以参考这篇博客Bringing HPC Techniques to Deep Learning，这边就不赘述了。整体上就是每次不会像上面这样整份数据传递，而是一部分一部分传，优化后，所有节点需要传输的数据量的传输 2(N−1)M/N 比较平均，所需要的时间可以大概是 2(N−1)M/(NB)，horovod 也是基于这种 all-reduce 的形式实现的。\n实践: pytorch.distributed 尝试使用 pytorch 自带的分布式工具包 torch.distributed，进行一些概念性的尝试。\n为了方便尝试，我这里提供了一个简单的 demo，大家如果安装了 gpu 版本的 pytorch \u0026gt;= 1.3，应该都可以尝试下面的例子尝试使用多进程模拟分布式（单机上可以跑）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 import os import torch import torch.distributed as dist import time import argparse from torch.multiprocessing import Process parser = argparse.ArgumentParser(description=\u0026#39;PyTorch MNIST Example\u0026#39;) parser.add_argument(\u0026#39;-m\u0026#39;, \u0026#39;--mode\u0026#39;, type=str, default=\u0026#39;one_device\u0026#39;, metavar=\u0026#39;N\u0026#39;, help=\u0026#39;distribute mode, distributed/one_device\u0026#39;) parser.add_argument(\u0026#39;-f\u0026#39;, \u0026#39;--function\u0026#39;, type=str, default=\u0026#39;p2p\u0026#39;, metavar=\u0026#39;N\u0026#39;, help=\u0026#39;function to run (p2p/all_reduce/gpu_all_reduce)\u0026#39;) parser.add_argument(\u0026#39;-b\u0026#39;, \u0026#39;--backend\u0026#39;, type=str, default=\u0026#34;nccl\u0026#34;, metavar=\u0026#39;N\u0026#39;, help=\u0026#39;distribute backend (gloo/nccl)\u0026#39;) def init_process(rank, size, fn, backend=\u0026#39;nccl\u0026#39;): \u0026#34;\u0026#34;\u0026#34; Initialize the distributed environment. \u0026#34;\u0026#34;\u0026#34; os.environ[\u0026#39;MASTER_ADDR\u0026#39;] = \u0026#39;127.0.0.1\u0026#39; os.environ[\u0026#39;MASTER_PORT\u0026#39;] = \u0026#39;29500\u0026#39; dist.init_process_group(backend, rank=rank, world_size=size) fn(rank, size) def run(rank, size): tensor = torch.zeros(1) print(\u0026#39;Rank \u0026#39;, rank, \u0026#39; has data before send/recv\u0026#39;, tensor) if rank == 0: tensor += 1 # Send the tensor to process 1 dist.send(tensor=tensor, dst=1) else: # Receive tensor from process 0 dist.recv(tensor=tensor, src=0) print(\u0026#39;Rank \u0026#39;, rank, \u0026#39; has data after send/recv\u0026#39;, tensor) def run_allreduce(rank, size): \u0026#34;\u0026#34;\u0026#34; Simple reduce communication. \u0026#34;\u0026#34;\u0026#34; group = dist.new_group([0, 1]) device = torch.device(\u0026#39;cuda:%d\u0026#39; % rank) tensor = torch.ones(1).to(device) dist.all_reduce(tensor, op=dist.ReduceOp.SUM, group=group) print(\u0026#39;Rank \u0026#39;, rank, \u0026#39; has data \u0026#39;, tensor[0]) def run_multigpu_allreduce(rank, size): group = dist.new_group([0, 1]) tensor_list = [] for dev_idx in range(2): device = torch.device(\u0026#39;cuda:%d\u0026#39; % (2 * rank + dev_idx)) tensor = torch.ones(1).to(device) tensor_list.append(tensor) dist.all_reduce_multigpu(tensor_list) print(\u0026#39;all_reduce_multigpu\u0026#39;, tensor_list) dist.all_reduce(tensor_list[0], op=dist.ReduceOp.SUM, group=group) print(\u0026#39;Rank \u0026#39;, rank, \u0026#39; has data tensor[0]:\u0026#39;, tensor_list[0], \u0026#34;, tensor[1]:\u0026#34;, tensor_list[1]) if __name__ == \u0026#34;__main__\u0026#34;: args = parser.parse_args() backend = args.backend if args.mode == \u0026#34;distributed\u0026#34; or os.environ.get(\u0026#39;RANK\u0026#39;,None): print(\u0026#34;in distribute mode\u0026#34;) if args.function == \u0026#34;all_reduce\u0026#34;: function, size = run_allreduce, 2 elif args.function == \u0026#34;gpu_all_reduce\u0026#34;: function, size = run_multigpu_allreduce, 2 else: function, size, backend = run, 2, \u0026#34;gloo\u0026#34; rank = int(os.environ[\u0026#39;RANK\u0026#39;]) p = Process(target=init_process, args=(rank, size, function, backend)) p.start() p.join() else: print(\u0026#34;in one device mode\u0026#34;) if args.function == \u0026#34;all_reduce\u0026#34;: function, size = run_allreduce, 2 elif args.function == \u0026#34;gpu_all_reduce\u0026#34;: function, size = run_multigpu_allreduce, 2 else: function, size, backend = run, 2, \u0026#34;gloo\u0026#34; processes = [] for rank in range(size): p = Process(target=init_process, args=(rank, size, function, backend)) p.start() processes.append(p) for p in processes: p.join() 可以简单地运行上面的例子：\nsend/recv:\n1 2 3 4 5 6 7 8 $ python3 distribute_test.py # 输出如下： in one device mode Rank 0 has data before send/recv tensor([0.]) Rank 1 has data before send/recv tensor([0.]) Rank 0 has data after send/recv tensor([1.]) Rank 1 has data after send/recv tensor([1.]) 上面是演示的是通过 pytorch 的 multiprocessing 包，模拟一次分布式的 send/recv 过程，这里是 rank0 的进程往 rank1 的进程发送一个 tensor，可以看到 rank 1 tensor 初始化为 0，是接收到 rank 0 的tensor 后变为 1 的。（注意：这里特别设置了 backend 为 gloo 是因为 nccl 不支持 point2point 的传输，具体不同 backend 支持什么形式的原语，参考文档backend部分 ）\nall_reduce\n1 2 3 4 5 6 7 8 9 10 11 12 13 $ python3 distribute_test.py -f all_reduce # 输出如下： in one device mode Rank 0 has data tensor(2., device=\u0026#39;cuda:0\u0026#39;) Rank 1 has data tensor(2., device=\u0026#39;cuda:1\u0026#39;) # 对应函数 def run_allreduce(rank, size): \u0026#34;\u0026#34;\u0026#34; Simple reduce communication. \u0026#34;\u0026#34;\u0026#34; group = dist.new_group([0, 1]) # use rank 0 and rank 1 device = torch.device(\u0026#39;cuda:%d\u0026#39; % rank) tensor = torch.ones(1).to(device) dist.all_reduce(tensor, op=dist.ReduceOp.SUM, group=group) print(\u0026#39;Rank \u0026#39;, rank, \u0026#39; has data \u0026#39;, tensor[0]) 这里也很浅白，主要就是对两个进程上的 tensor 进行一次 allreduce，可以看到两个 rank 上的结果都为 2了。\ngpu_all_reduce\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 $ python3 distribute_test.py -f gpu_all_reduce # 输出如下： #in one device mode # [tensor([1.], device=\u0026#39;cuda:0\u0026#39;)] # [tensor([1.], device=\u0026#39;cuda:2\u0026#39;)] # [tensor([1.], device=\u0026#39;cuda:2\u0026#39;), tensor([1.], device=\u0026#39;cuda:3\u0026#39;)] # [tensor([1.], device=\u0026#39;cuda:0\u0026#39;), tensor([1.], device=\u0026#39;cuda:1\u0026#39;)] #all_reduce_multigpu [tensor([4.], device=\u0026#39;cuda:2\u0026#39;), tensor([4.], device=\u0026#39;cuda:3\u0026#39;)] #all_reduce_multigpu [tensor([4.], device=\u0026#39;cuda:0\u0026#39;), tensor([4.], device=\u0026#39;cuda:1\u0026#39;)] #Rank 0 has data tensor[0]: tensor([8.], device=\u0026#39;cuda:0\u0026#39;) , tensor[1]: tensor([4.], device=\u0026#39;cuda:1\u0026#39;) #Rank 1 has data tensor[0]: tensor([8.], device=\u0026#39;cuda:2\u0026#39;) , tensor[1]: tensor([4.], device=\u0026#39;cuda:3\u0026#39;) # 对应函数 def run_multigpu_allreduce(rank, size): group = dist.new_group([0, 1]) tensor_list = [] for dev_idx in range(2): device = torch.device(\u0026#39;cuda:%d\u0026#39; % (2 * rank + dev_idx)) tensor = torch.ones(1).to(device) tensor_list.append(tensor) print(tensor_list) dist.all_reduce_multigpu(tensor_list) print(\u0026#39;all_reduce_multigpu\u0026#39;, tensor_list) dist.all_reduce(tensor_list[0], op=dist.ReduceOp.SUM, group=group) print(\u0026#39;Rank \u0026#39;, rank, \u0026#39; has data tensor[0]:\u0026#39;, tensor_list[0], \u0026#34;, tensor[1]:\u0026#34;, tensor_list[1]) all_reduce_multigpu: 相当于将多个gpu内的多进程的值进行相加; all_reduce: 相当于单个gpu内的多进程的值相加\n这里演示的是尝试对不同进程下多个 gpu (这里是 4 个) 进行 reduce，具体逻辑就是：\n- 对不同的进程分别把 tensor 初始化在不同的 gpu 上，rank0 初始化在 0，1 gpu 上，rank 1 在 2，3上。 - 进行一次 all_reduce_multigpu （这个函数跟 all_reduce 不同，是把不同的 node 上不同的gpu 上的tensor 都放到一个 list 中，进行reduce），这时所有 gpu 上的值都是4，作为对比，我们对 tensor_list[0] 的tensor 做一次all_reduce，得到的结果在 gpu 0,2 上的 tensor 进行了all_reduce 结果是 8，在 gpu 1,3 的 tensor 没有任何变化。 多terminal尝试\n在验证分布式逻辑的时候，其实我们不一定需要多台机子才可以，对一些不涉及网络性能的验证，可以尝试在一台机子上开多个 terminal 进行验证。可以使用上面的例子，在多个 terminal 下跑以下命令。\nterminal0:\n1 2 3 4 5 RANK=0 python3 distribute_test.py -f gpu_all_reduce # 输出如下 in distribute mode all_reduce_multigpu [tensor([4.], device=\u0026#39;cuda:0\u0026#39;), tensor([4.], device=\u0026#39;cuda:1\u0026#39;)] Rank 0 has data tensor[0]: tensor([8.], device=\u0026#39;cuda:0\u0026#39;) , tensor[1]: tensor([4.], device=\u0026#39;cuda:1\u0026#39;) terminal1:\n1 2 3 4 5 RANK=1 python3 distribute_test.py -f gpu_all_reduce # 输出如下 in distribute mode all_reduce_multigpu [tensor([4.], device=\u0026#39;cuda:2\u0026#39;), tensor([4.], device=\u0026#39;cuda:3\u0026#39;)] Rank 1 has data tensor[0]: tensor([8.], device=\u0026#39;cuda:2\u0026#39;) , tensor[1]: tensor([4.], device=\u0026#39;cuda:3\u0026#39;) 这里是通过本地机子上的回送地址进行模拟，结果是分别在不同的 terminal 呈现，当然可以用上面的demo，在多台机子上跑，不过需要修改一下 init_process 函数中的 os.environ[\u0026lsquo;MASTER_ADDR\u0026rsquo;] = \u0026lsquo;127.0.0.1\u0026rsquo; 为 rank 0 机子的 IP，这里就不演示了。具体 pytorch distributed 工具相关的内容可以参考官方博客\n练习： 如果大概理解了上面的一些集合通信的原语，可以尝试着用上面 pytorch 提供的 send/recv 尝试去实现一下上面的树状 allreduce。\nMPI 更深入的尝试，可以尝试了解一下 mpi 的知识，这个mpi教程 算是写得比较系统的，大家可以参考一下来练习，特别是对底层不是很了解的同学，可以多看看 Running an MPI cluster within a LAN 的部分，实操一下通过 ssh 跑起一个分布式的 demo。集合通信库的基础大概先到这里，如果要深入的可以再去看看 openMPI，和 nccl 的实现。\nHorovod流程分析 下面我会以一个简单的 pytorch horovod 的 demo 尝试去理解一下 horovod 的工作机理，demo 如下（省略了一些不关键的代码段）。为了准确起见，我们是根据 horovod v0.20.3 的版本进行阅读的，如果是其他版本，可能会跟这里的内容有一些出入。\npytorch demo 一般的 horovod 训练程序都会包含以下几个关键步骤：\n1. hvd.init: 对 horovod 2. 初始化。初始化模型，数据集，优化器，初始化不同 node 的模型权重。 3. 使用 hvd.DistributedOptimizer 包装优化器。 4. 进入训练流程，进行优化迭代。 我们会着重介绍第 1 和 4 步，因为主要也是1，4步会跟 c++ 后端进行信息交换。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 import torch.backends.cudnn as cudnn import torch.nn.functional as F import torch.optim as optim import torch.utils.data.distributed from torchvision import models import horovod.torch as hvd import timeit import numpy as np ... # some argparse hvd.init() # Set up standard model. model = getattr(models, args.model)() optimizer = optim.SGD(model.parameters(), lr=0.01 * lr_scaler) # Horovod: (optional) compression algorithm. compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none # Horovod: wrap optimizer with DistributedOptimizer. optimizer = hvd.DistributedOptimizer(optimizer, named_parameters=model.named_parameters(), compression=compression, op=hvd.Adasum if args.use_adasum else hvd.Average) # Horovod: broadcast parameters \u0026amp; optimizer state. hvd.broadcast_parameters(model.state_dict(), root_rank=0) hvd.broadcast_optimizer_state(optimizer, root_rank=0) # Set up fixed fake data data = torch.randn(args.batch_size, 3, 224, 224) target = torch.LongTensor(args.batch_size).random_() % 1000 if args.cuda: data, target = data.cuda(), target.cuda() def benchmark_step(): optimizer.zero_grad() output = model(data) loss = F.cross_entropy(output, target) loss.backward() optimizer.step() #... some log configuration img_secs = [] for x in range(args.num_iters): time = timeit.timeit(benchmark_step, number=args.num_batches_per_iter) img_sec = args.batch_size * args.num_batches_per_iter / time img_secs.append(img_sec) # Results ... 然后下图是我对 horovod 整体流程的梳理，把一些不是很关键的部分隐藏了，可能有一些细节的地方和实现有出入，不过我待会会有详细的说明。这里先解释一下，下面几个大的部分:\nmain.py： 表示训练脚本，一般是 使用 horovod 提供的函数跟特定的训练框架相互合作完成分布式训练（下文称前端） C++ interface：是指 horovod python 函数调用 C++ 的接口 GlobalState：在 horovod 中是一个全局变量，其中的元素可以供不同的线程访问，在加载 C++ 的代码时候就已经创建了，同时创建的还有各种 context（mpi_context, nccl_context, gpu_context）后面会提到，主要会在下图 backgroundThreadLoop 中完成 globalstate 不同元素初始化，比较重要的有 controller 管理总体通信控制流，tensor_queue 会处理从前端过来的通信需求（allreduce，broadcast 等）。 BackgroundThreadLoop：是训练过程中的后台线程，主要负责跟其他节点的通信，和处理前端过来的通信需求（request），会轮询调用 RunLoopOnce，不断查看 tensor_queue 中有没有需要通信的tensor，如果有跟其他节点同步更新，然后执行通信操作。 流程分析 下面使用 mpi_controller 进行 allreduce 操作进行分析。\n1.hvd.init()-\u0026gt;InitializeHorovodOnce\n首先，hvd.init() 会通过一系列的调用和配置最终调用 horovod/common/http://operations.cc 下的 InitializeHorovodOnce 函数，这个函数会根据加载的集合通讯库（mpi 或者 gloo）为 globalstate 创建对应的 controller，然后使用 BackgroundThreadLoop 启动一个后台线程。\nhorovod/common/http://operations.cc #628\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 void InitializeHorovodOnce(const int* ranks, int nranks) { // ... some envParse #if HAVE_MPI // Enable mpi is it\u0026#39;s used either i[n cpu data transfer or controller if (horovod_global.cpu_operation == LibType::MPI || horovod_global.control_operation == LibType::MPI) { mpi_context.Enable(); } // 创建一个 MPIController 对象 if (horovod_global.control_operation == LibType::MPI){ horovod_global.controller.reset(new MPIController( horovod_global.response_cache, horovod_global.tensor_queue, horovod_global.timeline, horovod_global.parameter_manager, mpi_context)); horovod_global.controller-\u0026gt;SetRanks(ranks, nranks); } #endif #if HAVE_GLOO //... #endif // Reset initialization flag horovod_global.initialization_done = false; // 启动后台线程 horovod_global.background_thread = std::thread( BackgroundThreadLoop, std::ref(horovod_global)); } while (!horovod_global.initialization_done) { std::this_thread::sleep_for(std::chrono::milliseconds(1)); } } 2.BackgroundThreadLoop\nBackgroundThreadLoop 会为 GlobalState 初始化一系列包括初始化 mpi_context， controller的元素，然后轮询调用 RunLoopOnce，还有一些对 RunLoopOnce 结束后的后处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 void BackgroundThreadLoop(HorovodGlobalState\u0026amp; state) { #if HAVE_MPI // Initialize mpi context auto mpi_ctx_manager = MPIContextManager(); #endif // mpi_context 会根据前端和环境变量传过来的信息，创建 mpi 线程，和一些 mpiOps mpi_context.Initialize(state.controller-\u0026gt;GetRanks(), mpi_ctx_manager); #endif // Initialize controller // 会同步不同 node 的 global_size, local_size, rank, is_coordinator 等信息 state.controller-\u0026gt;Initialize(); // Set background thread affinity parse_and_set_affinity(std::getenv(HOROVOD_THREAD_AFFINITY), local_size, local_rank); #if HAVE_GPU ... // 设置 gpu_context 的 stream 数目等初始化动作 #endif // 下面是设置 parameter_manager 这里为了节省篇幅直接给出，设置的语句， // 原来这里会读取对应的环境变量的，去设置 parameter_manager。 // 后面也会有篇幅介绍 parameter_manager，这里先不展开。 state.parameter_manager.SetTensorFusionThresholdBytes(64 * 1024 * 1024); state.parameter_manager.SetCycleTimeMs(5); state.parameter_manager.SetCacheEnabled(true); state.response_cache.set_capacity( (int)state.parameter_manager.CacheEnabled() * state.cache_capacity); state.parameter_manager.SetHierarchicalAllgather(value, true); state.parameter_manager.SetAutoTuning(true); ... // 其他一些初始化设置 // 设置op_manager，这里主要是注册不同的集合通信库的 ops //（ 如：NCCLAllreduce, MPI_GPUAllgather 等） op_manager.reset(CreateOperationManager(state)); // 初始化完成 state.initialization_done = true; // Iterate until shutdown. try { while (RunLoopOnce(state)); } catch (const std::exception\u0026amp; ex) { LOG(ERROR) \u0026lt;\u0026lt; \u0026#34;Horovod background loop uncaught exception: \u0026#34; \u0026lt;\u0026lt; ex.what(); } ... // 其他一些后处理函数 } 3.Optimizer.step()-\u0026gt;DoAllReduce 这里我们先不急着看 RunLoopOnce 函数，先回到 InitializeHorovodOnce ，因为上面的 initialization_done = True，所以 InitializeHorovodOnce 可以退出了，就是前端的 hvd.init() 可以进行下一步了。这里 main.py 走完前向 loss = model(data,target)，后向逻辑 loss.backward()，调用 optimizer.step() 进行梯度同步。optimizer.step() 会通过一系列的调用和处理（如：compression 等操作）最终会调用 C++ interface 的 DoAllReduce 函数。\nDoAllReduce 函数会调用 EnqueueTensorAllreduce 函数会把需要 reduce 的 tensor 组装成一个Request 往 GlobalState 的 tensor_queue 里面塞。这里注意每个 tensor 会创建对应 TensorTableEntry，用于保存tensor 的权重，message 主要是一些 元信息 metadata。然后就等后台线程去读取这些allreduce 的请求了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 Status EnqueueTensorAllreduce(std::shared_ptr\u0026lt;OpContext\u0026gt; context, std::shared_ptr\u0026lt;Tensor\u0026gt; tensor, std::shared_ptr\u0026lt;Tensor\u0026gt; output, std::shared_ptr\u0026lt;ReadyEvent\u0026gt; ready_event, const std::string name, const int device, StatusCallback callback, ReduceOp reduce_op, double prescale_factor, double postscale_factor) { Status status; ... // some config Request message; message.set_request_rank(horovod_global.controller-\u0026gt;GetRank()); message.set_tensor_name(name); message.set_tensor_type(tensor-\u0026gt;dtype()); message.set_device(device); message.set_prescale_factor(prescale_factor); message.set_postscale_factor(postscale_factor); if (reduce_op == ReduceOp::ADASUM) { message.set_request_type(Request::ADASUM); } else { message.set_request_type(Request::ALLREDUCE); } for (int i = 0; i \u0026lt; tensor-\u0026gt;shape().dims(); ++i) { message.add_tensor_shape((int64_t)tensor-\u0026gt;shape().dim_size(i)); } TensorTableEntry e; e.tensor_name = name; e.context = context; e.tensor = tensor; e.output = output; e.ready_event = ready_event; e.device = device; e.callback = callback; if (horovod_global.shut_down) { return SHUT_DOWN_ERROR; } status = horovod_global.tensor_queue.AddToTensorQueue(e, message); if (status.ok()) { LOG(TRACE, horovod_global.controller-\u0026gt;GetRank()) \u0026lt;\u0026lt; \u0026#34;Enqueued \u0026#34; \u0026lt;\u0026lt; name; } return status; } 4.RunLoopOnce\n回到后台线程 BackgroundThreadLoop，后面会轮询调用 RunLoopOnce。 RunLoopOnce会首先调用 ComputeResponseList 函数，其主要工作是同步不同 worker 之间的需要 allreduce 的 tensors，为后面 allreduce 的执行做好准备。\n？？？为什么会在执行 tensor 的 allreduce 之前执行这样一步工作呢？而不是直接执行 allreduce 呢？我自己的猜测是，因为分布式训练是运行在不同的机子上的，因为 horovod 没有引入类似参数服务器（parameter server）的节点，而是采取 master-worker 的形式 进行 allreduce的。所以 allreduce 的时候必须确保所有的节点都是走到了同一句 allreduce 上，然后传输的 tensors 也要求是一致的，否则传输的 tensors 有可能没有匹配起来就执行allreduce，导致一些不可预知的错误。另外这部分引入了一些提高性能的 tricks，如对之前 reduce 过的 tensor 通过一个 bitmap 进行缓存，每次调用看一下是不是都是之前的 tensor，如果不是再 update 一下，不需要每次都全量更新。？？？（不是很确定）\nComputeResponseList具体的流程是(可以对照上面流程图看):\n从自己进程的 GlobalState 读取 tensor_queue 的信息，如果有新的元素，会通过图中 popMessagesFromQueue pop 出来，然后经过一系列处理缓存到 message_queue_tmp 中。 当 worker 到达了前端 all_reduce 这句的时候，会用 message_queue_tmp 整理成一个 message_list通过流程图中的 SendReadyTensors 函数往主节点( coordinator ) 发送一个请求表明我打算reduce，然后会把准备 reduce 的 tensor 信息通过 message_list 迭代地送过去，最后有一个 Done 的请求 coordinator 会接收通过图中 RecvReadyTensors 这些 requests，然后保存在 ready_to_reduce 中，coordinator 会持续接收这些信息，直到获取的 Done 的数目等于 global_size。 coordinator 会找到所有准备好 reduce 的 tensors，通过 SendFinalTensors 返回一个 response 给所有的 worker，如果信息有误会返回一个 error，发送完成也会发送一个 Done。 worker 会通过 RecvFinalTensors 监听 response 的信息，整理出需要 reduce 的 tensor，当收到 Done，会尝试调用 performation 去进行 reduce 。 coordinator 和 worker 都会把同步的信息整理成一个 responses 的数组给到后面的 PerformOperation 操作。 这里说一下mpi是怎么实现的，就是对应的 coordinator 和 worker 会阻塞地到同一条指令：\nSendReadyTensors 和 RecvReadyTensors 阻塞到 MPI_Gather，SendFinalTensors 和 RecvFinalTensors 到 MPI_Bcast ，可以这样分辨：如果是 coordinator 发送的就是 MPI_Bcast，如果是worker 发送的是 MPI_Gather。通信都是先同步需要通信message的大小 length，再同步message，代码如下：\nhorovod/common/mpi/http://mpi_controller.cc\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 void MPIController::SendReadyTensors(RequestList\u0026amp; message_list) { std::string encoded_message; RequestList::SerializeToString(message_list, encoded_message); int encoded_message_length = (int)encoded_message.length() + 1; // 先 gather 这个 message 的大小 int ret_code = MPI_Gather(\u0026amp;encoded_message_length, 1, MPI_INT, nullptr, 1, MPI_INT, RANK_ZERO, mpi_ctx_.mpi_comm); if (ret_code != MPI_SUCCESS) { throw std::runtime_error(\u0026#34;MPI_Gather failed, see MPI output for details.\u0026#34;); } // 再 gather 这个 message ret_code = MPI_Gatherv((void*)encoded_message.c_str(), encoded_message_length, MPI_BYTE, nullptr, nullptr, nullptr, MPI_BYTE, RANK_ZERO, mpi_ctx_.mpi_comm); ... } void MPIController::RecvReadyTensors(std::vector\u0026lt;std::string\u0026gt;\u0026amp; ready_to_reduce,std::vector\u0026lt;RequestList\u0026gt;\u0026amp; ready_list) { MPI_Gather(MPI_IN_PLACE, 1, MPI_INT, recvcounts, 1, MPI_INT, RANK_ZERO, mpi_ctx_.mpi_comm); ... MPI_Gatherv(nullptr, 0, MPI_BYTE, buffer, recvcounts, displcmnts, MPI_BYTE, RANK_ZERO, mpi_ctx_.mpi_comm); ... } void MPIController::RecvFinalTensors(ResponseList\u0026amp; response_list) { int msg_length; int ret_code = MPI_Bcast(\u0026amp;msg_length, 1, MPI_INT, RANK_ZERO, mpi_ctx_.mpi_comm); if (ret_code != MPI_SUCCESS) { throw std::runtime_error( \u0026#34;MPI_Broadcast failed, see MPI output for details.\u0026#34;); } auto buffer = new uint8_t[msg_length]; ret_code = MPI_Bcast(buffer, msg_length, MPI_BYTE, RANK_ZERO, mpi_ctx_.mpi_comm); ... } 5.PerformOperation\n从 ComputeResponseList 继续跑 RunLoopOnce， 不同 node 下面会根据前面 ComputeResponseList 返回的 response_list 对每个 response 轮询调用 PerformOperation 完成对应的 reduce 工作。\nPerformOperation 流程：\nhorovod/common/http://operations.cc\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 void PerformOperation(Response response, HorovodGlobalState\u0026amp; state) { std::vector\u0026lt;TensorTableEntry\u0026gt; entries; auto\u0026amp; timeline = horovod_global.timeline; if (response.response_type() != Response::JOIN) { horovod_global.tensor_queue.GetTensorEntriesFromResponse(response, entries, state.joined); ... // 对数据预处理和 buffer 初始化 Status status; // 执行 all_reduce 等操作 try { status = op_manager-\u0026gt;ExecuteOperation(entries, response); } catch (const std::exception\u0026amp; ex) { status = Status::UnknownError(ex.what()); } ... // 调用 callback 函数 } PerformOperation 会从 horovod_global.tensor_queue 通过函数 GetTensorEntriesFromResponse 取出对应的 TensorEntry 如果还没初始化buffer，调用 horovod_global.fusion_buffer.InitializeBuffer 初始化 然后 status = op_manager-\u0026gt;ExecuteOperation(entries, response) 会调用不同的 op-\u0026gt;Execute(entries, response) 执行reduce 运算 下面以 MPIAllreduce::Execute 为例： horovod/common/ops/http://mpi_operations.cc\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Status MPIAllreduce::Execute(std::vector\u0026lt;TensorTableEntry\u0026gt;\u0026amp; entries, const Response\u0026amp; response) { ... // 一些变量声明 // 把 tensor copy 到 buffer 中 if (entries.size() \u0026gt; 1) { timeline.ActivityStartAll(entries, MEMCPY_IN_FUSION_BUFFER); MemcpyInFusionBuffer(entries, fused_input_data, buffer_data, buffer_len); timeline.ActivityEndAll(entries); } else { fused_input_data = first_entry.tensor-\u0026gt;data(); buffer_data = (void*) first_entry.output-\u0026gt;data(); buffer_len = (size_t) first_entry.output-\u0026gt;size(); } // Do allreduce const void* sendbuf = entries.size() \u0026gt; 1 || fused_input_data == buffer_data ? MPI_IN_PLACE : fused_input_data; int op = MPI_Allreduce(sendbuf, buffer_data, (int) num_elements, mpi_context_-\u0026gt;GetMPIDataType(first_entry.tensor), mpi_context_-\u0026gt;GetMPISumOp(first_entry.tensor-\u0026gt;dtype()), mpi_context_-\u0026gt;GetMPICommunicator(Communicator::GLOBAL)); if (op != MPI_SUCCESS) { throw std::runtime_error(\u0026#34;MPI_Allreduce failed, see MPI output for details.\u0026#34;); } // Copy memory out of the fusion buffer. // 把 allreduce 后的 tensor copy 会 entries if (entries.size() \u0026gt; 1) { timeline.ActivityStartAll(entries, MEMCPY_OUT_FUSION_BUFFER); MemcpyOutFusionBuffer(buffer_data, entries); timeline.ActivityEndAll(entries); } return Status::OK(); } 然后调用不同 entries 的 callback，这里 callback 一般是给前端作相应的。 6.parameter_manager.update\n完成上述步骤之后，如果设置了 state.parameter_manager.IsAutoTuning()，RunLoopOnce 还会调用相关的逻辑，调整传输的参数，然后返回 BackgroundThreadLoop 重新调用。_重新调用时会睡一定时间再继续_上述第 3 - 5 步的工作。\n其他关键模块 上面只是介绍了 horovod 主流程工作原理，不过 horovod 还有其他一些模块协同主流程工作的，下面会对其中的一些我认为可以值得一说的模块说一下。\nParameter_manager: Parameter_manager 主要是 GlobalState 的一个用于管理一些调节 horovod 性能的参数的管理器，在 BackgroundThreadLoop 中跟其他的 GlobalState 的元素一同初始化，然后会读取下面这些对应的环境变量，然后进行设置。\nHOROVOD_FUSION_THRESHOLD：指传输数据切片的大小，默认是64M，如果切片太大，传输的时候就不能很好地 pipeline 传输，如果太小，一个 tensor 需要传输多次，增加 IO 的 overhead。\nHOROVOD_CYCLE_TIME：指 RunLoopOnce 的睡眠时长，默认是 5ms，我自己的猜测（还没进行验证）比较理想的睡眠时间应该是 RunLoopOnce 其余逻辑处理的时间 + HOROVOD_CYCLE_TIME 刚好等于一次前向传播和后向传播所用的时间，因为睡太久前端会在等 RunLoopOnce 睡醒；如果睡太短，不断地跑一次 RunLoopOnce，tensor_queue 也不会有新的元素，只是白跑。\nHOROVOD_CACHE_CAPACITY：指 cache 的大小，这个可能跟 model 层数参数量相关了。\nHOROVOD_HIERARCHICAL_ALLGATHER：是否使用分层的allgather的方式等\nParameter_manager也提供了对这些参数自动调节的功能。通过Parameter_manager.SetAutoTuning进行设置，设置后会在初始的几个batch尝试不同的参数组合进行通信，后面会收敛到一组最优的参数值。\nMPIContext mpi_context 是在加载 C++ 的代码时候就已经创建了，同时创建的还有其他 context（ nccl_context, gpu_context），主要是维护一些节点上 mpi 通信的必要环境信息和设置，如：\n3 个 MPI communicator，mpi_comm，local_comm，cross_comm 分别负责 horovod mpi 传输，节点内传输，和节点间分层传输（主要用于 hierarchical allreduce）。 mpi_float16_t: horovod 主要以 float16 传输。 mpi_float16_sum: float16 对应的sum 操作。 在 horovod 使用 mpi 的时候，都会使用上面的 communicator 进行数据传输。\nTensorflow2 TensorFlow2 前端对 horovod 的调用跟 pytorch 类似，只是因为 tensorflow 2 是通过 tape 等级制记录梯度的, 所以会有一些不同。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 hvd.init() # Set up standard model. model = getattr(applications, args.model)(weights=None) opt = tf.optimizers.SGD(0.01) data = tf.random.uniform([args.batch_size, 224, 224, 3]) target = tf.random.uniform([args.batch_size, 1], minval=0, maxval=999, dtype=tf.int64) @tf.function def benchmark_step(first_batch): # Horovod: (optional) compression algorithm. compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none # Horovod: use DistributedGradientTape with tf.GradientTape() as tape: probs = model(data, training=True) loss = tf.losses.sparse_categorical_crossentropy(target, probs) # Horovod: add Horovod Distributed GradientTape. tape = hvd.DistributedGradientTape(tape, compression=compression) gradients = tape.gradient(loss, model.trainable_variables) opt.apply_gradients(zip(gradients, model.trainable_variables)) if first_batch: hvd.broadcast_variables(model.variables, root_rank=0) hvd.broadcast_variables(opt.variables(), root_rank=0) for x in range(args.num_iters): benchmark_step(first_batch=False) with tf.GradientTape() as tape这一句会调用 horovod/tensorflow/__init__.py 中_DistributedGradientTape 下 init 函数注册 allreduce 的句柄（handle） 然后调用 gradients = tape.gradient(loss, model.trainable_variables) 会调用一系列的跳转最后会调用 tensorflow/mpi_ops.py 下的 _allreduce ，进而调用 `MPI_LIB.horovod_allreduce MPI_LIB.horovod_allreduce 在 horovod/tensorflow/http://mpi_ops.cc 中被 HorovodAllreduceOp 所注册，根据 TensorFlow 的 ops流程，会调用 ops.ComputeAsync，到这里会跟 pytorch 类似会调用 EnqueueTensorAllreduce 把对应的 tensor 和 ops 送到 GlobalState 的 tensor_queue 中。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class HorovodAllreduceOp : public AsyncOpKernel { public: explicit HorovodAllreduceOp(OpKernelConstruction* context) : AsyncOpKernel(context) { OP_REQUIRES_OK(context, context-\u0026gt;GetAttr(\u0026#34;reduce_op\u0026#34;, \u0026amp;reduce_op_)); OP_REQUIRES_OK(context, context-\u0026gt;GetAttr(\u0026#34;prescale_factor\u0026#34;, \u0026amp;prescale_factor_)); OP_REQUIRES_OK(context, context-\u0026gt;GetAttr(\u0026#34;postscale_factor\u0026#34;, \u0026amp;postscale_factor_)); OP_REQUIRES_OK(context, context-\u0026gt;GetAttr(\u0026#34;ignore_name_scope\u0026#34;, \u0026amp;ignore_name_scope_)); } void ComputeAsync(OpKernelContext* context, DoneCallback done) override { OP_REQUIRES_OK_ASYNC(context, ConvertStatus(common::CheckInitialized()), done); ... // 一些变量验证，初始化 auto enqueue_result = EnqueueTensorAllreduce( hvd_context, hvd_tensor, hvd_output, ready_event, node_name, device, [context, done](const common::Status\u0026amp; status) { context-\u0026gt;SetStatus(ConvertStatus(status)); done(); }, reduce_op, (double) prescale_factor_, (double) postscale_factor_); OP_REQUIRES_OK_ASYNC(context, ConvertStatus(enqueue_result), done); } private: int reduce_op_; // Using float since TF does not support double OP attributes float prescale_factor_; float postscale_factor_; bool ignore_name_scope_; }; 总结 horovod 的流程分析大概就是这样，没有特别复杂，代码的阅读体验也是比较好的，在主流程的关键函数都有比较清晰的注释。对于第三方开发者来说，horovod 本身已经用了很多提高性能的 tricks，可以 custom 优化的地方不多，一些可以动的参数，也已经提供了autotuning，直接使用就可以得到很好的性能。如果尝试优化，可能要从传输上着手，如 BytePS 会尝试使用不同的网络拓扑引入一些 PS 节点提高带宽等，如果有时间我也会聊一下这个。另外上面的分析也有很多是我自己阅读代码时候的一些思考可能不一定准确，如果有不准确或者模糊的地方，也希望大家可以多多斧正。\nReferences: [1]. https://zhuanlan.zhihu.com/p/332825987 [2]. https://zhuanlan.zhihu.com/p/158584571 [3]. https://zhuanlan.zhihu.com/p/79030485 [4]. https://github.com/zjykzj/pytorch-distributed [5]. MPI教程 https://blog.csdn.net/qq_47058489/article/details/125980505\nhttps://blog.csdn.net/weixin_45385568/article/details/121208161?spm=1001.2101.3001.6650.1\u0026amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-121208161-blog-87971642.pc_relevant_multi_platform_featuressortv2removedup\u0026amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-121208161-blog-87971642.pc_relevant_multi_platform_featuressortv2removedup\u0026amp;utm_relevant_index=1\n[5.] ubuntu20.04 + docker + horovod\nHorovod and Distributed Training ","permalink":"https://jianye0428.github.io/en/posts/notes/2022-07-27_horovod_and_openmpi/","summary":"Horovod 介绍 Horovod 是 Uber 开源的深度学习工具，它的发展吸取了Facebook \u0026ldquo;Training ImageNet In 1 Hour\u0026rdquo; 与百度 \u0026ldquo;Ring Allreduce\u0026rdquo; 的优点，在保证分布式训练性能的同时，兼顾了前端的简洁和对不","title":"[Distributed Training] Horovod_and_Openmpi"},{"content":"一、 apt-get source update apt-get source change the /etc/apt/sources.list file to aliyun source add sudo user in rootlink 1 adduser [name] 1 apt-get install sudo 赋予用户sudo权限: 1 2 3 sudo usermod -a -G adm username sudo usermod -a -G sudo username su [name] 在文件/etc/sudoers 中更改用户的sudo权限: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # sudoers file. # # This file MUST be edited with the \u0026#39;vi sudo\u0026#39; command as root. # # See the sudoers man page for the details on how to write a sudoers file. # # Host alias specification # User alias specification # Cmnd alias specification # Defaults specification # User privilege specification root ALL=(ALL) ALL [username] ALL=(ALL) ALL # Uncomment to allow people in group wheel to run all commands # %wheel ALL=(ALL) ALL # Same thing without a password # %wheel ALL=(ALL) NOPASSWD: ALL # Samples # %users ALL=/sbin/mount /cdrom,/sbin/umount /cdrom # %users localhost=/sbin/shutdown -h now 二、 Anaconda or Miniconda Installation download anaconda or miniconda from tsinghua source website\ndownload command:\n1 wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-latest-Linux-x86_64.sh run the command to install:\n1 bash Miniconda3-latest-linux-x86_64.sh change the conda channels to tsinghua source\n1 nano ~/.condarc paste the following channels into your ~/.condarc file:ref link\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ #Conda Forge conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ #msys2（可略） conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/ #bioconda（可略） conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ #menpo（可略） conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/ #pytorch conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ # for legacy win-64（可略） conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/peterjc123/ conda config --set show_channel_urls yes 三、 Cmake Installation Ref Link\nDownload cmake source file: 1 wget https://cmake.org/files/v3.20/cmake-3.20.0-linux-x86_64.tar.gz extract the file and move the file to /opt/cmake-3.20.0 1 2 tar zxvf cmake-3.20.0-linux-x86_64.tar.gz mv cmake-3.20.0-linux-x86_64 /opt/cmake-3.20.0 link the cmake as system cmake 1 ln -sf /opt/cmake-3.20.0/bin/* /usr/bin/ check if successfully installed 1 cmake --version 四、 openmpi installation (Ref Link) Install openmpi with command line:\n1 sudo apt-get install openmpi-bin openmpi-doc libopenmpi-dev 在conda下安装openmapi:\n1 conda install openmpi 五、 Anaconda下安装jupyter notebook 1、 安装jupyter notebook conda intall jupyter notebook\n2、 安装nbextensions pip install jupyter_contrib_nbextensions jupyter contrib nbextension install --user 3、 安装nbextensions_configurator pip install jupyter_nbextensions_configurator jupyter nbextensions_configurator enable --user 4、 在codemirror.css文件中更改字体\n","permalink":"https://jianye0428.github.io/en/posts/notes/2022-07-19_softwareinstallation/","summary":"一、 apt-get source update apt-get source change the /etc/apt/sources.list file to aliyun source add sudo user in rootlink 1 adduser [name] 1 apt-get install sudo 赋予用户sudo权限: 1 2 3 sudo usermod -a -G adm username sudo usermod -a -G sudo username su [name] 在文件/etc/sudoers 中","title":"Software Installation Notes"},{"content":"docker 入门教程 Ref Link:\n[1] https://ruanyifeng.com/blog/2018/02/docker-tutorial.html\n[2] https://cloud.tencent.com/developer/article/1885678\n[3] 「Docker」 - 保存镜像\n[4] 如何制作Docker镜像(image)?\n一、Docker 是什么？ \u0026amp;\u0026amp; Docker 的用途 Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。\nDocker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。\n总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。\n二、docker 安装 参考连接:ubuntu下docker的安装\n安装完成后，运行下面的命令，验证是否安装成功。\n1 2 3 docker version # or docker info Docker 需要用户具有 sudo 权限，为了避免每次命令都输入sudo，可以把用户加入 Docker 用户组。\n1 2 # 创建docker用户组 sudo groupadd docker 1 2 # 应用用户加入docker用户组 sudo usermod -aG docker $USER 1 2 # 重启docker服务 sudo systemctl restart docker 1 2 su root su ${USER} Docker是服务器\u0026ndash;客户端(server\u0026ndash;client)架构。命令行运行docker命令的时候，需要本机有 Docker 服务。如果这项服务没有启动，可以用下面的命令启动:\n1 2 3 4 5 # service 命令的用法 sudo service docker start # systemctl 命令的用法 sudo systemctl start docker 三、image 文件 Docker 把应用程序及其依赖，打包在 image 文件里面。只有通过这个文件，才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。\nimage 是二进制文件。实际开发中，一个 image 文件往往通过继承另一个 image 文件，加上一些个性化设置而生成。举例来说，你可以在 Ubuntu 的 image 基础上，往里面加入 Apache 服务器，形成你的 image。\n1 2 3 4 5 # 列出本机的所有 image 文件。 $ docker image ls # 删除 image 文件 $ docker image rm [imageName] image 文件是通用的，一台机器的 image 文件拷贝到另一台机器，照样可以使用。一般来说，为了节省时间，我们应该尽量使用别人制作好的 image 文件，而不是自己制作。即使要定制，也应该基于别人的 image 文件进行加工，而不是从零开始制作。\n为了方便共享，image 文件制作完成后，可以上传到网上的仓库。Docker 的官方仓库 Docker Hub 是最重要、最常用的 image 仓库。此外，出售自己制作的 image 文件也是可以的。\n四、实例：hello world 首先，运行下面的命令，将 image 文件从仓库抓取到本地。\n1 docker image pull library/hello-world 上面代码中，docker image pull是抓取 image 文件的命令。library/hello-world是 image 文件在仓库里面的位置，其中library是 image 文件所在的组，hello-world是 image 文件的名字。\n由于 Docker 官方提供的 image 文件，都放在library组里面，所以它的是默认组，可以省略。因此，上面的命令可以写成下面这样。\n1 docker image pull hello-world 抓取成功以后，就可以在本机看到这个 image 文件了。\n1 docker image ls 运行image:\n1 docker container run hello-world docker container run命令会从 image 文件，生成一个正在运行的容器实例。\n注意，docker container run命令具有自动抓取 image 文件的功能。如果发现本地没有指定的 image 文件，就会从仓库自动抓取。因此，前面的docker image pull命令并不是必需的步骤。\n如果运行成功，你会在屏幕上读到下面的输出。\n1 2 3 4 5 6 7 $ docker container run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. ... ... 输出这段提示以后，hello world就会停止运行，容器自动终止。\n有些容器不会自动终止，因为提供的是服务。比如，安装运行 Ubuntu 的 image，就可以在命令行体验 Ubuntu 系统。\n1 $ docker container run -it ubuntu bash 对于那些不会自动终止的容器，必须使用docker container kill命令手动终止。\n1 $ docker container kill [containID] 五、容器文件 image文件生成的容器实例，本身也是一个文件，称为容器文件。也就是说，一旦容器生成，就会同时存在两个文件： image文件和容器文件。而且关闭容器并不会删除容器文件，只是容器停止运行而已。\n上面命令的输出结果之中，包括容器的 ID。很多地方都需要提供这个 ID，比如上一节终止容器运行的docker container kill命令。\n终止运行的容器文件，依然会占据硬盘空间，可以使用docker container rm命令删除。\n1 $ docker container rm [containerID] 运行上面的命令之后，再使用docker container ls --all命令，就会发现被删除的容器文件已经消失了。\n六、 Dockerfile 文件 学会使用 image 文件以后，接下来的问题就是，如何可以生成 image 文件？如果你要推广自己的软件，势必要自己制作 image 文件。\n这就需要用到 Dockerfile 文件。它是一个文本文件，用来配置 image。Docker 根据 该文件生成二进制的 image 文件。\n下面通过一个实例，演示如何编写 Dockerfile 文件。\n七、实例: 下面我以 koa-demos 项目为例，介绍怎么写 Dockerfile 文件，实现让用户在 Docker 容器里面运行 Koa 框架。\n作为准备工作，请先下载源码[]。\n1 2 $ git clone https://github.com/ruanyf/koa-demos.git $ cd koa-demos 7.1 编写 Dockerfile 文件\n首先，在项目的根目录下，新建一个文本文件.dockerignore，写入下面的内容。\n1 2 3 .git node_modules npm-debug.log 上面代码表示，这三个路径要排除，不要打包进入 image 文件。如果你没有路径要排除，这个文件可以不新建。\n然后，在项目的根目录下，新建一个文本文件 Dockerfile，写入下面的内容。\n1 2 3 4 5 FROM node:8.4 COPY . /app WORKDIR /app RUN npm install --registry=https://registry.npm.taobao.org EXPOSE 3000 上面代码一共五行，含义如下。\nFROM node:8.4：该 image 文件继承官方的 node image，冒号表示标签，这里标签是8.4，即8.4版本的 node。 COPY . /app：将当前目录下的所有文件（除了.dockerignore排除的路径），都拷贝进入 image 文件的/app目录。 WORKDIR /app：指定接下来的工作路径为/app。 RUN npm install：在/app目录下，运行npm install命令安装依赖。注意，安装后所有的依赖，都将打包进入 image 文件。 EXPOSE 3000：将容器 3000 端口暴露出来， 允许外部连接这个端口。 7.2 创建image文件\n有了 Dockerfile 文件以后，就可以使用docker image build命令创建 image 文件了。\n1 2 3 $ docker image build -t koa-demo . # 或者 $ docker image build -t koa-demo:0.0.1 . 上面代码中，-t参数用来指定 image 文件的名字，后面还可以用冒号指定标签。如果不指定，默认的标签就是latest。最后的那个点表示 Dockerfile 文件所在的路径，上例是当前路径，所以是一个点。\n如果运行成功，就可以看到新生成的 image 文件koa-demo了。\n1 docker image ls 7.3 生成容器\ndocker container run命令会从 image 文件生成容器。\n1 2 3 4 $ docker container run -p 8000:3000 -it koa-demo /bin/bash # 或者 $ docker container run -p 8000:3000 -it koa-demo:0.0.1 /bin/bash 上面命令的各个参数含义如下：\np参数：容器的 3000 端口映射到本机的 8000 端口。 it参数：容器的 Shell 映射到当前的 Shell，然后你在本机窗口输入的命令，就会传入容器。 koa-demo:0.0.1：image 文件的名字（如果有标签，还需要提供标签，默认是 latest 标签）。 /bin/bash：容器启动以后，内部第一个执行的命令。这里是启动 Bash，保证用户可以使用 Shell。 如果一切正常，运行上面的命令以后，就会返回一个命令行提示符。\n1 root@66d80f4aaf1e:/app# 这表示你已经在容器里面了，返回的提示符就是容器内部的 Shell 提示符。执行下面的命令。\n1 root@66d80f4aaf1e:/app# node demos/01.js 这时，Koa 框架已经运行起来了。打开本机的浏览器，访问 http://127.0.0.1:8000，网页显示\u0026quot;Not Found\u0026quot;，这是因为这个 demo 没有写路由。\n这个例子中，Node 进程运行在 Docker 容器的虚拟环境里面，进程接触到的文件系统和网络接口都是虚拟的，与本机的文件系统和网络接口是隔离的，因此需要定义容器与物理机的端口映射（map）。\n现在，在容器的命令行，按下 Ctrl + c 停止 Node 进程，然后按下 Ctrl + d （或者输入 exit）退出容器。此外，也可以用docker container kill终止容器运行。\n1 2 3 4 5 6 # 在本机的另一个终端窗口，查出容器的 ID $ docker container ls # 停止指定的容器运行 $ docker container kill [containerID] 容器停止运行之后，并不会消失，用下面的命令删除容器文件。\n1 2 3 4 5 6 # 查出容器的 ID $ docker container ls --all # 删除指定的容器文件 $ docker container rm [containerID] 也可以使用docker container run命令的\u0026ndash;rm参数，在容器终止运行后自动删除容器文件。\n1 $ docker container run --rm -p 8000:3000 -it koa-demo /bin/bash 7.4 CMD命令\n上一节的例子里面，容器启动以后，需要手动输入命令node demos/01.js。我们可以把这个命令写在 Dockerfile 里面，这样容器启动以后，这个命令就已经执行了，不用再手动输入了。\n1 2 3 4 5 6 FROM node:8.4 COPY . /app WORKDIR /app RUN npm install --registry=https://registry.npm.taobao.org EXPOSE 3000 CMD node demos/01.js 上面的 Dockerfile 里面，多了最后一行CMD node demos/01.js，它表示容器启动后自动执行node demos/01.js。\n你可能会问，RUN命令与CMD命令的区别在哪里？简单说，RUN命令在 image 文件的构建阶段执行，执行结果都会打包进入 image 文件；CMD命令则是在容器启动后执行。另外，一个 Dockerfile 可以包含多个RUN命令，但是只能有一个CMD命令。\n注意，指定了CMD命令以后，docker container run命令就不能附加命令了（比如前面的/bin/bash），否则它会覆盖CMD命令。现在，启动容器可以使用下面的命令。\n1 $ docker container run --rm -p 8000:3000 -it koa-demo:0.0.1 7.5 发布 image 文件\n容器运行成功后，就确认了 image 文件的有效性。这时，我们就可以考虑把 image 文件分享到网上，让其他人使用。\n首先，去 hub.docker.com 或 cloud.docker.com 注册一个账户。然后，用下面的命令登录。\n1 $ docker login 接着，为本地的 image 标注用户名和版本。\n1 2 3 4 $ docker image tag [imageName] [username]/[repository]:[tag] # 实例 $ docker image tag koa-demos:0.0.1 ruanyf/koa-demos:0.0.1 也可以不标注用户名，重新构建一下 image 文件。\n1 $ docker image build -t [username]/[repository]:[tag] . 最后，发布 image 文件。\n1 $ docker image push [username]/[repository]:[tag] 发布成功以后，登录 hub.docker.com，就可以看到已经发布的 image 文件。\n八、其他有用的命令 (1) docker container start\n前面的docker container run命令是新建容器，每运行一次，就会新建一个容器。同样的命令运行两次，就会生成两个一模一样的容器文件。如果希望重复使用容器，就要使用docker container start命令，它用来启动已经生成、已经停止运行的容器文件。\n1 $ docker container start [containerID] (2) docker container stop\n前面的docker container kill命令终止容器运行，相当于向容器里面的主进程发出 SIGKILL 信号。而docker container stop命令也是用来终止容器运行，相当于向容器里面的主进程发出 SIGTERM 信号，然后过一段时间再发出 SIGKILL 信号。\n1 docker container stop [containerID] 这两个信号的差别是，应用程序收到 SIGTERM 信号以后，可以自行进行收尾清理工作，但也可以不理会这个信号。如果收到 SIGKILL 信号，就会强行立即终止，那些正在进行中的操作会全部丢失。\n(3) docker container logs\ndocker container logs命令用来查看 docker 容器的输出，即容器里面 Shell 的标准输出。如果docker run命令运行容器的时候，没有使用-it参数，就要用这个命令查看输出。\n1 docker container logs [containerID] (4) docker container exec\ndocker container exec命令用于进入一个正在运行的 docker 容器。如果docker run命令运行容器的时候，没有使用-it参数，就要用这个命令进入容器。一旦进入了容器，就可以在容器的 Shell 执行命令了。\n1 2 $ docker container exec -it [containerID] /bin/bash (5) docker container cp 和 docker cp\ndocker container cp命令用于从正在运行的 Docker 容器里面，将文件拷贝到本机。下面是拷贝到当前目录的写法。 1 docker container cp [containID]:[/path/to/file] . docker cp命令用于从将宿主机内的文件拷贝文件到container中: 1 docker cp [OPTIONS] [src path] [container id]:[dest path] 非常感谢你一直读到了这里，这个系列还有下一篇，介绍如何使用 Docker 搭建真正的网站，欢迎继续阅读。\n(6) docker commit\ndocker commit命令用于保存container的修改。\n1 docker commit -m \u0026#34;commit message\u0026#34; [containr ID] [new REPOSITORY:TAG] (7) docker save and docker load docker save 和 docker load 将image文件保存为压缩文件或者加载本地的压缩文件为image。\n1 docker save -o [outputname path] [REPOSITORY:TAG] 1 docker load -i [outputname.tar] ","permalink":"https://jianye0428.github.io/en/posts/notes/2022-07-15_docker/","summary":"docker 入门教程 Ref Link: [1] https://ruanyifeng.com/blog/2018/02/docker-tutorial.html [2] https://cloud.tencent.com/developer/article/1885678 [3] 「Docker」 - 保存镜像 [4] 如何制作Docker镜像(image)? 一、Docker 是什么？ \u0026amp;\u0026amp; Docker 的用途 Docker 属于 Linux 容器的","title":"Docker安装及学习"},{"content":"TNT: Target-driveN Trajectory Prediction **ref link:** https://zhuanlan.zhihu.com/p/435953928\nhttps://blog.csdn.net/weixin_40633696/article/details/124542807?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-2-124542807-blog-122758833.pc_relevant_vip_default\u0026amp;spm=1001.2101.3001.4242.2\u0026amp;utm_relevant_index=5\n概览 在预测车辆的轨迹时, 需要尽可能考虑到车辆不同的情况，即不同的模态，如前行或左转，并预测出对应的概率。\n模态的定义是比较模糊的，例如，有不同的速度前行，左转可以以不同的转弯角度实现。为了能够更加通用且精确地定义每条轨迹的模态，我们直接将每条轨迹的模态定义在每条轨迹的终点上。这里的一个重要假设是，轨迹的模态基本由终点所决定，当终点确定后，轨迹的形状也大体确定了。这样我们就把轨迹预测变成了终点预测问题，极大地简化了问题的复杂度。\nTNT的预测方式: 首先预测轨迹的终点，然后基于这个终点补充完整条轨迹。\nTNT 基于终点的轨迹预测流程图: TNT使用VectorNet对高精地图和车辆信息进行编码，得到要预测的车辆的全局特征，以用于接下来的解码，从而完成轨迹预测：\n(1). 终点预测: 为每个Anchor预测一个偏移，得到终点，这些Anchor从道路的中心线上采样得到; (2). 轨迹补全: 基于上一步预测的终点将整条轨迹补充完整; (3). 轨迹打分和筛选: 根据场景特征，为每条轨迹进行打分，并筛选出最有可能的若干条轨迹。\nTNT 实现 原理 给定一个单个障碍物的观测状态序列 $S_P = [s_{-T^{\u0026rsquo;}+1}, s_{-T^{\u0026rsquo;}+2}, \u0026hellip;, s_0]$。我们的目标是预测它的未来状态 $S_F = [s_1, s_2, \u0026hellip;, s_T]$ 到某个固定时间步 T。自然地，障碍物与由其它障碍物和场景元素组成的环境交互作为背景: $C_P​=[c_{-T′+1}​,c_{-T′+2}​,\u0026hellip;,c_0​]$。为简洁起见，我们记 $X = (s_P, c_P)$，因此我们想捕捉的整体概率分布是 $p(S_F|X)$ 。\n实际上， $p(S_F|X)$ 可以是高度多模态的。例如，车辆驶近十字路口时可能左转、直行或改变车道。直观上，未来状态的不确定性可以被分解为两部分：目标或者意图的不确定性，比如左右转的决定；以及控制的不确定性，比如转弯时需要的细粒度运动。因此，我们可以通过对目标设定条件，然后将其边缘化，从而对概率分布进行分解：\n$$p(S_F​∣X)=∫_{τ∈τ(C_P​)}​p(τ∣X)p(S_F​∣τ,X)d_τ​, \\tag{1}$$\n其中 $\\tau(C_P)$ 表示取决于观察到的背景 $C_P$ ​的合理目标空间。\n在这个公式下，我们的主要见解是，对于轨迹预测等应用，通过正确设计目标空间 $\\tau τ ( C_P )$（如目标位置），目标分布 $ p(\\tau|X)$ 可以很好地捕捉意图不确定性。一旦目标确定，我们会进一步证明控制不确定性（如轨迹）可以通过简单的单模态分布可靠地建模。我们用一组离散位置来模拟目标空间 $\\tau{C_P}$，将 $p(\\tau|X)$ 的估计主要转化为一个分类任务。与隐变分模型相比，我们的模型以明确的目标分布的形式提供了更好的可解释性，并且在设计目标空间 $\\tau{C_P}$ 时可以自然地结合专家知识（如道路拓扑）。\n我们的整体框架有三个概念阶段。第一阶段是障碍物意图预测，其目标是用基于观察背景 $X$ 的目标空间 $\\tau$ 的离散集合对意图不确定性进行建模，并且输出目标分布 $p(\\tau|X)$ 。第二个阶段是障碍物条件运动估计，它用单模态分布对从初始状态到目标可能的未来运动进行建模。前两个阶段产生了以下概率预测 $p(S_F|X) = \\sum_{\\tau\\in\\tau(C_P)}p(\\tau|X)p(S_F|\\tau, X)$。\n许多下游应用，例如实时行为预测，需要一小组具有代表性的未来预测，而不是所有可能未来的完整分布。我们的最终阶段，评分和选择，就是为此目的量身定制的。我们从所有代表性预测上学习一个评分函数 $\\phi(S_F)$，并选择一个最终的多样化预测集。\n场景编码VectorNet 建模场景背景是轨迹预测的第一步，以获取车辆-道路和车辆-车辆之间的交互。TNT可以使用任何合适的背景编码器：当高清地图可用时，我们使用最优秀的层次图神经网络 VectorNet 对背景进行编码。具体来说，使用多段线来抽象出高清地图元素 $C_P$(车道，交通标志) 和代理轨迹 $S_P$​；采用子图（subgraph）网络对多段线进行编码，多段线包含可变数量的向量；然后使用全局图（global graph）对多段线之间的交互进行建模。输出是每个建模代理的全局背景特征 $X$。如果场景背景只在自上而下的图像形式中可用，则使用卷积网络作为背景编码器。\n目标预测 在我们的公式中，目标 $\\tau$ 被定义为一个预测目标可能在固定时间范围 $T$ 上的位置 $(x,y)$ 。在第一步目标预测阶段，我们的目的是提供一个预测目标的未来目标的分布 $p( \\tau ∣ X )$ 。我们通过一组$N$个离散的、带有连续偏移的量化位置来建模潜在的未来目标： $\\tau ={\\tau^n}={(x^n,y^n)+(\\Delta x^n,\\Delta y^n)}^N_{n=1}$​。然后这个目标上分布可以通过一个离散-连续分解来建模：\n$$p(τ^n∣X)=π(τ^n∣X)⋅N(Δx^n∣v^x_n​(X))⋅N(Δ_y^n∣v_y^n​(X)),\\tag{2}$$\n中 $\\pi(\\tau^n|X)=\\frac{e^{f(\\tau^n,X)}}{\\sum_{\\tau^{\u0026rsquo;}}e^{f(\\tau^{\u0026rsquo;},X)}}$ 是在位置选择 $(x^n,y^n)$上的离散分布。术语 $N(·|v(·))$ 表示一个广义正态分布，其中我们选择Huber作为距离函数。我们将均值表示为 $v(·)$并假设单位方差。\n可训练函数 $f(·)$ 和 $v(·)$ 由一个2层的多层感知机(MLP)实现，目标坐标 $(x^k,y^k)$ 和场景背景特征 $X$ 作为输入。它们预测目标位置上的离散分布及其最可能的偏移量。这一阶段的训练损失函数由以下公式给出：\n$$L_{S1}​=L_{cls​}(π,u)+L_{offset}​(v_x​,v_y​,Δx^u,Δy^u),\\tag{3}$$\n其中 $L_{cls}$ 是交叉熵损失， $L_{offset}$​ 是 Huber 损失；$u$ 是离真实位置最近的目标，并且 $\\Delta x^u,\\Delta y^u$ 是 $u$ 相对于真值的空间偏移量。\n离散目标空间的选择在不同应用中是灵活的，如图3所示。在车辆轨迹预测问题中，我们从高清地图里均匀地采样车道中心线上的点并且将他们作为目标候选点(标记为黄色菱形)，假设车辆从未远离车道线；对于行人，我们在代理周围生成了一个虚拟网格并将网格点作为目标候选点。对每个候选目标，TNT目标预测器生成了一个 $(\\pi,\\Delta x, \\Delta y)$ 的元组；回归后的目标以橙色五角星标记。与直接回归相比，将未来建模成一组离散目标的最显著的优势在于，它不受模态平均的影响，模态平均是阻止多模态预测的主要因素。\n基于目标的运动估计 在第二阶段，我们将给定目标轨迹的可能性建模为 $p(S_F|\\tau,X)=\\prod^T_{t=1}p(s_t|\\tau,X)$，同样采用了广义正态分布。这里有两个假设。首先，未来时间步是条件独立的，这使得我们的模型通过避免顺序预测提高了计算效率。其次，我们正在作出有力但合理的假设，即给定目标的轨迹分布是单模态(正态)的。对于短的时间范围来说，这当然是正确的；对于更长的时间范围，可以在(中间)目标预测和运动估计之间迭代，以便假设仍然成立。\n这一阶段使用2层的MLP实现。它将背景特征 X 和目标位置 $\\tau$ 作为输入，并且每个目标输出一条最可能的轨迹 $[\\hat{s_1},\u0026hellip;,\\hat{s_T}] [s1​^​,\u0026hellip;,sT​^​]$。由于它以第一阶段的预测目标为条件，为了实现平滑的学习过程，我们在训练时采用teacher forcing Technique[36]，将真实位置 $(x^n,y^n)$ 作为目标。该阶段的损失项是预测状态 $\\hat{s_t}$​ 和真值 $s_t$​ 之间的距离：\n$$L_{S2}​ = \\sum_{t=1}^{T}​L_{reg}​(\\hat{s},s_t​),\\tag{4}$$\n其中， $L_{reg}$​ 作为每一步坐标偏移的 Huber 损失来实现。\n轨迹评分和选择 我们的最终阶段估计未来完整轨迹 S F S_F SF​ 的可能性。这和第二阶段不同，第二阶段分解时间步和目标，也和第一阶段不同，第一阶段只知道目标，但没有完整的轨迹——例如，一个目标可能被估计有很高的可能性，但到达该目标完整轨迹的可能性可能不是。\n我们使用最大熵模型对第二阶段的所有 M 条轨迹进行评分:\n$$\\phi (S_F | X) = \\frac{e^{g(S_F, X)}}{{\\sum}_{m=1}^{M} e^{g(S_F^m, X)}}​$$,\n其中 $g(·)$ 被建模为一个2层的 MLP。这一阶段训练的损失项是预测分数和真值分数之间的交叉熵，\n$$L_{S3} = L_{CE}(\\phi (S_F | X), \\psi(S_F))$$\n其中每个预测轨迹的真值评分由预测轨迹到真值轨迹的距离 $\\psi(S_F)=\\frac{exp(-D(S,S_{GT})/\\alpha)}{\\sum_{s^{\u0026rsquo;}}exp(-D(S^{\u0026rsquo;},S_{GT})/\\alpha)}$ 定义，其中 $D(·)$ 单位为米， $\\alpha$ 是温度。距离度量定义为 $D(S^i,S^j)=max(||s^i_1-s^j_1||^2_2,\u0026hellip;,||s^i_t-s^j_t||^2_2)$。\n为了从已评分的 $M$ 个轨迹获得最终一小组 $K$ 个预测轨迹，我们实现了一个轨迹选择算法来排除近似重复的轨迹。我们首先根据他们的分数对轨迹进行降序排列，并且贪婪地选择轨迹； 如果一个轨迹距离所有的选择轨迹都足够远，我们也会选择它，否则排除它。这里使用的距离度量和评分过程相同。这个过程的灵感来源于通常应用于计算机视觉问题（如目标检测）的非极大值抑制算法。\n训练和推理细节 上述的 TNT 公式产生全监督的端到端训练，具有损失函数 $$L = \\lambda_1 L_{S1} + \\lambda_2 L_{S2} + \\lambda_3 L_{S3}$$\n其中，选择 $\\lambda_1,\\lambda_2,\\lambda_3$ 来平衡训练过程。\n在推理时，TNT 的工作原理如下： (1) 工作场景编码；\n(2) 采样 N 个候选目标作为目标预测器的输入，取由 $\\pi(\\tau|X)$ 估计的前 M 个目标；\n(3) 从运动估计模型 $p(S_F|\\tau,X)$ 中获取 M 个目标中每个目标的 MAP 轨迹；\n(4) 通过 $\\phi(S_F|\\tau,X)$ 给 M 个轨迹评分，并且选择一组最终的 K 个轨迹。\nDenseTNT: ref link: https://blog.csdn.net/weixin_39397852/article/details/122764880\nComparison between DenseTNT and TNT TNT(左图)是根据lane定义一些anchor，再regress和classify获得最终的位置，之后还要通过NMS的筛选法选出最后的轨迹。 DenseTNT(右图)是通过密集地采点避免了定义anchor，同时也避免了使用NMS等规则来筛选轨迹。\n意图预测中非常重要的一个问题是ground truth只有一个，而对于多意图的预测来说，多个方向的预测都是允许的，这导致了label中有很多都是无效的，因为gt只包含了一个意图下的结果。此处设计了一个offline的model来提供多个意图下的label。这个model使用了一个优化算法从goal的分布里取出了一个set作为online model的label。\nMethod 具体实现方法 sparse context encoding \u0026ndash; VectorNet 本文使用VectorNet来提取地图的feature。(没有的高精地图的话也可使用CNN)\nDense goal probability estimation TNT对于一个goal只预测一条轨迹的概率是有问题的：一个goal只有一条预测(可能通向这个goal的别的预测概率很高)，一个goal获取的feature不够丰富(goal附近的点的信息也用上会更好)。\n我们使用了dense goal encoder。它以一定的采样频率获取了地图上在道路上的所有点。然后预测了这些密集点的概率分布。\nLane Scoring 在论文实现中，可以用point scoring代替，效果更好。目的在与选出距离final pos(gt)更近的点。\n为了减少需要sample的点，我们先预测goal落在不同lane上的概率，这样能过滤掉明显不在candidate lane附近的点，提升运算速度。 这是一个二分类问题。因此使用了二分类的交叉熵计算loss。对于label，使用离gt的goal最近的lane作为1，别的lane为0。对于别的lane $l$，假设gt的goal是$y_{gt}$​，定义一个distance\n$$d(l,y_{gt}) = min(||l_1 - y_{gt}||^2, ||l_2 - y_{gt}||^2, \u0026hellip;, ||l_t - y_{gt}||^2,)$$\n直觉上就是gt的goal到这条lane的最短距离的平方。\nProbability Estimation 获得概率分布的做法是self-attention。首先agent的feature经过两次MLP。然后把goal的feature $F$作为需要query的变量，从地图上所有元素 (lane，agent)的feature中去查找索引对应的键和值。目的就是建立goal的feature与地图上所有元素的联系。直观上，这一步是把agent的未来状态(goal)表示成由历史的信息作为变量的函数，这个函数采用的是self-attention的做法。\n轨迹目标点(goals)和道路的局部信息可以用以下注意力机制表示:\n$$\\mathbf{Q} = \\mathbf{FW}^{\\mathbf{Q}}, \\mathbf{K} = \\mathbf{LW}^{\\mathbf{K}}, \\mathbf{V}=\\mathbf{LW}^{\\mathbf{V}}$$\n$$\\mathbf{A}(\\mathbf{Q},\\mathbf{K},\\mathbf{V}) = softmax(\\frac{\\mathbf{QK^\\top}}{\\sqrt{d_k}})\\mathbf{V}$$\nwhere $\\mathbf{W}^Q, \\mathbf{W}^{K}, \\mathbf{W}^{V} \\in \\mathbb{R}^{d_h \\times d_k}$ are the matrices for linear projection, $d_k$ is the dimension of query / key / value vectors, and $\\mathbf{F}, \\mathbf{F}$ are feature matrices of the dense goal candidates and all map elements (i.e., lanes or agents), respectively.\n这一步之后的结果是goal新的feature $\\mathbf{F}$。再通过两次MLP，即下图中的 $g(.)$.用softmax中的方法获得每个goal的概率。将所有goal在地图上表示出来的话就是一个概率分布heatmap。\n$$\\phi_i = \\frac{\\exp(g(\\mathbf{F}i))}{\\sum{n=1}^{N}\\exp(g(\\mathbf{F}_n))}$$\n对于Loss的计算，离gt的goal最近的goal的label定为1，其余都为0.采取二分类交叉熵的算法。\n$$\\mathcal{L}\\text{goal} = \\mathcal{L}{\\text{CE}}(\\phi, \\psi)$$\nGoal Set Prediction 对于多意图的预测，在TNT中，预先设定好target，采用NMS(non-maximum suppression)(靠的近或概率低的过滤掉)。而DenseTNT的上一步获得是heatmap，因此不能简单使用NMS，因为用于筛选的阈值比较难定。这是因为TNT中采用的是从高到低排序概率，而DenseTNT中的概率分布是针对于整个鸟瞰图的，一旦意图的可能性变多了，平均分布到每一个意图的概率就低了(对于概率分布，所有的点的概率加起来需要为1)。\nheatmap，输出是goal set，这个有点像目标检测的框生成。但和目标检测不同，对于一个输入，我们的label只有一个，即gt。这样的话可能会有别的意图的结果在训练中被忽略。为此，设计了一个offline model来制造这些label。它和online model的区别就在这一步中。没有使用goal set predictor而是采用了优化算法。\nOffline Optimization 上一步heatmap的输出，实际上是对于地图上众多goal每个点的一个函数。设定 $C={c_1,c_2,\u0026hellip;,c_m}$ 为所有dense goal的candidate，heatmap就把 $C$ 映射到一个0到1的集合，写成 $h(c_i)$ ，这也是每个goal的概率。 接下来定义一个目标函数:\n$$E[d(\\hat{y}, Y)] = \\sum^m_{i=1}h(c_i)d(\\hat{y}, c_i)$$\n其中，$d(\\hat{y}, c_i) = \\mathop{\\min}\\limits_{y_i \\in \\hat{y}}||y_j - y_{c_i}||$\n从直观上讲，目标是有M个goal（大池子），要从中选取K个靠谱的goal（小池子）。 $d$ 是针对于大池子的，对于大池子里所有candidate都有一个 $d$。这每个candidate都与小池子中的goal计算距离，取最近的作为 d d d，即寻找小池子中离candidate最近的点。对于所有的 $d$，用概率加权计算期望。总体的话在收敛情况，大池子中的所有goal到距离自己最近的小池子中的goal乘上概率加权应当达到最小。以下是这个优化算法的实现。\n翻译成中文：\n初始化K个goal，从M个goal的大池子里随机选 小池子里的每个goal做随机扰动，变为别的goal 计算原来的和现在的小池子的d的期望e和e’ 如果现在的小池子d的期望更小，则使用现在的小池子。否则以1%的概率采用现在的小池子。（避免局部最优） 不停循环2-4直到步数达到阈值（或时间太长） 优化算法之后得到的就是全局最优的选中的小池子。这个小池子里的结果能作为训练online模型的伪label。\nGoal Set Predictor (online) 模型采用了encode+decode的办法。encoder部分是一层self-attention加上max pooling，decoder部分是2层MLP，输入是heatmap，输出是2K+1个值，分别对应K个2维坐标（goal set）和一个当前goal set的confidence。\n考虑到heatmap的概率分布比较散，可以采用N头同时运算。即N个goal set predictor输出N个2K+1的值，从当中选取confidence最高的那个goal set预测。为了运算效率的提升，这N头使用相同的self-attention层，但是不同的2个MLP。\n在训练过程中，采用了offline模型的伪label作为监督。上述offline中讲到的初始选定的小池子，在这里采用的是online模型的K个goal的set的预测。然后经过L次随机扰动（即不停随机选取邻居点，L=100），选取当中expected error（offline里的期望项）最小的那个set作为伪label。\n标记 $\\dot{y}$ ​为预测结果， $\\hat{y}$ ​为伪label，则loss的计算如下。即一一对应后的L1距离之和。\n$$\\mathcal{L_{set}(\\dot{y}, \\hat{y})} = \\sum_{i=1}^{k}\\mathcal{L}_{\\text{reg}}(\\dot{y}, \\hat{y})$$\n再考虑到采用了N头预测，这部分的loss将采用二分类的交叉熵。其中 $\\mu$ 为所有head的confidence，$\\nu$ 为label，只有expected error最低的label为1，别的为0。\n$$\\mathcal{L}\\text{head} = \\mathcal{L}{\\text{CE}}(\\mu, \\nu)$$\nTrajectory Completion 这一步和TNT做法类似。类似于dense goal encoding（2层MLP后过self-attention）最后过2层MLP来decode得到整条预测轨迹的state。采用teacher forcing技巧（因为只有一条gt）训练时只用gt的goal来算这条预测轨迹。Loss的算法和TNT一样，用的是点点之间的Huber loss。\n$$\\mathcal{L}{\\text{completion}} = \\sum{t=1}^{T}\\mathcal{L_{reg}}(\\hat{s}_t, s_t)$$\nLearning 训练分为两个stage。第一个stage使用gt轨迹训练除了goal set predictor的部分。即把dense的goal输入。获得大量的轨迹。\n$$\\mathcal{L}{s1} = \\mathcal{L}{lane} + \\mathcal{L}{goal}+ \\mathcal{L}{completion}$$\n第二个stage主要负责goal set predictor的部分。\n$$\\mathcal{L}{s2} = \\mathcal{L}{head} + \\mathcal{L}_{set}$$\n","permalink":"https://jianye0428.github.io/en/posts/tech/2022-07-09_densetnt_and_tnt/","summary":"TNT: Target-driveN Trajectory Prediction **ref link:** https://zhuanlan.zhihu.com/p/435953928 https://blog.csdn.net/weixin_40633696/article/details/124542807?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-2-124542807-blog-122758833.pc_relevant_vip_default\u0026amp;spm=1001.2101.3001.4242.2\u0026amp;utm_relevant_index=5 概览 在预测车辆的轨迹时, 需要尽可能考虑到车辆不同的情况，即不同的模态，如前行或左转，并预测出对应的概率。 模态的定义是比较模糊","title":"Target driveN Trajectory: DenseTNT and TNT"},{"content":"dp: https://juejin.cn/post/6844903993429196813\nknapsack problem: https://blog.csdn.net/qq_38410730/article/details/81667885\n完全背包问题: https://www.cnblogs.com/darkerg/p/15464987.html\nKnapSack 背包问题 Definiton 定义 背包问题是一种组合优化的NP完全问题:有N个物品和容量为W的背包，每个物品都有自己的体积w和价值v， 求拿哪些物品可以使得背包所装下的物品的总价值最大。如果限定每种物品只能选择0个或者1个，则称问题为0-1背包问题;如果不限定每种物品的数量，则问题称为无界背包问题和或者完全背包问题。\n0-1 背包问题 以 0-1 背包问题为例。我们可以定义一个二维数组 dp 存储最大价值，其中 dp[i][j] 表示前 i 件物品体积不超过 j 的情况下能达到的最大价值。在我们遍历到第 i 件物品时，在当前背包总容量为 j 的情况下，如果我们不将物品 i 放入背包，那么 dp[i][j] = dp[i-1][j]，即前 i 个物品的最大价值等于只取前 i-1 个物品时的最大价值；如果我们将物品 i 放入背包，假设第 i 件物品体积为 w，价值为 v，那么我们得到 dp[i][j] = dp[i-1][j-w] + v。我们只需在遍历过程中对这两种情况取最大值即可，总时间复杂度和空间复杂度都为 O(NW)。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 int knapsack(vector\u0026lt;int\u0026gt;\u0026amp; weights, vector\u0026lt;int\u0026gt;\u0026amp; values, int N, int W) { vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; dp(N+1, vector\u0026lt;int\u0026gt; (W+1, 0)); for (int i = 1; i \u0026lt;=N; ++i) { int w = weight[i-1], v = values[i-1]; for (int j = 1; j \u0026lt;= W; ++j) { if (j \u0026gt;= w) { dp[i][j] = max(dp[i-1][j], dp[i-1][j-w] + v); } else { dp[i][j] = dp[i-1][j]; } } } return dp[N][W]; } 空间压缩:\n1 2 3 4 5 6 7 8 9 10 int knapsack(vector\u0026lt;int\u0026gt;\u0026amp; weights, vector\u0026lt;int\u0026gt;\u0026amp; values, int N, int W) { vector\u0026lt;int\u0026gt; dp(W+1, 0); for (int i = 1; i \u0026lt;= N; ++i) { int w = weights[i-1], v = values[i-1]; for (j = W; j \u0026gt;= w; ++j) { dp[j] = max(dp[j], dp[j-w] + v); } } return dp[W]; } 完全背包问题 完全背包问题中，一个物品可以拿多次。对于拿多个物品的情况，我们只需考虑 dp[2][3] 即可，即 dp[2][5] = max(dp[1][5], dp[2][3] + 3)。这样，我们 就得到了完全背包问题的状态转移方程：dp[i][j] = max(dp[i-1][j], dp[i][j-w] + v)，其与 0-1背包问题的差别仅仅是把状态转移方程中的第二个 i-1 变成了 i。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 int knapsack(vector\u0026lt;int\u0026gt;\u0026amp; weights, vector\u0026lt;int\u0026gt;\u0026amp; values, int N, int W) { vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; dp(N+1, vector\u0026lt;int\u0026gt;(W+1, 0)); for (int i = 1; i \u0026lt;= N; ++i) { int w = weights[i-1], v = values[i-1]; for (int j = 1; j \u0026lt;= W; ++j) { if (j \u0026gt;= w) { dp[i][j] = max(dp[i-1][j], dp[i][j-w] + v); } else { dp[i][j] = dp[i-1][j]; } } } return dp[N][W]; } 空间压缩:\n1 2 3 4 5 6 7 8 9 10 int knapsack(vector\u0026lt;int\u0026gt;\u0026amp; weights, vector\u0026lt;int\u0026gt;\u0026amp; values, int N, int W) { vector\u0026lt;int\u0026gt; dp(W+1, 0); for (int i = 1; i \u0026lt;= N; ++i) { int w = weights[i-1], v = values[i-1]; for (int j = w; j \u0026lt;= W; ++j) { dp[j] = max(dp[j], dp[j-w] + v); } } return dp[W]; } ","permalink":"https://jianye0428.github.io/en/posts/tech/2022-06-27_knapsack/","summary":"dp: https://juejin.cn/post/6844903993429196813 knapsack problem: https://blog.csdn.net/qq_38410730/article/details/81667885 完全背包问题: https://www.cnblogs.com/darkerg/p/15464987.html KnapSack 背包问题 Definiton 定义 背包问题是一种组合优化的NP完全问题:有N个物品和容量为W的背包，每个物品都有自己的体积w和价值v","title":"KnapSack Problem"},{"content":"Sorting Algotithms Collection Quick Sort 快速排序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 void quick_sort(vector\u0026lt;int\u0026gt;\u0026amp; nums, int l, int r) { if (l + 1 \u0026gt;= r) { return; } int first = l, last = r - 1, key = nums[first]; while (first \u0026lt; last) { while (first \u0026lt; last \u0026amp;\u0026amp; nums[last] \u0026gt;= key) { --last; } nums[first] = nums[last]; while (first \u0026lt; last \u0026amp;\u0026amp; nums[first] \u0026lt;= key) { ++first; } nums[last] = nums[first]; } nums[first] = key; quick_sort(nums, l, first); quick_sort(nums, first + 1, r); } Merge Sort 归并排序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 void merge_sort(vector\u0026lt;int\u0026gt;\u0026amp; nums, int l, int r, vector\u0026lt;int\u0026gt;\u0026amp; temp) { if (l + 1 \u0026gt;= r) { return; } // divide int m = l + (r - l) / 2; merge_sort(nums, l, m, temp); merge_sort(nums, m, r, temp); // conquer int p = l, q = m, i = l; while (q \u0026lt; m || q \u0026lt; r\u0026gt;) { if (q \u0026gt;= r || q \u0026lt; r) { if (q \u0026gt;= r || (p \u0026lt; m \u0026amp;\u0026amp; nums[p] \u0026lt;= nums[q])) { temp[i++] = nums[p++]; } else { temp[i++] = nums[q++]; } } } for (int i = l; i \u0026lt; r; ++i) { nums[i] = temp[i]; } } Insertion Sort 插入排序 1 2 3 4 5 6 7 void insertion_sort(vector\u0026lt;int\u0026gt;\u0026amp; nums, int n) { for (int i = 0; i \u0026lt; n; ++i) { for (int j = i; j \u0026gt; 0 \u0026amp;\u0026amp; nums[j] \u0026lt; nums[j-1]; --j) { swap(nums[j], nums[j-1]); } } } Bubble Sort 冒泡排序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void bubble_sort(vector\u0026lt;int\u0026gt;\u0026amp; nums, int n) { bool swapped; for (int i = 1; i \u0026lt; n; ++i) { swapped = false; for (int j = 1; j \u0026lt; n - i + 1; ++j) { if (nums[j] \u0026lt; nums[j-1]) { swap(nums[j], nums[j-1]); swapped = true; } } if (!swapped) { break; } } } Selection Sort 选择排序 1 2 3 4 5 6 7 8 9 10 void selection_sort(vector\u0026lt;int\u0026gt;\u0026amp; nums, int n) { int mid; for (int i = 0; i \u0026lt; n - 1; ++i) { mid = i; for (int j = i + 1; j \u0026lt; n; ++j) { mid = j; } } swap(nums[mid], nums[i]); } ","permalink":"https://jianye0428.github.io/en/posts/tech/2022-06-27_sort_algo/","summary":"Sorting Algotithms Collection Quick Sort 快速排序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 void quick_sort(vector\u0026lt;int\u0026gt;\u0026amp; nums, int l, int r) { if (l + 1 \u0026gt;= r) { return; } int first = l, last = r - 1, key = nums[first]; while (first \u0026lt; last) { while (first \u0026lt; last \u0026amp;\u0026amp; nums[last] \u0026gt;=","title":"Sorting Algorithms"},{"content":"ref link:\n[1] https://blog.csdn.net/qq_41897558/article/details/120087113 [2] https://zhuanlan.zhihu.com/p/355131328 ref code:\n[1]https://github.com/xk-huang/yet-another-vectornet\n[2]https://github.com/DQSSSSS/VectorNet\nNovel Highlights (1) 使用矢量化的高精地图以及障碍物的历史轨迹，从而避免有损渲染以及ConvNet编码(计算开销比较大)。\n(2) 设计子图网络以及全局图网络，建模低阶以及高阶交互\n(3) auxiliary task 提高网络性能\nVecotorNet 网络介绍 轨迹和地图的向量表示 Representing trajectories and HD maps lane可以表示为splines，人行道可以表示为一个很多个点组成的polygon，stop sign标记可以表示为单一个点。 对于agent来说，他们的轨迹也是一种splines。 这些元素都可以向量表示。\n对于地图的特征：选择一个start point和朝向，等间距均匀采样关键点，并于相邻的关键点相连为向量 对于agent轨迹，按照0.1s sample关键点，并将它们连接成向量。 通过向量化的过程，可以得到折线polylines，这个polylines和轨迹、地图标注之间是一一对应的。如果给定的时空间隔足够小，得到的这些折线就与原始地图和轨迹十分接近。\n我们将属于折线 $P_j$​ 的每一个向量$v_i$看出图中的一个节点，节点特征如下:\n$$v_i = [d_i^s, d_i^e, a_i, j]$$\n其中前两个vector分别是vector的start point和end point的坐标，可以是(x,y)或者(x,y,z)三维的形式 第三个向量则是attribute属性的特征，比如object的类型，轨迹的时间戳，道路的特征，道路限速等 最后一个是障碍物id，表示 $v_i$ ​属于 $P_j$ Polyline 子图构建 对于一个Polyline P, 它的节点有 ${v_1,v_2,\u0026hellip;,v_p}$， 可以定义一个子图网络：\n$$v_i^{l+1} = \\varphi_{rel}(g_{enc}(v_i^{(l)}), \\varphi({g_{enc}(v_j^{(l)})}))$$\n$v_i^{(l)}$​ 代表第i个节点第L层的节点特征。\n$g_{enc}(\\cdot)$代表节点的变换，实践中采用MLP来实现。\n$\\varphi_{agg}(\\cdot)$代表特征聚合，用来从相邻的节点来获取信息，实践中采用的是max_pooling。\n$\\varphi_{rel}(\\cdot)$代表vi和周围节点的关系，实践中采用的是concate的操作。\n最后经过多层的堆叠，来获取整个Polyline级别的特征：\n$$P = \\varphi_{agg}(v_i^{L_p})$$\n这里， $φ_{agg}(⋅)$也是max pooling操作.\n全局图的高阶交互 Global graph for high-order interactions 经过上面的子图进行低阶模型建模后，现在有了polyline级别节点的特征${p_1,p_2,\u0026hellip;,p_P}$.\n为了建立高阶的交互，需要建立一个global的交互图，详见论文图2的第3个子图。\n$$P_i^{l+1} = GNN(p^l_i, A)$$\n$p_i^l$​代表polyline节点的集合\nA代表邻接矩阵，实践中采用全链接\n$GNN(⋅)$代表一层的GNN网络，实践中采用的是self attention layer： $$GNN(P) = softmax(P_Q P_K^T)P_V$$\n其中，P是node的feature matrix， $P_Q$,$P_k$,$P_v$ ​则是它的线性投影。\n经过了全局的网络之后，就生成了节点的特征$P^{L_t}_i$，其中Lt是全局GNN网络的层数。然后将$P^{(L_t)}_i$放入decoder进行轨迹的生成:\n$$v_i^{future} = \\varphi_{traj}(P_i^{L_t})$$\n论文中，decoder $φ_{traj}(⋅)$ 使用的是MLP，当然也可以用MultiPath中anchor-based的方法或者variational RNNs 来进行多模态轨迹预测。\n辅助任务训练 auxiliary graph completion task 为了让全局交互图能更好地捕捉不同轨迹和地图元素之间的交互信息，论文还提出了一个辅助的任务：在训练过程中，随机mask掉一些节点的特征，然后尝试去还原被掩盖的节点特征:\n$$\\hat{P}i = \\varphi{node}(P_i^{L_t})$$\n这里节点的decoder $φ_{node}(⋅)$ 也是一个MLP，只在训练的时候使用,在inference过程中不使用。\n损失函数 Loss Function 多任务训练目标， multi-task training task:\n$$\\mathcal{L} = \\mathcal{L_{traj}} + \\alpha \\mathcal{L_{node}}$$\n$L_{traj}​$: negative Gaussian log-likelihood loss\n$L_{node}$​: 是预测的节点和被掩盖节点的huber损失函数\n其中， negative Gaussian Log Likelihood 损失函数为:\n$$L(x, y) = -\\log P(y) = - \\log P(y|\\mu(x), \\sum(x))$$\nwhere,\n$$p(y) = p(y∣μ,Σ)=1(2π)n/2∣Σ∣1/2exp−12(y−μ)⊤Σ−1(y−μ)$$\nHuber 损失函数为:\n$$ L(Y|f(x))= \\begin{cases} \\frac{1}{2} (Y-f(x))^2, \u0026amp; |Y-f(x)|\u0026lt;= \\delta \\\\ \\delta |Y-f(x)| - \\frac{1}{2}\\delta^2, \u0026amp; |Y-f(x)| \u0026gt; \\delta \\end{cases} $$\n整理 VectorNet数据处理部分:\n对actor的处理:\n输入: 取轨迹点，每两个轨迹点构建vector, 形式为(x1, x2, y1, y2), 其他特征(object type, timestamp, track_id) 对lane node的处理:\n输入: 针对lane segment 的点，求polyline，原则上求lane segment的左右边界的点的向量(x_start, x_end, y_start, y_end, turn_direction, traffic_control, is_intersection, lane_id) 网络部分:\n构建subgraphnet: 针对每一个polyline，通过mlp和maxpool构构建subgraphnet\n构建globalgraphnet: 以每个polyline作为graph node，构建全局图网络，采用全链接，通过自注意力机制$GNN(P) = softmax(P_Q, P_K)^T(P_V)$\n轨迹生成:\n将全局网络的节点特征，通过mlp进行轨迹生成。\n","permalink":"https://jianye0428.github.io/en/posts/tech/2022-06-20_vectornet/","summary":"ref link: [1] https://blog.csdn.net/qq_41897558/article/details/120087113 [2] https://zhuanlan.zhihu.com/p/355131328 ref code: [1]https://github.com/xk-huang/yet-another-vectornet [2]https://github.com/DQSSSSS/VectorNet Novel Highlights (1) 使用矢量化的高精地图以及障碍物的历史轨迹，从而避免有损渲染以及ConvNet编码(计算开销比较大)。 (2) 设计子图网络","title":"VectorNet: Encoding HD Maps and Agent Dynamics from Vectorized Representation"},{"content":"link: https://chenllliang.github.io/2020/02/04/dataloader/\ndistributed training with dataloader and dataset: https://blog.csdn.net/zyq12345678/article/details/90268668\nhttps://cloud.tencent.com/developer/article/1877393\nDataset PyTorch为我们提供的两个Dataset和DataLoader类分别负责可被Pytorch使用的数据集的创建以及向训练传递数据的任务。如果想个性化自己的数据集或者数据传递方式，也可以自己重写子类。\nDataset是DataLoader实例化的一个参数，所以这篇文章会先从Dataset的源代码讲起，然后讲到DataLoader，关注主要函数，少细枝末节，目的是使大家学会自定义自己的数据集。\n什么时候使用Dataset CIFAR10是CV训练中经常使用到的一个数据集，在PyTorch中CIFAR10是一个写好的Dataset，我们使用时只需以下代码：\n1 data = datasets.CIFAR10(\u0026#34;./data/\u0026#34;, transform=transform, train=True, download=True) datasets.CIFAR10就是一个Datasets子类，data是这个类的一个实例。\n我们有的时候需要用自己在一个文件夹中的数据作为数据集，这个时候，我们可以使用ImageFolder这个方便的API。\n1 FaceDataset = datasets.ImageFolder(\u0026#39;./data\u0026#39;, transform=img_transform) 如何定义一个自己的数据集合 torch.utils.data.dataset 是一个表示数据集的抽象类。任何自定义的数据集都需要继承这个类并覆写相关方法。\n所谓数据集，其实就是一个负责处理索引(index)到样本(sample)映射的一个类(class)。\nPytorch提供两种数据集：\nMap式数据集 Iterable式数据集 Map式数据集 一个Map式的数据集必须要重写__getitem__(self, index), len(self) 两个内建方法，用来表示从索引到样本的映射(Map).\n这样一个数据集dataset，举个例子，当使用dataset[idx]命令时，可以在你的硬盘中读取你的数据集中第idx张图片以及其标签（如果有的话）;len(dataset)则会返回这个数据集的容量。\n例子-1： 自己实验中写的一个例子：这里我们的图片文件储存在“./data/faces/”文件夹下，图片的名字并不是从1开始，而是从final_train_tag_dict.txt这个文件保存的字典中读取，label信息也是用这个文件中读取。大家可以照着上面的注释阅读这段代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from torch.utils import data import numpy as np from PIL import Image class face_dataset(data.Dataset): def __init__(self): self.file_path = \u0026#39;./data/faces/\u0026#39; f=open(\u0026#34;final_train_tag_dict.txt\u0026#34;,\u0026#34;r\u0026#34;) self.label_dict=eval(f.read()) f.close() def __getitem__(self,index): label = list(self.label_dict.values())[index-1] img_id = list(self.label_dict.keys())[index-1] img_path = self.file_path+str(img_id)+\u0026#34;.jpg\u0026#34; img = np.array(Image.open(img_path)) return img,label def __len__(self): return len(self.label_dict) 下面我们看一下官方MNIST数据集的例子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 class MNIST(data.Dataset): \u0026#34;\u0026#34;\u0026#34;`MNIST \u0026lt;http://yann.lecun.com/exdb/mnist/\u0026gt;`_ Dataset. Args: root (string): Root directory of dataset where ``processed/training.pt`` and ``processed/test.pt`` exist. train (bool, optional): If True, creates dataset from ``training.pt``, otherwise from ``test.pt``. download (bool, optional): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again. transform (callable, optional): A function/transform that takes in an PIL image and returns a transformed version. E.g, ``transforms.RandomCrop`` target_transform (callable, optional): A function/transform that takes in the target and transforms it. \u0026#34;\u0026#34;\u0026#34; urls = [ \u0026#39;http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\u0026#39;, \u0026#39;http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\u0026#39;, \u0026#39;http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\u0026#39;, \u0026#39;http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\u0026#39;, ] raw_folder = \u0026#39;raw\u0026#39; processed_folder = \u0026#39;processed\u0026#39; training_file = \u0026#39;training.pt\u0026#39; test_file = \u0026#39;test.pt\u0026#39; classes = [\u0026#39;0 - zero\u0026#39;, \u0026#39;1 - one\u0026#39;, \u0026#39;2 - two\u0026#39;, \u0026#39;3 - three\u0026#39;, \u0026#39;4 - four\u0026#39;, \u0026#39;5 - five\u0026#39;, \u0026#39;6 - six\u0026#39;, \u0026#39;7 - seven\u0026#39;, \u0026#39;8 - eight\u0026#39;, \u0026#39;9 - nine\u0026#39;] class_to_idx = {_class: i for i, _class in enumerate(classes)} @property def targets(self): if self.train: return self.train_labels else: return self.test_labels def __init__(self, root, train=True, transform=None, target_transform=None, download=False): self.root = os.path.expanduser(root) self.transform = transform self.target_transform = target_transform self.train = train # training set or test set if download: self.download() if not self._check_exists(): raise RuntimeError(\u0026#39;Dataset not found.\u0026#39; + \u0026#39; You can use download=True to download it\u0026#39;) if self.train: self.train_data, self.train_labels = torch.load( os.path.join(self.root, self.processed_folder, self.training_file)) else: self.test_data, self.test_labels = torch.load( os.path.join(self.root, self.processed_folder, self.test_file)) def __getitem__(self, index): \u0026#34;\u0026#34;\u0026#34; Args: index (int): Index Returns: tuple: (image, target) where target is index of the target class. \u0026#34;\u0026#34;\u0026#34; if self.train: img, target = self.train_data[index], self.train_labels[index] else: img, target = self.test_data[index], self.test_labels[index] # doing this so that it is consistent with all other datasets # to return a PIL Image img = Image.fromarray(img.numpy(), mode=\u0026#39;L\u0026#39;) if self.transform is not None: img = self.transform(img) if self.target_transform is not None: target = self.target_transform(target) return img, target def __len__(self): if self.train: return len(self.train_data) else: return len(self.test_data) def _check_exists(self): return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\ os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file)) def download(self): \u0026#34;\u0026#34;\u0026#34;Download the MNIST data if it doesn\u0026#39;t exist in processed_folder already.\u0026#34;\u0026#34;\u0026#34; from six.moves import urllib import gzip if self._check_exists(): return # download files try: os.makedirs(os.path.join(self.root, self.raw_folder)) os.makedirs(os.path.join(self.root, self.processed_folder)) except OSError as e: if e.errno == errno.EEXIST: pass else: raise for url in self.urls: print(\u0026#39;Downloading \u0026#39; + url) data = urllib.request.urlopen(url) filename = url.rpartition(\u0026#39;/\u0026#39;)[2] file_path = os.path.join(self.root, self.raw_folder, filename) with open(file_path, \u0026#39;wb\u0026#39;) as f: f.write(data.read()) with open(file_path.replace(\u0026#39;.gz\u0026#39;, \u0026#39;\u0026#39;), \u0026#39;wb\u0026#39;) as out_f, \\ gzip.GzipFile(file_path) as zip_f: out_f.write(zip_f.read()) os.unlink(file_path) # process and save as torch files print(\u0026#39;Processing...\u0026#39;) training_set = ( read_image_file(os.path.join(self.root, self.raw_folder, \u0026#39;train-images-idx3-ubyte\u0026#39;)), read_label_file(os.path.join(self.root, self.raw_folder, \u0026#39;train-labels-idx1-ubyte\u0026#39;)) ) test_set = ( read_image_file(os.path.join(self.root, self.raw_folder, \u0026#39;t10k-images-idx3-ubyte\u0026#39;)), read_label_file(os.path.join(self.root, self.raw_folder, \u0026#39;t10k-labels-idx1-ubyte\u0026#39;)) ) with open(os.path.join(self.root, self.processed_folder, self.training_file), \u0026#39;wb\u0026#39;) as f: torch.save(training_set, f) with open(os.path.join(self.root, self.processed_folder, self.test_file), \u0026#39;wb\u0026#39;) as f: torch.save(test_set, f) print(\u0026#39;Done!\u0026#39;) def __repr__(self): fmt_str = \u0026#39;Dataset \u0026#39; + self.__class__.__name__ + \u0026#39;\\n\u0026#39; fmt_str += \u0026#39; Number of datapoints: {}\\n\u0026#39;.format(self.__len__()) tmp = \u0026#39;train\u0026#39; if self.train is True else \u0026#39;test\u0026#39; fmt_str += \u0026#39; Split: {}\\n\u0026#39;.format(tmp) fmt_str += \u0026#39; Root Location: {}\\n\u0026#39;.format(self.root) tmp = \u0026#39; Transforms (if any): \u0026#39; fmt_str += \u0026#39;{0}{1}\\n\u0026#39;.format(tmp, self.transform.__repr__().replace(\u0026#39;\\n\u0026#39;, \u0026#39;\\n\u0026#39; + \u0026#39; \u0026#39; * len(tmp))) tmp = \u0026#39; Target Transforms (if any): \u0026#39; fmt_str += \u0026#39;{0}{1}\u0026#39;.format(tmp, self.target_transform.__repr__().replace(\u0026#39;\\n\u0026#39;, \u0026#39;\\n\u0026#39; + \u0026#39; \u0026#39; * len(tmp))) return fmt_str Iterable数据集 一个Iterable（迭代）式数据集是抽象类data.IterableDataset的子类，并且覆写了__iter__方法成为一个迭代器。这种数据集主要用于数据大小未知，或者以流的形式的输入，本地文件不固定的情况，需要以迭代的方式来获取样本索引。\n关于迭代器与生成器的知识可以参见博主的另一篇文章Python迭代器与生成器介绍及在Pytorch源码中应用[https://chenllliang.github.io/2020/02/06/PyIter/]。\nDataLoader Data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset. –PyTorch Documents\n一般来说PyTorch中深度学习训练的流程是这样的：\n创建Dateset Dataset传递给DataLoader DataLoader迭代产生训练数据提供给模型 对应的一般都会有这三部分代码\n1 2 3 4 5 6 7 8 # 创建Dateset(可以自定义) dataset = face_dataset # Dataset部分自定义过的face_dataset # Dataset传递给DataLoader dataloader = torch.utils.data.DataLoader(dataset,batch_size=64,shuffle=False,num_workers=8) # DataLoader迭代产生训练数据提供给模型 for i in range(epoch): for index,(img,label) in enumerate(dataloader): pass 到这里应该就PyTorch的数据集和数据传递机制应该就比较清晰明了了。Dataset负责建立索引到样本的映射，DataLoader负责以特定的方式从数据集中迭代的产生 一个个batch的样本集合。在enumerate过程中实际上是dataloader按照其参数sampler规定的策略调用了其dataset的getitem方法。\n参数介绍 先看一下实例化一个DataLoader所需的参数，我们只关注几个重点即可。\n1 2 3 4 DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None) 参数介绍:\ndataset (Dataset) – 定义好的Map式或者Iterable式数据集。 batch_size (python:int, optional) – 一个batch含有多少样本 (default: 1)。 shuffle (bool, optional) – 每一个epoch的batch样本是相同还是随机 (default: False)。 sampler (Sampler, optional) – 决定数据集中采样的方法. 如果有，则shuffle参数必须为False。 batch_sampler (Sampler, optional) – 和 sampler 类似，但是一次返回的是一个batch内所有样本的index。和 batch_size, shuffle, sampler, and drop_last 三个参数互斥。 num_workers (python:int, optional) – 多少个子程序同时工作来获取数据，多线程。 (default: 0) collate_fn (callable, optional) – 合并样本列表以形成小批量。 pin_memory (bool, optional) – 如果为True，数据加载器在返回前将张量复制到CUDA固定内存中。 drop_last (bool, optional) – 如果数据集大小不能被batch_size整除，设置为True可删除最后一个不完整的批处理。如果设为False并且数据集的大小不能被batch_size整除，则最后一个batch将更小。(default: False) timeout (numeric, optional) – 如果是正数，表明等待从worker进程中收集一个batch等待的时间，若超出设定的时间还没有收集到，那就不收集这个内容了。这个numeric应总是大于等于0。 (default: 0) worker_init_fn (callable, optional) – 每个worker初始化函数 (default: None) dataset 没什么好说的，很重要，需要按照前面所说的两种dataset定义好，完成相关函数的重写。\nbatch_size 也没啥好说的，就是训练的一个批次的样本数。\nshuffle 表示每一个epoch中训练样本的顺序是否相同，一般True。\n采样器 sampler 重点参数，采样器，是一个迭代器。PyTorch提供了多种采样器，用户也可以自定义采样器。\n所有sampler都是继承 torch.utils.data.sampler.Sampler这个抽象类。\n关于迭代器的基础知识在博主这篇文章中可以找到Python迭代器与生成器介绍及在Pytorch源码中应用。[]\n1 2 3 4 5 6 7 8 9 class Sampler(object): # \u0026#34;\u0026#34;\u0026#34;Base class for all Samplers. # Every Sampler subclass has to provide an __iter__ method, providing a way # to iterate over indices of dataset elements, and a __len__ method that # returns the length of the returned iterators. # \u0026#34;\u0026#34;\u0026#34; # 一个 迭代器 基类 def __init__(self, data_source): pass def __iter__(self): raise NotImplementedError def __len__(self): raise NotImplementedError PyTorch自带的Sampler SequentialSampler RandomSampler SubsetRandomSampler WeightedRandomSampler SequentialSampler 很好理解就是顺序采样器。\n其原理是首先在初始化的时候拿到数据集data_source，之后在__iter__方法中首先得到一个和data_source一样长度的range可迭代器。每次只会返回一个索引值。\n1 2 3 4 5 6 7 8 9 class SequentialSampler(Sampler): # r\u0026#34;\u0026#34;\u0026#34;Samples elements sequentially, always in the same order. # Arguments: # data_source (Dataset): dataset to sample from # \u0026#34;\u0026#34;\u0026#34; # 产生顺序 迭代器 def __init__(self, data_source): self.data_source = data_source def __iter__(self): return iter(range(len(self.data_source))) def __len__(self): return len(self.data_source) 参数作用:\ndata_source: 同上 num_sampler: 指定采样的数量，默认是所有。 replacement: 若为True，则表示可以重复采样，即同一个样本可以重复采样，这样可能导致有的样本采样不到。所以此时我们可以设置num_samples来增加采样数量使得每个样本都可能被采样到。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class RandomSampler(Sampler): # r\u0026#34;\u0026#34;\u0026#34;Samples elements randomly. If without replacement, then sample from a shuffled dataset. # If with replacement, then user can specify ``num_samples`` to draw. # Arguments: # data_source (Dataset): dataset to sample from # num_samples (int): number of samples to draw, default=len(dataset) # replacement (bool): samples are drawn with replacement if ``True``, default=False # \u0026#34;\u0026#34;\u0026#34; def __init__(self, data_source, replacement=False, num_samples=None): self.data_source = data_source self.replacement = replacement self.num_samples = num_samples if self.num_samples is not None and replacement is False: raise ValueError(\u0026#34;With replacement=False, num_samples should not be specified, \u0026#34; \u0026#34;since a random permute will be performed.\u0026#34;) if self.num_samples is None: self.num_samples = len(self.data_source) if not isinstance(self.num_samples, int) or self.num_samples \u0026lt;= 0: raise ValueError(\u0026#34;num_samples should be a positive integeral \u0026#34; \u0026#34;value, but got num_samples={}\u0026#34;.format(self.num_samples)) if not isinstance(self.replacement, bool): raise ValueError(\u0026#34;replacement should be a boolean value, but got \u0026#34; \u0026#34;replacement={}\u0026#34;.format(self.replacement)) def __iter__(self): n = len(self.data_source) if self.replacement: return iter(torch.randint(high=n, size=(self.num_samples,), dtype=torch.int64).tolist()) return iter(torch.randperm(n).tolist()) def __len__(self): return len(self.data_source) 这个采样器常见的使用场景是将训练集划分成训练集和验证集:\n1 2 3 4 5 6 7 8 9 10 class SubsetRandomSampler(Sampler): # r\u0026#34;\u0026#34;\u0026#34;Samples elements randomly from a given list of indices, without replacement. # Arguments: # indices (sequence): a sequence of indices # \u0026#34;\u0026#34;\u0026#34; def __init__(self, indices): self.indices = indices def __iter__(self): return (self.indices[i] for i in torch.randperm(len(self.indices))) def __len__(self): return len(self.indices) batch_sampler 前面的采样器每次都只返回一个索引，但是我们在训练时是对批量的数据进行训练，而这个工作就需要BatchSampler来做。也就是说BatchSampler的作用就是将前面的Sampler采样得到的索引值进行合并，当数量等于一个batch大小后就将这一批的索引值返回。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 class BatchSampler(Sampler): # Wraps another sampler to yield a mini-batch of indices. # Args: # sampler (Sampler): Base sampler. # batch_size (int): Size of mini-batch. # drop_last (bool): If ``True``, the sampler will drop the last batch if # its size would be less than ``batch_size`` # Example: # \u0026gt;\u0026gt;\u0026gt; list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False)) # [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] # \u0026gt;\u0026gt;\u0026gt; list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True)) # [[0, 1, 2], [3, 4, 5], [6, 7, 8]] # 批次采样 def __init__(self, sampler, batch_size, drop_last): if not isinstance(sampler, Sampler): raise ValueError(\u0026#34;sampler should be an instance of \u0026#34; \u0026#34;torch.utils.data.Sampler, but got sampler={}\u0026#34; .format(sampler)) if not isinstance(batch_size, _int_classes) or isinstance(batch_size, bool) or \\ batch_size \u0026lt;= 0: raise ValueError(\u0026#34;batch_size should be a positive integeral value, \u0026#34; \u0026#34;but got batch_size={}\u0026#34;.format(batch_size)) if not isinstance(drop_last, bool): raise ValueError(\u0026#34;drop_last should be a boolean value, but got \u0026#34; \u0026#34;drop_last={}\u0026#34;.format(drop_last)) self.sampler = sampler self.batch_size = batch_size self.drop_last = drop_last def __iter__(self): batch = [] for idx in self.sampler: batch.append(idx) if len(batch) == self.batch_size: yield batch batch = [] if len(batch) \u0026gt; 0 and not self.drop_last: yield batch def __len__(self): if self.drop_last: return len(self.sampler) // self.batch_size else: return (len(self.sampler) + self.batch_size - 1) // self.batch_size 多线程 num_workers 参数表示同时参与数据读取的线程数量，多线程技术可以加快数据读取，提供GPU/CPU利用率。\n未来会出一篇文章讲一讲PyTorch多线程实现的原理。\nDataLoader 和 Dataset 简单举例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # construct dataset import torch from torch.utils.data import Dataset,DataLoader class MyDataset(Dataset): def __init__(self): self.data = torch.tensor([[1,2,3],[2,3,4],[3,4,5],[4,5,6]]) self.label = torch.LongTensor([1,1,0,0]) def __getitem__(self,index): return self.data[index],self.label[index] def __len__(self): return len(self.data) # dataloader mydataloader = DataLoader(dataset=mydataset, batch_size = 2, shuffle=True) for i, (data, label) in enumerate(mydataloader): print(data, label) DEMO1 - MLP\u0026rsquo;s Dataset and DataLoader 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 dim_output = 2 class TrainValidDataset(Dataset): \u0026#39;\u0026#39;\u0026#39; Args: - root_dir (string): Directory containing all folders with different dates, each folder containing .cruise.h5 data files. \u0026#39;\u0026#39;\u0026#39; def __init__(self, list_of_files): self.list_of_files_ = list_of_files self.data_size_until_this_file_ = [] self.dataset_size = 0 for file in self.list_of_files_: with h5py.File(file, \u0026#39;r\u0026#39;) as h5_file: data_size = h5_file[list(h5_file.keys())[0]].shape[0] self.dataset_size += data_size self.data_size_until_this_file_.append(self.dataset_size) print (\u0026#39;Total size of dataset: {}\u0026#39;.format(self.data_size_until_this_file_)) def __len__(self): return self.dataset_size def __getitem__(self, index): bin_idx = self.FindBin(index, 0, len( self.data_size_until_this_file_)-1) with h5py.File(self.list_of_files_[bin_idx], \u0026#39;r\u0026#39;) as h5_file: idx_offset = self.data_size_until_this_file_[bin_idx] - \\ h5_file[list(h5_file.keys())[0]].shape[0] data = h5_file[list(h5_file.keys())[0]][index-idx_offset] label = data[-dim_output:] label[0] = (label[0] \u0026gt; 0.0).astype(float) return data[:-dim_output], label # Binary search to expedite the data-loading process. def FindBin(self, index, start, end): if (start == end): return start mid = int((start+end)/2.0) if (self.data_size_until_this_file_[mid] \u0026lt;= index): return self.FindBin(index, mid+1, end) else: return self.FindBin(index, start, mid) # search all the files in the directory def getListOfFiles(dirName): listOfFiles = os.listdir(dirName) allFiles = list() for entry in listOfFiles: fullPath = os.path.join(dirName, entry) if os.path.isdir(fullPath): allFiles = allFiles + getListOfFiles(fullPath) else: allFiles.append(fullPath) return allFiles if __name__ == \u0026#39;__main__\u0026#39;: list_of_training_files = getListOfFiles(\u0026#39;data\u0026#39;) train_dataset = TrainValidDataset(list_of_training_files) myDataLoader = DataLoader(dataset=train_dataset, batch_size=2, drop_last=True, shuffle=True) for i, (data, label) in enumerate(myDataLoader): print(data.shape) DEMO2 - LaneGCN\u0026rsquo;s Dataset and DataLoader dataset description:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 class ArgoDataset(Dataset): def __init__(self, split, config, train=True): self.config = config self.train = train if \u0026#39;preprocess\u0026#39; in config and config[\u0026#39;preprocess\u0026#39;]: if train: self.split = np.load(self.config[\u0026#39;preprocess_train\u0026#39;], allow_pickle=True) else: self.split = np.load(self.config[\u0026#39;preprocess_val\u0026#39;], allow_pickle=True) else: self.avl = ArgoverseForecastingLoader(split) self.avl.seq_list = sorted(self.avl.seq_list) self.am = ArgoverseMap() if \u0026#39;raster\u0026#39; in config and config[\u0026#39;raster\u0026#39;]: #TODO: DELETE self.map_query = MapQuery(config[\u0026#39;map_scale\u0026#39;]) def __getitem__(self, idx): if \u0026#39;preprocess\u0026#39; in self.config and self.config[\u0026#39;preprocess\u0026#39;]: data = self.split[idx] if self.train and self.config[\u0026#39;rot_aug\u0026#39;]: new_data = dict() for key in [\u0026#39;city\u0026#39;, \u0026#39;orig\u0026#39;, \u0026#39;gt_preds\u0026#39;, \u0026#39;has_preds\u0026#39;]: if key in data: new_data[key] = ref_copy(data[key]) dt = np.random.rand() * self.config[\u0026#39;rot_size\u0026#39;]#np.pi * 2.0 theta = data[\u0026#39;theta\u0026#39;] + dt new_data[\u0026#39;theta\u0026#39;] = theta new_data[\u0026#39;rot\u0026#39;] = np.asarray([ [np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]], np.float32) rot = np.asarray([ [np.cos(-dt), -np.sin(-dt)], [np.sin(-dt), np.cos(-dt)]], np.float32) new_data[\u0026#39;feats\u0026#39;] = data[\u0026#39;feats\u0026#39;].copy() new_data[\u0026#39;feats\u0026#39;][:, :, :2] = np.matmul(new_data[\u0026#39;feats\u0026#39;][:, :, :2], rot) new_data[\u0026#39;ctrs\u0026#39;] = np.matmul(data[\u0026#39;ctrs\u0026#39;], rot) graph = dict() for key in [\u0026#39;num_nodes\u0026#39;, \u0026#39;turn\u0026#39;, \u0026#39;control\u0026#39;, \u0026#39;intersect\u0026#39;, \u0026#39;pre\u0026#39;, \u0026#39;suc\u0026#39;, \u0026#39;lane_idcs\u0026#39;, \u0026#39;left_pairs\u0026#39;, \u0026#39;right_pairs\u0026#39;, \u0026#39;left\u0026#39;, \u0026#39;right\u0026#39;]: graph[key] = ref_copy(data[\u0026#39;graph\u0026#39;][key]) graph[\u0026#39;ctrs\u0026#39;] = np.matmul(data[\u0026#39;graph\u0026#39;][\u0026#39;ctrs\u0026#39;], rot) graph[\u0026#39;feats\u0026#39;] = np.matmul(data[\u0026#39;graph\u0026#39;][\u0026#39;feats\u0026#39;], rot) new_data[\u0026#39;graph\u0026#39;] = graph data = new_data else: new_data = dict() for key in [\u0026#39;city\u0026#39;, \u0026#39;orig\u0026#39;, \u0026#39;gt_preds\u0026#39;, \u0026#39;has_preds\u0026#39;, \u0026#39;theta\u0026#39;, \u0026#39;rot\u0026#39;, \u0026#39;feats\u0026#39;, \u0026#39;ctrs\u0026#39;, \u0026#39;graph\u0026#39;]: if key in data: new_data[key] = ref_copy(data[key]) data = new_data if \u0026#39;raster\u0026#39; in self.config and self.config[\u0026#39;raster\u0026#39;]: data.pop(\u0026#39;graph\u0026#39;) x_min, x_max, y_min, y_max = self.config[\u0026#39;pred_range\u0026#39;] cx, cy = data[\u0026#39;orig\u0026#39;] region = [cx + x_min, cx + x_max, cy + y_min, cy + y_max] raster = self.map_query.query(region, data[\u0026#39;theta\u0026#39;], data[\u0026#39;city\u0026#39;]) data[\u0026#39;raster\u0026#39;] = raster return data data = self.read_argo_data(idx) data = self.get_obj_feats(data) data[\u0026#39;idx\u0026#39;] = idx if \u0026#39;raster\u0026#39; in self.config and self.config[\u0026#39;raster\u0026#39;]: x_min, x_max, y_min, y_max = self.config[\u0026#39;pred_range\u0026#39;] cx, cy = data[\u0026#39;orig\u0026#39;] region = [cx + x_min, cx + x_max, cy + y_min, cy + y_max] raster = self.map_query.query(region, data[\u0026#39;theta\u0026#39;], data[\u0026#39;city\u0026#39;]) data[\u0026#39;raster\u0026#39;] = raster return data data[\u0026#39;graph\u0026#39;] = self.get_lane_graph(data) return data def __len__(self): if \u0026#39;preprocess\u0026#39; in self.config and self.config[\u0026#39;preprocess\u0026#39;]: return len(self.split) else: return len(self.avl) def read_argo_data(self, idx): city = copy.deepcopy(self.avl[idx].city) \u0026#34;\u0026#34;\u0026#34;TIMESTAMP,TRACK_ID,OBJECT_TYPE,X,Y,CITY_NAME\u0026#34;\u0026#34;\u0026#34; df = copy.deepcopy(self.avl[idx].seq_df) agt_ts = np.sort(np.unique(df[\u0026#39;TIMESTAMP\u0026#39;].values)) mapping = dict() for i, ts in enumerate(agt_ts): mapping[ts] = i trajs = np.concatenate(( df.X.to_numpy().reshape(-1, 1), df.Y.to_numpy().reshape(-1, 1)), 1) steps = [mapping[x] for x in df[\u0026#39;TIMESTAMP\u0026#39;].values] steps = np.asarray(steps, np.int64) objs = df.groupby([\u0026#39;TRACK_ID\u0026#39;, \u0026#39;OBJECT_TYPE\u0026#39;]).groups keys = list(objs.keys()) obj_type = [x[1] for x in keys] agt_idx = obj_type.index(\u0026#39;AGENT\u0026#39;) idcs = objs[keys[agt_idx]] agt_traj = trajs[idcs] agt_step = steps[idcs] del keys[agt_idx] ctx_trajs, ctx_steps = [], [] for key in keys: idcs = objs[key] ctx_trajs.append(trajs[idcs]) ctx_steps.append(steps[idcs]) data = dict() data[\u0026#39;city\u0026#39;] = city data[\u0026#39;trajs\u0026#39;] = [agt_traj] + ctx_trajs data[\u0026#39;steps\u0026#39;] = [agt_step] + ctx_steps return data def get_obj_feats(self, data): orig = data[\u0026#39;trajs\u0026#39;][0][19].copy().astype(np.float32) if self.train and self.config[\u0026#39;rot_aug\u0026#39;]: theta = np.random.rand() * np.pi * 2.0 else: pre = data[\u0026#39;trajs\u0026#39;][0][18] - orig theta = np.pi - np.arctan2(pre[1], pre[0]) rot = np.asarray([ [np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]], np.float32) feats, ctrs, gt_preds, has_preds = [], [], [], [] for traj, step in zip(data[\u0026#39;trajs\u0026#39;], data[\u0026#39;steps\u0026#39;]): if 19 not in step: continue gt_pred = np.zeros((30, 2), np.float32) has_pred = np.zeros(30, np.bool) future_mask = np.logical_and(step \u0026gt;= 20, step \u0026lt; 50) post_step = step[future_mask] - 20 post_traj = traj[future_mask] gt_pred[post_step] = post_traj has_pred[post_step] = 1 obs_mask = step \u0026lt; 20 step = step[obs_mask] traj = traj[obs_mask] idcs = step.argsort() step = step[idcs] traj = traj[idcs] for i in range(len(step)): if step[i] == 19 - (len(step) - 1) + i: break step = step[i:] traj = traj[i:] feat = np.zeros((20, 3), np.float32) feat[step, :2] = np.matmul(rot, (traj - orig.reshape(-1, 2)).T).T feat[step, 2] = 1.0 x_min, x_max, y_min, y_max = self.config[\u0026#39;pred_range\u0026#39;] if feat[-1, 0] \u0026lt; x_min or feat[-1, 0] \u0026gt; x_max or feat[-1, 1] \u0026lt; y_min or feat[-1, 1] \u0026gt; y_max: continue ctrs.append(feat[-1, :2].copy()) feat[1:, :2] -= feat[:-1, :2] feat[step[0], :2] = 0 feats.append(feat) gt_preds.append(gt_pred) has_preds.append(has_pred) feats = np.asarray(feats, np.float32) ctrs = np.asarray(ctrs, np.float32) gt_preds = np.asarray(gt_preds, np.float32) has_preds = np.asarray(has_preds, np.bool) data[\u0026#39;feats\u0026#39;] = feats data[\u0026#39;ctrs\u0026#39;] = ctrs data[\u0026#39;orig\u0026#39;] = orig data[\u0026#39;theta\u0026#39;] = theta data[\u0026#39;rot\u0026#39;] = rot data[\u0026#39;gt_preds\u0026#39;] = gt_preds data[\u0026#39;has_preds\u0026#39;] = has_preds return data def get_lane_graph(self, data): \u0026#34;\u0026#34;\u0026#34;Get a rectangle area defined by pred_range.\u0026#34;\u0026#34;\u0026#34; x_min, x_max, y_min, y_max = self.config[\u0026#39;pred_range\u0026#39;] radius = max(abs(x_min), abs(x_max)) + max(abs(y_min), abs(y_max)) lane_ids = self.am.get_lane_ids_in_xy_bbox(data[\u0026#39;orig\u0026#39;][0], data[\u0026#39;orig\u0026#39;][1], data[\u0026#39;city\u0026#39;], radius) lane_ids = copy.deepcopy(lane_ids) lanes = dict() for lane_id in lane_ids: lane = self.am.city_lane_centerlines_dict[data[\u0026#39;city\u0026#39;]][lane_id] lane = copy.deepcopy(lane) centerline = np.matmul(data[\u0026#39;rot\u0026#39;], (lane.centerline - data[\u0026#39;orig\u0026#39;].reshape(-1, 2)).T).T x, y = centerline[:, 0], centerline[:, 1] if x.max() \u0026lt; x_min or x.min() \u0026gt; x_max or y.max() \u0026lt; y_min or y.min() \u0026gt; y_max: continue else: \u0026#34;\u0026#34;\u0026#34;Getting polygons requires original centerline\u0026#34;\u0026#34;\u0026#34; polygon = self.am.get_lane_segment_polygon(lane_id, data[\u0026#39;city\u0026#39;]) polygon = copy.deepcopy(polygon) lane.centerline = centerline lane.polygon = np.matmul(data[\u0026#39;rot\u0026#39;], (polygon[:, :2] - data[\u0026#39;orig\u0026#39;].reshape(-1, 2)).T).T lanes[lane_id] = lane lane_ids = list(lanes.keys()) ctrs, feats, turn, control, intersect = [], [], [], [], [] for lane_id in lane_ids: lane = lanes[lane_id] ctrln = lane.centerline num_segs = len(ctrln) - 1 ctrs.append(np.asarray((ctrln[:-1] + ctrln[1:]) / 2.0, np.float32)) feats.append(np.asarray(ctrln[1:] - ctrln[:-1], np.float32)) x = np.zeros((num_segs, 2), np.float32) if lane.turn_direction == \u0026#39;LEFT\u0026#39;: x[:, 0] = 1 elif lane.turn_direction == \u0026#39;RIGHT\u0026#39;: x[:, 1] = 1 else: pass turn.append(x) control.append(lane.has_traffic_control * np.ones(num_segs, np.float32)) intersect.append(lane.is_intersection * np.ones(num_segs, np.float32)) node_idcs = [] count = 0 for i, ctr in enumerate(ctrs): node_idcs.append(range(count, count + len(ctr))) count += len(ctr) num_nodes = count pre, suc = dict(), dict() for key in [\u0026#39;u\u0026#39;, \u0026#39;v\u0026#39;]: pre[key], suc[key] = [], [] for i, lane_id in enumerate(lane_ids): lane = lanes[lane_id] idcs = node_idcs[i] pre[\u0026#39;u\u0026#39;] += idcs[1:] pre[\u0026#39;v\u0026#39;] += idcs[:-1] if lane.predecessors is not None: for nbr_id in lane.predecessors: if nbr_id in lane_ids: j = lane_ids.index(nbr_id) pre[\u0026#39;u\u0026#39;].append(idcs[0]) pre[\u0026#39;v\u0026#39;].append(node_idcs[j][-1]) suc[\u0026#39;u\u0026#39;] += idcs[:-1] suc[\u0026#39;v\u0026#39;] += idcs[1:] if lane.successors is not None: for nbr_id in lane.successors: if nbr_id in lane_ids: j = lane_ids.index(nbr_id) suc[\u0026#39;u\u0026#39;].append(idcs[-1]) suc[\u0026#39;v\u0026#39;].append(node_idcs[j][0]) lane_idcs = [] for i, idcs in enumerate(node_idcs): lane_idcs.append(i * np.ones(len(idcs), np.int64)) lane_idcs = np.concatenate(lane_idcs, 0) pre_pairs, suc_pairs, left_pairs, right_pairs = [], [], [], [] for i, lane_id in enumerate(lane_ids): lane = lanes[lane_id] nbr_ids = lane.predecessors if nbr_ids is not None: for nbr_id in nbr_ids: if nbr_id in lane_ids: j = lane_ids.index(nbr_id) pre_pairs.append([i, j]) nbr_ids = lane.successors if nbr_ids is not None: for nbr_id in nbr_ids: if nbr_id in lane_ids: j = lane_ids.index(nbr_id) suc_pairs.append([i, j]) nbr_id = lane.l_neighbor_id if nbr_id is not None: if nbr_id in lane_ids: j = lane_ids.index(nbr_id) left_pairs.append([i, j]) nbr_id = lane.r_neighbor_id if nbr_id is not None: if nbr_id in lane_ids: j = lane_ids.index(nbr_id) right_pairs.append([i, j]) pre_pairs = np.asarray(pre_pairs, np.int64) suc_pairs = np.asarray(suc_pairs, np.int64) left_pairs = np.asarray(left_pairs, np.int64) right_pairs = np.asarray(right_pairs, np.int64) graph = dict() graph[\u0026#39;ctrs\u0026#39;] = np.concatenate(ctrs, 0) graph[\u0026#39;num_nodes\u0026#39;] = num_nodes graph[\u0026#39;feats\u0026#39;] = np.concatenate(feats, 0) graph[\u0026#39;turn\u0026#39;] = np.concatenate(turn, 0) graph[\u0026#39;control\u0026#39;] = np.concatenate(control, 0) graph[\u0026#39;intersect\u0026#39;] = np.concatenate(intersect, 0) graph[\u0026#39;pre\u0026#39;] = [pre] graph[\u0026#39;suc\u0026#39;] = [suc] graph[\u0026#39;lane_idcs\u0026#39;] = lane_idcs graph[\u0026#39;pre_pairs\u0026#39;] = pre_pairs graph[\u0026#39;suc_pairs\u0026#39;] = suc_pairs graph[\u0026#39;left_pairs\u0026#39;] = left_pairs graph[\u0026#39;right_pairs\u0026#39;] = right_pairs for k1 in [\u0026#39;pre\u0026#39;, \u0026#39;suc\u0026#39;]: for k2 in [\u0026#39;u\u0026#39;, \u0026#39;v\u0026#39;]: graph[k1][0][k2] = np.asarray(graph[k1][0][k2], np.int64) for key in [\u0026#39;pre\u0026#39;, \u0026#39;suc\u0026#39;]: if \u0026#39;scales\u0026#39; in self.config and self.config[\u0026#39;scales\u0026#39;]: #TODO: delete here graph[key] += dilated_nbrs2(graph[key][0], graph[\u0026#39;num_nodes\u0026#39;], self.config[\u0026#39;scales\u0026#39;]) else: graph[key] += dilated_nbrs(graph[key][0], graph[\u0026#39;num_nodes\u0026#39;], self.config[\u0026#39;num_scales\u0026#39;]) return graph DataLoader:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # Data loader for training dataset = Dataset(config[\u0026#34;train_split\u0026#34;], config, train=True) train_sampler = DistributedSampler( dataset, num_replicas=hvd.size(), rank=hvd.rank() ) train_loader = DataLoader( dataset, batch_size=config[\u0026#34;batch_size\u0026#34;], num_workers=config[\u0026#34;workers\u0026#34;], sampler=train_sampler, collate_fn=collate_fn, pin_memory=True, worker_init_fn=worker_init_fn, drop_last=True, ) # Data loader for evaluation dataset = Dataset(config[\u0026#34;val_split\u0026#34;], config, train=False) val_sampler = DistributedSampler(dataset, num_replicas=hvd.size(), rank=hvd.rank()) val_loader = DataLoader( dataset, batch_size=config[\u0026#34;val_batch_size\u0026#34;], num_workers=config[\u0026#34;val_workers\u0026#34;], sampler=val_sampler, collate_fn=collate_fn, pin_memory=True, ) ","permalink":"https://jianye0428.github.io/en/posts/notes/2022-06-17_pytorch_dataset_dataloader/","summary":"link: https://chenllliang.github.io/2020/02/04/dataloader/ distributed training with dataloader and dataset: https://blog.csdn.net/zyq12345678/article/details/90268668 https://cloud.tencent.com/developer/article/1877393 Dataset PyTorch为我们提供的两个Dataset和DataLoader类分别负责可被Pytorch使用的数据集的创建以及向","title":"The Utilization of Dataset and DataLoader"},{"content":"paper link: https://arxiv.org/abs/2007.13732\nPPT: https://www.cs.toronto.edu/~byang/slides/LaneGCN.pdf\nArchitechture Lane Graph + Actor Map:\nconstruct lane graph from vectorized map data to preserve the map structure and can avoid information loss 构建矢量化地图信息，避免地图信息丢失\nLaneGCN:\nextends graph convolutions with multiple adjacency matrices and along-lane dilation\nto capture complex topology and long range dependencies of the lane graph. exploit a fusion network consisting of four types of interactions: actor-to-lane, lane-to-actor, actor-to-actor, lane-to-lane.\npresent both actors and lanes as nodes in the graph and use a 1D CNN and LaneGCN to extract the features for the actor and lane nodes respectively, and then exploit spatial attention and another LaneGCN to model four types of interactions. Difference between VectorNet and LaneGCN:\nVecotrNet uses vanilla graph networks with undirected full connections; LaneGCN uses connected lane graph folllowing the map topology and propose task specific multi-type and dilated graph operators. VectorNet uses polyline-level nodes for interactions; LaneGCN uses polyline segments as map nodes to capture higher resolution. Lane Graph Representations for Motion Forecasting ActorNet: Extracting Traffic Participant Representations Each Trajctory is represented as a sequence of displacement ${ \\bigtriangleup{p_{-(T-1)},\u0026hellip;,\\bigtriangleup{p_{-1}}, \\bigtriangleup{p_0}}}$, where $\\bigtriangleup{p_t}$ is the 2D displacement from time step $t-1$ to t, and T is the trajectory size.\nFor trajectories with sizes smaller than $T$ , we pad them with zeros. We add a binary $1 × T$ mask to indicate if the element at each step is padded or not and concatenate it with the trajectory tensor, resulting in an input tensor of size $3 × T$.\n1D CNN is used to process the trajectory input for its effectiveness in extracting multi-scale features and efficiency in parallel computing. The output of ActorNet is a temporal feature map, whose element at $t = 0$ is used as the actor feature. The network has 3 groups/scales of 1D convolutions.\nEach group consists of 2 residual blocks, with the stride of the first block as 2. We then use a Feature Pyramid Network (FPN) to fuse the multi-scale features, and apply another residual block to obtain the output tensor. For all layers, the convolution kernel size is 3 and the number of output channels is 128. Layer normalization and the Rectified Linear Unit (ReLU) are used after each convolution.\nMapNet: Extracting Structured Map Representation General Architecture:\npart 1: building a lane graph from vectorized map data; part 2: applying our novel LaneGCN to the lane graph to output the map features. Map Data:\nIn this paper, we adopt a simple form of vectorized map data as our representation of HD maps. Specifically, the map data is represented as a set of lanes and their connectivity. Each lane contains a centerline, i.e., a sequence of 2D BEV points, which are arranged following the lane direction (see Fig. 3, top). For any two lanes which are directly reachable, 4 types of connections are given: predecessor, successor, left neighbour and right neighbour.\nLane Graph Construction:\nfirst define a lane node as the straight line segment formed by any two consecutive points (grey circles in Fig. 3) of the centerline. The location of a lane node is the averaged coordinates of its two end points. Following the connections between lane centerlines, we also derive 4 connectivity types for the lane nodes, i.e., predecessor, successor, left neighbour and right neighbour.\nWe denote the lane nodes with $V ∈ \\mathbb R^{N ×2}$ , where $N$ is the number of lane nodes and the $i$-th row of $V$ is the BEV coordinates of the $i$-th node. We represent the connectivity with 4 adjacency matrices ${\\lbrace A_i \\rbrace}_{i \\in {pre,suc,left,right}}$ , with $A_i \\in \\mathbb R^{N ×N}$.\nWe denote $A_{i,jk}$, as the element in the $j$-th row and $k$-th column of $A_i$. Then $A_{i,jk} = 1$ if node $k$ is an $i$-type neighbor of node $j$.\nLaneConv Operator:\nNode Feature:\nEach lane node corresponds to a straight line segment of a centerline. To encode all the lane node information, we need to take into account both the shape (size and orientation) and the location (the coordinates of the center) of the corresponding line segment. We parameterize the node feature as follows,\n$$x_i = MLP_{shape} (v_{i}^{end} - v_{i}^{start}) + MLP_{loc}(v_i) $$\nwhere $MLP$ indicates a multi-layer perceptron and the two subscripts refer to shape and location, respectively. $v_i$ is the location of the i-th lane node, i.e., the center between two end points, $v_i^{start}$ and $v_i^{end}$ are the BEV coordinates of the node $i’s$ starting and ending points, and $x_i$ is the $i$-th row of the node feature matrix $X$, denoting the input feature of the $i$-th lane node.\nLaneConv: To aggregate the topology information of the lane graph at a larger scale, we design the following LaneConv operator:\n$$Y = XW_0 + \\sum_{i\\in{pre, suc, left, right}}A_iXW_i,\\tag{2}$$\nwhere $A_i$ and $W_i$ are the adjacency and the weight matrices corresponding to the $i$-th connection type respectively. Since we order the lane nodes from the start to the end of the lane, $A_{suc}$ and $A_{pre}$ are matrices obtained by shifting the identity matrix (diagnal 1) one step towards upper right (non-zero superdiagonal) and lower left (non-zero subdiagonal). $A_{suc}$ and $A_{pre}$ can propagate information from the forward and backward neighbours whereas $A_{left}$ and $A_{right}$ allow information to flow from the cross-lane neighbours. It is not hard to see that our LaneConv builds on top of the general graph convolution and encodes more geometric (e.g., connection type/direction) information. As shown in our experiments this improves over the vanilla graph convolution.\nDilated LaneConv:\nFunctionality: The model needs to capture the long range dependency along the lane direction for accurate prediction.\nthe k-dilation LaneConv operator is defined as follows:\n$$Y = XW_0 + A_{pre}^k XW_{pre,k} + A_{suc}^k X W_{suc,k} \\tag{3}$$\nwhere $A_{pre}^k$ is the $k$-th matrix power of $A_{pre}$. This allows us to directly propagate information along the lane for $k$ steps, with $k$ a hyperparameter. Since $A_{pre}^k$ is highly sparse, one can efficiently compute it using sparse matrix multiplication. Note that the dilated LaneConv is only used for predecessor and successor, as the long range dependency is mostly along the lane direction.\nLaneGCN:\nWith Eq.(2) and Eq.(3), we get a multi-scale LaneConv operator with C dilation size as follows:\n$$Y = XW_0 + \\sum_{i\\in \\lbrace left, right \\rbrace} A_i X W_i + \\sum_{c=1}^C (A_{pre}^{k_c}XW_{pre, k_c} + A_{suc}^{k_c}XW_{suc, k_c})， \\tag{4}$$\nwhere $k_c$ is the $c$-th dilation size. We denote $LaneConv(k_1 , · · · , k_C)$ this multi-scale layer.\nFusion Net Four types fusion modules:\nA2L: introduces real-time traffic information to lane nodes, such as blockage or usage of the lanes. L2L: updates lane node features by propagating the traffic information over the lane graph. -\u0026gt; LaneGCN L2A: fuses updated map features with real-time traffic information back to the actors. A2A: handles the interactions between actors and produces the output actor features, which are then used by the prediction header for motion forecasting. We implement L2L using another LaneGCN, which has the same architecture as the one used in our MapNet (see Section 3.2). In the following we describe the other three modules in detail. We exploit a spatial attention layer for A2L, L2A and A2A. The attention layer applies to each of the three modules in the same way. Taking A2L as an example, given an actor node i, we aggregate the features from its context lane nodes j as follows:\n$$y_i = x_i W_0 + \\sum_j \\phi (concat(x_i, \\Delta_{i,j}, x_j)W_1)W_2, \\tag{5}$$\nwith $x_i$ the feature of the $i$-th node, $W$ a weight matrix, $\\phi$ the compositon of layer notmalization and RelU, and $\\Delta_{ij} = MLP(v_j - v_i)$, where $v$ denotes the node location.\nPrediction Header Take after-fusion actor features as input, a multi-modal prediction header outputs the final motion forecasting. For each actor, it predicts $K$ possible future trajectories and their confidence scores.\nThe header has two branches, a regression branch to predict the trajectory of each mode and a classification branch to predict the confidence score of each mode.\nFor the m-th actor, we apply a residual block and a linear layer in the regression branch to regress the K sequences of BEV coordinates:\n$$O_{m,reg} = \\lbrace (p_{m,1}^k, p_{m,2}^k, \u0026hellip;, p_{m,T}^k) \\rbrace _{k\\in[0,K-1]}$$\nwhere $p_{m,i}^k$ is the predicted $m$-th actor\u0026rsquo;s BEV coordinates of the $k$-th mode at the $i$-th time step. For the classification branch, we apply an MLP to $p^k_{m,T} − p_{m,0}$ to get $K$ distance embeddings. We then concatenate each distance embedding with the actor feature, apply a residual block and a linear layer to output $K$ confidence scores, $O_{m,cls} = (c_{m,0}, c_{m,1}, \u0026hellip;, c_{m,K−1})$.\nLearning use the sum of classification and regreesion losses to train the model:\n$$ L = L_{cls} + \\alpha L_{reg},$$\nwhere $\\alpha = 1.0$.\nFor classification, we use the max-margin loss:\n$$L_{cls} = \\frac{1}{M(K-1)}\\sum_{m=1}^M \\sum_{k \\neq \\hat{k}} \\max(0, c_{m,k} + \\epsilon - c_{m, \\hat{k}}) \\tag{6}$$\nwhere $\\epsilon$ is the margin and $M$ is the total number of actors. For regression, we apply the smooth $l1$ loss on all predicted time steps:\n$$L_{reg} = \\frac{1}{MT} \\sum_{m=1}^M \\sum_{t=1}^T reg(p_{m,y}^{\\hat{k}} - p_{m,t}^*) \\tag{7}$$\nwhere $p_t^*$ is the ground truth BEV coordinates at time step $t$, $reg(x) = \\sum\\limits_i d(x_i)$, $x_i$ is the $i$-th element of $x$, and $d(x_i)$ is the smooth $\\ell1$ loss defined as:\n$$d(x_i) = \\begin{cases} 0.5x_i^2 \u0026amp;\\text{if} ||x|| \u0026lt; 1, \\ ||x_i|| - 0.5 \u0026amp; \\text{otherwise,} \\end{cases} \\tag{8}$$\nwhere $||x_i||$ denotes the $\\ell1$ norm of $x_i$.\nNeural Network Layout Data Process And Network Construction 以官方的2645.csv数据集为例子\nagent node:\ndata['city']:城市名称 data['trajs'] = [agt_traj] + ctx_trajs:轨迹点，(agent + context vehicles) data['steps'] = [agt_step] + ctx_steps:在原始数据中的位置 data['feats'] = feats: (13 X 20 X 3) 前20预测轨迹 + 一维是否存在点 data['ctrs'] = ctrs: (13 X 2) 中心点 data['orig'] = orig: AGENT 当前点坐标 data['theta'] = theta: AGENT 偏转角 data['rot'] = rot: (2 X 2) 旋转矩阵 data['gt_preds'] = gt_preds:(13 X 30 X 2) 后30帧真实轨迹 data['has_preds'] = has_preds: (13 X 30) 标识后30帧轨迹是否存在 lane node:\ngraph['ctrs'] = np.concatenate(ctrs, 0): lane node的中心点坐标 graph['num_nodes'] = num_nodes: lane node的数量 graph['feats'] = np.concatenate(feats, 0): lane node 方向向量 graph['turn'] = np.concatenate(turn, 0): lane node 转向标识 graph['control'] = np.concatenate(control, 0): lane node 的 has_traffic_control 标识 graph['intersect'] = np.concatenate(intersect, 0): lane node 的 is_intersection 标识 graph['pre'] = [pre]: pre[\u0026lsquo;u\u0026rsquo;] 和 pre[\u0026lsquo;v\u0026rsquo;], v 是 u 的pre， 这里表述的是lane node之间的关系 graph['suc'] = [suc]: suc[\u0026lsquo;u\u0026rsquo;] 和 suc[\u0026lsquo;v\u0026rsquo;], v 是 u 的suc， 这里表述的是lane node之间的关系 graph['lane_idcs'] = lane_idcs: lane node index 1 2 3 4 0 0 0 ... 0 1 1 1 ... 1 ... 83 83 83 ... 83 graph['pre_pairs'] = pre_pairs: pair 表述的是lane之间的关系 graph['suc_pairs'] = suc_pairs: pair 表述的是lane之间的关系 graph['left_pairs'] = left_pairs: pair 表述的是lane之间的关系 graph['right_pairs'] = right_pairs: pair 表述的是lane之间的关系 对于pre['u']和pre['v'], v 是 u 的 pre 对于suc['u']和suc['v'], v 是 u 的 suc 对于left['u']和left['v'], v 是 u 的 left 对于right['u']和right['v'], v 是 u 的 right Net结构\nActorNet input: M x 3 x 20 output: M x 128 x 20 解释:\nMapNet: 把 v 按照 u 加到center上 input: N x 4 output: N x 128\nA2M input: N x 128 output: N x 128\nM2M input: N x 128 output: N x 128\nM2A input: N x 128 output: M x 128\nA2A input: N x 128 output: N x 128\nPrediction Header: input M x 128\nMLP Regression MLP Classification ref link: https://zhuanlan.zhihu.com/p/447129428\n","permalink":"https://jianye0428.github.io/en/posts/tech/2022-06-13_lanegcn/","summary":"paper link: https://arxiv.org/abs/2007.13732 PPT: https://www.cs.toronto.edu/~byang/slides/LaneGCN.pdf Architechture Lane Graph + Actor Map: construct lane graph from vectorized map data to preserve the map structure and can avoid information loss 构建矢量化地图信息，避免地图信息丢失 LaneGCN: extends graph convolutions with multiple adjacency matrices and along-lane dilation to capture complex topology and long range dependencies of the lane graph. exploit","title":"LaneGCN: Learning Lane Graph Representations for Motion Forecasting"},{"content":"paper link: https://arxiv.org/abs/2012.11717\n论文解读参考:\n[1] https://zhuanlan.zhihu.com/p/434650863\n[2] https://www.gushiciku.cn/pl/amod\nIssue to solve and its Solution Due to the ill-distributed training Data, it\u0026rsquo;s difficult to capture the notion of the \u0026ldquo;negative\u0026rdquo; examples like collision.\nSolution:\nModeling the negative samples through self-supervision:\na social contrastive loss: regularizes the extracted motion representation by discerning the ground-truth positive events from synthetic negative ones; Construct negative samples based on prior knowledge of rare but dangerous circumstances. a social sampling strategy (informed): construct the positive event from the ground-truth location of the primary agent and the negative events from the regions of other neighbors. given that one location cannot be occupied by multiple agents at the same time.\nMethod: Contrastive Learning + Social NCE Contrastive Representation Learning Functionality:\nRepresentation Learning: to learn a parametric function that maps the raw data into a feature space to extract abstract and useful information for downstream tasks.\nNCE(Noise Contrastive Estimation): to train encoder\n$$\\mathcal{L_{NCE}} = -\\log \\frac{\\exp(sim(q,k^+)/\\tau)}{\\sum_{n=0}^N \\exp(sim(q,k_n)/ \\tau)}$$\nwhere the encoded query $q$ is brought close to one positive key $k_0 = k^+$ and pushed apart from $N$ negative keys ${ k_1, k_2, \u0026hellip; , k_N}$, $\\tau$ is a temperature hyperparameter, and $sim(u,v) = u^{\\mathsf{T}}v/(||u||||v||)$ is the cosine similarity between two feature vectors.\nSocial NCE Social NCE Description:\n智能体 $i$ 在时刻 $t$ 上的位置记为 $s^i_t=(x^i_t,y^i_t)$ 。那么 $M$ 个智能体的联合状态记为 $s_t = { s_t^1, \u0026hellip;, s^M_t}$ 。给定一个历史观测序列 ${s_1, s_2, \u0026hellip;, s_t}$ ，任务是预测所有智能体未来直至 $T$ 时刻的轨迹 ${s_{t+1}, \u0026hellip;, s_T}$，许多最近的预测模型被设计为编码器 - 解码器神经网络，其中运动编码器 $f(\\cdot)$ 首先提取与 $i$ 相关的紧密表示 $h_t^i$ ，然后解码器 $g(\\cdot)$ 随后推测出其未来的轨迹 $\\hat{s}^i_{t+1,T}$ :\n$$h^i_t = f(s_{1:t}, i), $$ $$\\hat{s}^i_{t+1:T} = g(h^i_t)$$\n为了多智能体之间的社交互动，$f(\\cdot)$通常包含两个子模块：一个序列建模模块 $f_S(\\cdot)$ 用于编码每个单独的序列，以及一个交互模块 $f_I(\\cdot)$ 用于在多智能体之间共享信息：\n$$z^i_t = f_S(h^i_{t-1}, s^i_t),$$ $$h^i_t = f_I(z_t, i)$$\n其中， $z^i_t$ 是给定智能体 $i$ 在时间 $t$ 观察其自身状态的潜在表示， $z_t = {z^1_t,\u0026hellip;,z^M_t}$ 。很多方法已经探索了各种架构，并验证了其准确性。尽管如此，它们的鲁棒性仍然是一个悬而未决的问题。 最近的几项工作表明，现有模型预测的轨迹通常会输出社会不可接受的解决方案（例如，碰撞），表明缺乏关于社会准则的常识。\nquery: embedding of history observations $q = \\psi(h^i_t)$, where $\\psi(\\cdot)$ is an MLP projection head;\nkey: embedding of a future event $k = \\phi(s^i_{s+\\delta t}, \\delta t)$, where $\\phi(\\cdot)$ is an event encoder modeled by an MLP, $s_{t+\\delta t}^i$ is a sampled spatial location and $\\delta_t \u0026gt; 0$ is the sampling horizon.\ntuning $\\delta_t \\in \\Lambda$, e.g. $\\Lambda = {1,\u0026hellip;,4}$, then future events in the next few step can be taken in account simultaneously. Nevertheless, when $\\delta_t$ is a fixed value, then $\\phi(\\cdot)$ can be simplified as a location encoder, i.e., $\\phi(s^i_{t+\\delta t})$.\n给定一个场景，包括感兴趣的主智体（蓝色）和附近多个相邻智体（灰色），Social-NCE 损失鼓励在嵌入空间中提取的运动表示，接近未来的正样本事件，并远离可能导致碰撞或不适的合成负样本事件. Social NCE的损失函数如下:\n$$\\mathcal{L_{SocialNCE}} = -\\log\\frac{\\exp(\\psi(h^i_t)\\cdot\\phi(s^{i,+}{t+\\delta t}, \\delta t)/\\tau)}{\\sum{\\delta t\\in\\Lambda}\\sum_{n=0}^{N}\\exp(\\psi(h^i_t)\\cdot\\phi(s^{i,n}_{t+\\delta t}, \\delta t)/\\tau))}$$\n最终的训练损失函数为Social-NCE和传统任务损失项之和，即轨迹预测的mean squared error (MSE) 或者negative log-likelihood (NLL)：\n$$\\mathcal{L}(f,g,\\psi, \\phi) = \\mathcal{L}{task}(f,g) + \\lambda \\mathcal{L}{SocialNCE}(f, \\psi, \\phi)$$\n其中，$\\lambda$ 为超参数，控制SocialNCE损失函数的重要程度。\nsampling strategy in multi-agent context 采样策略 在其他智能体附近寻求更多信息的负样本:\n$$s^{i,n-}{t+\\delta t} = s^{j}{t+\\delta t} + \\bigtriangleup{s_p} + \\epsilon$$\n其中， $j\\in{1,2,\u0026hellip;,M} \\backslash i$ 是其他agent的index, $\\bigtriangleup{s_p}$ 是适合社交距离的局部位移。\n对于positive sample, 对该agent周围直接采样获得:\n$$s^{i,n-}{t+\\delta t} = s^{i}{t+\\delta t} + \\epsilon$$\n","permalink":"https://jianye0428.github.io/en/posts/tech/2022-06-12_social_nce/","summary":"paper link: https://arxiv.org/abs/2012.11717 论文解读参考: [1] https://zhuanlan.zhihu.com/p/434650863 [2] https://www.gushiciku.cn/pl/amod Issue to solve and its Solution Due to the ill-distributed training Data, it\u0026rsquo;s difficult to capture the notion of the \u0026ldquo;negative\u0026rdquo; examples like collision. Solution: Modeling the negative samples through self-supervision: a social contrastive loss: regularizes the extracted motion representation by discerning the ground-truth positive events from synthetic negative ones; Construct negative samples based on prior","title":"Social_NCE: Contrastive Learning of Socially-aware Motion Representation"},{"content":"Torch 基本函数 1. torch.einsum() torch.einsum(equation, *operands)-\u0026gt;Tensor:爱因斯坦求和 ref1: 算子部署: https://blog.csdn.net/HW140701/article/details/120654252 ref2: 例子: https://zhuanlan.zhihu.com/p/361209187\n三条基本规则:\n规则一: equation 箭头左边，在不同输入之间重复出现的索引表示，把输入张量沿着该维度做乘法操作，比如还是以上面矩阵乘法为例， \u0026ldquo;ik,kj-\u0026gt;ij\u0026rdquo;，k 在输入中重复出现，所以就是把 a 和 b 沿着 k 这个维度作相乘操作； 规则二: 只出现在 equation 箭头左边的索引，表示中间计算结果需要在这个维度上求和，也就是上面提到的求和索引； 规则三: equation 箭头右边的索引顺序可以是任意的，比如上面的 \u0026ldquo;ik,kj-\u0026gt;ij\u0026rdquo; 如果写成 \u0026ldquo;ik,kj-\u0026gt;ji\u0026rdquo;，那么就是返回输出结果的转置，用户只需要定义好索引的顺序，转置操作会在 einsum 内部完成 特殊规则:\nequation 可以不写包括箭头在内的右边部分，那么在这种情况下，输出张量的维度会根据默认规则推导。就是把输入中只出现一次的索引取出来，然后按字母表顺序排列，比如上面的矩阵乘法 \u0026ldquo;ik,kj-\u0026gt;ij\u0026rdquo; 也可以简化为 \u0026ldquo;ik,kj\u0026rdquo;，根据默认规则，输出就是 \u0026ldquo;ij\u0026rdquo; 与原来一样； equation 中支持 \u0026ldquo;\u0026hellip;\u0026rdquo; 省略号，用于表示用户并不关心的索引。比如只对一个高维张量的最后两维做转置可以这么写： 1 2 3 a = torch.randn(2,3,5,7,9) # i = 7, j = 9 b = torch.einsum(\u0026#39;...ij-\u0026gt;...ji\u0026#39;, [a]) 2. torch.permute()/torch.transpose() torch.permute(dim0, dim1, dim2):用于调换不同维度的顺序 torch.transpose(input, dim0, dim1):交换矩阵的两个维度\n3. torch.rand() torch.rand(dim0, dim1):生成dim0 x dim1的tensor\n4. torch.size()/torch.shape torch.size():返回tensor的size torch.shape:返回tensor的size\n5. torch.tensordot() ref: tensordot()和einsum()的区别: https://blog.csdn.net/Eric_1993/article/details/105670381 torch.tensordot(tensor1， tensor2， axes=([dim1,dim2],[dim0, dim1])): 将axes指定的子数组进行点乘, axes 指定具体的维度.\n6. torch.transpose() torch.transpose(tensor, dim0, dim2) —\u0026gt; Tensor:在dim0和dim1方向上转置\n###7. torch.index_add_()\nTensor.index_add_(dim, index, source, *, alpha=1) → Tensor\ndemo:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt;\u0026gt;\u0026gt; x = torch.ones(5, 3) \u0026gt;\u0026gt;\u0026gt; t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float) \u0026gt;\u0026gt;\u0026gt; index = torch.tensor([0, 4, 2]) \u0026gt;\u0026gt;\u0026gt; x.index_add_(0, index, t) tensor([[ 2., 3., 4.], [ 1., 1., 1.], [ 8., 9., 10.], [ 1., 1., 1.], [ 5., 6., 7.]]) \u0026gt;\u0026gt;\u0026gt; x.index_add_(0, index, t, alpha=-1) tensor([[ 1., 1., 1.], [ 1., 1., 1.], [ 1., 1., 1.], [ 1., 1., 1.], [ 1., 1., 1.]]) Torch NN Module 1 2 3 import torch from torch import nn from torch import functional as F 1. nn.Conv1d() torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\nShape: - Input: $(N, C_{in}, L_{in})$ or $(C_{in}, L_{in})$ - Output: $(N, C_{in}, L_{in})$ or $(C_{in}, L_{in})$, where $$L_{out} = \\frac{L_{in} + 2 \\cdot \\text{padding} - \\text{dilation} \\cdot (\\text{kernel_size} - 1) - 1}{stride}$$\nDemo:\n1 2 3 4 m = nn.Conv1d(16, 33, 3, stride=2) input = torch.randn(20, 16, 50) # B x C x H or N x C x L output = m(input) print(output.shape) # torch.Size([20, 33, 24]) 2. nn.Conv2d() torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\nShape:\nInput: $(N, C_{\\text in}, H_{\\text in}, W_{\\text in})$ or $(C_{\\text in}, H_{\\text in}, W_{\\text in})$ - Output: $(N, C_{\\text out}, H_{\\text out}, W_{\\text out})$ or $(C_{\\text out}, H_{\\text out}, W_{\\text out})$, where $$ H_{out} = \\frac{H_{in} + 2 \\cdot \\text{padding[0]} - \\text{dilation[0]} \\cdot (\\text{kernel_size[0]} - 1) - 1}{stride[0]} + 1 $$ $$ W_{out} = \\frac{W_{in} + 2 \\cdot \\text{padding[1]} - \\text{dilation[1]} \\cdot (\\text{kernel_size[1]} - 1) - 1}{stride[1]} + 1 $$ Demo:\n1 2 3 4 5 6 7 8 # With square kernels and equal stride m = nn.Conv2d(16, 33, 3, stride=2) # non-square kernels and unequal stride and with padding m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2)) # output.shape: 20 x 33 x 28 x 100 # non-square kernels and unequal stride and with padding and dilation m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1)) # output.shape: 20 x 33 x 26 x 100 input = torch.randn(20, 16, 50, 100) output = m(input) # 3. nn.functional.interpolate() torch.nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None, antialias=False)\n4. nn.functional.ReLU() $$ \\text{ReLU} = (x)^+ = \\max {(0,x)}$$\ntorch.nn.ReLU(inplace=False)\n作用:\nSigmoid的导数只有在0附近的时候有比较好的激活性，在正负饱和区的梯度都接近于0，所以这会造成梯度弥散，而ReLU函数在大于0的部分梯度为常数，所以不会产生梯度弥散现象。\nReLU函数在负半区的导数为0 ，所以一旦神经元激活值进入负半区，那么梯度就会为0，而正值不变，这种操作被成为单侧抑制。（也就是说：在输入是负值的情况下，它会输出0，那么神经元就不会被激活。这意味着同一时间只有部分神经元会被激活，从而使得网络很稀疏，进而对计算来说是非常有效率的。）正因为有了这单侧抑制，才使得神经网络中的神经元也具有了稀疏激活性。尤其体现在深度神经网络模型(如CNN)中，当模型增加N层之后，理论上ReLU神经元的激活率将降低2的N次方倍。\nrelu函数的导数计算更快，程序实现就是一个if-else语句，而sigmoid函数要进行浮点四则运算。\nShape:\nInput: $(∗)$, where $*$ means any number of dimensions. Output: $(∗)$, same shape as the input. Demo:\n1 2 3 4 5 6 7 m = nn.ReLU() input = torch.randn(2) output = m(input) # An implementation of CReLU - https://arxiv.org/abs/1603.05201 m = nn.ReLU() input = torch.randn(2).unsqueeze(0) output = torch.cat((m(input),m(-input))) 5. nn.MaxPool2d() torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\nShape:\nInput: $(N, C, H_{in}, W_{in})$ or $(C, H_{in}, W_{in})$ Output: $(N, C, H_{out}, W_{out})$ or $(C, H_{out}, W_{out})$ where,\n$$ H_{out} = \\frac{H_{in} + 2 * \\text{padding}[0] - \\text{dilation}[0] * (\\text{kernel_size}[0]-1) - 1}{\\text{stride}[0]} + 1$$\n$$ W_{out} = \\frac{W_{in} + 2 * \\text{padding}[1] - \\text{dilation}[1] * (\\text{kernel_size}[1]-1) - 1}{\\text{stride}[1]} + 1$$\ndemo:\n1 2 3 4 5 6 # pool of square window of size=3, stride=2 m = nn.MaxPool2d(3, stride=2) # pool of non-square window m = nn.MaxPool2d((3, 2), stride=(2, 1)) input = torch.randn(20, 16, 50, 32) output = m(input) # 20 16 24 31 6. nn.AvgPool2d() 1 torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None) Shape:\nInput: $(N, C, H_{in}, W_{in})$ or $(C, H_{in}, W_{in})$ Output: $(N, C, H_{out}, W_{out})$ or $(C, H_{out}, W_{out})$ where,\n$$ H_{out} = \\frac{H_{in} + 2 * \\text{padding}[0] - (\\text{kernel_size}[0])}{\\text{stride}[0]} + 1$$\n$$ W_{out} = \\frac{W_{in} + 2 * \\text{padding}[1] - (\\text{kernel_size}[1])}{\\text{stride}[1]} + 1$$\ndemo:\n1 2 3 4 5 6 # pool of square window of size=3, stride=2 m = nn.AvgPool2d(3, stride=2) # pool of non-square window m = nn.AvgPool2d((3, 2), stride=(2, 1)) input = torch.randn(20, 16, 50, 32) output = m(input) # 20 16, 24 31 torch.cuda ref link: https://zhuanlan.zhihu.com/p/76908135\ntorch.cuda.current_device(): 返回当前选择的设备的索引\ntorch.cuda.current_stream(): 返回参数设备的当前的Stream\ntorch.cuda.default_stream(): 返回当前参数设备的Stream\nCLASS torch.cuda.device: 可以改变选择的设备的上下文管理器 Parameters：device (torch.device or int) – device index to select. It’s a no-op if this argument is a negative integer or None.\ntorch.cuda.device_count(): 返回可使用GPU的数量\nCLASS torch.cuda.device_of(obj) Context-manager 将参数对象的设备改成当前的设备。你可以使用张量或者存储作为参数。如果传入的对象没有分配在GPU上，这个操作是无效的。\ntorch.cuda.empty_cache() 释放caching allocator当前持有的所有未占用的cached memory，使其可以用在其他GPU应用且可以在 nvidia-smi可视化。\n注意：empty_cache() 并不会增加PyTorch可以使用的GPU显存的大小。 查看 Memory management 来获取更多的GPU显存管理的信息。\ntorch.cuda.get_device_capability(device=None) Gets the cuda capability of a device.\nParameters：device (torch.device or int, optional) – device for which to return the device capability. This function is a no-op if this argument is a negative integer. It uses the current device, given bycurrent_device(), if device is None (default).\nReturns：the major and minor cuda capability of the device\nReturn type ： tuple(int, int)\ntorch.cuda.get_device_name(device=None)\ntorch.cuda.init() 初始化PyTorch的CUDA状态。如果你通过C API与PyTorch进行交互，你可能需要显式调用这个方法。只有CUDA的初始化完成，CUDA的功能才会绑定到Python。用户一般不应该需要这个，因为所有PyTorch的CUDA方法都会自动在需要的时候初始化CUDA。如果CUDA的状态已经初始化了，将不起任何作用。\n[torch.cuda.is_available()]\ntorch.cuda.max_memory_allocated(device=None) Returns the maximum GPU memory occupied by tensors in bytes for a given device.\ntorch.cuda.max_memory_cached(device=None)\ntorch.cuda.memory_allocated(device=None) Parameters：device (torch.device or int, optional) – selected device. Returns statistic for the current device, given by current_device(), if device is None (default).\ntorch.cuda.memory_cached(devide=None)\n[``]\n","permalink":"https://jianye0428.github.io/en/posts/notes/2022-06-09_pytorch/","summary":"Torch 基本函数 1. torch.einsum() torch.einsum(equation, *operands)-\u0026gt;Tensor:爱因斯坦求和 ref1: 算子部署: https://blog.csdn.net/HW140701/article/details/120654252 ref2: 例子: https://zhuanlan.zhihu.com/p/361209187 三条基本规则: 规则一: equation 箭头左边，在不同输入","title":"PyTorch Notes"},{"content":"paper link: https://arxiv.org/abs/2002.11927?from=leiphonecolumn_paperreview0323\n网络结构 特点: Social STGCNN不同于其他方法只是聚合各种学习的行人状态，而是对行人交互做图建模。其中提出一种kernel function把行人社交交互嵌入一个adjacency matrix。\n代码显示，图建模一般在数据前处理完成。\nModel Description 两部分：时空图卷积神经网络ST-GCNN、时间外推器TXP-CNN。\nST-GCNN对行人轨迹的图表示进行时空卷积操作以提取特征。这些特征是观察到的行人轨迹历史的紧凑表示。 TXP-CNN将这些特征作为输入，并预测所有行人作为一个整体的未来轨迹。我们使用时间外推器的名字是因为TXP-CNN期望通过卷积运算外推未来的轨迹。\n给定T帧，构造表示 $G=(V,A)$ 的时空图. 然后，$G$ 通过时空图卷积神经网络(ST-GCNNs)转发，创建一个时空嵌入。 之后，TXP-CNNs 预测了未来的轨迹。 $P$ 是行人位置的维数，$N$ 是行人的数目，$T$ 是时间步长, $\\hat{P}$是来自ST-GCNN的嵌入的维数.\n(1) Graph Representation of Pedestrian Trajectories\n我们首先构造一组空间图 $G_t$，表示每个时间步长 $t$ 在场景中行人的相对位置，$G_t = (V_t, E_t)$ 。 $V_t$是图 $G_t$ 的顶点集，观察到的位置 $(x^i_t，y^i_t)$ 是顶点 $v^i_t$ 的属性; $E_t$ 是边集，如果顶点 $v^i_t$ 和顶点 $v^j_t$ 相连 $e^{ij}_t = 1$ ，否则 $=0$。\n为了建模两个节点之间相互影响的强度，我们附加了一个值$a^{ij}_t$, 它是由每个$ e^{ij}_t$ 的某种核函数计算得到。$a^{ij}_t$ 被组织为带权邻接矩阵$A_t$。\n$a^{ij}_{sim,t}$是要在邻接矩阵$A_t$中使用的内核函数。 定义为:\n$$\\begin{equation} a^{ij}_{sim,t}= \\left { \\begin{aligned} 1/||v^i_t - v^j_t||_2 , ||v^i_t - v^j_t||_1\\neq0 \\ 0, Otherwise \\end{aligned} \\right. \\end{equation}$$\n(2) Graph Convolution Neural Network\n对于在二维网格地图或特征地图上定义的卷积运算，定义如下:\n$$z^{(l+1)} = \\sigma(\\sum_{h=1}^{k}\\sum_{\\omega=1}^{k}(p(z^{(l)},h, \\omega) \\cdot \\boldsymbol{W}^{(l)}(h, \\omega))$$\n其中，$k$是内核大小，$p(.)$ 是采样函数，其聚集以$z$为中心的邻居的信息， $\\sigma$ 是激活函数。${l}$表示神经网络层。\n图卷积定义如下:\n$$v^{i(l+1)} =\\sigma (\\frac{1}{\\Omega}\\sum_{v^{j(l)}\\in B(v^{j(l)})}p(v^{i(l)}, v^{j(l)}) \\cdot \\boldsymbol{W}(v^{i(l)}, v^{j(l)}))$$\n其中$\\frac{1}{\\Omega}$ 是正则化项，$B(v^i) = { v^j|d(v^i,v^j)≤D }$是顶点的邻居集，而$d(v^i,v^j)$表示连接$v^i$和$v^j$的最短距离， $\\Omega$是邻居集的基数。\n(3) Spatio-Temporal Graph Convolution Neural Network(ST-GCNNs)\n通过定义一个新的图G，其属性是$G_t$属性的集合，ST-GCNN将空间图卷积扩展到时空图卷积。 $G$结合了行人轨迹的时空信息。值得注意的是，$G_1，…，G_T$的拓扑结构是相同的，而当t变化时，不同的属性被分配给$v^i_t$。\n因此，我们将$G$定义为$(V,E)$，其中$V={v_i|i\\in { 1，…，N }}$ 和 $E={e_{ij}|i，j，{1，…，N}}$。 顶点$v_i$在G中的属性是$v^i_t$的集合，$∀t∈{0，…，T}$。 另外， 加权邻接矩阵A对应于$G$ 是${ A_1，…，A_T}$的集合。 我们将ST-GCNN产生的嵌入表示为 $\\overline{V}$.\n(4) Time-Extrapolator Convolution Neural Network (TXP-CNN)\nST-GCNN的功能是从输入图中提取时空节点嵌入。然而，我们的目标是预测行人未来的进一步位置。 TXP-CNN直接作用于图嵌入 $\\overline{V}$ 的时间维度，并将其扩展为预测的必要条件。 由于TXP-CNN依赖于特征空间的卷积运算，因此与递归单元相比，它的参数较小。需要注意的一个特性是， TXP-CNN层不是置换不变的，因为在TXP-CNN之前，图嵌入的变化会导致不同的结果。Other than this, if the order of pedestrians is permutated starting from the input to Social-STGCNN then the predictions are invariant.\nmodel(Social STGCNN) Implementation Adjacency Matrix Normalization $$ A_t = \\Lambda_t^{-\\frac{1}{2}}\\hat{A}\\Lambda_t^{-\\frac{1}{2}}$$\nwhere $\\hat{A_t} = A_t + I$ and $\\Lambda_t$ is the diagonal node degree matric of $\\hat{A_t}$. We use $\\hat{A}$ and $\\Lambda$ to denote the stack of $\\hat{A_t}$ and $\\Lambda_t$ repectively.\nThe normalization of adjacency is essential for the graph CNN to work properly.\nSTGCNN Network Mechanism $$f(V^{l}, A) = \\sigma(\\Lambda_t^{-\\frac{1}{2}}\\hat{A}\\Lambda_t^{-\\frac{1}{2}}V^{(l)}W^{(l)})$$\nwhere, $V^{(l)}$ denotes the stack of $V^{(l)}_t$, and $W^{(l)}$ denotes the trainable parameters.\nData Processing 数据处理以及图构建 obs_traj - 前8帧观察轨迹(绝对坐标)\npred_traj_gt - 后12帧预测轨迹(ground truth)(绝对坐标)\nobs_traj_rel - 前8帧观察轨迹(相对坐标)\npred_traj_gt_rel - 后12帧预测轨迹(ground truth)(相对坐标)\nnon_linear_ped - 非线性轨迹 (剔除)\nloss_mask V_obs - graph nodes\nA_obs - graph Adjacency Matrix\nV_tr - 预测轨迹 graph nodes\nA_tr - 预测轨迹 graph Adjacency Matrix\n","permalink":"https://jianye0428.github.io/en/posts/tech/2022-06-08_social_stgcnn/","summary":"paper link: https://arxiv.org/abs/2002.11927?from=leiphonecolumn_paperreview0323 网络结构 特点: Social STGCNN不同于其他方法只是聚合各种学习的行人状态，而是对行人交互做图建模。其中提出一种kernel function","title":"Social_STGCNN: A Social Spatio-Temporal Graph Convolutional Neural Network for Human Trajectory Prediction"},{"content":"最大似然估计（Maximum likelihood estimation, 简称MLE）和最大后验概率估计（Maximum a posteriori estimation, 简称MAP）是很常用的两种参数估计方法，如果不理解这两种方法的思路，很容易弄混它们。下文将详细说明MLE和MAP的思路与区别。\n但别急，我们先从概率和统计的区别讲起。\n概率和统计是一个东西吗？ 概率(probabilty)和统计(statistics)看似两个相近的概念，其实研究的问题刚好相反。\n概率研究的问题是，已知一个模型和参数，怎么去预测这个模型产生的结果的特性(例如均值，方差，协方差等等)。 举个例子，我想研究怎么养猪(模型是猪)，我选好了想养的品种、喂养方式、猪棚的设计等等(选择参数)，我想知道我养出来的猪大概能有多肥，肉质怎么样(预测结果)。\n统计研究的问题则相反。统计是，有一堆数据，要利用这堆数据去预测模型和参数。仍以猪为例。现在我买到了一堆肉，通过观察和判断，我确定这是猪肉(这就确定了模型。在实际研究中，也是通过观察数据推测模型是／像高斯分布的、指数分布的、拉普拉斯分布的等等)，然后，可以进一步研究，判定这猪的品种、这是圈养猪还是跑山猪还是网易猪，等等(推测模型参数)。\n一句话总结：概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。\n显然，本文解释的MLE和MAP都是统计领域的问题。它们都是用来推测参数的方法。为什么会存在着两种不同方法呢？ 这需要理解贝叶斯思想。我们来看看贝叶斯公式。\n贝叶斯公式到底在说什么？ 学习机器学习和模式识别的人一定都听过贝叶斯公式(Bayes’ Theorem)： 式[1] $P(A|B)=\\frac{P(B|A)P(A)}{P(B)}$\n贝叶斯公式看起来很简单，无非是倒了倒条件概率和联合概率的公式。\n把B展开，可以写成: 式[2] $P(A|B)=\\frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|\\sim A)P(\\sim A)}$\n这个式子就很有意思了。\n想想这个情况。一辆汽车(或者电瓶车)的警报响了，你通常是什么反应？有小偷？撞车了？ 不。。 你通常什么反应都没有。因为汽车警报响一响实在是太正常了！每天都要发生好多次。本来，汽车警报设置的功能是，出现了异常情况，需要人关注。然而，由于虚警实在是太多，人们渐渐不相信警报的功能了。\n贝叶斯公式就是在描述，你有多大把握能相信一件证据？（how much you can trust the evidence）\n我们假设响警报的目的就是想说汽车被砸了。把$A$计作“汽车被砸了”，$B$计作“警报响了”，带进贝叶斯公式里看。我们想求等式左边发生$A∣B$的概率，这是在说警报响了，汽车也确实被砸了。汽车被砸**引起(trigger)**警报响，即B∣A。但是，也有可能是汽车被小孩子皮球踢了一下、被行人碰了一下等其他原因(统统计作$\\sim A$)，其他原因引起汽车警报响了，即 $B|\\sim A$。那么，现在突然听见警报响了，这时汽车已经被砸了的概率是多少呢(这即是说，警报响这个证据有了，多大把握能相信它确实是在报警说汽车被砸了)想一想，应当这样来计算。用警报响起、汽车也被砸了这事件的数量，除以响警报事件的数量(这即[式1])。进一步展开，即警报响起、汽车也被砸了的事件的数量，除以警报响起、汽车被砸了的事件数量加上警报响起、汽车没被砸的事件数量(这即[式2])。\n再思考[式2]。想让$P(A∣B)=1$，即警报响了，汽车一定被砸了，该怎么做呢？让$P(B|\\sim A)P(\\sim A) = 0$即 可 。很容易想清楚，假若让$P(\\sim A)=0$,即杜绝了汽车被球踢、被行人碰到等等其他所有情况，那自然，警报响了，只剩下一种可能——汽车被砸了。这即是提高了响警报这个证据的说服力。\n**从这个角度总结贝叶斯公式：做判断的时候，要考虑所有的因素。**老板骂你，不一定是你把什么工作搞砸了，可能只是他今天出门前和太太吵了一架。\n再思考[式2]。观察【式2】右边的分子，$P(B∣A)$为汽车被砸后响警报的概率。姑且认为这是1吧。但是，若$P(A)$很小，即汽车被砸的概率本身就很小，则$P(B∣A)P(A)$仍然很小，即【式2】右边分子仍然很小，$P(A|B)$还是大不起来。 这里，$​P(A)$ 即是常说的先验概率，如果A的先验概率很小，就算$P(B∣A)$较大，可能A的后验概率$P(A∣B)$还是不会大(假设$P(B∣\\sim A)P(\\sim A)$不变的情况下)。\n从这个角度思考贝叶斯公式：一个本来就难以发生的事情，就算出现某个证据和他强烈相关，也要谨慎。证据很可能来自别的虽然不是很相关，但发生概率较高的事情。\n似然函数 似然(likelihood)这个词其实和概率(probability)是差不多的意思，Colins字典这么解释:The likelihood of something happening is how likely it is to happen. 你把likelihood换成probability，这解释也读得通。但是在统计里面，似然函数和概率函数却是两个不同的概念(其实也很相近就是了)。\n对于这个函数:\n$$P(x|\\theta)$$\n输入有两个: $x$表示某一个具体的数据；$\\theta$表示模型的参数。\n如果$\\theta$是已知确定的，$x$是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点x，其出现概率是多少。\n如果$x$是已知确定的，$\\theta$是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现$x$这个样本点的概率是多少。\n最大似然估计(MLE) 假设有一个造币厂生产某种硬币，现在我们拿到了一枚这种硬币，想试试这硬币是不是均匀的。即想知道抛这枚硬币，正反面出现的概率（记为$\\theta$）各是多少？\n这是一个统计问题，回想一下，解决统计问题需要什么？ 数据！\n于是我们拿这枚硬币抛了10次，得到的数据($x_0$)是：反正正正正反正正正反。我们想求的正面概率$\\theta$是模型参数，而抛硬币模型我们可以假设是二项分布。\n那么，出现实验结果$x_0$(即反正正正正反正正正反)的似然函数是多少呢？\n$$f(x_0 ,\\theta) = (1-\\theta)\\times\\theta\\times\\theta\\times\\theta\\times\\theta\\times(1-\\theta)\\times\\theta\\times\\theta\\times\\theta\\times(1-\\theta) = \\theta ^ 7(1 - \\theta)^3 = f(\\theta)$$ ​ 注意，这是个只关于$\\theta$的函数。而最大似然估计，顾名思义，就是要最大化这个函数。我们可以画出$f(\\theta)$的图像：\n可以看出，在$\\theta = 0.7$时，似然函数取得最大值。\n这样，我们已经完成了对$\\theta$的最大似然估计。即，抛10次硬币，发现7次硬币正面向上，最大似然估计认为正面向上的概率是0.7。（ummm…这非常直观合理，对吧？）\n且慢，一些人可能会说，硬币一般都是均匀的啊！ 就算你做实验发现结果是“反正正正正反正正正反”，我也不信$\\theta = 0.7$。\n这里就包含了贝叶斯学派的思想了——要考虑先验概率。 为此，引入了最大后验概率估计。\n最大后验概率估计(MAP) 最大似然估计是求参数$\\theta$, 使似然函数$P(x_0 | \\theta)$最 大 。 最大后验概率估计则是想求$\\theta$使$P(x_0|\\theta)$ 最大。求得的$\\theta$不单单让似然函数大，不单单让似然函数大，$\\theta$自己出现的先验概率也得大。(这有点像正则化里加惩罚项的思想，不过正则化里是利用加法，而MAP里是利用乘法).\nMAP其实是在最大化$P(\\theta|x_0) = \\frac{P(x_0|\\theta)P(\\theta)}{P(x_0)}$，不过因为$x_0$是确定的(即投出的“反正正正正反正正正反”)，$P(x_0)$是一个已知值，所以去掉了分母$P(x_0)$(假设“投10次硬币”是一次实验，实验做了1000次，“反正正正正反正正正反”出现了n次，则$P(x_0) = n/1000$)。总之，这是一个可以由数据集得到的值）。最大化$P(\\theta | x_0)$的意义也很明确，$x_0$已经出现了，要求$\\theta$取什么值使$P(\\theta | x_0)$最大。顺带一提，$P(\\theta | x_0)$, ​即后验概率，这就是“最大后验概率估计”名字的由来。\n对于投硬币的例子来看，我们认为（”先验地知道“$\\theta$取0.5的概率很大，取其他值的概率小一些。我们用一个高斯分布来具体描述我们掌握的这个先验知识，例如假设$P(\\theta)$为均值0.5，方差0.1的高斯函数，如下图：\n则$P(x_0 | \\theta)$的函数图像为：\n注意，此时函数取最大值时，θ \\thetaθ取值已向左偏移，不再是0.7。实际上，在$\\theta = 0.558$时函数取得了最大值。即，用最大后验概率估计，得到$\\theta = 0.558$\n最后，那要怎样才能说服一个贝叶斯派相信$\\theta = 0.7$呢？你得多做点实验。。\n如果做了1000次实验，其中700次都是正面向上，这时似然函数为:\n如果仍然假设$P(\\theta)$为均值0.5，方差0.1的高斯函数，$P(x_0 | \\theta) P(\\theta)$的函数图像为:\n在$\\theta = 0.696$处，$P(x_0 | \\theta) P(\\theta)$取得最大值。\n这样，就算一个考虑了先验概率的贝叶斯派，也不得不承认得把θ \\thetaθ估计在0.7附近了。\nPS. 要是遇上了顽固的贝叶斯派，认为$P(\\theta = 0.5) = 1$，那就没得玩了。。 无论怎么做实验，使用MAP估计出来都是$\\theta = 0.5$。这也说明，一个合理的先验概率假设是很重要的。（通常，先验概率能从数据中直接分析得到）\n最大似然估计和最大后验概率估计的区别 相信读完上文，MLE和MAP的区别应该是很清楚的了。MAP就是多个作为因子的先验概率$P(\\theta)$。或者，也可以反过来，认为MLE是把先验概率$P(\\theta)$认为等于1，即认为$\\theta$是均匀分布。\nref：https://blog.csdn.net/u011508640/article/details/72815981\n","permalink":"https://jianye0428.github.io/en/posts/tech/2022-05-30_mle/","summary":"最大似然估计（Maximum likelihood estimation, 简称MLE）和最大后验概率估计（Maximum a posteriori estimation, 简称MAP）是很常用的两种参数估计方法，如果不理解这两种","title":"详解最大似然估计(MLE)、最大后验概率估计(MAP)，以及贝叶斯公式的理解"},{"content":"用pickle保存和加载模型 保存模型 1 2 3 4 5 6 7 import pickle from sklearn.svm import SVC model_dir = \u0026#39;./model.pkl\u0026#39; model = SVC() with open(model_dir, \u0026#39;wb\u0026#39;) as f: pickle.dump(model, f) f.close() # 注意:保存完模型之后要关闭文件 加载模型 1 2 3 4 5 import pickle model_dir = \u0026#39;./model.pkl\u0026#39; with open(model_dir, \u0026#39;rb\u0026#39;) as f: model = pickel.load(f) print(mode.predict(x)) 逻辑回归 Logistic Regression LR Implementation code snippets 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score import numpy as np import matplotlib.pyplot as plt import pickle from tqdm import tqdm data_path = \u0026#39;./data/merged_data/data.npy\u0026#39; data = np.load(data_path, allow_pickle=True) model_l1_path=\u0026#39;./model/logistic_reg_l1.pickle\u0026#39; model_l2_path=\u0026#39;./model/logictic_reg_l2.pickle\u0026#39; X = data[:,0:35] y = data[:, -1] X_train, x_test, Y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # lr_l1 = LogisticRegression(penalty=\u0026#34;l1\u0026#34;, C=0.5, solver=\u0026#39;sag\u0026#39;, multi_class=\u0026#34;auto\u0026#34;) # lr_l2 = LogisticRegression(penalty=\u0026#34;l2\u0026#34;, C=0.5, solver=\u0026#39;sag\u0026#39;, multi_class=\u0026#34;auto\u0026#34;) # # train model # lr_l1.fit(X_train, Y_train) # lr_l2.fit(X_train, Y_train) # model performence on train set l1_train_predict = [] l2_train_predict = [] # model performence on test set l1_test_predict = [] l2_test_predict = [] for c in tqdm(np.linspace(0.01, 2, 50)): # lr_l1 = LogisticRegression(penalty=\u0026#34;l1\u0026#34;, C=c, solver=\u0026#39;liblinear\u0026#39;, max_iter=1000) # lr_l2 = LogisticRegression(penalty=\u0026#39;l2\u0026#39;, C=c, solver=\u0026#39;liblinear\u0026#39;, max_iter=1000) lr_l1 = LogisticRegression(penalty=\u0026#34;l1\u0026#34;, C=c, solver=\u0026#39;liblinear\u0026#39;, max_iter=1000, multi_class=\u0026#39;auto\u0026#39;) lr_l2 = LogisticRegression(penalty=\u0026#39;l2\u0026#39;, C=c, solver=\u0026#39;liblinear\u0026#39;, max_iter=1000, multi_class=\u0026#39;auto\u0026#39;) # 训练模型，记录L1正则化模型在训练集测试集上的表现 lr_l1.fit(X_train, Y_train) l1_train_predict.append(accuracy_score(lr_l1.predict(X_train), Y_train)) l1_test_predict.append(accuracy_score(lr_l1.predict(x_test), y_test)) # 记录L2正则化模型的表现 lr_l2.fit(X_train, Y_train) l2_train_predict.append(accuracy_score(lr_l2.predict(X_train), Y_train)) l2_test_predict.append(accuracy_score(lr_l2.predict(x_test), y_test)) if c == 2: pred_y_test = lr_l2.predict(x_test) mask = abs(pred_y_test-y_test) \u0026lt; 5 neg_test = pred_y_test[mask] res = (len(neg_test)/len(pred_y_test)) print(res) with open(model_l1_path, \u0026#39;wb\u0026#39;) as f1: pickle.dump(lr_l1, f1) with open(model_l2_path, \u0026#39;wb\u0026#39;) as f2: pickle.dump(lr_l2, f2) data = [l1_train_predict, l2_train_predict, l1_test_predict, l2_test_predict] label = [\u0026#39;l1_train\u0026#39;, \u0026#39;l2_train\u0026#39;, \u0026#39;l1_test\u0026#39;, \u0026#34;l2_test\u0026#34;] color = [\u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;blue\u0026#39;] plt.figure(figsize=(12, 6)) for i in range(4) : plt.plot(np.linspace(0.01, 2, 50), data[i], label=label[i], color=color[i]) plt.legend(loc=\u0026#34;best\u0026#34;) plt.show() 支持向量机 Support Vector Machine Using GridSearch to find the best parameters [code snippets] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 import numpy as np import matplotlib.pyplot as plt from sklearn.linear_model import Perceptron, LogisticRegression from sklearn.svm import SVC from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn import datasets from sklearn import metrics import pickle merged_data_dir = \u0026#39;../data/merged_data/merged_data.npy\u0026#39; model_dir=\u0026#39;./svm.pkl\u0026#39; data = np.load(merged_data_dir, allow_pickle=True) #labeling for ele in data: if ele[-1] \u0026lt; 20: ele[-1] = 0 elif ele[-1] \u0026gt;=20 and ele[-1] \u0026lt; 40: ele[-1] = 1 else: ele[-1] = 2 X = data[:,0:34] y = data[:,-1] print(y) # Create training and test split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y) # feature scaling # sc = StandardScaler() # sc.fit(X_train) # X_train_std = sc.transform(X_train) # X_test_std = sc.transform(X_test) ################################## # # Instantiate the Support Vector Classifier (SVC) # svc = SVC(C=10, random_state=1, kernel=\u0026#39;rbf\u0026#39;, gamma=0.3) # # Fit the model # svc.fit(X_train, y_train) # # Make the predictions # y_predict = svc.predict(X_test) # # Measure the performance # print(\u0026#34;Accuracy score %.3f\u0026#34; %metrics.accuracy_score(y_test, y_predict)) ############################################# def svm_cross_validation(train_x, train_y): from sklearn.model_selection import GridSearchCV from sklearn.svm import SVC model = SVC(kernel=\u0026#39;rbf\u0026#39;, probability=True) param_grid = {\u0026#39;C\u0026#39;: [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000], \u0026#39;gamma\u0026#39;: [0.001, 0.0001]} grid_search = GridSearchCV(model, param_grid, n_jobs = 8, verbose=1, scoring=\u0026#39;accuracy\u0026#39;) grid_search.fit(train_x, train_y) best_parameters = grid_search.best_estimator_.get_params() for para, val in list(best_parameters.items()): print(para, val) model = SVC(kernel=\u0026#39;rbf\u0026#39;, C=best_parameters[\u0026#39;C\u0026#39;], gamma=best_parameters[\u0026#39;gamma\u0026#39;], probability=True) model.fit(train_x, train_y) return model svm_model = svm_cross_validation(X_train, y_train) with open(model_dir, \u0026#39;wb\u0026#39;) as f1: pickle.dump(svm_model, f1) f1.close() print(svm_model.score(X_test, y_test)) y_predict = svm_model.predict(X_test) print(y_predict) ","permalink":"https://jianye0428.github.io/en/posts/notes/2022-05-28_ml/","summary":"用pickle保存和加载模型 保存模型 1 2 3 4 5 6 7 import pickle from sklearn.svm import SVC model_dir = \u0026#39;./model.pkl\u0026#39; model = SVC() with open(model_dir, \u0026#39;wb\u0026#39;) as f: pickle.dump(model, f) f.close() # 注意:保存完模型之后要关闭文件 加载模型 1 2 3 4 5","title":"Machine Learning Algo"},{"content":"numpy function 1. np.stack();np.vstack();np.hstack();np.concatenate() 区别 np.concatenate()函数根据指定的维度，对一个元组、列表中的list或者ndarray进行连接 1 2 3 # np.concatenate() numpy.concatenate((a1, a2, ...), axis=0)#在0维进行拼接 numpy.concatenate((a1, a2, ...), axis=1)#在1维进行拼接 - ```np.stack()```函数的原型是numpy.stack(arrays, axis=0)，即将一堆数组的数据按照指定的维度进行堆叠。 ```python # np.stack() numpy.stack([a1, a2], axis=0)#在0维进行拼接 numpy.stack([a1, a2], axis=1)#在1维进行拼接 ``` \u0026gt; 注意:进行stack的两个数组必须有相同的形状，同时，输出的结果的维度是比输入的数组都要多一维。 - ```np.vstack()```的函数原型：vstack(tup) ，参数tup可以是元组，列表，或者numpy数组，返回结果为numpy的数组。它是**垂直（按照行顺序）的把数组给堆叠起来**。 - ```np.hstack()```的函数原型：hstack(tup) ，参数tup可以是元组，列表，或者numpy数组，返回结果为numpy的数组。它其实就是**水平(按列顺序)把数组给堆叠起来**，与vstack()函数正好相反。 \u0026gt; ref: https://cloud.tencent.com/developer/article/1378491 2. np.sort() 3. np.unique() 4. np.argsort() ","permalink":"https://jianye0428.github.io/en/posts/notes/2022-05-24_numpy/","summary":"numpy function 1. np.stack();np.vstack();np.hstack();np.concatenate() 区别 np.concatenate()函数根据指定的维度，对一个元组、列表中的list或者ndarray进行连接 1 2 3 # np.concatenate() numpy.concatenate((a1, a2, ...), axi","title":"Numpy Notes"},{"content":"python文件相关 os.path模块 os.path.exists(): 判断当前目录以及文件是否存在 os.path.mkdir(): 若目录或文件不存在，则创建\n1 2 3 4 5 6 7 8 9 import os # 目录 dirs = \u0026#39;/Users/joseph/work/python/\u0026#39; if not os.path.exists(dirs): os.makedirs(dirs) # 文件 filename = \u0026#39;/Users/joseph/work/python/poem.txt\u0026#39; if not os.path.exists(filename): os.system(r\u0026#34;touch {}\u0026#34;.format(path))#调用系统命令行来创建文件 os.listdir()： 用于返回指定的文件夹包含的文件或文件夹的名字的列表\n1 2 3 4 5 6 7 8 # 打开文件 path = \u0026#34;/var/www/html/\u0026#34; # 如果目录名字为中文 需要转码处理 path = unicode(path,\u0026#39;utf-8\u0026#39;) dirs = os.listdir(path) # 输出所有文件和文件夹 for file in dirs: print(file) os.path.join(): 路径拼接\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import os path = \u0026#34;/home\u0026#34; # Join various path components print(os.path.join(path, \u0026#34;User/Desktop\u0026#34;, \u0026#34;file.txt\u0026#34;)) # /home/User/Desktop/file.txt path = \u0026#34;User/Documents\u0026#34; # Join various path components print(os.path.join(path, \u0026#34;/home\u0026#34;, \u0026#34;file.txt\u0026#34;)) # /home/file.txt # In above example \u0026#39;/home\u0026#39; # represents an absolute path # so all previous components i.e User / Documents # are thrown away and joining continues # from the absolute path component i.e / home. print(os.path.join(path, \u0026#34;Downloads\u0026#34;, \u0026#34;file.txt\u0026#34;, \u0026#34;/home\u0026#34;)) # /home # In above example \u0026#39;/User\u0026#39; and \u0026#39;/home\u0026#39; # both represents an absolute path # but \u0026#39;/home\u0026#39; is the last value # so all previous components before \u0026#39;/home\u0026#39; # will be discarded and joining will # continue from \u0026#39;/home\u0026#39; os.path.abspath(path): 返回绝对路径\nos.path.basename(path): 返回文件名\nos.path.commonprefix(list): 返回list(多个路径)中，所有path共有的最长的路径\nos.path.dirname(path): 返回文件路径\nos.path.expanduser(path): 把path中包含的\u0026quot;~\u0026ldquo;和\u0026rdquo;~user\u0026quot;转换成用户目录\nos.path.expandvars(path): 根据环境变量的值替换path中包含的 \u0026ldquo;$name\u0026rdquo; 和 \u0026ldquo;${name}\u0026rdquo;\nos.path.getatime(path): 返回最近访问时间(浮点型秒数)\nos.path.getmtime(path): 返回最近文件修改时间\nos.path.getctime(path): 返回文件 path 创建时间\nos.path.getsize(path): 返回文件大小，如果文件不存在就返回错误\nos.path.isfile(path): 判断路径是否为文件\nos.path.isdir(path): 判断路径是否为目录\nos.path.islink(path): 判断路径是否为链接\nos.path.ismount(path): 判断路径是否为挂载点\nos.path.normcase(path): 转换path的大小写和斜杠\nos.path.normpath(path): 规范path字符串形式\nos.path.realpath(path): 返回path的真实路径\nos.path.relpath(path[, start]): 从start开始计算相对路径\nos.path.samefile(path1, path2): 判断目录或文件是否相同\nos.path.sameopenfile(fp1, fp2): 判断fp1和fp2是否指向同一文件\nos.path.samestat(stat1, stat2): 判断stat tuple stat1和stat2是否指向同一个文件\nos.path.split(path): 把路径分割成 dirname 和 basename，返回一个元组\nos.path.splitdrive(path): 一般用在 windows 下，返回驱动器名和路径组成的元组\nos.path.splitext(path): 分割路径，返回路径名和文件扩展名的元组\nos.path.splitunc(path): 把路径分割为加载点与文件\nos.path.walk(path, visit, arg): 遍历path，进入每个目录都调用visit函数，visit函数必须有3个参数(arg, dirname, names)，dirname表示当前目录的目录名，names代表当前目录下的所有文件名，args则为walk的第三个参数\nos.walk(path,topdown=True,onerror=None): 函数返回一个元组，含有三个元素。这三个元素分别是：每次遍历的路径名、路径下子目录列表、目录下文件列表。\n1 2 3 4 5 path = \u0026#39;xxx/xxx\u0026#39; for root, dirs, files in os.walk(path): print(root) # path以及path下的目录 print(dirs) # path下的文件夹 print(files) # path下每个文件夹中的文件 区别：os.path.walk()与os.walk()产生的文件名列表并不相同.os.walk()产生目录树下的目录路径和文件路径，而os.path.walk()只产生文件路径（是子目录与文件的混合列表）。 ref: https://www.cnblogs.com/zmlctt/p/4222621.html\nos.path.supports_unicode_filenames: 设置是否支持unicode路径名\n","permalink":"https://jianye0428.github.io/en/posts/notes/2022-05-23_python/","summary":"python文件相关 os.path模块 os.path.exists(): 判断当前目录以及文件是否存在 os.path.mkdir(): 若目录或文件不存在，则创建 1 2 3 4 5 6 7 8 9 import os # 目录 dirs = \u0026#39;/Users/joseph/work/python/\u0026#39; if not os.path.exists(dirs): os.makedirs(dirs) #","title":"Python Notes"},{"content":"Pandas Notes Input/Output pd.read_csv(filepath): 读取csv文件 ref: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html?highlight=read_csv\npd.read_pickle():读取pickle数据\n1 2 import pandas pandas.read_pickle(filepath_or_buffer, compression=\u0026#39;infer\u0026#39;, storage_options=None) ref: https://pandas.pydata.org/docs/reference/api/pandas.read_pickle.html Parameters:\nfilepath_or_buffer: 文件名或者文件路径 字符串、路径对象(实现 os.PathLike[str] )或 file-like 对象实现二进制 readlines() 函数。 compression: str or dict, default ‘infer’ 用于on-disk 数据的即时解压缩。如果 ‘infer’ 和 ‘filepath_or_buffer’ 是 path-like，则从以下扩展名检测压缩：“.gz”、“.bz2”、“.zip”、“.xz”或“.zst”(否则不压缩)。如果使用‘zip’，ZIP 文件必须只包含一个要读入的数据文件。设置为None 不解压缩。也可以是键 \u0026lsquo;method\u0026rsquo; 设置为 {'zip' , 'gzip' , 'bz2' , 'zstd' } 之一的字典，其他键值对分别转发到 zipfile.ZipFile , gzip.GzipFile , bz2.BZ2File 或 zstandard.ZstdDecompressor 。例如，可以使用自定义压缩字典为 Zstandard 解压缩传递以下内容：compression={\u0026lsquo;method\u0026rsquo;: \u0026lsquo;zstd\u0026rsquo;, \u0026lsquo;dict_data\u0026rsquo;: my_compression_dict}。 storage_options: dict, optional 对特定存储连接有意义的额外选项，例如主机、端口、用户名、密码等。对于 HTTP(S) URL，键值对作为标头选项转发到 urllib。对于其他 URL(例如以 “s3://” 和 “gcs://” 开头)，键值对被转发到fsspec 。有关详细信息，请参阅fsspec和urllib。 General functions 通用函数 Series DataFrame DataFrame是一个【表格型】的数据结构，可以看做是【由Series组成的字典】（共用同一个索引）。DataFrame由按一定顺序排列的多列数据组成。设计初衷是将Series的使用场景从一维拓展到多维。\nConstructor DataFrame[data, index, columns, dtype, copy]: 构造一个DataFrame对象 Attributes and underlying data DataFrame.index: 行标签(行信息)-\u0026gt;第0列的信息 DataFrame.columns: 列标签(列信息)-\u0026gt; 第0行的信息 DataFrame.dtypes: 返回DataFrame的数据类型 DataFrame.info([verbose, buf, max_cols, ...]): 返回df的信息 DataFrame.select_dtypes([include, exclude]): 返回DataFrame中根据columns筛选的部分数据 DataFrame.values: 以numpy数组的形式返回数据 DataFrame.axes: 返回一个list，其中是df的axes DataFrame.ndim: 返回int，代表axes/array的数量 DataFrame.shape: 返回tuple, 代表df维度 DataFrame.memory_usage([index, deep]): 返回数据内存使用情况 DataFrame.empty: 判断df是否为空 DataFrame.set_flags(*[, copy, ...]): 返回带有更新标记的df DataFrame.set_flags(*, copy=False, allows_duplicate_labels=None) 参数：allows_duplicate_labels：布尔型，可选。返回的对象是否允许重复标签。 返回：Series或DataFrame, 与调用者相同的类型。 注意：此方法返回一个新对象，该对象是与输入数据相同的视图。改变输入或输出值将反映在另一个中。此方法旨在用于方法链中。“Flags” 与 “metadata” 不同。标志反映了 pandas 对象(Series 或 DataFrame)的属性。元数据是 index 据集的属性，应存储在 DataFrame.attrs 中。 demo: 1 2 3 4 5 6 \u0026gt;\u0026gt;\u0026gt; df = pd.DataFrame({\u0026#34;A\u0026#34;:[1, 2]}) \u0026gt;\u0026gt;\u0026gt; df.flags.allows_duplicate_labels True \u0026gt;\u0026gt;\u0026gt; df2 = df.set_flags(allows_duplicate_labels=False) \u0026gt;\u0026gt;\u0026gt; df2.flags.allows_duplicate_labels False DataFrame.groupby(): Conversion DataFrame.astype(dtype[,copy, errors]):数据类型转换 DataFrame.convert_dtypes([infer_objects, ...]):根据现存数据推断pd.NA数据类型 DataFrame.infer_objects():根据现有数据大部分数据推断类型 DataFrame.copy([deep]):深度拷贝 demo 1 2 3 s = pd.Series([1,2], index=[\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;]) deep = s.copy()# 深拷贝 shallow = s.copy(deep=False) # 浅拷贝 DataFrame.bool():判断数据是ture还是false，只针对单个元素对象 Indexing，iteration DataFrame.head([n]): return the first n rows DataFrame.at[4,'B']: 用标签取值(行名为4，列名为B的值) DataFrame.iat[1,2]: 用行列的整数取值(第1行,第二列的值) DataFrame.loc['cobra':'viper', 'max_speed']: 取行名为\u0026rsquo;cobra\u0026rsquo;至\u0026rsquo;viper\u0026rsquo;, 列名为\u0026rsquo;max_speed\u0026rsquo;的值 DataFrame.iloc: 通过行列的值取值 df.iloc[0]:取第0行，所有列的值，返回series类型 df.iloc[[0]]:取得第0行，所有列的值，返回df类型 df.iloc[[0,1]]:取得第0行和第1行的所有列的值 df.iloc[:3]:取得第0，1，2行的值 df.iloc[[True, False, True]]: 用True/False标记要取的行 df.iloc[lambda x:x.index % 2 == 0]: 用lambda标记要取的行 df.iloc[0,1]:取得第0行，第1列的值 df.iloc[[0,2],[1,3]]: 取得第0行，第2行，第1列，第3列的值 df.iloc[1:3, 0:3]: 取得第1行，第2行，第0列，第1列，第2列的值 df.iloc[:, [True,False,True,False]]:取所有的行，用True/False取相应的列 df.iloc[:,lambda df:[0,2]]: 取所有的行，取第0列，第2列 df.insert(loc, column, value, allow_duplicates=False):插入相应的列 loc:(int), 列的位置 column: 列的名字，一般类型为string value: 列数据的值 df.drop():删除固定的行或者列 df.drop_duplicates(subset, keep, inplace=False,ignore_index=False):删除重复的行或者列 subset: 根据某一列的值，删除行数据 keep: 设置保留第一次出现的数据或者最后一次出现的数据 ","permalink":"https://jianye0428.github.io/en/posts/notes/2022-05-23_pandas/","summary":"Pandas Notes Input/Output pd.read_csv(filepath): 读取csv文件 ref: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html?highlight=read_csv pd.read_pickle():读取pickle数据 1 2 import pandas pandas.read_pickle(filepath_or_buffer, compression=\u0026#39;infer\u0026#39;, storage_options=None) ref: https://pandas.pydata.org/docs/reference/api/pandas.read_pickle.html Parameters: filepath_or_buffer: 文件名或者文件路径 字符串、路径对象(实","title":"Pandas Notes"},{"content":"Linux系统各系统文件夹下的区别 首先，usr 指 Unix System Resource，而不是User。\n通常，\n/usr/bin下面的都是系统预装的可执行程序，会随着系统升级而改变。\n/usr/local/bin目录是给用户放置自己的可执行程序的地方，推荐放在这里，不会被系统升级而覆盖同名文件。\n如果两个目录下有相同的可执行程序，谁优先执行受到PATH环境变量的影响，比如我的一台服务器的PATH变量为。\n1 echo $PATH 这里/usr/local/bin优先于/usr/bin, 一般都是如此。\n/lib是内核级的, /usr/lib是系统级的, /usr/local/lib是用户级的.\n/ - 对你的电脑来说, 有且只有一个根目录。所有的东西都是从这里开始。举个例子: 当你在终端里输入\u0026quot;/home\u0026quot;，你其实是在告诉电脑，先从/(根目录)开始，再进入到home目录。\n/lib/ — 包含许多被/bin/和/sbin/中的程序使用的库文件。目录/usr/lib/中含有更多用于用户程序的库文件。/lib目录下放置的是/bin和/sbin目录下程序所需的库文件。/lib目录下的文件的名称遵循下面的格式：\nlibc.so.* ld* 仅仅被/usr目录下的程序所使用的共享库不必放到/lib目录下。只有/bin和/sbin下的程序所需要的库有必要放到/lib目录下。实际上，libm.so.*类型的库文件如果被是/bin和/sbin所需要的，也可以放到/usr/lib下。 /bin/ — 用来贮存用户命令。目录 /usr/bin 也被用来贮存用户命令。\n/sbin/ — 许多系统命令(例如 shutdown)的贮存位置。目录/usr/sbin中也包括了许多系统命令。\n/root/ — 根用户(超级用户)的主目录。\n/mnt/ — 该目录中通常包括系统引导后被挂载的文件系统的挂载点。譬如，默认的光盘挂载点是/mnt/cdrom/.\n/boot/ — 包括内核和其它系统启动期间使用的文件。\n/lost+found/ — 被fsck用来放置零散文件(没有名称的文件)。\n/lib/ — 包含许多被/bin/和/sbin/中的程序使用的库文件。目录/usr/lib/中含有更多用于用户程序的库文件。\n/dev/ — 贮存设备文件。\n/etc/ — 包含许多配置文件和目录。系统主要的设定档几乎都放置在这个目录内，例如人员的帐号密码档、各种服务的启始档等等。 一般来说，这个目录下的各档案属性是可以让一般使用者查阅的，但是只有root有权力修改。\n/var/ — 用于贮存variable(或不断改变的)文件，例如日志文件和打印机假脱机文件。\n/usr/ — 包括与系统用户直接有关的文件和目录，例如应用程序及支持它们的库文件。在这个目录下，你可以找到那些不适合放在/bin或/etc目录下的额外的工具。比如像游戏阿，一些打印工具拉等等。/usr目录包含了许多子目录： /usr/bin目录用于存放程序; /usr/share用于存放一些共享的数据，比如音乐文件或者图标等等;/usr/lib目录用于存放那些不能直接运行的，但却是许多程序运行所必需的一些函数库文件。\n/proc/ — 一个虚拟的文件系统(不是实际贮存在磁盘上的)，它包括被某些程序使用的系统信息。\n/initrd/ — 用来在计算机启动时挂载 initrd.img 映像文件的目录以及载入所需设备模块的目录。\n警告: 不要删除/initrd/目录。如果你删除了该目录后再重新引导Red Hat Linux时，你将无法引导你的计算机。\n/tmp/ — 用户和程序的临时目录。/tmp给予所有系统用户读写权。**这是让一般使用者或者是正在执行的程序暂时放置档案的地方。**这个目录是任何人都能够存取的，所以你需要定期的清理一下。当然，重要资料不可放置在此目录啊。 因为FHS甚至建议在开机时，应该要将/tmp下的资料都删除。\n/home/ — 用户主目录的默认位置。\n/opt/ — 可选文件和程序的贮存目录。该目录主要被第三方开发者用来简易地安装和卸装他们的软件包。这里主要存放那些可选的程序。你想尝试最新的firefox测试版吗?那就装到/opt目录下吧，这样，当你尝试完，想删掉firefox的时候，你就可 以直接删除它，而不影响系统其他任何设置。安装到/opt目录下的程序，它所有的数据、库文件等等都是放在同个目录下面。\n/usr/local/ - 这里主要存放那些手动安装的软件，即apt或者apt-get安装的软件。它和/usr目录具有相类似的目录结构。让软件包管理器来管理/usr目录，而把自定义的脚本(scripts)放到/usr/local目录下面，我想这应该是个不错的主意。\n/media/ - 有些linux的发行版使用这个目录来挂载那些usb接口的移动硬盘(包括U盘)、CD/DVD驱动器等等。\n/usr/local/ 和 /usr/share/ 区别 /usr/local - 这个目录一般是用来存放用户自编译安装软件的存放目录; 一般是通过源码包安装的软件，如果没有特别指定安装目录的话，一般是安装在这个目录中。这个目录下面有子目录。\n/usr/share - 系统共用的东西存放地，比如/usr/share/fonts是字体目录，/usr/share/doc和/usr/share/man帮助文件。\n/var/log - 系统日志存放，分析日志要看这个目录的东西;\n/var/spool - 打印机、邮件、代理服务器等脱机目录。\nLinux Command Notes 查找文件的命令:find/locate/whereis/which/type/grep find find命令准确，但速度非常慢，它可以查找任何类型的文件\n使用格式\n1 find [指定目录] [指定条件] [指定动作] 参数说明:\n[指定目录]： 所要搜索的目录及其所有子目录。默认为当前目录 [指定条件]： 所要搜索的文件的特征 -name：按文件名来查找文件 -user：按照文件的属主来查找文件 -group：按照文件所属的组来查找文件 -perm：按照文件权限来查找文件 -prune：不在当前指定目录中查找 [指定动作]： 对搜索结果进行特定的处理 -print：将匹配的文件输出到标准输出 -exec：对匹配的文件执行该参数所给出的shell命令 -ok：和-exec的作用相同，在执行每一个命令之前，让用户来确定是否执行 find命令不加任何参数时，表示搜索路径为当前目录及其子目录，默认的动作为-print，即不过滤任何结果，也就是说输出所有的文件\n使用示例: - 递归搜索当前目录中，所有以file开头的文件 shell find . -name 'file*' - 递归搜索当前目录中，所有以file开头的文件，并显示它们的详细信息 shell find . -name 'file*' -ls locate locate命令可以说是find -name的另一种写法，但是要比后者快得多，原因在于它不搜索具体目录，而是搜索一个数据库/var/lib/locatedb，这个数据库中含有本地所有文件信息.\nLinux自动创建这个数据库，并且每天自动更新一次，所以使用locate命令查不到最新变动过的文件。为了避免这种情况，可以在使用locate之前，先使用updatedb命令，手动更新数据库.\n使用格式:\n1 locate [参数] \u0026lt;文件名\u0026gt; 使用示例:\n搜索etc目录下所有以file开头的文件 1 locate /etc/file 搜索用户主目录下，所有以f开头的文件，并且忽略大小写 1 locate -i ~/f whereis whereis命令只能搜索特定格式的文件\n使用格式 1 whereis [参数] \u0026lt;文件名\u0026gt; 可搜索文集类型 二进制文件(-b) 源代码文件(-s) 说明文件(-m) 如果省略参数，则返回所有信息\n使用示例: 找出名为find的文件位置 1 whereis find which which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果, 也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。\n使用格式 1 which \u0026lt;命令\u0026gt; 使用实例: 查找find命令的位置 1 which find type type命令其实不能算查找命令，它是用来区分某个命令到底是由shell自带的，还是由shell外部的独立二进制文件提供的; 如果一个命令是外部命令，那么使用-p参数，会显示该命令的路径，相当于which命令。\n使用格式 1 type \u0026lt;命令\u0026gt; 使用实例: 查看cd命令是否为shell自带的命令 1 type cd 查看grep是否为外部命令 1 type grep grep grep命令用于查找拥有特殊字段的文件。\n语法\n1 grep [-abcEFGhHilLnqrsvVwxy][-A\u0026lt;显示行数\u0026gt;][-B\u0026lt;显示列数\u0026gt;][-C\u0026lt;显示列数\u0026gt;][-d\u0026lt;进行动作\u0026gt;][-e\u0026lt;范本样式\u0026gt;][-f\u0026lt;范本文件\u0026gt;][--help][范本样式][文件或目录...] 参数:\n-a 或 \u0026ndash;text : 不要忽略二进制的数据。 -A\u0026lt;显示行数\u0026gt; 或 \u0026ndash;after-context=\u0026lt;显示行数\u0026gt; : 除了显示符合范本样式的那一列之外，并显示该行之后的内容。 -b 或 \u0026ndash;byte-offset : 在显示符合样式的那一行之前，标示出该行第一个字符的编号。 -B\u0026lt;显示行数\u0026gt; 或 \u0026ndash;before-context=\u0026lt;显示行数\u0026gt; : 除了显示符合样式的那一行之外，并显示该行之前的内容。 -c 或 \u0026ndash;count : 计算符合样式的列数。 -C\u0026lt;显示行数\u0026gt; 或 \u0026ndash;context=\u0026lt;显示行数\u0026gt;或-\u0026lt;显示行数\u0026gt; : 除了显示符合样式的那一行之外，并显示该行之前后的内容。 -d \u0026lt;动作\u0026gt; 或 \u0026ndash;directories=\u0026lt;动作\u0026gt; : 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。 -e\u0026lt;范本样式\u0026gt; 或 \u0026ndash;regexp=\u0026lt;范本样式\u0026gt; : 指定字符串做为查找文件内容的样式。 -E 或 \u0026ndash;extended-regexp : 将样式为延伸的正则表达式来使用。 -f\u0026lt;规则文件\u0026gt; 或 \u0026ndash;file=\u0026lt;规则文件\u0026gt; : 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。 -F 或 \u0026ndash;fixed-regexp : 将样式视为固定字符串的列表。 -G 或 \u0026ndash;basic-regexp : 将样式视为普通的表示法来使用。 -h 或 \u0026ndash;no-filename : 在显示符合样式的那一行之前，不标示该行所属的文件名称。 -H 或 \u0026ndash;with-filename : 在显示符合样式的那一行之前，表示该行所属的文件名称。 -i 或 \u0026ndash;ignore-case : 忽略字符大小写的差别。 -l 或 \u0026ndash;file-with-matches : 列出文件内容符合指定的样式的文件名称。 -L 或 \u0026ndash;files-without-match : 列出文件内容不符合指定的样式的文件名称。 -n 或 \u0026ndash;line-number : 在显示符合样式的那一行之前，标示出该行的列数编号。 -o 或 \u0026ndash;only-matching : 只显示匹配PATTERN 部分。 -q 或 \u0026ndash;quiet或\u0026ndash;silent : 不显示任何信息。 -r 或 \u0026ndash;recursive : 此参数的效果和指定\u0026quot;-d recurse\u0026quot;参数相同。 -s 或 \u0026ndash;no-messages : 不显示错误信息。 -v 或 \u0026ndash;invert-match : 显示不包含匹配文本的所有行。 -V 或 \u0026ndash;version : 显示版本信息。 -w 或 \u0026ndash;word-regexp : 只显示全字符合的列。 -x \u0026ndash;line-regexp : 只显示全列符合的列。 -y : 此参数的效果和指定\u0026quot;-i\u0026quot;参数相同。 示例:\n1 2 # 查找指定目录/etc/acpi 及其子目录（如果存在子目录的话）下所有文件中包含字符串\u0026#34;update\u0026#34;的文件，并打印出该字符串所在行的内容 grep -r update /etc/acpi 1 2 # 查看符合条件的日志条目。 grep -n \u0026#39;2019-10-24 00:01:11\u0026#39; *.log 1 2 # 只匹配文本文件，不匹配二进制文件的命令 grep -srn \u0026#34;parameter\u0026#34; . --binary-files=without-match ","permalink":"https://jianye0428.github.io/en/posts/tech/2022-05-13_linux_filesystem/","summary":"Linux系统各系统文件夹下的区别 首先，usr 指 Unix System Resource，而不是User。 通常， /usr/bin下面的都是系统预装的可执行程序，","title":"Linux filesystem"},{"content":"VIM 8.2 安装 1. Install Python3.9 from source Update the packages list and install the packages necessary to build Python\n1 sudo apt update \u0026amp;\u0026amp; sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev libsqlite3-dev wget libbz2-dev Download the latest release’s source code from the Python download page using wget\n1 wegt https://www.python.org/ftp/python/3.9.0/Python-3.9.1.tgz Switch to the Python source directory and execute the configure script which performs a number of checks to make sure all of the dependencies on your system are present\n1 2 3 cd Python-3.9.1 ./configure --enable-optimizations --with-lto --enable-shared --prefix=/usr/local/python39 make -j8 When the build process is complete, install the Python binaries by typing\n1 sudo make altinstall Do not use the standard make install as it will overwrite the default system python3 binary.\ncopy the dynamic library to usr/lib/x86_64-linux-gnu/libpython3.9.so.1.0\n1 sudo cp /usr/local/python39/lib/libpython3.9.so.1.0 /usr/lib/x86_64-linux-gnu/ the command can slove the error: error while loading shared libraries: libpython3.9.so.1.0: cannot open shared object file: No such file or directory\nmake the soft link to set python39 as default python3\n1 2 sudo ln -sf /usr/local/python39/bin/python3.9 /usr/bin/python3 sudo ln -s /usr/local/python39/bin/python3.9 /usr/bin/python3.9 using update-alternatives to switch different python version\nlist all the python versions\n1 sudo update-alternatives --list python3 display python3\n1 sudo update-alternatives --display python3 set different number for different version\n1 2 sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1 sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2 show different mode and select number to switch another mode\n1 sudo update-alternatives --config python3 2. 源码安装cmake 2.1 download the cmake source code download source code 1 wget https://github.com/Kitware/CMake/releases/download/v3.23.1/cmake-3.23.1.tar.gz 2.2 extract the source code directory and run the command to install extraction and configuration 1 2 3 cd cmake-2.23.0 ./bootstrap //需要的话也可以指定安装目录，例如--prefix=/usr/local/cmake make \u0026amp;\u0026amp; sudo make install 2.3 create soft link and set cmake as default set cmake as default 1 sudo ln -s /usr/local/bin/cmake /usr/bin/cmake 3. 首先从github下载源码vim 8.2 3.1 源码安装vim8.2 run the following command to downlaod source code of VIM from github\n1 2 3 4 5 git clone git clone https://github.com/vim/vim.git cd vim git pull cd src/ sudo make distclean # 如果您以前构建国vim cofigure the installation file\n1 2 3 ./configure --with-features=huge --enable-multibyte --enable-python3interp=dynamic --with-python3-config-dir=/usr/lib/python3.10/config-3.10-x86_64-linux-gnu/ --enable-cscope --enable-gui=auto --enable-gtk2-check --enable-fontset --enable-largefile --disable-netbeans --with-compiledby=\u0026#34;18817571704@163.com\u0026#34; --enable-fail-if-missing --prefix=/usr/local/vim82 sudo make sudo make install enable clipboard\nthen you can copy the content from system clipboard to vim 1 sudo apt-get install vim-gtk3 卸载vim\n使用以下命令重置编译操作\n1 sudo make distclean 使用以下命令，可以卸载命令\n1 sudo make uninstall 3.2 安装vim-plug以及插件 安装vim-plug:\n1 2 curl -fLo ~/.vim/autoload/plug.vim --create-dirs \\ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim 安装主题gruvbox\nto fix error: Cannot find color scheme \u0026lsquo;gruvbox\u0026rsquo;\n1 2 mkdir ~/.vim/colors/ cp ~/.vim/plugged/gruvbox/gruvbox.vim ~/.vim/colors/ 安装YCM(YouCompleteMe) 根据~/.vimrc按装YCM\n1 2 cd ~/.vim/plugged/YouCompleteMe/ ./install.py --clang-completer 安装ctags\n1 sudo apt-get install exuberant-ctags 其他主题直接编辑:PlugInstall进行安装\n3.2 reference 参考链接:\n[1] https://github.com/ycm-core/YouCompleteMe/wiki/Building-Vim-from-source [2] https://wizardforcel.gitbooks.io/use-vim-as-ide/content/0.html ","permalink":"https://jianye0428.github.io/en/posts/tech/2022-05-11_vim_installation/","summary":"VIM 8.2 安装 1. Install Python3.9 from source Update the packages list and install the packages necessary to build Python 1 sudo apt update \u0026amp;\u0026amp; sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev libsqlite3-dev wget libbz2-dev Download the latest release’s source code from the Python download page using wget 1 wegt https://www.python.org/ftp/python/3.9.0/Python-3.9.1.tgz Switch to the Python source directory","title":"Build VIM 8.2 from source"},{"content":"git command record as my cheatsheet 1. git rebase ref: https://git-scm.com/docs/git-rebase\n用法一:git rebase \u0026lt;branch-name\u0026gt; 将topic分支的base由E改为master\n1 2 3 A---B---C topic / D---E---F---G master 运行:\n1 2 git rebase master git rebase master topic 结果:\n1 2 3 A\u0026#39;--B\u0026#39;--C\u0026#39; topic / D---E---F---G master if upstream branch already has a change like below:\n1 2 3 A---B---C topic / D---E---A\u0026#39;---F master then run the command git rebase master, you will get following result:\n1 2 3 B\u0026#39;---C\u0026#39; topic / D---E---A\u0026#39;---F master 用法二:git rebase --onto assume topic is based on next, and next is based on master\n1 2 3 4 5 o---o---o---o---o master \\ o---o---o---o---o next \\ o---o---o topic run the command below:\n1 git rebase --onto master next topic then we get the result below:\n1 2 3 4 5 o---o---o---o---o master | \\ | o\u0026#39;--o\u0026#39;--o\u0026#39; topic \\ o---o---o---o---o next Another example: A range of commits could also be removed with rebase. If we have the following situation:\n1 E---F---G---H---I---J topicA then the command\n1 git rebase --onto topicA~5 topicA~3 topicA would result in the removal of commits F and G:\n1 E---H\u0026#39;---I\u0026#39;---J\u0026#39; topicA 用法三:git rebase -i \u0026lt;commit_id\u0026gt; \u0026lt;commit_id\u0026gt; $\\mathbb{\\rightarrow}$ 将多个commit合并为一个。\n1 2 3 4 5 # 执行git log，得到以下commit_ids \u0026gt;\u0026gt;\u0026gt;21fd585 \u0026gt;\u0026gt;\u0026gt;45j3483 \u0026gt;\u0026gt;\u0026gt;9i8975d \u0026gt;\u0026gt;\u0026gt;73c20ec 目标: 将21fd585、45j3483、9i8975d rebase 到 73c20ec\n1 git rebase -i 73c20ec 21fd585 得到:\n1 2 3 4 pick pick pick pick 改为\n1 2 3 4 pick squash squash squash 最后，编辑commit内容， 得到\n1 2 \u0026gt;\u0026gt;\u0026gt;b8bec33 # 此处为新的commit \u0026gt;\u0026gt;\u0026gt;73c20ec 推送到remote:\n1 git push -f origin master ref:\nhttps://www.bilibili.com/video/BV15h411f74h/ https://blog.csdn.net/weixin_45953517/article/details/114362752 https://blog.csdn.net/weixin_44691608/article/details/118740059#t7 遇到detached HEAD的解决办法\n1 2 3 4 5 git branch b1 git checkout master git merge b1 git push origin master git branch -d b1 2. git cherrypick 将指定的提交用于其他分支 例如: 1 2 3 a - b - c - d Master \\ e - f - g Feature run the command below and apply commit(f) to master 1 2 git checkout master git cherry-pick f get the result 1 2 3 a - b - c - d - f Master \\ e - f - g Feature 转移多个提交 1 2 # 将 A 和 B 两个提交应用到当前分支 git cherry-pick \u0026lt;HashA\u0026gt; \u0026lt;HashB\u0026gt; 或者 1 2 # 该命令可以转移从 A 到 B 的所有提交,它们必须按照正确的顺序放置：提交 A 必须早于提交 B，否则命令将失败，但不会报错。 git cherry-pick A..B 1 2 # 使用上面的命令，提交 A 将不会包含在 Cherry pick 中， 如果要包含提交 A，可以使用下面的语法。 git cherry-pick A^..B ref:https://www.ruanyifeng.com/blog/2020/04/git-cherry-pick.html 3. git submodule 将一个repo添加为submodule 1 git submodule add https://github.com/chaconinc/DbConnector 克隆含有子模块的项目 1 2 3 4 5 6 git clone https://github.com/chaconinc/MainProject #此时包含子模块目录，但是其中没有任何文件 cd MainProject cd DbConnector/ # 此时有DbConnector目录，但是文件夹是空的 git submodule init # 用来初始化本地配置文件 git submodule update # 从该项目中抓取并检出父项目中列出的合适的提交 或者 1 git clone --recurse-submodules https://github.com/chaconinc/MainProject 或者已经克隆了项目，但是忘记--recurse-submodule, 则使用 1 git submodule update --init --recursive 4. 拉取远程分支到本地 拉取某一个远程的分支，并在创建相应的本地分支名称\n1 2 git fetch origin remote-branch-name git checkout -b local-branch-name origin/remote-branch-name 5. git tag 用git tag打标签 1 2 git tag -a v1.0 git tag -a v0 85fc7e7 #追加标签 git clone 按照tag拉取代码 1 2 # git clone --branch [tags标签] [git地址] git clone -b v5.2.0 --depth=1 http://gitlab地址 6. git stash git stash:隐藏修改 1 2 3 4 5 6 7 8 9 10 git stash # 隐藏修改 git stash save \u0026#34;stash-name\u0026#34; #给每一个stash取名字 git stash pop # 恢复隐藏的修改 git stash list # 列出所有的隐藏 git stash apply [number] # 指定恢复使用哪一个隐藏修改 git stash drop # 移除某一项修改 git stash clear # 删除所有隐藏的修改 git stash show # 查看隐藏的修改 git stash show -p git stash show --patch # 查看特定的stash的diff 7. 代码回退: git reset/git revert ref:https://blog.csdn.net/weixin_35082950/article/details/113629326\n本地分支版本回退的方法\n1 2 git reflog # 找回要回退的版本的commit_id git reset --hard \u0026lt;commit_id\u0026gt; 自己的远程分支版本回退的方法\n1 2 3 4 5 6 # 如果你的错误提交已经推送到自己的远程分支了，那么就需要回滚远程分支了。 # 1. 首先要回退本地分支： git reflog git reset --hard \u0026lt;commit_id\u0026gt; # 2. 强制推送到远程分支 git push -f 公共远程分支版本回退的问题\n一个显而易见的问题：如果你回退公共远程分支，把别人的提交给丢掉了怎么办？\n假设你的远程master分支情况是这样的:\n1 A1–A2–B1 # 其中A、B分别代表两个人，A1、A2、B1代表各自的提交。并且所有人的本地分支都已经更新到最新版本，和远程分支一致。\n这个时候你发现A2这次提交有错误，你用reset回滚远程分支master到A1，那么理想状态是你的队友一拉代码git pull，他们的master分支也回滚了，然而现实却是，你的队友会看到下面的提示：\n1 2 3 4 5 $ git status On branch master Your branch is ahead of \u0026#39;origin/master\u0026#39; by 2 commits. (use \u0026#34;git push\u0026#34; to publish your local commits) nothing to commit, working directory clean 也就是说，你的队友的分支并没有主动回退，而是比远程分支超前了两次提交，因为远程分支回退了嘛。\n1 2 3 git revert HEAD #撤销最近一次提交 git revert HEAD~1 #撤销上上次的提交，注意：数字从0开始 git revert 0ffaacc #撤销0ffaacc这次提交 git revert 命令意思是撤销某次提交。它会产生一个新的提交，虽然代码回退了，但是版本依然是向前的，所以，当你用revert回退之后，所有人pull之后，他们的代码也自动的回退了。 但是，要注意以下几点：\n1、revert 是撤销一次提交，所以后面的commit id是你需要回滚到的版本的前一次提交。\n2、使用revert HEAD是撤销最近的一次提交，如果你最近一次提交是用revert命令产生的，那么你再执行一次，就相当于撤销了上次的撤销操作，换句话说，你连续执行两次revert HEAD命令，就跟没执行是一样的。\n3、使用revert HEAD~1 表示撤销最近2次提交，这个数字是从0开始的，如果你之前撤销过产生了commi id，那么也会计算在内的。\n4、如果使用 revert 撤销的不是最近一次提交，那么一定会有代码冲突，需要你合并代码，合并代码只需要把当前的代码全部去掉，保留之前版本的代码就可以了。\ngit revert 命令的好处就是不会丢掉别人的提交，即使你撤销后覆盖了别人的提交，他更新代码后，可以在本地用 reset 向前回滚，找到自己的代码，然后拉一下分支，再回来合并上去就可以找回被你覆盖的提交了。\nrevert 合并代码，解决冲突 使用revert命令，如果不是撤销的最近一次提交，那么一定会有冲突，如下所示：\n1 2 全部清空 第一次提交 解决冲突很简单，因为我们只想回到某次提交，因此需要把当前最新的代码去掉即可，也就是HEAD标记的代码:\n1 2 3 4 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD 全部清空 第一次提交 ======= 把上面部分代码去掉就可以了，然后再提交一次代码就可以解决冲突了。\n8. git branch 将本地分支与远程分支关联: 1 git branch --set-upstream=origin/remote_branch your_branch 9. git commit git commit --amend: 提交小修改但是不增加commit_id: 1 2 3 git add . git commmit --amend # 此除可以修改commit message git push origin master 10. git pull 示例: 1 git pull \u0026lt;远程主机名\u0026gt; \u0026lt;远程分支名\u0026gt;:\u0026lt;本地分支名\u0026gt; Examples： 取回origin主机的next分支，与本地的master分支合并 1 git pull origin next:master 远程分支(next)要与当前分支合并，则冒号后面的部分可以省略。 1 git pull origin next 如果当前分支与远程分支存在追踪关系，git pull就可以省略远程分支名 1 git pull origin 如果当前分支只有一个追踪分支，连远程主机名都可以省略 1 git pull 11. git clone - `git clone shallow` ","permalink":"https://jianye0428.github.io/en/posts/tech/2022-05-11_git_command/","summary":"git command record as my cheatsheet 1. git rebase ref: https://git-scm.com/docs/git-rebase 用法一:git rebase \u0026lt;branch-name\u0026gt; 将topic分支的base由E改为master 1 2 3 A---B---C topic / D---E---F---G master 运行: 1 2 git rebase master git rebase master topic 结果: 1 2 3 A\u0026#39;--B\u0026#39;--C\u0026#39;","title":"Git Command Notes"},{"content":"zsh说明 zsh是一个Linux下强大的shell, 由于大多数Linux产品安装以及默认使用bash shell, 但是丝毫不影响极客们对zsh的热衷, 几乎每一款Linux产品都包含有zsh，通常可以用apt-get、urpmi或yum等包管理器进行安装.\nzsh是bash的增强版，其实zsh和bash是两个不同的概念，zsh更加强大。\n通常zsh配置起来非常麻烦，且相当的复杂，所以oh-my-zsh是为了简化zsh的配置而开发的，因此oh-my-zsh算是zsh的配置.\n准备 查看当前系统用shell版本\n1 echo $SHELL 查看系统自带哪些shell\n1 cat /etc/shells 安装zsh 通过命令行安装zsh 1 sudo apt install zsh zsh配置 将zsh设置为默认的shell\n1 chsh -s /bin/zsh 然后重启电脑\n1 reboot 安装oh-my-zsh及其个性化配置 安装oh-my-zsh 执行以下命令安装oh-my-zsh 1 sh -c \u0026#34;$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\u0026#34; 或者 1 sh -c \u0026#34;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\u0026#34; 主题配置 打开配置文件~/.zshrc 输入:\n1 ZSH_THEME=\u0026#34;xxf\u0026#34; xxf.zsh-theme文件下载地址: xxf.zsh-theme文件下载\n下载之后将文件拷贝到以下路径: /home/username/.oh-my-zsh/themes/\n插件 安装自动补全插件incr 首先，下载incr插件到本地 1 2 3 cd ~/.oh-my-zsh/plugins/ mkdir incr \u0026amp;\u0026amp; cd incr wget http://mimosa-pudica.net/src/incr-0.2.zsh 编辑~/.zshrc文件，添加以下内容: 1 source ~/.oh-my-zsh/plugins/incr/incr*.zsh 然后，source一下: 1 source ~/.zshrc 直接使用默认插件 在~/.zshrc文件中添加插件:\n1 plugins=(git extract z) 安装autojump插件 通过命令行安装autojump 1 sudo apt install autojump 在~/.zshrc文件中编辑: 1 . /usr/share/autojump/autojump.sh 然后，source一下: 1 source ~/.zshrc 安装zsh-syntax-highlighting语法高亮插件 从gihub下载源码并放在~/.oh-my-zsh/plugins/文件夹下:\n1 2 cd ~/.oh-my-zsh/plugins/ git clone https://github.com/zsh-users/zsh-syntax-highlighting.git 在~/.zshrc文件中编辑:\n1 source ~/.oh-my-zsh/plugins/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh 然后，source一下:\n1 source ~/.zshrc 安装zsh-autosuggestions语法历史记录插件 从gihub下载源码并放在~/.oh-my-zsh/plugins/文件夹下:\n1 2 cd ~/.oh-my-zsh/plugins/ git clone git@github.com:zsh-users/zsh-autosuggestions.git 在~/.zshrc文件中编辑:\n1 source ~/.oh-my-zsh/plugins/zsh-autosuggestions/zsh-autosuggestions.zsh 然后，source一下:\n1 source ~/.zshrc 其他 设置更新日期 在~/.zshrc文件中编： 1 exprot UPDATE_ZSH_DAYS=13 禁止自动更新 1 DISABLE_AUTO_UPDATE=\u0026#34;true\u0026#34; 手动更新oh-my-zsh 1 upgrade_oh_my_zsh 卸载oh-my-zsh 1 uninstall_on_my_zsh zsh 从bash到zsh的切换 直接执行zsh和oh-my-zsh的安装以及配置，并且在~/.zshrc文件中添加: 1 source ~/.bashrc zsh 快捷键 快捷键 ⌃ + u: 清空当前行 ⌃ + a: 移动到行首 ⌃ + e: 移动到行尾 ⌃ + f: 向前移动 ⌃ + b: 向后移动 ⌃ + p: 上一条命令 ⌃ + n: 下一条命令 ⌃ + r: 搜索历史命令 ⌃ + y: 召回最近用命令删除的文字 ⌃ + h: 删除光标之前的字符 ⌃ + d: 删除光标所指的字符 ⌃ + w: 删除光标之前的单词 ⌃ + k: 删除从光标到行尾的内容 ⌃ + t: 交换光标和之前的字符 ","permalink":"https://jianye0428.github.io/en/posts/tech/2022-05-09_zsh_installation/","summary":"zsh说明 zsh是一个Linux下强大的shell, 由于大多数Linux产品安装以及默认使用bash shell, 但是丝毫不影响极客们对zsh的热衷, 几","title":"Ubuntu 22.04 | zsh 以及 oh-my-zsh的安装和配置"},{"content":"PPO Architechture ","permalink":"https://jianye0428.github.io/en/posts/tech/rl/2022-05-06_ppo/","summary":"PPO Architechture ","title":"PPO -- Proximal Policy Optimization"},{"content":"[DQN]paper link: https://arxiv.org/pdf/1312.5602v1.pdf\nDQN: Playing Atari with Deep Reinforcement Learning General Architecture Here is Network listed:\nplay Atari games using RL and perform better than human CNN + Q Learning: CNN for frame-skiped images features extraction; and Q Learning for policy generation Network Channel Kernel Size Stride Activation Output Size Input NA NA NA NA $84\\times84\\times4$ First Conv 16 8x8 4 Relu $20 \\times 20 \\times 6$ Second Conv 32 4x4 2 Relu $9 \\times 9 \\times 32$ Hidden NA NA NA Relu 256 Output NA NA NA None 4 to 18 在当时，普遍的做法是为每一个action学习一个函数，而不是一个网络结构直接输出所有q的value.\nKey 1: Input Info Process 图像处理部分\nGrayscale, Downsampling and Cropping RGB channels to gray scale channel (将RGB取均值为灰度图): 216 x 163 x 3 =\u0026gt;(grayscale) 216 x 163 x 1 =\u0026gt;(downsampling) 110 x 84 x 1 =\u0026gt;(cropping) 84 x 84 x 1 游戏部分\nKey Frame and Action Repeat select skipped frames (每个4帧选取关键帧)，假设智能体看不见中间过程; 而且agent在每k帧选择一个action，可以加速训练 作用: 加速游戏进行: 计算Q-Value是最耗时的步骤; 减少噪声: 过分紧密的frame重复信息过多，之前的action容易被否决; 缩短reward signal到具体aciton之间的时间间隔。 History as Input continuous history key frames as input (连续四个关键帧作为输入) 作用: 可以帮助智能体获得更多有效信息进行训练 Reward Clipping 将多有的reward简化为+1, -1和0 缺点: 有可能对训练效果有影响 作用: 损失了部分信息，但是可以保证不同游戏的reward scale相同，可以用相同的参数进行训练(因为在论文中，作者在多个游戏上对DQN进行了验证)。 Key 2: Replay Buffer 原理:\nDQN中对神经网络的训练本质依然是SGD，SGD要求多次利用样本，并且样本独立，但相邻的transition都是高度相关的，所以要记住过去的transition一起抽样; Replay Buffer通过记忆一段时间内的trainsition，可以让训练数据分布更平稳; Replay Buffer通过忘记很久之前的trainsition，可以保证记住的分布大致模拟当前policy的分布，从而进行policy update; 可以多次重复采样，提升data efficiency. Replay Buffer生效的一个重要条件: 存储transition数量合适\n太多: 可能使reward signal太过稀疏，影响训练 太少: 可能会导致训练数据的分布迅速变化 Key 3: Semi-Gradient Method 在Eauation3中，\n$$y_i = r + \\gamma \\max_{a\u0026rsquo;}Q(s\u0026rsquo;, a\u0026rsquo;; \\theta_{t-1})$$\n不和之后的Q函数共享参数;\n但是在实际的训练过程中，采用 $$ y_i = r + \\gamma \\max_{a\u0026rsquo;}Q(s\u0026rsquo;, a\u0026rsquo;; \\theta_{t})$$\n和之后的Q函数共享参数，但是实际上不参与导数计算，这种方法称为Semi-Gradient Method。\n作用: 使训练更新更稳定。 ","permalink":"https://jianye0428.github.io/en/posts/tech/rl/2022-05-05_dqn/","summary":"[DQN]paper link: https://arxiv.org/pdf/1312.5602v1.pdf DQN: Playing Atari with Deep Reinforcement Learning General Architecture Here is Network listed: play Atari games using RL and perform better than human CNN + Q Learning: CNN for frame-skiped images features extraction; and Q Learning for policy generation Network Channel Kernel Size Stride Activation Output Size Input NA NA NA NA $84\\times84\\times4$ First Conv 16 8x8 4 Relu $20 \\times 20 \\times 6$ Second Conv 32","title":"DQN -- Deep Q Network"},{"content":"TensorRT 介绍 TensorRT是一个高性能的深度学习推理（Inference）优化器，可以为深度学习应用提供低延迟、高吞吐率的部署推理。TensorRT可用于对超大规模数据中心、嵌入式平台或自动驾驶平台进行推理加速。TensorRT现已能支持TensorFlow、Caffe、Mxnet、Pytorch等几乎所有的深度学习框架，将TensorRT和NVIDIA的GPU结合起来，能在几乎所有的框架中进行快速和高效的部署推理。\nTensorRT 是一个C++库，从 TensorRT 3 开始提供C++ API和Python API，主要用来针对 NVIDIA GPU进行 高性能推理（Inference）加速。\n由以上图可以很清楚的看出，训练(training)和 推理(inference)的区别：\n**训练(training)**包含了前向传播和后向传播两个阶段，针对的是训练集。训练时通过误差反向传播来不断修改网络权值(weights)。 **推理(inference)**只包含前向传播一个阶段，针对的是除了训练集之外的新数据。可以是测试集，但不完全是，更多的是整个数据集之外的数据。其实就是针对新数据进行预测，预测时，速度是一个很重要的因素。 一般的深度学习项目，训练时为了加快速度，会使用多GPU分布式训练。但在部署推理时，为了降低成本，往往使用单个GPU机器甚至嵌入式平台（比如 NVIDIA Jetson）进行部署，部署端也要有与训练时相同的深度学习环境，如caffe，TensorFlow等。\n由于训练的网络模型可能会很大（比如，inception，resnet等），参数很多，而且部署端的机器性能存在差异，就会导致推理速度慢，延迟高。这对于那些高实时性的应用场合是致命的，比如自动驾驶要求实时目标检测，目标追踪等。所以为了提高部署推理的速度，出现了很多轻量级神经网络，比如squeezenet，mobilenet，shufflenet等。基本做法都是基于现有的经典模型提出一种新的模型结构，然后用这些改造过的模型重新训练，再重新部署。\n而tensorRT 则是对训练好的模型进行优化。 tensorRT就只是 推理优化器。当你的网络训练完之后，可以将训练模型文件直接丢进tensorRT中，而不再需要依赖深度学习框架（Caffe，TensorFlow等），如下:\n可以认为tensorRT是一个只有前向传播的深度学习框架，这个框架可以将 Caffe，TensorFlow的网络模型解析，然后与tensorRT中对应的层进行一一映射，把其他框架的模型统一全部 转换到tensorRT中，然后在tensorRT中可以针对NVIDIA自家GPU实施优化策略，并进行部署加速。\n目前TensorRT8.0 几乎可以支持所有常用的深度学习框架，对于caffe和TensorFlow来说，tensorRT可以直接解析他们的网络模型；对于caffe2，pytorch，mxnet，chainer，CNTK等框架则是首先要将模型转为 ONNX 的通用深度学习模型，然后对ONNX模型做解析。而tensorflow和MATLAB已经将TensorRT集成到框架中去了。\n**ONNX(Open Neural Network Exchange)**是微软和Facebook携手开发的开放式神经网络交换工具，也就是说不管用什么框架训练，只要转换为ONNX模型，就可以放在其他框架上面去inference。这是一种统一的神经网络模型定义和保存方式，上面提到的除了tensorflow之外的其他框架官方应该都对onnx做了支持，而ONNX自己开发了对tensorflow的支持。从深度学习框架方面来说，这是各大厂商对抗谷歌tensorflow垄断地位的一种有效方式；从研究人员和开发者方面来说，这可以使开发者轻易地在不同机器学习工具之间进行转换，并为项目选择最好的组合方式，加快从研究到生产的速度。\nONNX / TensorFlow / Custom deep-learning frame模型的工作方式： tensorRT中有一个 Plugin 层，这个层提供了 API 可以由用户自己定义tensorRT不支持的层。 TensorRT-plugin 目前TensorRT支持的层有:https://github.com/onnx/onnx-tensorrt/blob/main/docs/operators.md 目前ONNX支持的算子:https://github.com/onnx/onnx/blob/main/docs/Operators.md\nTensorRT 优化方式 TensorRT优化方法主要有以下几种方式，最主要的是前面两种。\n层间融合或张量融合(Layer \u0026amp; Tensor Fusion)\n如下图左侧是GoogLeNetInception模块的计算图。这个结构中有很多层，在部署模型推理时，这每一层的运算操作都是由GPU完成的，但实际上是GPU通过启动不同的CUDA（Compute unified device architecture）核心来完成计算的，CUDA核心计算张量的速度是很快的，但是往往大量的时间是浪费在CUDA核心的启动和对每一层输入/输出张量的读写操作上面，这造成了内存带宽的瓶颈和GPU资源的浪费。TensorRT通过对层间的横向或纵向合并（合并后的结构称为CBR，意指 convolution, bias, and ReLU layers are fused to form a single layer），使得层的数量大大减少。横向合并可以把卷积、偏置和激活层合并成一个CBR结构，只占用一个CUDA核心。纵向合并可以把结构相同，但是权值不同的层合并成一个更宽的层，也只占用一个CUDA核心。合并之后的计算图（图4右侧）的层次更少了，占用的CUDA核心数也少了，因此整个模型结构会更小，更快，更高效。\n数据精度校准(Weight \u0026amp;Activation Precision Calibration)\n大部分深度学习框架在训练神经网络时网络中的张量（Tensor）都是32位浮点数的精度（Full 32-bit precision，FP32），一旦网络训练完成，在部署推理的过程中由于不需要反向传播，完全可以适当降低数据精度，比如降为FP16或INT8的精度。更低的数据精度将会使得内存占用和延迟更低，模型体积更小。\nPrecision Dynamic Range FP32 −3.4×1038 +3.4×1038 FP16 −65504 +65504 INT8 −128 +127 INT8只有256个不同的数值，使用INT8来表示 FP32精度的数值，肯定会丢失信息，造成性能下降。不过TensorRT会提供完全自动化的校准（Calibration ）过程，会以最好的匹配性能将FP32精度的数据降低为INT8精度，最小化性能损失。\nKernel Auto-Tuning 网络模型在推理计算时，是调用GPU的CUDA核进行计算的。TensorRT可以针对不同的算法，不同的网络模型，不同的GPU平台，进行 CUDA核的调整（怎么调整的还不清楚），以保证当前模型在特定平台上以最优性能计算。\nTensorRT will pick the implementation from a library of kernels that delivers the best performance for the target GPU, input data size, filter size, tensor layout, batch size and other parameters.\nDynamic Tensor Memory 在每个tensor的使用期间，TensorRT会为其指定显存，避免显存重复申请，减少内存占用和提高重复使用效率。\nMulti-Stream Execution Scalable design to process multiple input streams in parallel，这个应该就是GPU底层的优化了。\nTensorRT 安装 CUDA的安装\n安装显卡驱动\n安装cuda 2.1 进入nvidia开发者网站的CUDA下载页面选择runfile格式的文件下载。\n2.2 下载完成后，解压，并运行上图中的命令，会有条款，接受即可，注意安装CUDA的时候不要安装驱动 2.3 路径设置\n1 2 $ export PATH=/usr/local/cuda-10.2/bin:/usr/local/cuda-10.2/nsight-compute-2019.5.0${PATH:+:${PATH}} $ export LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64/${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} 并使设置生效:\n1 source ~/.bashrc 2.4 验证安装是否成功 进入/usr/local/cuda-10.1/samples/1_Utilities/目录，\n1 2 3 cd deviceQuery sudo make ./deviceQuery 出现如下输出，则CUDA安装成功。 安装cuDNN 3.1进入cudnn下载页面，下载版本合适的版 3.2 解压，并进入到相应目录，运行以下命令：\n1 2 3 4 sudo cp cuda/include/cudnn*.h /usr/local/cuda-10.2/include sudo cp cuda/lib64/libcudnn* /usr/local/cuda-10.2/lib64 sudo chmod a+r /usr/local/cuda-10.2/include/cudnn*.h sudo chmod a+r /usr/local/cuda-10.2/lib64/libcudnn* 3.3 查看cudnn版本\n1 cat /usr/local/cuda-10.2/include/cudnn.h | grep CUDNN_MAJOR -A 2 新版本:\n1 cat /usr/local/cuda-10.2/include/cudnn_version.h | grep CUDNN_MAJOR -A 2 ref: https://blog.csdn.net/weixin_43592742/article/details/115689886?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-0\u0026amp;spm=1001.2101.3001.4242\nTensorRT的安装\n英伟达提供的安装指导\ntensorRT 要匹配cuda和cudnn版本。在安装之前请匹配。\nOSS 和 GA 两个版本:\nTensorRT OSS:\n1 2 3 git clone -b master https://github.com/nvidia/TensorRT TensorRT cd TensorRT git submodule update --init --recursive GA 版本(下载地址)\n对GA版本和OSS版本在~/.bashrc文件中声明路径: (GA: General Availability Stable Version) (OSS: OPEN SOURCE)\n[oss版本路径]export TRT_SOURCE=/home/yejian/TensorRT/TensorRT_7.2.1 [GA Release 版本路径]export TRT_RELEASE=/home/yejian/TensorRT/TensorRT_7.2.1/TensorRT-7.2.1.6/TensorRT-7.2.1.6 Build TensorRT RSS (这一步需要在编写自定义算子的时候编译通过，参能调用自定义算子)\n1 2 3 4 cd $TRT_OSSPATH mkdir -p build \u0026amp;\u0026amp; cd build cmake .. -DTRT_LIB_DIR=$TRT_LIBPATH -DTRT_OUT_DIR=`pwd`/out make -j$(nproc) 自定义算子开发 \u0026ndash; ScatterElements 在自定义算子开发过程中，需要撰写一下4个文件，并且把文件放在scatterElementsPlugin文件夹中:\nCmakeLists.txt scatterElements.cu scatterElementsPlugin.cpp scatterElementsPlugin.h 如图所示:\n自定义算子的生成与注册\n将以上四个文件报括文件夹复制到TensorRT(OOS)下的plugin文件夹下; 然后修改注册信息文件:(这些文件也在plugin文件夹下) ${TRT_SOURCE}/plugin: CMakeLists.txt ${TRT_SOURCE}/InferPlugin.cpp ${TRT_SOURCE}/common/kernels/kernel.h ${TRT_SOURCE}/parsers/onnx/builtin_op_importers.cpp 执行完以上步骤以后，重新编译OOS版本，然后就可以调用自定义算子:\n1 2 3 4 cd $TRT_OSSPATH mkdir -p build \u0026amp;\u0026amp; cd build cmake .. -DTRT_LIB_DIR=$TRT_LIBPATH -DTRT_OUT_DIR=`pwd`/out make -j$(nproc) ","permalink":"https://jianye0428.github.io/en/posts/tech/2022-04-24_tensorrt/","summary":"TensorRT 介绍 TensorRT是一个高性能的深度学习推理（Inference）优化器，可以为深度学习应用提供低延迟、高吞吐率的部署推理。Tensor","title":"TensorRT "}]