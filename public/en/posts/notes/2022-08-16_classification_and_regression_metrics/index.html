<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>分类问题与回归问题指标综述 | Jian&#39;s Blog</title>
<meta name="keywords" content="ML, classify">
<meta name="description" content="ref: [1] https://www.cnblogs.com/rushup0930/p/13359513.html [2] https://blog.csdn.net/u013250861/article/details/123029585#t12 [3] https://blog.csdn.net/wf592523813/article/details/95202448 [4] https://zhuanlan.zhihu.com/p/69101372 classification 分类 主要涉及的知识点： 混淆矩阵、Precision(精准率)、Recall(召回率)、Accuracy(准确率)、F1-">
<meta name="author" content="Jian">
<link rel="canonical" href="https://jianye0428.github.io/en/posts/notes/2022-08-16_classification_and_regression_metrics/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.1ea9c8832138446635789668415e5c75b8a534b191ee749a44f5ab404c9f27c2.css" integrity="sha256-HqnIgyE4RGY1eJZoQV5cdbilNLGR7nSaRPWrQEyfJ8I=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://jianye0428.github.io/favicon/jian_icon.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://jianye0428.github.io/favicon/jian_icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://jianye0428.github.io/favicon/jian_icon.png">
<link rel="apple-touch-icon" href="https://jianye0428.github.io/favicon/apple-touch-icon.png">
<link rel="mask-icon" href="https://jianye0428.github.io/favicon/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://jianye0428.github.io/en/posts/notes/2022-08-16_classification_and_regression_metrics/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<meta name="baidu-site-verification" content="code-9oLyeix0aK" />
<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?4a41bf85d719f0e8c3165fc76904f546";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>



<script defer crossorigin="anonymous" src="/js/katex.min.8f5024e83d2055dd60e021751066111b0057e230db34911dd56242d67f0a4c86.js" integrity="sha256-j1Ak6D0gVd1g4CF1EGYRGwBX4jDbNJEd1WJC1n8KTIY="></script>


<script defer crossorigin="anonymous" src="/js/auto-render.min.b09accad850e4e87b8a2fc8b93fae790def79172b68de72fd777958c52e566ad.js" integrity="sha256-sJrMrYUOToe4ovyLk/rnkN73kXK2jecv13eVjFLlZq0="></script>

<script>
    
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });

    
    window.WebFontConfig = {
        custom: {
            families: ['KaTeX_AMS', 'KaTeX_Caligraphic:n4,n7', 'KaTeX_Fraktur:n4,n7',
            'KaTeX_Main:n4,n7,i4,i7', 'KaTeX_Math:i4,i7', 'KaTeX_Script',
            'KaTeX_SansSerif:n4,n7,i4', 'KaTeX_Size1', 'KaTeX_Size2', 'KaTeX_Size3',
            'KaTeX_Size4', 'KaTeX_Typewriter'],
        },
    };
</script>


<script defer crossorigin="anonymous" src="/js/webfontloader.min.min.d1c6c39d18e2decb5c99dc9efc579098ab37b9654725df3f9c0737bc2dd00760.js" integrity="sha256-0cbDnRji3stcmdye/FeQmKs3uWVHJd8/nAc3vC3QB2A="></script>


 

<script async src="https://www.googletagmanager.com/gtag/js?id=G-C6GDZ56F4S"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-C6GDZ56F4S', { 'anonymize_ip': false });
}
</script>
<meta property="og:title" content="分类问题与回归问题指标综述" />
<meta property="og:description" content="ref: [1] https://www.cnblogs.com/rushup0930/p/13359513.html [2] https://blog.csdn.net/u013250861/article/details/123029585#t12 [3] https://blog.csdn.net/wf592523813/article/details/95202448 [4] https://zhuanlan.zhihu.com/p/69101372 classification 分类 主要涉及的知识点： 混淆矩阵、Precision(精准率)、Recall(召回率)、Accuracy(准确率)、F1-" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jianye0428.github.io/en/posts/notes/2022-08-16_classification_and_regression_metrics/" /><meta property="og:image" content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-08-16T15:37:02&#43;08:00" />
<meta property="article:modified_time" content="2022-08-16T15:37:02&#43;08:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://i.loli.net/2021/09/26/3OMGXylm8HUYJ6p.png"/>

<meta name="twitter:title" content="分类问题与回归问题指标综述"/>
<meta name="twitter:description" content="ref: [1] https://www.cnblogs.com/rushup0930/p/13359513.html [2] https://blog.csdn.net/u013250861/article/details/123029585#t12 [3] https://blog.csdn.net/wf592523813/article/details/95202448 [4] https://zhuanlan.zhihu.com/p/69101372 classification 分类 主要涉及的知识点： 混淆矩阵、Precision(精准率)、Recall(召回率)、Accuracy(准确率)、F1-"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://jianye0428.github.io/en/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "分类问题与回归问题指标综述",
      "item": "https://jianye0428.github.io/en/posts/notes/2022-08-16_classification_and_regression_metrics/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "分类问题与回归问题指标综述",
  "name": "分类问题与回归问题指标综述",
  "description": "ref: [1] https://www.cnblogs.com/rushup0930/p/13359513.html [2] https://blog.csdn.net/u013250861/article/details/123029585#t12 [3] https://blog.csdn.net/wf592523813/article/details/95202448 [4] https://zhuanlan.zhihu.com/p/69101372 classification 分类 主要涉及的知识点： 混淆矩阵、Precision(精准率)、Recall(召回率)、Accuracy(准确率)、F1-",
  "keywords": [
    "ML", "classify"
  ],
  "articleBody": "ref: [1] https://www.cnblogs.com/rushup0930/p/13359513.html\n[2] https://blog.csdn.net/u013250861/article/details/123029585#t12\n[3] https://blog.csdn.net/wf592523813/article/details/95202448\n[4] https://zhuanlan.zhihu.com/p/69101372\nclassification 分类 主要涉及的知识点：\n混淆矩阵、Precision(精准率)、Recall(召回率)、Accuracy(准确率)、F1-score （包括二分类和多分类问题） ROC、AUC 最常见的指标Accuracy到底有哪些不足？ 解: Accuracy是分类问题中最常用的指标，它计算了分类正确的预测数与总预测数的比值。但是，对于不平衡数据集而言，Accuracy并不是一个好指标。 假设我们有100张图片，其中91张图片是「狗」，5张是「猫」，4张是「猪」，我们希望训练一个三分类器，能正确识别图片里动物的类别。其中，狗这个类别就是大多数类 (majority class)。当大多数类中样本（狗）的数量远超过其他类别（猫、猪）时，如果采用Accuracy来评估分类器的好坏，那么即便模型性能很差 (如无论输入什么图片，都预测为「狗」)，也可以得到较高的Accuracy Score (如91%)。此时，虽然Accuracy Score很高，但是意义不大。当数据异常不平衡时，Accuracy评估方法的缺陷尤为显著。\n二分类模型的常见指标 在二分类问题中，假设该样本一共有两种类别：Positive和Negative。当分类器预测结束，我们可以绘制出混淆矩阵（confusion matrix）。其中分类结果分为如下几种：\nTrue Positive (TP): 把正样本成功预测为正。 True Negative (TN)：把负样本成功预测为负。 False Positive (FP)：把负样本错误地预测为正。 False Negative (FN)：把正样本错误的预测为负。 一个小技巧， 第一个字母表示划分正确与否， T 表示判定正确（判定正确）， F表示判定错误(False)； 第二个字母表示分类器判定结果， P表示判定为正例， N表示判定为负例。\n在二分类模型中，Accuracy，Precision，Recall和F1 score的定义如下：\n$$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\nAccuracy 能够清晰的判断我们模型的表现，但有一个严重的缺陷： 在正负样本不均衡的情况下，占比大的类别往往会成为影响 Accuracy 的最主要因素，此时的 Accuracy 并不能很好的反映模型的整体情况。\n$$\\text{Precision} = \\frac{TP}{TP + FP}$$\nPrecision着重评估在预测为Positive的所有数据中，真实Positve的数据到底占多少？\n精确率高，意味着分类器要尽量在 “更有把握” 的情况下才将样本预测为正样本， 这意味着精确率能够很好的体现模型对于负样本的区分能力，精确率越高，则模型对负样本区分能力越强。\n$$\\text{Recall} = \\frac{TP}{TP + FN}$$\nRecall着重评估：在所有的Positive数据中，到底有多少数据被成功预测为Positive\n召回率高，意味着分类器尽可能将有可能为正样本的样本预测为正样本，这意味着召回率能够很好的体现模型对于正样本的区分能力，召回率越高，则模型对正样本的区分能力越强。\n举例:\n一个医院新开发了一套癌症AI诊断系统，想评估其性能好坏。我们把病人得了癌症定义为Positive，没得癌症定义为Negative。那么， 到底该用什么指标进行评估呢？\n如用Precision对系统进行评估，那么其回答的问题就是： 在诊断为癌症的一堆人中，到底有多少人真得了癌症？\n如用Recall对系统进行评估，那么其回答的问题就是： 在一堆得了癌症的病人中，到底有多少人能被成功检测出癌症？\n如用Accuracy对系统进行评估，那么其回答的问题就是： 在一堆癌症病人和正常人中，有多少人被系统给出了正确诊断结果（患癌或没患癌）？\n那啥时候应该更注重Recall而不是Precision呢？\n当False Negative (FN)的成本代价很高 (后果很严重)，希望尽量避免产生FN时，应该着重考虑提高Recall指标。\n那啥时候应该更注重Precision而不是Recall呢？\n当False Positive (FP)的成本代价很高 (后果很严重)时，即期望尽量避免产生FP时，应该着重考虑提高Precision指标。\n$$\\text{F1-score} = \\frac{2 \\times Precision \\times Recall}{Precision + Recall}$$\n而F1-score是Precision和Recall两者的综合。\n举个更有意思的例子（我拍脑袋想出来的，绝对原创哈），假设检察机关想将罪犯捉拿归案，需要对所有人群进行分析，以判断某人犯了罪（Positive），还是没犯罪（Negative）。显然，检察机关希望不漏掉一个罪人（提高recall），也不错怪一个好人（提高precision），所以就需要同时权衡recall和precision两个指标。\n尤其在上个世纪，中国司法体制会更偏向Recall，即「天网恢恢，疏而不漏，任何罪犯都插翅难飞」。而西方司法系统会更偏向Precision，即「绝不冤枉一个好人，但是难免有罪犯成为漏网之鱼，逍遥法外」。到底是哪种更好呢？显然，极端并不可取。Precision和Recall都应该越高越好，也就是F1应该越高越好。\n如何通俗的解释召回率与精确率？\n例：公园里有50只皮卡丘和10只臭臭泥。有正常审美的人都会想要用精灵球把尽可能多的皮卡丘抓回来，同时尽可能少地抓住臭臭泥。 最终我们的精灵球成功抓回来了45只皮卡丘和10只臭臭泥。 我们就可以说50只皮卡丘中有45只被召唤 (call) 回来 (re) 了，所以 recall = 45 / 50。 但同时，这台机器还误把5只臭臭泥识别为皮卡丘，在它抓回来的所有55只神奇宝贝中，精灵球对皮卡丘判断的精准性 (precision) = 45 / 55。 在上面的例子中，精灵球=预测模型，皮卡丘=正样本，臭臭泥=负样本。 总结这两个概念的用处：描述模型对正样本的预测性能 1、recall描述模型“把正样本叫 (call) 回来(re)”的能力。 2、precision描述模型“叫回来的正样本”有多少是精确的。\nAOC / AUC 混淆矩阵中有着Positive、Negative、True、False的概念，其意义如下：\n称预测类别为1的为Positive（阳性），预测类别为0的为Negative（阴性）。 预测正确的为True（真），预测错误的为False（伪）。 对上述概念进行组合，就产生了如下的混淆矩阵:\n然后，由此引出True Positive Rate（真阳率）、False Positive（伪阳率）两个概念：\n$$TP Rate = \\frac{TP}{TP + FN}$$ $$FP Rate = \\frac{FP}{FP + TN}$$\n仔细看这两个公式，发现其实TPRate就是TP除以TP所在的列，FPRate就是FP除以FP所在的列，二者意义如下：\nTPRate的意义是所有真实类别为1的样本中，预测类别为1的比例。 FPRate的意义是所有真实类别为0的样本中，预测类别为1的比例。 如果上述概念都弄懂了，那么ROC曲线和AUC就so easy了：\n按照定义，AUC即ROC曲线下的面积，而ROC曲线的横轴是FPRate，纵轴是TPRate，当二者相等时，即y=x，如下图:\n表示的意义是：对于不论真实类别是1还是0的样本，分类器预测为1的概率是相等的。\n换句话说，分类器对于正例和负例毫无区分能力，和抛硬币没什么区别，一个抛硬币的分类器是我们能想象的最差的情况，因此一般来说我们认为AUC的最小值为0.5（当然也存在预测相反这种极端的情况，AUC小于0.5，这种情况相当于分类器总是把对的说成错的，错的认为是对的，那么只要把预测类别取反，便得到了一个AUC大于0.5的分类器）。\n而我们希望分类器达到的效果是：对于真实类别为1的样本，分类器预测为1的概率（即TPRate），要大于真实类别为0而预测类别为1的概率（即FPRate），即y＞x，因此大部分的ROC曲线长成下面这个样子：\n说了这么多还是不够直观，不妨举个简单的例子。\n首先对于硬分类器（例如SVM，NB），预测类别为离散标签，对于8个样本的预测情况如下：\n得到混淆矩阵如下：\n进而算得TPRate=3/4，FPRate=2/4，得到ROC曲线：\n最终得到AUC为0.625。\n对于LR等预测类别为概率的分类器，依然用上述例子，假设预测结果如下：\n这时，需要设置阈值来得到混淆矩阵，不同的阈值会影响得到的TPRate，FPRate，如果阈值取0.5，小于0.5的为0，否则为1，那么我们就得到了与之前一样的混淆矩阵。其他的阈值就不再啰嗦了。依次使用所有预测值作为阈值，得到一系列TPRate，FPRate，描点，求面积，即可得到AUC。\n最后说说AUC的优势，AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价。\n例如在反欺诈场景，设欺诈类样本为正例，正例占比很少（假设0.1%），如果使用准确率评估，把所有的样本预测为负例，便可以获得99.9%的准确率。\n但是如果使用AUC，把所有样本预测为负例，TPRate和FPRate同时为0（没有Positive），与(0,0) (1,1)连接，得出AUC仅为0.5，成功规避了样本不均匀带来的问题。\n多分类模型的常见指标详细解析 在多分类（大于两个类）问题中，假设我们要开发一个动物识别系统，来区分输入图片是猫，狗还是猪。给定分类器一堆动物图片，产生了如下结果混淆矩阵。\n在混淆矩阵中，正确的分类样本（Actual label = Predicted label）分布在左上到右下的对角线上。其中，Accuracy的定义为分类正确（对角线上）的样本数与总样本数的比值。Accuracy度量的是全局样本预测情况。而对于Precision和Recall而言，每个类都需要单独计算其Precision和Recall。 classify_multiclass_prediction 比如，对类别「猪」而言，其Precision和Recall分别为:\n$$\\text{Precision} = \\frac{TP}{TP + FP} = \\frac{20}{20 + 50} = \\frac{2}{7}$$\n$$\\text{Recall} = \\frac{TP}{TP + FN} = \\frac{20}{10} = \\frac{2}{3}$$\n也就是: $$P_{cat} = \\frac{8}{15}, P_{dog} = \\frac{17}{23}, P_{pig} = \\frac{2}{7}, (P代表Precision) $$ $$R_{cat} = \\frac{4}{7}, R_{dog} = \\frac{17}{32}, R_{pig} = \\frac{2}{3}, (R代表Recall) $$\n如果想评估该识别系统的总体功能，必须考虑猫、狗、猪三个类别的综合预测性能。那么，到底要怎么综合这三个类别的Precision呢？是简单加起来做平均吗？通常来说， 我们有如下几种解决方案（也可参考scikit-learn官网）：\n1. Macro-average方法 该方法最简单，直接将不同类别的评估指标（Precision/ Recall/ F1-score）加起来求平均，给所有类别相同的权重。该方法能够平等看待每个类别，但是它的值会受稀有类别影响。\n$$\\text{Macro-Precision} = \\frac{P_{cat} + P_{dog} + P_{pig}}{3} = 0.5194$$ $$\\text{Macro-Recall} = \\frac{R_{cat} + R_{dog} + R_{pig}}{3} = 0.5898$$\n2. Weighted-average方法\n该方法给不同类别不同权重（权重根据该类别的真实分布比例确定），每个类别乘权重后再进行相加。该方法考虑了类别不平衡情况，它的值更容易受到常见类（majority class）的影响。\n$$W_{cat} : W_{dog} : W_{pig} = N_{cat} : N_{dog} : N_{pig} = \\frac{7}{26} : \\frac{16}{26} : \\frac{3}{26} (W代表权重，N代表样本在该类别下的真实数目)$$ $$\\text{Weighted-Precision} = P_{cat} \\times W_{cat} + P_{dog} \\times W_{dog} + P_{pig} \\times W_{pig} = 0.6314$$ $$\\text{Weighted-Recall} = {R_{cat} \\times W_{cat} + R_{dog} \\times W_{dog} + R_{pig} \\times W_{pig}}= 0.5577$$\n3. Micro-average方法\n该方法把每个类别的TP, FP, FN先相加之后，在根据二分类的公式进行计算。\n$$\\text{Micro-Precision} = \\frac{TP_{cat} + TP_{dog} + TP_{pig}}{TP_{cat} + TP_{dog} + TP_{pig} + FP_{cat} + FP_{dog} + FP_{pig}} = 0.5577$$ $$\\text{Micro-Recall} = \\frac{TP_{cat} + TP_{dog} + TP_{pig}}{TP_{cat} + TP_{dog} + TP_{pig} + FN_{cat} + FN_{dog} + FN_{pig}} = 0.5577$$\n其中，特别有意思的是，Micro-precision 和 Micro-recall竟然始终相同！这是为啥呢？\n这是因为在某一类中的False Positive样本，一定是其他某类别的False Negative样本。听起来有点抽象？举个例子，比如说系统错把「狗」预测成「猫」，那么对于狗而言，其错误类型就是False Negative，对于猫而言，其错误类型就是False Positive。于此同时，Micro-precision和Micro-recall的数值都等于Accuracy，因为它们计算了对角线样本数和总样本数的比值，总结就是\n$$\\text{Micro-Precision} = \\text{Micro-Recall} = \\text{Micro-F1 score} = \\text{Accuracy}$$\ndemo示例:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import numpy as np import seaborn as sns from sklearn.metrics import confusion_matrix import pandas as pd import matplotlib.pyplot as plt from sklearn.metrics import accuracy_score, average_precision_score,precision_score,f1_score,recall_score # create confusion matrix y_true = np.array([-1]*70 + [0]*160 + [1]*30) y_pred = np.array([-1]*40 + [0]*20 + [1]*20 + [-1]*30 + [0]*80 + [1]*30 + [-1]*5 + [0]*15 + [1]*20) cm = confusion_matrix(y_true, y_pred) conf_matrix = pd.DataFrame(cm, index=['Cat','Dog','Pig'], columns=['Cat','Dog','Pig']) # plot size setting fig, ax = plt.subplots(figsize = (4.5,3.5)) sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 19}, cmap=\"Blues\") plt.ylabel('True label', fontsize=18) plt.xlabel('Predicted label', fontsize=18) plt.xticks(fontsize=18) plt.yticks(fontsize=18) plt.savefig('confusion.pdf', bbox_inches='tight') plt.show() print('------Weighted------') print('Weighted precision', precision_score(y_true, y_pred, average='weighted')) print('Weighted recall', recall_score(y_true, y_pred, average='weighted')) print('Weighted f1-score', f1_score(y_true, y_pred, average='weighted')) print('------Macro------') print('Macro precision', precision_score(y_true, y_pred, average='macro')) print('Macro recall', recall_score(y_true, y_pred, average='macro')) print('Macro f1-score', f1_score(y_true, y_pred, average='macro')) print('------Micro------') print('Micro precision', precision_score(y_true, y_pred, average='micro')) print('Micro recall', recall_score(y_true, y_pred, average='micro')) print('Micro f1-score', f1_score(y_true, y_pred, average='micro')) Regression 回归 回归算法的评价指标就是MSE，RMSE，MAE、R-Squared。\nMSE和MAE适用于误差相对明显的时候，大的误差也有比较高的权重，RMSE则是针对误差不是很明显的时候；MAE是一个线性的指标，所有个体差异在平均值上均等加权，所以它更加凸显出异常值，相比MSE；\nRMSLE: 主要针对数据集中有一个特别大的异常值，这种情况下，data会被skew，RMSE会被明显拉大，这时候就需要先对数据log下，再求RMSE，这个过程就是RMSLE。对低估值（under-predicted）的判罚明显多于估值过高(over-predicted)的情况（RMSE则相反）\n",
  "wordCount" : "5035",
  "inLanguage": "en",
  "datePublished": "2022-08-16T15:37:02+08:00",
  "dateModified": "2022-08-16T15:37:02+08:00",
  "author":[{
    "@type": "Person",
    "name": "Jian"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://jianye0428.github.io/en/posts/notes/2022-08-16_classification_and_regression_metrics/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Jian's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://jianye0428.github.io/favicon/jian_icon.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://jianye0428.github.io/en/" accesskey="h" title="Jian&#39;s Blog (Alt + H)">
                <img src="https://jianye0428.github.io/favicon/jian_icon.png" alt="logo" aria-label="logo"
                    height="30">Jian&#39;s Blog</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="https://jianye0428.github.io/cn/" title="Chinese"
                            aria-label="Chinese">Chinese</a>
                    </li>
                </ul>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://jianye0428.github.io/en/myresume/" title="My Resume">
                    <span>My Resume</span>
                </a>
            </li>
            <li>
                <a href="https://jianye0428.github.io/en/tags/" title="🔖Tags">
                    <span>🔖Tags</span>
                </a>
            </li>
            <li>
                <a href="https://jianye0428.github.io/en/archives" title="🙋🏻‍♂️Archive">
                    <span>🙋🏻‍♂️Archive</span>
                </a>
            </li>
            <li>
                <a href="https://jianye0428.github.io/en/search/" title="🔍Search (Alt &#43; /)" accesskey=/>
                    <span>🔍Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://jianye0428.github.io/en/">Home</a>&nbsp;»&nbsp;<a href="https://jianye0428.github.io/en/posts/">Posts</a></div>
    <h1 class="post-title">
      分类问题与回归问题指标综述
    </h1>
    <div class="post-meta"><span title='2022-08-16 15:37:02 +0800 CST'>2022-08-16</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;Jian&nbsp;|&nbsp;<a href="https://github.com/jianye0428/myblog/tree/main/content/posts/notes/2022-08-16_classification_and_regression_metrics.md" rel="noopener noreferrer" target="_blank">Suggest Changes</a>

</div>
  </header> <aside id="toc-container" class="toc-container wide">
    <div class="toc">
        <details  open>
            <summary accesskey="c" title="(Alt + C)">
                <span class="details">Table of Contents</span>
            </summary>

            <div class="inner"><ul>
                    <li>
                        <a href="#classification-%e5%88%86%e7%b1%bb" aria-label="classification 分类">classification 分类</a><ul>
                            
                    <li>
                        <a href="#%e4%ba%8c%e5%88%86%e7%b1%bb%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%b8%b8%e8%a7%81%e6%8c%87%e6%a0%87" aria-label="二分类模型的常见指标">二分类模型的常见指标</a></li>
                    <li>
                        <a href="#aoc--auc" aria-label="AOC / AUC">AOC / AUC</a></li>
                    <li>
                        <a href="#%e5%a4%9a%e5%88%86%e7%b1%bb%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%b8%b8%e8%a7%81%e6%8c%87%e6%a0%87%e8%af%a6%e7%bb%86%e8%a7%a3%e6%9e%90" aria-label="多分类模型的常见指标详细解析">多分类模型的常见指标详细解析</a></li></ul>
                    </li>
                    <li>
                        <a href="#regression-%e5%9b%9e%e5%bd%92" aria-label="Regression 回归">Regression 回归</a>
                    </li>
                </ul>
            </div>
        </details>
    </div>
</aside>
<script>
    let activeElement;
    let elements;
    window.addEventListener('DOMContentLoaded', function (event) {
        checkTocPosition();

        elements = document.querySelectorAll('h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]');
         
         activeElement = elements[0];
         const id = encodeURI(activeElement.getAttribute('id')).toLowerCase();
         document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
     }, false);

    window.addEventListener('resize', function(event) {
        checkTocPosition();
    }, false);

    window.addEventListener('scroll', () => {
        
        activeElement = Array.from(elements).find((element) => {
            if ((getOffsetTop(element) - window.pageYOffset) > 0 && 
                (getOffsetTop(element) - window.pageYOffset) < window.innerHeight/2) {
                return element;
            }
        }) || activeElement

        elements.forEach(element => {
             const id = encodeURI(element.getAttribute('id')).toLowerCase();
             if (element === activeElement){
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.add('active');
             } else {
                 document.querySelector(`.inner ul li a[href="#${id}"]`).classList.remove('active');
             }
         })
     }, false);

    const main = parseInt(getComputedStyle(document.body).getPropertyValue('--article-width'), 10);
    const toc = parseInt(getComputedStyle(document.body).getPropertyValue('--toc-width'), 10);
    const gap = parseInt(getComputedStyle(document.body).getPropertyValue('--gap'), 10);

    function checkTocPosition() {
        const width = document.body.scrollWidth;

        if (width - main - (toc * 2) - (gap * 4) > 0) {
            document.getElementById("toc-container").classList.add("wide");
        } else {
            document.getElementById("toc-container").classList.remove("wide");
        }
    }

    function getOffsetTop(element) {
        if (!element.getClientRects().length) {
            return 0;
        }
        let rect = element.getBoundingClientRect();
        let win = element.ownerDocument.defaultView;
        return rect.top + win.pageYOffset;   
    }
</script>

  <div class="post-content"><p>ref:
[1] <a href="https://www.cnblogs.com/rushup0930/p/13359513.html">https://www.cnblogs.com/rushup0930/p/13359513.html</a></p>
<p>[2] <a href="https://blog.csdn.net/u013250861/article/details/123029585#t12">https://blog.csdn.net/u013250861/article/details/123029585#t12</a></p>
<p>[3] <a href="https://blog.csdn.net/wf592523813/article/details/95202448">https://blog.csdn.net/wf592523813/article/details/95202448</a></p>
<p>[4] <a href="https://zhuanlan.zhihu.com/p/69101372">https://zhuanlan.zhihu.com/p/69101372</a></p>
<h1 id="classification-分类">classification 分类<a hidden class="anchor" aria-hidden="true" href="#classification-分类">#</a></h1>
<p>主要涉及的知识点：</p>
<ul>
<li>混淆矩阵、Precision(精准率)、Recall(召回率)、Accuracy(准确率)、F1-score    （包括二分类和多分类问题）</li>
<li>ROC、AUC</li>
</ul>
<blockquote>
<p>最常见的指标Accuracy到底有哪些不足？
解: Accuracy是分类问题中最常用的指标，它计算了分类正确的预测数与总预测数的比值。但是，<font color=red>对于不平衡数据集而言，Accuracy并不是一个好指标</font>。
假设我们有100张图片，其中91张图片是「狗」，5张是「猫」，4张是「猪」，我们希望训练一个三分类器，能正确识别图片里动物的类别。其中，狗这个类别就是大多数类 (majority class)。当大多数类中样本（狗）的数量远超过其他类别（猫、猪）时，如果采用Accuracy来评估分类器的好坏，那么即便模型性能很差 (如无论输入什么图片，都预测为「狗」)，也可以得到较高的Accuracy Score (如91%)。此时，虽然Accuracy Score很高，但是意义不大。当数据异常不平衡时，Accuracy评估方法的缺陷尤为显著。</p>
</blockquote>
<h2 id="二分类模型的常见指标">二分类模型的常见指标<a hidden class="anchor" aria-hidden="true" href="#二分类模型的常见指标">#</a></h2>
<p>在二分类问题中，假设该样本一共有两种类别：Positive和Negative。当分类器预测结束，我们可以绘制出混淆矩阵（confusion matrix）。其中分类结果分为如下几种：</p>
<p><img loading="lazy" src="https://github.com/jianye0428/hello-hugo/raw/master/img/posts/notes/2022-08-16_classification_metrics/classify_confusion_matrix.png" alt="Confusion Matrix"  />
</p>
<ul>
<li>True Positive (TP): 把正样本成功预测为正。</li>
<li>True Negative (TN)：把负样本成功预测为负。</li>
<li>False Positive (FP)：把负样本错误地预测为正。</li>
<li>False Negative (FN)：把正样本错误的预测为负。</li>
</ul>
<blockquote>
<p>一个小技巧， <font color=red>第一个字母表示划分正确与否</font>， T 表示判定正确（判定正确）， F表示判定错误(False)； <font color=red>第二个字母表示分类器判定结果</font>， P表示判定为正例， N表示判定为负例。</p>
</blockquote>
<p>在二分类模型中，Accuracy，Precision，Recall和F1 score的定义如下：</p>
<p>$$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$$</p>
<blockquote>
<blockquote>
<p>Accuracy 能够清晰的判断我们模型的表现，但有一个严重的缺陷： 在正负样本不均衡的情况下，占比大的类别往往会成为影响 Accuracy 的最主要因素，此时的 Accuracy 并不能很好的反映模型的整体情况。</p>
</blockquote>
</blockquote>
<p>$$\text{Precision} = \frac{TP}{TP + FP}$$</p>
<blockquote>
<blockquote>
<p>Precision着重评估在预测为Positive的所有数据中，真实Positve的数据到底占多少？</p>
</blockquote>
</blockquote>
<p>精确率高，意味着分类器要尽量在 “更有把握” 的情况下才将样本预测为正样本， 这意味着精确率能够很好的体现模型对于负样本的区分能力，精确率越高，则模型对负样本区分能力越强。</p>
<p>$$\text{Recall} = \frac{TP}{TP + FN}$$</p>
<blockquote>
<blockquote>
<p>Recall着重评估：在所有的Positive数据中，到底有多少数据被成功预测为Positive</p>
</blockquote>
</blockquote>
<p>召回率高，意味着分类器尽可能将有可能为正样本的样本预测为正样本，这意味着<font color=red>召回率能够很好的体现模型对于正样本的区分能力，召回率越高，则模型对正样本的区分能力越强</font>。</p>
<p><strong>举例</strong>:</p>
<p>一个医院新开发了一套癌症AI诊断系统，想评估其性能好坏。我们把病人得了癌症定义为Positive，没得癌症定义为Negative。那么， 到底该用什么指标进行评估呢？</p>
<ul>
<li>如用Precision对系统进行评估，那么其回答的问题就是：
<blockquote>
<p>在诊断为癌症的一堆人中，到底有多少人真得了癌症？</p>
</blockquote>
</li>
<li>如用Recall对系统进行评估，那么其回答的问题就是：
<blockquote>
<p>在一堆得了癌症的病人中，到底有多少人能被成功检测出癌症？</p>
</blockquote>
</li>
<li>如用Accuracy对系统进行评估，那么其回答的问题就是：
<blockquote>
<p>在一堆癌症病人和正常人中，有多少人被系统给出了正确诊断结果（患癌或没患癌）？</p>
</blockquote>
</li>
</ul>
<p><font color=red>那啥时候应该更注重Recall而不是Precision呢？</font></p>
<blockquote>
<p>当False Negative (FN)的成本代价很高 (后果很严重)，希望尽量避免产生FN时，应该着重考虑提高Recall指标。</p>
</blockquote>
<p><font color=red>那啥时候应该更注重Precision而不是Recall呢？</font></p>
<blockquote>
<p>当False Positive (FP)的成本代价很高 (后果很严重)时，即期望尽量避免产生FP时，应该着重考虑提高Precision指标。</p>
</blockquote>
<p>$$\text{F1-score} = \frac{2 \times Precision \times Recall}{Precision + Recall}$$</p>
<p>而F1-score是Precision和Recall两者的综合。</p>
<p>举个更有意思的例子（我拍脑袋想出来的，绝对原创哈），假设检察机关想将罪犯捉拿归案，需要对所有人群进行分析，以判断某人犯了罪（Positive），还是没犯罪（Negative）。显然，检察机关希望不漏掉一个罪人（提高recall），也不错怪一个好人（提高precision），所以就需要同时权衡recall和precision两个指标。</p>
<p>尤其在上个世纪，中国司法体制会更偏向Recall，即「天网恢恢，疏而不漏，任何罪犯都插翅难飞」。而西方司法系统会更偏向Precision，即「绝不冤枉一个好人，但是难免有罪犯成为漏网之鱼，逍遥法外」。到底是哪种更好呢？显然，极端并不可取。Precision和Recall都应该越高越好，也就是F1应该越高越好。</p>
<p><strong><font color=green>如何通俗的解释召回率与精确率？</font></strong></p>
<blockquote>
<p>例：公园里有50只皮卡丘和10只臭臭泥。有正常审美的人都会想要用精灵球把尽可能多的皮卡丘抓回来，同时尽可能少地抓住臭臭泥。 最终我们的精灵球成功抓回来了45只皮卡丘和10只臭臭泥。
我们就可以说50只皮卡丘中有45只被召唤 (call) 回来 (re) 了，所以 recall = 45 / 50。
但同时，这台机器还误把5只臭臭泥识别为皮卡丘，在它抓回来的所有55只神奇宝贝中，精灵球对皮卡丘判断的精准性 (precision)  = 45 / 55。
在上面的例子中，精灵球=预测模型，皮卡丘=正样本，臭臭泥=负样本。
总结这两个概念的用处：描述模型对正样本的预测性能
1、recall描述模型“把正样本叫 (call) 回来(re)”的能力。
2、precision描述模型“叫回来的正样本”有多少是精确的。</p>
</blockquote>
<h2 id="aoc--auc">AOC / AUC<a hidden class="anchor" aria-hidden="true" href="#aoc--auc">#</a></h2>
<p>混淆矩阵中有着Positive、Negative、True、False的概念，其意义如下：</p>
<ul>
<li>称预测类别为1的为Positive（阳性），预测类别为0的为Negative（阴性）。</li>
<li>预测正确的为True（真），预测错误的为False（伪）。</li>
</ul>
<p>对上述概念进行组合，就产生了如下的混淆矩阵:</p>
<p><img loading="lazy" src="https://github.com/jianye0428/hello-hugo/raw/master/img/posts/notes/2022-08-16_classification_metrics/classify_confusion_matrix.png" alt="Confusion Matrix"  />
</p>
<p>然后，由此引出True Positive Rate（真阳率）、False Positive（伪阳率）两个概念：</p>
<p>$$TP Rate = \frac{TP}{TP + FN}$$
$$FP Rate = \frac{FP}{FP + TN}$$</p>
<p>仔细看这两个公式，发现其实TPRate就是TP除以TP所在的列，FPRate就是FP除以FP所在的列，二者意义如下：</p>
<ul>
<li>TPRate的意义是所有真实类别为1的样本中，预测类别为1的比例。</li>
<li>FPRate的意义是所有真实类别为0的样本中，预测类别为1的比例。</li>
</ul>
<p>如果上述概念都弄懂了，那么ROC曲线和AUC就so easy了：</p>
<p>按照定义，AUC即ROC曲线下的面积，而ROC曲线的横轴是FPRate，纵轴是TPRate，当二者相等时，即y=x，如下图:</p>
<p><img loading="lazy" src="https://github.com/jianye0428/hello-hugo/raw/master/img/posts/notes/2022-08-16_classification_metrics/classify_auc_roc.png" alt="Confusion Matrix"  />
</p>
<p>表示的意义是：对于不论真实类别是1还是0的样本，分类器预测为1的概率是相等的。</p>
<p>换句话说，分类器对于正例和负例毫无区分能力，和抛硬币没什么区别，一个抛硬币的分类器是我们能想象的最差的情况，因此一般来说我们认为AUC的最小值为0.5（当然也存在预测相反这种极端的情况，AUC小于0.5，这种情况相当于分类器总是把对的说成错的，错的认为是对的，那么只要把预测类别取反，便得到了一个AUC大于0.5的分类器）。</p>
<p>而我们希望分类器达到的效果是：对于真实类别为1的样本，分类器预测为1的概率（即TPRate），要大于真实类别为0而预测类别为1的概率（即FPRate），即y＞x，因此大部分的ROC曲线长成下面这个样子：</p>
<p><img loading="lazy" src="https://github.com/jianye0428/hello-hugo/raw/master/img/posts/notes/2022-08-16_classification_metrics/classify_auc_roc_normal.png" alt="Confusion Matrix"  />
</p>
<p>说了这么多还是不够直观，不妨举个简单的例子。</p>
<p>首先对于硬分类器（例如SVM，NB），预测类别为离散标签，对于8个样本的预测情况如下：</p>
<p><img loading="lazy" src="https://github.com/jianye0428/hello-hugo/raw/master/img/posts/notes/2022-08-16_classification_metrics/classify_auc_roc_example_1.png" alt="AUC ROC EXAMPLE"  />
</p>
<p>得到混淆矩阵如下：</p>
<p><img loading="lazy" src="https://github.com/jianye0428/hello-hugo/raw/master/img/posts/notes/2022-08-16_classification_metrics/classify_auc_roc_example_3.png" alt="AUC ROC Confusion Matrix"  />
</p>
<p>进而算得TPRate=3/4，FPRate=2/4，得到ROC曲线：</p>
<p><img loading="lazy" src="https://github.com/jianye0428/hello-hugo/raw/master/img/posts/notes/2022-08-16_classification_metrics/classify_auc_roc_example_2.png" alt="AUC ROC Confusion Matrix"  />
</p>
<p>最终得到AUC为0.625。</p>
<p>对于LR等预测类别为概率的分类器，依然用上述例子，假设预测结果如下：</p>
<p><img loading="lazy" src="https://github.com/jianye0428/hello-hugo/raw/master/img/posts/notes/2022-08-16_classification_metrics/classify_auc_roc_example_4.png" alt="AUC ROC Confusion Matrix"  />
</p>
<p>这时，需要设置阈值来得到混淆矩阵，不同的阈值会影响得到的TPRate，FPRate，如果阈值取0.5，小于0.5的为0，否则为1，那么我们就得到了与之前一样的混淆矩阵。其他的阈值就不再啰嗦了。依次使用所有预测值作为阈值，得到一系列TPRate，FPRate，描点，求面积，即可得到AUC。</p>
<p>最后说说AUC的优势，AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价。</p>
<p>例如在反欺诈场景，设欺诈类样本为正例，正例占比很少（假设0.1%），如果使用准确率评估，把所有的样本预测为负例，便可以获得99.9%的准确率。</p>
<p>但是如果使用AUC，把所有样本预测为负例，TPRate和FPRate同时为0（没有Positive），与(0,0) (1,1)连接，得出AUC仅为0.5，成功规避了样本不均匀带来的问题。</p>
<h2 id="多分类模型的常见指标详细解析">多分类模型的常见指标详细解析<a hidden class="anchor" aria-hidden="true" href="#多分类模型的常见指标详细解析">#</a></h2>
<p>在多分类（大于两个类）问题中，假设我们要开发一个动物识别系统，来区分输入图片是猫，狗还是猪。给定分类器一堆动物图片，产生了如下结果混淆矩阵。</p>
<p><img loading="lazy" src="https://github.com/jianye0428/hello-hugo/raw/master/img/posts/notes/2022-08-16_classification_metrics/classify_multiclass_confusion_matrix.png" alt="Mulitclass Confusion Matrix"  />
</p>
<p>在混淆矩阵中，正确的分类样本（Actual label = Predicted label）分布在左上到右下的对角线上。其中，Accuracy的定义为分类正确（对角线上）的样本数与总样本数的比值。<strong>Accuracy度量的是全局样本预测情况。而对于Precision和Recall而言，每个类都需要单独计算其Precision和Recall。</strong>
classify_multiclass_prediction
<img loading="lazy" src="https://github.com/jianye0428/**hello**-hugo/raw/master/img/posts/notes/2022-08-16_classification_metrics/classify_multiclass_prediction.png" alt="Mulitclass Confusion Matrix"  />
</p>
<p>比如，对类别「猪」而言，其Precision和Recall分别为:</p>
<p>$$\text{Precision} = \frac{TP}{TP + FP} = \frac{20}{20 + 50} = \frac{2}{7}$$</p>
<p>$$\text{Recall} = \frac{TP}{TP + FN} = \frac{20}{10} = \frac{2}{3}$$</p>
<p>也就是:
$$P_{cat} = \frac{8}{15}, P_{dog} = \frac{17}{23}, P_{pig} = \frac{2}{7}, (P代表Precision) $$
$$R_{cat} = \frac{4}{7}, R_{dog} = \frac{17}{32}, R_{pig} = \frac{2}{3}, (R代表Recall) $$</p>
<p>如果想评估该识别系统的总体功能，必须考虑猫、狗、猪三个类别的综合预测性能。那么，到底要怎么综合这三个类别的Precision呢？是简单加起来做平均吗？通常来说， 我们有如下几种解决方案（<a href="https://link.zhihu.com/?target=https%3A//scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html">也可参考scikit-learn官网</a>）：</p>
<p><strong>1. Macro-average方法</strong>
该方法最简单，直接将不同类别的评估指标（Precision/ Recall/ F1-score）加起来求平均，给所有类别相同的权重。该方法能够平等看待每个类别，但是它的值会受<strong>稀有类别</strong>影响。</p>
<p>$$\text{Macro-Precision} = \frac{P_{cat} + P_{dog} + P_{pig}}{3} = 0.5194$$
$$\text{Macro-Recall} = \frac{R_{cat} + R_{dog} + R_{pig}}{3} = 0.5898$$</p>
<p><strong>2. Weighted-average方法</strong></p>
<p>该方法给不同类别不同权重（权重根据该类别的真实分布比例确定），每个类别乘权重后再进行相加。该方法考虑了类别不平衡情况，它的值更容易受到常见类（majority class）的影响。</p>
<p>$$W_{cat} : W_{dog} : W_{pig} = N_{cat} : N_{dog} : N_{pig} = \frac{7}{26} : \frac{16}{26} : \frac{3}{26} (W代表权重，N代表样本在该类别下的真实数目)$$
$$\text{Weighted-Precision} = P_{cat} \times W_{cat} + P_{dog} \times W_{dog} + P_{pig} \times W_{pig} = 0.6314$$
$$\text{Weighted-Recall} = {R_{cat} \times W_{cat} + R_{dog} \times W_{dog} + R_{pig} \times W_{pig}}= 0.5577$$</p>
<p><strong>3. Micro-average方法</strong></p>
<p>该方法把每个类别的TP, FP, FN先相加之后，在根据二分类的公式进行计算。</p>
<p>$$\text{Micro-Precision} = \frac{TP_{cat} + TP_{dog} + TP_{pig}}{TP_{cat} + TP_{dog} + TP_{pig} + FP_{cat} + FP_{dog} + FP_{pig}} = 0.5577$$
$$\text{Micro-Recall} = \frac{TP_{cat} + TP_{dog} + TP_{pig}}{TP_{cat} + TP_{dog} + TP_{pig} + FN_{cat} + FN_{dog} + FN_{pig}} = 0.5577$$</p>
<p>其中，特别有意思的是，<u>Micro-precision 和 Micro-recall竟然始终相同！</u>这是为啥呢？</p>
<p>这是因为在某一类中的False Positive样本，一定是其他某类别的False Negative样本。听起来有点抽象？举个例子，比如说系统错把「狗」预测成「猫」，那么对于狗而言，其错误类型就是False Negative，对于猫而言，其错误类型就是False Positive。于此同时，Micro-precision和Micro-recall的数值都等于Accuracy，因为它们计算了对角线样本数和总样本数的比值，总结就是</p>
<p>$$\text{Micro-Precision} = \text{Micro-Recall} = \text{Micro-F1 score} = \text{Accuracy}$$</p>
<p>demo示例:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">average_precision_score</span><span class="p">,</span><span class="n">precision_score</span><span class="p">,</span><span class="n">f1_score</span><span class="p">,</span><span class="n">recall_score</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># create confusion matrix</span>
</span></span><span class="line"><span class="cl"><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">70</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">160</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">30</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">40</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">20</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">20</span> <span class="o">+</span> 
</span></span><span class="line"><span class="cl">                  <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">30</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">80</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">30</span> <span class="o">+</span> 
</span></span><span class="line"><span class="cl">                  <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">5</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">15</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Cat&#39;</span><span class="p">,</span><span class="s1">&#39;Dog&#39;</span><span class="p">,</span><span class="s1">&#39;Pig&#39;</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Cat&#39;</span><span class="p">,</span><span class="s1">&#39;Dog&#39;</span><span class="p">,</span><span class="s1">&#39;Pig&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># plot size setting</span>
</span></span><span class="line"><span class="cl"><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mf">4.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&#34;size&#34;</span><span class="p">:</span> <span class="mi">19</span><span class="p">},</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&#34;Blues&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True label&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted label&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;confusion.pdf&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------Weighted------&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Weighted precision&#39;</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Weighted recall&#39;</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Weighted f1-score&#39;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------Macro------&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Macro precision&#39;</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Macro recall&#39;</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Macro f1-score&#39;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------Micro------&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Micro precision&#39;</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Micro recall&#39;</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Micro f1-score&#39;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="regression-回归">Regression 回归<a hidden class="anchor" aria-hidden="true" href="#regression-回归">#</a></h1>
<p>回归算法的评价指标就是MSE，RMSE，MAE、R-Squared。</p>
<p>　　MSE和MAE适用于误差相对明显的时候，大的误差也有比较高的权重，RMSE则是针对误差不是很明显的时候；MAE是一个线性的指标，所有个体差异在平均值上均等加权，所以它更加凸显出异常值，相比MSE；</p>
<p>　　RMSLE: 主要针对数据集中有一个特别大的异常值，这种情况下，data会被skew，RMSE会被明显拉大，这时候就需要先对数据log下，再求RMSE，这个过程就是RMSLE。对低估值（under-predicted）的判罚明显多于估值过高(over-predicted)的情况（RMSE则相反）</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://jianye0428.github.io/en/tags/ml/">ML</a></li>
      <li><a href="https://jianye0428.github.io/en/tags/classify/">classify</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://jianye0428.github.io/en/posts/notes/2022-10-08_horovod_1/">
    <span class="title"><i class="fas fa-angle-double-left"></i> Prev Page</span>
    <br>
    <span>深度学习分布式训练框架 Horovod[1] -- 基础知识</span>
  </a>
  <a class="next" href="https://jianye0428.github.io/en/posts/tech/2022-08-01_c&#43;&#43;_data_structure/">
    <span class="title">Next Page <i class="fas fa-angle-double-right"></i></span>
    <br>
    <span>C&#43;&#43; STL (Standard Template Library) Containers</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share 分类问题与回归问题指标综述 on twitter"
        href="https://twitter.com/intent/tweet/?text=%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%98%e4%b8%8e%e5%9b%9e%e5%bd%92%e9%97%ae%e9%a2%98%e6%8c%87%e6%a0%87%e7%bb%bc%e8%bf%b0&amp;url=https%3a%2f%2fjianye0428.github.io%2fen%2fposts%2fnotes%2f2022-08-16_classification_and_regression_metrics%2f&amp;hashtags=ML%2cclassify">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 分类问题与回归问题指标综述 on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fjianye0428.github.io%2fen%2fposts%2fnotes%2f2022-08-16_classification_and_regression_metrics%2f&amp;title=%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%98%e4%b8%8e%e5%9b%9e%e5%bd%92%e9%97%ae%e9%a2%98%e6%8c%87%e6%a0%87%e7%bb%bc%e8%bf%b0&amp;summary=%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%98%e4%b8%8e%e5%9b%9e%e5%bd%92%e9%97%ae%e9%a2%98%e6%8c%87%e6%a0%87%e7%bb%bc%e8%bf%b0&amp;source=https%3a%2f%2fjianye0428.github.io%2fen%2fposts%2fnotes%2f2022-08-16_classification_and_regression_metrics%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 分类问题与回归问题指标综述 on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fjianye0428.github.io%2fen%2fposts%2fnotes%2f2022-08-16_classification_and_regression_metrics%2f&title=%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%98%e4%b8%8e%e5%9b%9e%e5%bd%92%e9%97%ae%e9%a2%98%e6%8c%87%e6%a0%87%e7%bb%bc%e8%bf%b0">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 分类问题与回归问题指标综述 on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fjianye0428.github.io%2fen%2fposts%2fnotes%2f2022-08-16_classification_and_regression_metrics%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 分类问题与回归问题指标综述 on whatsapp"
        href="https://api.whatsapp.com/send?text=%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%98%e4%b8%8e%e5%9b%9e%e5%bd%92%e9%97%ae%e9%a2%98%e6%8c%87%e6%a0%87%e7%bb%bc%e8%bf%b0%20-%20https%3a%2f%2fjianye0428.github.io%2fen%2fposts%2fnotes%2f2022-08-16_classification_and_regression_metrics%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 分类问题与回归问题指标综述 on telegram"
        href="https://telegram.me/share/url?text=%e5%88%86%e7%b1%bb%e9%97%ae%e9%a2%98%e4%b8%8e%e5%9b%9e%e5%bd%92%e9%97%ae%e9%a2%98%e6%8c%87%e6%a0%87%e7%bb%bc%e8%bf%b0&amp;url=https%3a%2f%2fjianye0428.github.io%2fen%2fposts%2fnotes%2f2022-08-16_classification_and_regression_metrics%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>

  </footer>




<footer class="tc-container" id="comment">
    <div class="tc-title"><p class="c-title">Discussion</p></div>
    <div id="tcomments"></div>
</footer>
<script crossorigin="anonymous" src="/js/twikoo.min.b16100b7cf8a61759eab076a122482054e083087aad37c3be1fe2e293934dc34.js" integrity="sha256-sWEAt8&#43;KYXWeqwdqEiSCBU4IMIeq03w74f4uKTk03DQ="></script>
<script>
    twikoo.init({
        envId: 'https://my-repository-pink.vercel.app/',
        el: '#tcomments',
        region: 'ap-shanghai', 
        
        lang: 'zh-CN', 
    });
</script>

</article>
    </main>
    
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
